---
title: "4. Analyses and Figures"
author: "Christopher Crawford, Princeton University"
output: html_notebook
editor_options: 
  chunk_output_type: console
---
This R Markdown file 1) outlines the primary analyses conducted on the tradeoff model runs completed in "3_Model_Runs.Rmd," and 2) details the production of a series of figures for the main manuscript and the supplemental Appendix. 

The analysis is broadly separated into the following sections:
- First, loading the raw data outputs from the tradeoff model, which have combined results for maize and soy into a single binary conversion recommendation for each model run, and combined all model runs into a single data.table for each model weighting specification. These data.tables have one row for each pixel in Zambia (1 km2 resolution), and one column for each model run, with either a 1 or 0 representing the model's recommendation to convert that pixel (or not);
- Calculating ensemble means for facets within each decision category, based on runs that hold a given factor constant;
- Converting data.tables to simple rasters, for visualization and the production of figures;
- Calculating the weighted Jaccard Similarity index that serves as the main metric of similarity between model results in our manuscript, along with a range of other summary statistics; and
- Running a variety of robustness checks, the results of which are detailed in the Appendix S1.

The section for figures includes the following:
- manuscript figures 2, 3, and 4, followed by a series of supplementary figures replicating Fig. 3 that end up in the appendix.
- supplementary figures showing the full range of model results as raster maps, for inclusion in the appendix.
- small thumbnail raster maps for use in creating the methods schematic in Fig. 1.
- a range of extra plots, for exploratory data analysis, but not ultimately included in the manuscript or SI.

See Appendix S1 for more details. 

```{r start-up, eval=TRUE}
## libraries --------------------------------------------------------------------------------
source("scripts/cc_libraries.R")
source("scripts/cc_functions.R")
source("scripts/cc_pathnames.R")
```

# Analysis

```{r bd_dt}
# -----------
# bd_input biodiversity scores for all unprotected areas in Zambia
# -----------

# append with _bd, for use creating the bd_dt
bd_input_names <- paste0(runs, "_bd")


bd_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates

tic()
for (i in 1:length(runs)) {
  bd_dt_temp <- fread(file = paste0(p_dat, .Platform$file.sep,
                    runs[i], .Platform$file.sep,
                    runs[i], "-cons-priorities.csv"))
  
  bd_dt[, bd_input_names[i] := bd_dt_temp[valinds]]
}
toc()

# bd_dt[, 1:18] %>% dt_to_raster(CRSobj) %T>% plot()
length(bd_dt)
object_size(bd_dt)


# -----------------------------------------------
# -------- add raw richness and endemism scores ----------------------------------------
# -----------------------------------------------
library(raster)
# build data.table of raw biodiversity scores for all, endemism, threatened, and small-ranged richness, to manipulate.
bd_raw_dt <- dtraster::as.data.table(vert_r$all_richness$sum, xy = TRUE)
names(bd_raw_dt)[3] <- "all"
bd_raw_dt[, "endemism" := as.data.table(vert_r$endemism_richness$sum, xy = FALSE)]
bd_raw_dt[, "threat" := as.data.table(vert_r$threat_richness$sum, xy = FALSE)]
bd_raw_dt[, "small" := as.data.table(vert_r$small_richness$sum, xy = FALSE)]
bd_raw_dt[, "threat_weighted" := as.data.table(vert_r$threat_weighted_richness$sum, xy = FALSE)]
bd_raw_dt[, "small_threat" := as.data.table(vert_r$small_threat_richness$sum, xy = FALSE)]
bd_raw_dt[, "small_zam" := as.data.table(vert_r$small_zam_richness$sum, xy = FALSE)]
bd_raw_dt[, "endemism_zam" := as.data.table(vert_r$endemism_zam_richness$sum, xy = FALSE)]
bd_raw_dt <- na.omit(bd_raw_dt) # omit NAs (this is critical)

names(bd_raw_dt)[3:10] <- paste0(runs[1:8], "_raw")

# see 1_Start.rmd, inputs and input_handler
bd_raw_dt <- bd_raw_dt[valinds, ] 
# check it out.
bd_raw_dt %>% dt_to_raster(., CRSobj) %T>% plot()


# -----------------------------------------------
# save to file
# -----------------------------------------------
fwrite(bd_dt, file = fp(p_mod_output, "bd_dt.csv"))
fwrite(bd_raw_dt, file = fp(p_mod_output, "bd_raw_dt.csv"))




# -----------------------------------------------
# optionally combine raw with all inputs
# bd_dt <- cbind(bd_dt, bd_raw_dt[, 3:10])
```

## Calculate ensemble means

Five decision categories:
1. Existing biodiversity indices
2. Taxonomic groups - average across a) all four types of richness for each taxa, and b) across the weights
3. Richness metrics - average across the a) three resolutions, and the b) weights. 
4. Methods for combining layers - average across a) mb, ae, and vp, b) weights
5. Resolution of inputs - average across a) four types of richness for each resolution, b) weights

Load data.tables for each model weighting specification, and combine into a single data.table.

```{r load-raw-data.tables}
# Note: in May 2020, I modified code so that the model results were combined and converted to a single merged data.table for each model run, saved to the following files.


bd_dt <- fread(file = fp(p_mod_output, "bd_dt.csv")) # just the biodiversity inputs. Note that I can also load in directly a data.table with ensembles added, etc. See chunk "bd_dt_m_ensemble_means"

conv_b_pure_dt <- fread(file = fp(p_mod_output, "conv_b_pure_dt.csv"))
conv_b_dt <- fread(file = fp(p_mod_output, "conv_b_dt.csv"))
conv_by_dt <- fread(file = fp(p_mod_output, "conv_by_dt.csv"))
conv_bc_dt <- fread(file = fp(p_mod_output, "conv_bc_dt.csv"))
conv_bt_dt <- fread(file = fp(p_mod_output, "conv_bt_dt.csv"))
conv_byct_dt <- fread(file = fp(p_mod_output, "conv_byct_dt.csv"))
conv_z50_dt <- fread(file = fp(p_mod_output, "conv_z50_dt.csv"))

conv_extras_bp_dt <- fread(file = fp(p_mod_output, "conv_extras_bp_dt.csv"))


object_size(conv_b_dt)
object_size(bd_dt)
object_size(bd_dt, conv_b_pure_dt, conv_b_dt, conv_by_dt, conv_bc_dt, conv_bt_dt, conv_byct_dt, conv_z50_dt, conv_extras_bp_dt)

```



```{r save-raw-data.tables}
# commented for safety!!
# 
# # save data.tables as backup
# save(bd_dt, # showing all bd scores 
#      conv_b_pure_dt,
#      conv_b_dt,
#      conv_by_dt,
#      conv_bc_dt,
#      conv_bt_dt,
#      conv_byct_dt,
#      conv_z50_dt,
#      conv_extras_bp_dt,
#      file = fp(p_mod_output, "mod_results_backup.RData"))
# 
# # save individual data.tables:
# fwrite(bd_dt, file = fp(p_mod_output, "mod_results_backup_bd_dt.csv"))
# fwrite(conv_b_pure_dt, file = fp(p_mod_output, "mod_results_backup_conv_b_pure_dt.csv"))
# fwrite(conv_b_dt, file = fp(p_mod_output, "mod_results_backup_conv_b_dt.csv"))
# fwrite(conv_by_dt, file = fp(p_mod_output, "mod_results_backup_conv_by_dt.csv"))
# fwrite(conv_bc_dt, file = fp(p_mod_output, "mod_results_backup_conv_bc_dt.csv"))
# fwrite(conv_bt_dt, file = fp(p_mod_output, "mod_results_backup_conv_bt_dt.csv"))
# fwrite(conv_byct_dt, file = fp(p_mod_output, "mod_results_backup_conv_byct_dt.csv"))
# fwrite(conv_z50_dt, file = fp(p_mod_output, "mod_results_backup_conv_z50_dt.csv"))
# fwrite(conv_extras_bp_dt, file = fp(p_mod_output, "mod_results_backup_conv_extras_bp_dt.csv"))
# 
# 
# # load back in:
# bd_dt <- fread(file = fp(p_mod_output, "mod_results_backup_bd_dt.csv"))
# conv_b_pure_dt <- fread(file = fp(p_mod_output, "mod_results_backup_conv_b_pure_dt.csv"))
# conv_b_dt <- fread(file = fp(p_mod_output, "mod_results_backup_conv_b_dt.csv"))
# conv_by_dt <- fread(file = fp(p_mod_output, "mod_results_backup_conv_by_dt.csv"))
# conv_bc_dt <- fread(file = fp(p_mod_output, "mod_results_backup_conv_bc_dt.csv"))
# conv_bt_dt <- fread(file = fp(p_mod_output, "mod_results_backup_conv_bt_dt.csv"))
# conv_byct_dt <- fread(file = fp(p_mod_output, "mod_results_backup_conv_byct_dt.csv"))
# conv_z50_dt <- fread(file = fp(p_mod_output, "mod_results_backup_conv_z50_dt.csv"))
# conv_extras_bp_dt <- fread(file = fp(p_mod_output, "mod_results_backup_conv_extras_bp_dt.csv"))
```

```{r rename-dts}
# rename and merge data.tables
# load the data.tables: see chunk {r load-raw-data.tables}

dt_bp <- copy(conv_b_pure_dt)
dt_b <- copy(conv_b_dt) 
dt_bc <- copy(conv_bc_dt)
dt_bt <- copy(conv_bt_dt)
dt_by <- copy(conv_by_dt)
dt_byct <- copy(conv_byct_dt)
dt_z50 <- copy(conv_z50_dt)

rm(conv_b_pure_dt, conv_b_dt, conv_bc_dt, conv_bt_dt, conv_by_dt, conv_byct_dt, conv_z50_dt)
object_size(dt_bp, dt_b, dt_by, dt_bc, dt_bt, dt_byct, dt_z50)
# rm(dt_bp, dt_b, dt_by, dt_bc, dt_bt, dt_byct, dt_z50) # if needed:

# dt_byct <- copy(conv_eq_dt[, c(1:2)]) # copy, selecting only x and y

# update column names
names(dt_b)

names(dt_bp) <- c("x", "y", paste0(runs, "_bp"))
names(dt_b) <- c("x", "y", paste0(runs, "_b"))
names(dt_by) <- c("x", "y", paste0(runs, "_by"))
names(dt_bc) <- c("x", "y", paste0(runs, "_bc"))
names(dt_bt) <- c("x", "y", paste0(runs, "_bt"))
names(dt_byct) <- c("x", "y", paste0(runs, "_byct"))
names(dt_z50) <- c("x", "y", paste0(runs, "_z50"))


# unused code to remove runs not included in ensemble means
# names(dt_b)[c(7:10,53:58)]
# 
# dt_b[, c(7:10, 53:58) := NULL] # or: dt[, names(dt)[48:58] := NULL]
# dt_by[, c(7:10, 53:58) := NULL]
# dt_byct[, c(7:10, 53:58) := NULL]
# 
# dt_bp[, c(7:10, 53:56) := NULL]
# dt_bc[, c(7:10, 53:56) := NULL]
# dt_bt[, c(7:10, 53:56) := NULL]
# dt_z50[, c(7:10, 53:56) := NULL]

# check that the lengths are identical

dt_bp %>% length
dt_b %>% length
dt_by %>% length
dt_bc %>% length
dt_bt %>% length
dt_byct %>% length
dt_z50 %>% length

ncol(dt_b)
# dt_bp[, key := 1:.N] # optional, to test the ordering.
```


```{r merge-save-dt}
# merge all data.tables into a single data.table:
# make sure that sort = FALSE, because without this, things get out of order!
dt <- merge(dt_bp, dt_b, by = c("x","y"), sort = FALSE)
dt <- merge(dt, dt_by, by = c("x","y"), sort = FALSE)
dt <- merge(dt, dt_bc, by = c("x","y"), sort = FALSE)
dt <- merge(dt, dt_bt, by = c("x","y"), sort = FALSE)
dt <- merge(dt, dt_byct, by = c("x","y"), sort = FALSE)
dt <- merge(dt, dt_z50, by = c("x","y"), sort = FALSE)

(ncol(dt) - 2) / 7 # 46 each, plus x and y
object_size(dt)


# save the dt, with the threatened species richness runs in still
dt_w_threat <- dt
fwrite(dt_w_threat, file = fp(p_mod_output, "dt_w_threat.csv")) # with 800 columns, including the threatened species runs
fwrite(dt_bp, file = fp(p_mod_output, "dt_bp.csv"))
fwrite(dt_b, file = fp(p_mod_output, "dt_b.csv"))
fwrite(dt_by, file = fp(p_mod_output, "dt_by.csv"))
fwrite(dt_bc, file = fp(p_mod_output, "dt_bc.csv"))
fwrite(dt_bt, file = fp(p_mod_output, "dt_bt.csv"))
fwrite(dt_byct, file = fp(p_mod_output, "dt_byct.csv"))
fwrite(dt_z50, file = fp(p_mod_output, "dt_z50.csv"))


rm(dt_w_threat, dt_bp, dt_b, dt_by, dt_bc, dt_bt, dt_byct, dt_z50)



# remove all threatened species richness runs from the primary dt model run:
dt[, grep("threat", names(dt)), with = FALSE] %>% length # 5*7*3 # 5 (4 taxa plus combo) * 3 resolutions * 7 weights
length(dt)
dt[, (grep("threat", names(dt), value = TRUE)) := NULL]

fwrite(dt, file = fp(p_mod_output, "dt.csv")) # this is the file I'll use going forward, containing results for all 7 model weighting scenarios, but excluding threatened species richness.


# save a backup version of this file:
# fwrite(dt, file = fp(p_mod_output, "mod_results_backup_dt.csv"))
```


```{r load-prepped-dts}
# load it back in
dt <- fread(file = fp(p_mod_output, "dt.csv"))  # note: this file contains model conversion results for all runs (excluding threatened species runs) for all 7 model weighting scenarios. This is the primary data.table from which I calculate ensemble means, below.  

dt_w_threat <- fread(file = fp(p_mod_output, "dt_w_threat.csv")) 
dt_bp <- fread(file = fp(p_mod_output, "dt_bp.csv"))
dt_b <- fread(file = fp(p_mod_output, "dt_b.csv"))
dt_by <- fread(file = fp(p_mod_output, "dt_by.csv"))
dt_bc <- fread(file = fp(p_mod_output, "dt_bc.csv"))
dt_bt <- fread(file = fp(p_mod_output, "dt_bt.csv"))
dt_byct <- fread(file = fp(p_mod_output, "dt_byct.csv"))
dt_z50 <- fread(file = fp(p_mod_output, "dt_z50.csv"))
```



```{r dt_m_ensemble_means}
# Calculate ensemble means for each facet within each decision category.

# Ensemble means are calculated within each model weighting specification first (7 of them, in the following 7 sections)
# Then, ensembles means are calculated for each facet across all weighting specifications,
# as well as for each weighting specification (across all facets).

# load the merged data.table containing all runs (excluding threatened species richness) across all 7 model weighting scenarios
dt <- fread(file = fp(p_mod_output, "dt.csv"))

# copy just x and y coordinates to a new data.table
dt_m <- copy(dt[, x:y])
dt_m %>% length

# ---------------------------------------------------------------------------------------------------------
# Pure Biodiversity (_bp), 100% weight on biodiversity with mean yields -----------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_bp := rowMeans(dt[, grep("_all.+bp$", names(dt)), with = FALSE])]
dt_m[, endemism_bp := rowMeans(dt[, grep("_endemism.+bp$", names(dt)), with = FALSE])]
dt_m[, threat_bp := rowMeans(dt[, grep("_threat.+bp$", names(dt)), with = FALSE])]
dt_m[, small_bp := rowMeans(dt[, grep("_small.+bp$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_bp := rowMeans(dt[, grep("mam.+bp$", names(dt)), with = FALSE])]
dt_m[, bird_bp := rowMeans(dt[, grep("bird.[^c]+bp$", names(dt)), with = FALSE])]
dt_m[, amp_bp := rowMeans(dt[, grep("amp.+bp$", names(dt)), with = FALSE])]
dt_m[, rep_bp := rowMeans(dt[, grep("rep.+bp$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_bp := rowMeans(dt[, grep("^average.+bp$", names(dt)), with = FALSE])]
dt_m[, geometric_bp := rowMeans(dt[, grep("^geometric.+bp$", names(dt)), with = FALSE])]
dt_m[, max_bp := rowMeans(dt[, grep("^max.+bp$", names(dt)), with = FALSE])]
dt_m[, multi_bp := rowMeans(dt[, grep("^multi.+bp$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_bp := rowMeans(dt[, grep("^[^1]+bp$", names(dt)), with = FALSE])]
dt_m[, res10_bp := rowMeans(dt[, grep("_10.bp$", names(dt)), with = FALSE])]
dt_m[, res110_bp := rowMeans(dt[, grep("_110.bp$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_bp := rowMeans(dt[, grep("vert_endemism.+bp$", names(dt)), with = FALSE])]
dt_m[, plants_bp := rowMeans(dt[, grep("plants.+bp$", names(dt)), with = FALSE])]
dt_m[, estes_bp := rowMeans(dt[, grep("estes.+bp$", names(dt)), with = FALSE])]
dt_m[, laurance_bp := rowMeans(dt[, grep("laurance.+bp$", names(dt)), with = FALSE])]
dt_m[, habitats_bp := rowMeans(dt[, grep("habitats.+bp$", names(dt)), with = FALSE])]
dt_m[, bird_composite_bp := rowMeans(dt[, grep("bird_composite.+bp$", names(dt)), with = FALSE])]
dt_m[, damania_bp := rowMeans(dt[, grep("damania.+bp$", names(dt)), with = FALSE])]


# ---------------------------------------------------------------------------------------------------------
# 100% weight on biodiversity (_b) with accurate, dynamic yields ------------------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_b := rowMeans(dt[, grep("_all.+b$", names(dt)), with = FALSE])]
dt_m[, endemism_b := rowMeans(dt[, grep("_endemism.+b$", names(dt)), with = FALSE])]
dt_m[, threat_b := rowMeans(dt[, grep("_threat.+b$", names(dt)), with = FALSE])]
dt_m[, small_b := rowMeans(dt[, grep("_small.+b$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_b := rowMeans(dt[, grep("mam.+b$", names(dt)), with = FALSE])]
dt_m[, bird_b := rowMeans(dt[, grep("bird.[^c]+b$", names(dt)), with = FALSE])]
dt_m[, amp_b := rowMeans(dt[, grep("amp.+b$", names(dt)), with = FALSE])]
dt_m[, rep_b := rowMeans(dt[, grep("rep.+b$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_b := rowMeans(dt[, grep("^average.+b$", names(dt)), with = FALSE])]
dt_m[, geometric_b := rowMeans(dt[, grep("^geometric.+b$", names(dt)), with = FALSE])]
dt_m[, max_b := rowMeans(dt[, grep("^max.+b$", names(dt)), with = FALSE])]
dt_m[, multi_b := rowMeans(dt[, grep("^multi.+b$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_b := rowMeans(dt[, grep("^[^1]+b$", names(dt)), with = FALSE])]
dt_m[, res10_b := rowMeans(dt[, grep("_10.b$", names(dt)), with = FALSE])]
dt_m[, res110_b := rowMeans(dt[, grep("_110.b$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_b := rowMeans(dt[, grep("vert_endemism.+b$", names(dt)), with = FALSE])]
dt_m[, plants_b := rowMeans(dt[, grep("plants.+b$", names(dt)), with = FALSE])]
dt_m[, estes_b := rowMeans(dt[, grep("estes.+b$", names(dt)), with = FALSE])]
dt_m[, laurance_b := rowMeans(dt[, grep("laurance.+b$", names(dt)), with = FALSE])]
dt_m[, habitats_b := rowMeans(dt[, grep("habitats.+b$", names(dt)), with = FALSE])]
dt_m[, bird_composite_b := rowMeans(dt[, grep("bird_composite.+b$", names(dt)), with = FALSE])]
dt_m[, damania_b := rowMeans(dt[, grep("damania.+b$", names(dt)), with = FALSE])]

# ---------------------------------------------------------------------------------------------------------
# 50% biodiversity, 50% yield (productivity) (dynamic yields) _by ---------------------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_by := rowMeans(dt[, grep("_all.+by$", names(dt)), with = FALSE])]
dt_m[, endemism_by := rowMeans(dt[, grep("_endemism.+by$", names(dt)), with = FALSE])]
dt_m[, threat_by := rowMeans(dt[, grep("_threat.+by$", names(dt)), with = FALSE])]
dt_m[, small_by := rowMeans(dt[, grep("_small.+by$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_by := rowMeans(dt[, grep("mam.+by$", names(dt)), with = FALSE])]
dt_m[, bird_by := rowMeans(dt[, grep("bird.[^c]+by$", names(dt)), with = FALSE])]
dt_m[, amp_by := rowMeans(dt[, grep("amp.+by$", names(dt)), with = FALSE])]
dt_m[, rep_by := rowMeans(dt[, grep("rep.+by$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_by := rowMeans(dt[, grep("^average.+by$", names(dt)), with = FALSE])]
dt_m[, geometric_by := rowMeans(dt[, grep("^geometric.+by$", names(dt)), with = FALSE])]
dt_m[, max_by := rowMeans(dt[, grep("^max.+by$", names(dt)), with = FALSE])]
dt_m[, multi_by := rowMeans(dt[, grep("^multi.+by$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_by := rowMeans(dt[, grep("^[^1]+by$", names(dt)), with = FALSE])]
dt_m[, res10_by := rowMeans(dt[, grep("_10.by$", names(dt)), with = FALSE])]
dt_m[, res110_by := rowMeans(dt[, grep("_110.by$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_by := rowMeans(dt[, grep("vert_endemism.+by$", names(dt)), with = FALSE])]
dt_m[, plants_by := rowMeans(dt[, grep("plants.+by$", names(dt)), with = FALSE])]
dt_m[, estes_by := rowMeans(dt[, grep("estes.+by$", names(dt)), with = FALSE])]
dt_m[, laurance_by := rowMeans(dt[, grep("laurance.+by$", names(dt)), with = FALSE])]
dt_m[, habitats_by := rowMeans(dt[, grep("habitats.+by$", names(dt)), with = FALSE])]
dt_m[, bird_composite_by := rowMeans(dt[, grep("bird_composite.+by$", names(dt)), with = FALSE])]
dt_m[, damania_by := rowMeans(dt[, grep("damania.+by$", names(dt)), with = FALSE])]

# ---------------------------------------------------------------------------------------------------------
# 50% biodiversity, 50% carbon loss (dynamic yields) ------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_bc := rowMeans(dt[, grep("_all.+bc$", names(dt)), with = FALSE])]
dt_m[, endemism_bc := rowMeans(dt[, grep("_endemism.+bc$", names(dt)), with = FALSE])]
dt_m[, threat_bc := rowMeans(dt[, grep("_threat.+bc$", names(dt)), with = FALSE])]
dt_m[, small_bc := rowMeans(dt[, grep("_small.+bc$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_bc := rowMeans(dt[, grep("mam.+bc$", names(dt)), with = FALSE])]
dt_m[, bird_bc := rowMeans(dt[, grep("bird.[^c]+bc$", names(dt)), with = FALSE])]
dt_m[, amp_bc := rowMeans(dt[, grep("amp.+bc$", names(dt)), with = FALSE])]
dt_m[, rep_bc := rowMeans(dt[, grep("rep.+bc$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_bc := rowMeans(dt[, grep("^average.+bc$", names(dt)), with = FALSE])]
dt_m[, geometric_bc := rowMeans(dt[, grep("^geometric.+bc$", names(dt)), with = FALSE])]
dt_m[, max_bc := rowMeans(dt[, grep("^max.+bc$", names(dt)), with = FALSE])]
dt_m[, multi_bc := rowMeans(dt[, grep("^multi.+bc$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_bc := rowMeans(dt[, grep("^[^1]+bc$", names(dt)), with = FALSE])]
dt_m[, res10_bc := rowMeans(dt[, grep("_10.bc$", names(dt)), with = FALSE])]
dt_m[, res110_bc := rowMeans(dt[, grep("_110.bc$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_bc := rowMeans(dt[, grep("vert_endemism.+bc$", names(dt)), with = FALSE])]
dt_m[, plants_bc := rowMeans(dt[, grep("plants.+bc$", names(dt)), with = FALSE])]
dt_m[, estes_bc := rowMeans(dt[, grep("estes.+bc$", names(dt)), with = FALSE])]
dt_m[, laurance_bc := rowMeans(dt[, grep("laurance.+bc$", names(dt)), with = FALSE])]
dt_m[, habitats_bc := rowMeans(dt[, grep("habitats.+bc$", names(dt)), with = FALSE])]
dt_m[, bird_composite_bc := rowMeans(dt[, grep("bird_composite.+bc$", names(dt)), with = FALSE])]
dt_m[, damania_bc := rowMeans(dt[, grep("damania.+bc$", names(dt)), with = FALSE])]

# ---------------------------------------------------------------------------------------------------------
# 50% biodiversity, 50% travel cost (dynamic yields) ------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_bt := rowMeans(dt[, grep("_all.+bt$", names(dt)), with = FALSE])]
dt_m[, endemism_bt := rowMeans(dt[, grep("_endemism.+bt$", names(dt)), with = FALSE])]
dt_m[, threat_bt := rowMeans(dt[, grep("_threat.+bt$", names(dt)), with = FALSE])]
dt_m[, small_bt := rowMeans(dt[, grep("_small.+bt$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_bt := rowMeans(dt[, grep("mam.+bt$", names(dt)), with = FALSE])]
dt_m[, bird_bt := rowMeans(dt[, grep("bird.[^c]+bt$", names(dt)), with = FALSE])]
dt_m[, amp_bt := rowMeans(dt[, grep("amp.+bt$", names(dt)), with = FALSE])]
dt_m[, rep_bt := rowMeans(dt[, grep("rep.+bt$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_bt := rowMeans(dt[, grep("^average.+bt$", names(dt)), with = FALSE])]
dt_m[, geometric_bt := rowMeans(dt[, grep("^geometric.+bt$", names(dt)), with = FALSE])]
dt_m[, max_bt := rowMeans(dt[, grep("^max.+bt$", names(dt)), with = FALSE])]
dt_m[, multi_bt := rowMeans(dt[, grep("^multi.+bt$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_bt := rowMeans(dt[, grep("^[^1]+bt$", names(dt)), with = FALSE])]
dt_m[, res10_bt := rowMeans(dt[, grep("_10.bt$", names(dt)), with = FALSE])]
dt_m[, res110_bt := rowMeans(dt[, grep("_110.bt$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_bt := rowMeans(dt[, grep("vert_endemism.+bt$", names(dt)), with = FALSE])]
dt_m[, plants_bt := rowMeans(dt[, grep("plants.+bt$", names(dt)), with = FALSE])]
dt_m[, estes_bt := rowMeans(dt[, grep("estes.+bt$", names(dt)), with = FALSE])]
dt_m[, laurance_bt := rowMeans(dt[, grep("laurance.+bt$", names(dt)), with = FALSE])]
dt_m[, habitats_bt := rowMeans(dt[, grep("habitats.+bt$", names(dt)), with = FALSE])]
dt_m[, bird_composite_bt := rowMeans(dt[, grep("bird_composite.+bt$", names(dt)), with = FALSE])]
dt_m[, damania_bt := rowMeans(dt[, grep("damania.+bt$", names(dt)), with = FALSE])]

# ---------------------------------------------------------------------------------------------------------
# equal weights, 25% on each constraint (biodiversity, yield, carbon, travel cost), with dynamic yields ---
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_byct := rowMeans(dt[, grep("_all.+byct$", names(dt)), with = FALSE])]
dt_m[, endemism_byct := rowMeans(dt[, grep("_endemism.+byct$", names(dt)), with = FALSE])]
dt_m[, threat_byct := rowMeans(dt[, grep("_threat.+byct$", names(dt)), with = FALSE])]
dt_m[, small_byct := rowMeans(dt[, grep("_small.+byct$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_byct := rowMeans(dt[, grep("mam.+byct$", names(dt)), with = FALSE])]
dt_m[, bird_byct := rowMeans(dt[, grep("bird.[^c]+byct$", names(dt)), with = FALSE])]
dt_m[, amp_byct := rowMeans(dt[, grep("amp.+byct$", names(dt)), with = FALSE])]
dt_m[, rep_byct := rowMeans(dt[, grep("rep.+byct$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_byct := rowMeans(dt[, grep("^average.+byct$", names(dt)), with = FALSE])]
dt_m[, geometric_byct := rowMeans(dt[, grep("^geometric.+byct$", names(dt)), with = FALSE])]
dt_m[, max_byct := rowMeans(dt[, grep("^max.+byct$", names(dt)), with = FALSE])]
dt_m[, multi_byct := rowMeans(dt[, grep("^multi.+byct$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_byct := rowMeans(dt[, grep("^[^1]+byct$", names(dt)), with = FALSE])]
dt_m[, res10_byct := rowMeans(dt[, grep("_10.byct$", names(dt)), with = FALSE])]
dt_m[, res110_byct := rowMeans(dt[, grep("_110.byct$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_byct := rowMeans(dt[, grep("vert_endemism.+byct$", names(dt)), with = FALSE])]
dt_m[, plants_byct := rowMeans(dt[, grep("plants.+byct$", names(dt)), with = FALSE])]
dt_m[, estes_byct := rowMeans(dt[, grep("estes.+byct$", names(dt)), with = FALSE])]
dt_m[, laurance_byct := rowMeans(dt[, grep("laurance.+byct$", names(dt)), with = FALSE])]
dt_m[, habitats_byct := rowMeans(dt[, grep("habitats.+byct$", names(dt)), with = FALSE])]
dt_m[, bird_composite_byct := rowMeans(dt[, grep("bird_composite.+byct$", names(dt)), with = FALSE])]
dt_m[, damania_byct := rowMeans(dt[, grep("damania.+byct$", names(dt)), with = FALSE])]

# ---------------------------------------------------------------------------------------------------------
# z50 - converting 50% of Zambia --------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_z50 := rowMeans(dt[, grep("_all.+z50$", names(dt)), with = FALSE])]
dt_m[, endemism_z50 := rowMeans(dt[, grep("_endemism.+z50$", names(dt)), with = FALSE])]
dt_m[, threat_z50 := rowMeans(dt[, grep("_threat.+z50$", names(dt)), with = FALSE])]
dt_m[, small_z50 := rowMeans(dt[, grep("_small.+z50$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_z50 := rowMeans(dt[, grep("mam.+z50$", names(dt)), with = FALSE])]
dt_m[, bird_z50 := rowMeans(dt[, grep("bird.[^c]+z50$", names(dt)), with = FALSE])]
dt_m[, amp_z50 := rowMeans(dt[, grep("amp.+z50$", names(dt)), with = FALSE])]
dt_m[, rep_z50 := rowMeans(dt[, grep("rep.+z50$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_z50 := rowMeans(dt[, grep("^average.+z50$", names(dt)), with = FALSE])]
dt_m[, geometric_z50 := rowMeans(dt[, grep("^geometric.+z50$", names(dt)), with = FALSE])]
dt_m[, max_z50 := rowMeans(dt[, grep("^max.+z50$", names(dt)), with = FALSE])]
dt_m[, multi_z50 := rowMeans(dt[, grep("^multi.+z50$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_z50 := rowMeans(dt[, grep("^[^1]+z50$", names(dt)), with = FALSE])]
dt_m[, res10_z50 := rowMeans(dt[, grep("_10.z50$", names(dt)), with = FALSE])]
dt_m[, res110_z50 := rowMeans(dt[, grep("_110.z50$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_z50 := rowMeans(dt[, grep("vert_endemism.+z50$", names(dt)), with = FALSE])]
dt_m[, plants_z50 := rowMeans(dt[, grep("plants.+z50$", names(dt)), with = FALSE])]
dt_m[, estes_z50 := rowMeans(dt[, grep("estes.+z50$", names(dt)), with = FALSE])]
dt_m[, laurance_z50 := rowMeans(dt[, grep("laurance.+z50$", names(dt)), with = FALSE])]
dt_m[, habitats_z50 := rowMeans(dt[, grep("habitats.+z50$", names(dt)), with = FALSE])]
dt_m[, bird_composite_z50 := rowMeans(dt[, grep("bird_composite.+z50$", names(dt)), with = FALSE])]
dt_m[, damania_z50 := rowMeans(dt[, grep("damania.+z50$", names(dt)), with = FALSE])]




# -------------------------------------------------------------------------------------
# averages across all weights ---------------------------------------------------------
# -------------------------------------------------------------------------------------
# # subsetting dt to include only some of the runs, not all.
## exclude z50

# richness type averages -----------------------------------------------------------------
dt_m[, all := rowMeans(dt_m[, grep("^all.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, endemism := rowMeans(dt_m[, grep("^endemism.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, threat := rowMeans(dt_m[, grep("^threat.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, small := rowMeans(dt_m[, grep("^small.[^z]+", names(dt_m)), with = FALSE])]

# taxa averages -----------------------------------------------------------------
dt_m[, mam := rowMeans(dt_m[, grep("^mam.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, bird := rowMeans(dt_m[, grep("^bird.[^sz]+$", names(dt_m)), with = FALSE])] # must remove bird_composite
dt_m[, amp := rowMeans(dt_m[, grep("^amp.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, rep := rowMeans(dt_m[, grep("^rep.[^z]+", names(dt_m)), with = FALSE])]

# methods averages -----------------------------------------------------------------
dt_m[, average := rowMeans(dt_m[, grep("^average.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, geometric := rowMeans(dt_m[, grep("^geometric.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, max := rowMeans(dt_m[, grep("^max.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, multi := rowMeans(dt_m[, grep("^multi.[^z]+", names(dt_m)), with = FALSE])]

# resolution averages -----------------------------------------------------------------
dt_m[, res1 := rowMeans(dt_m[, grep("^res1_[^z]+", names(dt_m)), with = FALSE])]
dt_m[, res10 := rowMeans(dt_m[, grep("^res10_[^z]+", names(dt_m)), with = FALSE])]
dt_m[, res110 := rowMeans(dt_m[, grep("^res110_[^z]+", names(dt_m)), with = FALSE])]

# composites --------------------------------------------------------------------------
# excluding z50 (to keep the production target constant)
dt_m[, vert_endemism := rowMeans(dt[, grep("vert_endemism[^z]+$", names(dt)), with = FALSE])]
dt_m[, plants := rowMeans(dt[, grep("plants[^z]+$", names(dt)), with = FALSE])]
dt_m[, estes := rowMeans(dt[, grep("estes[^z]+$", names(dt)), with = FALSE])]
dt_m[, laurance := rowMeans(dt[, grep("laurance[^z]+$", names(dt)), with = FALSE])]
dt_m[, habitats := rowMeans(dt[, grep("habitats[^z]+$", names(dt)), with = FALSE])]
dt_m[, bird_composite := rowMeans(dt[, grep("bird_composite[^z]+$", names(dt)), with = FALSE])]
dt_m[, damania := rowMeans(dt[, grep("damania[^z]+$", names(dt)), with = FALSE])]



# -------------------------------------------------------------------------------------
# individual weights ------------------------------------------------------------------
# -------------------------------------------------------------------------------------
dt_m[, bp := rowMeans(dt[, grep("_bp$", names(dt)), with = FALSE])]
dt_m[, b := rowMeans(dt[, grep("_b$", names(dt)), with = FALSE])]
dt_m[, by := rowMeans(dt[, grep("_by$", names(dt)), with = FALSE])]
dt_m[, bc := rowMeans(dt[, grep("_bc$", names(dt)), with = FALSE])]
dt_m[, bt := rowMeans(dt[, grep("_bt$", names(dt)), with = FALSE])]
dt_m[, byct := rowMeans(dt[, grep("_byct$", names(dt)), with = FALSE])]
dt_m[, z50 := rowMeans(dt[, grep("_z50$", names(dt)), with = FALSE])]






# -------------------------------------------------------------------------------------
# Save new ensemble mean data.table
# -------------------------------------------------------------------------------------

# # to remove all threat runs: (note that this messes up the code at the end, weighted jaccard, which needs 22, not 21)
# dt_m[, grep("threat", names(dt_m)), with = FALSE] %>% length # 7 weights plus all
# length(dt_m)
# dt_m[, (grep("threat", names(dt_m), value = TRUE)) := NULL]

# save the dt_m
object_size(dt_m)

fwrite(dt_m, file = fp(p_mod_output, "dt_m.csv"))
fwrite(dt_m_w_threat, file = fp(p_mod_output, "dt_m_w_threat.csv"))



# # check against previous version:
# dt_m0 <- fread(file = fp(p_mod_output, "dt_m.csv")) # as of 2020.06.11
# identical(dt_m, dt_m0)
# 
# digits_to_round <- 13
# for (i in seq_along(dt_m)) {
#   cat("column", i)
#   print(identical(
#     round(dt_m[[i]], digits_to_round), 
#     round(dt_m0[[i]], digits_to_round)
#     ))
# } # passes muster
```


```{r adjust-by-convertible-area}
# In order to calculate the area converted, I need to account for the amount of "convertible area" in each cell (i.e. the proportion of each cell that is currently non-ag and non-urban, or, what the proportion that is current convertible still). 
# Rather than simply calculating the total area converted by summing across cells, e.g.:

# area_conv = colSums(dt_m[, -c(1:2)])

# I need to mutliply each cell (1 or 0) by the convertible area to get an accurate area.


# see "1_Start.rmd" chunk "inputs_agroEcoTradeoff" for more details on the agroEcoTradeoff model inputs, but most important is the below:
il <- agroEcoTradeoff::fetch_inputs(path = p_ZA)


# Next, select just the indices where convertible is greater than 0, i.e. only cells that are at least partially convertible (i.e. outside of pas and entirely urban areas). This is essentially the data.table method for masking:
valinds <- which(il$convertible > 0) # create a vector of indices where convertible is > 0, then use to select rows in the data.table:
il$convertible[valinds, ] 

# -----------------------------------------------
# multiply ensemble means (dt_m) by the convertible proportions, as a vector of values, not a data.table column.
dt_m_convertible <- dt_m[, lapply(.SD, function(x) {
  il$convertible[valinds, ]$convertible * x})]

dt_m_convertible[, x := dt_m$x]
dt_m_convertible[, y := dt_m$y]


length(dt_m_convertible)
# write to file:
fwrite(dt_m_convertible, file = fp(p_mod_output, "dt_m_convertible.csv"))

fwrite(dt_m_convertible_w_threat, file = fp(p_mod_output, "dt_m_convertible_w_threat.csv"))


# load in dt_m_convertible, the data.table consisting of only the ensemble means across the decision categories, but weighted by the area of each pixel that is convertible
dt_m_convertible <- fread(file = fp(p_mod_output, "dt_m_convertible.csv"))
```


``` {r bd_dt_m_ensemble_means}
# Produce ensemble means of the biodiversity inputs themselves:

bd_dt <- fread(file = fp(p_mod_output, "bd_dt.csv")) # just the biodiversity inputs.
names(bd_dt)

bd_dt_m <- copy(bd_dt)
rm(bd_dt)
object_size(bd_dt_m)
names(bd_dt_m)
length(bd_dt_m) # 116 (38*3 = 114 + x and y)

# remove threat layers:
bd_dt_m[, grep("threat", names(bd_dt_m)), with = FALSE] %>% length # 5*7*3 # 5 (4 taxa plus combo) * 3 resolutions * 7 weights
bd_dt_m[, grep("threat", names(bd_dt_m)), with = FALSE] %>% names # 5*7*3 # 5 (4 taxa plus combo) * 3 resolutions * 7 weights
length(bd_dt_m)
bd_dt_m[, (grep("threat", names(bd_dt_m), value = TRUE)) := NULL]

# richness type averages -----------------------------------------------------------------
bd_dt_m[, all := rowMeans(bd_dt_m[, grep("_all", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, endemism := rowMeans(bd_dt_m[, grep("endemism", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, threat := rowMeans(bd_dt_m[, grep("threat", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, small := rowMeans(bd_dt_m[, grep("_small", names(bd_dt_m)), with = FALSE])]

# taxa averages -----------------------------------------------------------------
bd_dt_m[, mam := rowMeans(bd_dt_m[, grep("mam", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, bird := rowMeans(bd_dt_m[, grep("bird.[^c]", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, amp := rowMeans(bd_dt_m[, grep("amp", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, rep := rowMeans(bd_dt_m[, grep("rep", names(bd_dt_m)), with = FALSE])]

# methods averages -----------------------------------------------------------------
bd_dt_m[, average := rowMeans(bd_dt_m[, grep("average", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, geometric := rowMeans(bd_dt_m[, grep("geometric", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, max := rowMeans(bd_dt_m[, grep("max", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, multi := rowMeans(bd_dt_m[, grep("multi", names(bd_dt_m)), with = FALSE])]

# resolution averages -----------------------------------------------------------------
bd_dt_m[, res1 := rowMeans(bd_dt_m[, grep("[^1]._bd$", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, res10 := rowMeans(bd_dt_m[, grep("_10_bd$", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, res110 := rowMeans(bd_dt_m[, grep("_110_bd$", names(bd_dt_m)), with = FALSE])]

# composites --------------------------------------------------------------------------
bd_dt_m[, vert_endemism := rowMeans(bd_dt_m[, grep("vert_endemism", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, plants := rowMeans(bd_dt_m[, grep("plants", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, estes := rowMeans(bd_dt_m[, grep("estes", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, laurance := rowMeans(bd_dt_m[, grep("laurance", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, habitats := rowMeans(bd_dt_m[, grep("habitats", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, bird_composite := rowMeans(bd_dt_m[, grep("bird_composite", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, damania := rowMeans(bd_dt_m[, grep("damania", names(bd_dt_m)), with = FALSE])]

# not sure what's going on here....
# averages of entire comparisons: 
# average of all rasters, so that the only thing that changes is the weight:
bd_dt_m[, c("types", "taxa", "methods", "resolution") := .(
  rowMeans(bd_dt_m[, c("all", "endemism", "small"), with = FALSE]), # comparison_names$types
  rowMeans(bd_dt_m[, comparison_names$taxa, with = FALSE]),
  rowMeans(bd_dt_m[, comparison_names$methods, with = FALSE]),
  rowMeans(bd_dt_m[, comparison_names$resolution, with = FALSE])
  )
  ]

bd_dt_m[, weights := rowMeans(bd_dt_m[, 3:116])]

# --------------------------------------------------------------------------------
# remove the unnecessary columns at the start of the dt
# bd_dt_m[, c(3:116) := NULL]
bd_dt_m[, c(3:101) := NULL] # without the threat layers

# --------------------------------------------------------------------------------
# save the dt_m
object_size(bd_dt_m)
fwrite(bd_dt_m, file = fp(p_mod_output, "bd_dt_m.csv"))

# load it back in
bd_dt_m <- fread(file = fp(p_mod_output, "bd_dt_m.csv"))
```


```{r load-ensemble-mean-dts}
# load in dt_m, the data.table consisting of only the ensemble means across the decision categories
dt_m <- fread(file = fp(p_mod_output, "dt_m.csv"))

# load in dt_m_convertible, the data.table consisting of only the ensemble means across the decision categories, but weighted by the area of each pixel that is convertible
dt_m_convertible <- fread(file = fp(p_mod_output, "dt_m_convertible.csv"))

# Biodiversity input ensemble means:
bd_dt_m <- fread(file = fp(p_mod_output, "bd_dt_m.csv"))
```


## Convert data tables to rasters

```{r rasters_simple}
# produce simple version of the biodiversity input rasters, as well as of the conversion maps:

# Load these data.tables in chunk: "load-prepped-dts" or "load-ensemble-mean-dts"

dt_bp %>% length
dt_b %>% length #reference
dt_by %>% length
dt_bc %>% length
dt_bt %>% length
dt_byct %>% length
dt_z50  %>% length
dt_m_convertible %>% length
bd_dt_m %>% length
bd_dt %>% length

# save raster bricks:
dt_bp_r <- writeRaster(dt_to_raster(dt_bp, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_bp_r.tif"))
dt_b_r <- writeRaster(dt_to_raster(dt_b, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_b_r.tif"))
dt_by_r <- writeRaster(dt_to_raster(dt_by, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_by_r.tif"))
dt_bc_r <- writeRaster(dt_to_raster(dt_bc, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_bc_r.tif"))
dt_bt_r <- writeRaster(dt_to_raster(dt_bt, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_bt_r.tif"))
dt_byct_r <- writeRaster(dt_to_raster(dt_byct, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_byct_r.tif"))
dt_z50_r <- writeRaster(dt_to_raster(dt_z50, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_z50_r.tif"))
bd_dt_m_r <- writeRaster(dt_to_raster(bd_dt_m, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"bd_dt_m_r.tif")) # bd means
bd_dt_r <- writeRaster(dt_to_raster(bd_dt, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"bd_dt_r.tif")) # bd raw raster


# dt_m_convertible rasters, aka facet_r
facet_r_all <- writeRaster(
  dt_to_raster(dt_m_convertible[, c("x", "y", facet_names_distill_w_threat), with = FALSE], CRSobj),
  overwrite=TRUE, fp(p_mod_output,"facet_r_all.tif"))
  
facet_r_bp <- writeRaster(
  dt_to_raster(dt_m_convertible[, c("x", "y", grep("_bp$", facet_names, value = TRUE)), 
                                with = FALSE], CRSobj),
  overwrite=TRUE, fp(p_mod_output,"facet_r_bp.tif"))
  
facet_r_b <- writeRaster(
  dt_to_raster(dt_m_convertible[, c("x", "y", grep("_b$", facet_names, value = TRUE)), 
                                with = FALSE], CRSobj),
  overwrite=TRUE, fp(p_mod_output,"facet_r_b.tif"))

facet_r_z50 <- writeRaster(
  dt_to_raster(dt_m_convertible[, c("x", "y", grep("_z50$", facet_names, value = TRUE)), 
                                with = FALSE], CRSobj),
  overwrite=TRUE, fp(p_mod_output,"facet_r_z50.tif"))
```

```{r load-rasters}
# -------------------------------------------------------------------
# load it back in:
dt_bp_r <- brick(fp(p_mod_output,"dt_bp_r.tif"))
dt_b_r <- brick(fp(p_mod_output,"dt_b_r.tif"))
dt_by_r <- brick(fp(p_mod_output,"dt_by_r.tif"))
dt_bc_r <- brick(fp(p_mod_output,"dt_bc_r.tif"))
dt_bt_r <- brick(fp(p_mod_output,"dt_bt_r.tif"))
dt_byct_r <- brick(fp(p_mod_output,"dt_byct_r.tif"))
dt_z50_r <- brick(fp(p_mod_output,"dt_z50_r.tif"))

bd_dt_r <- brick(fp(p_mod_output,"bd_dt_r.tif"))
bd_dt_m_r <- brick(fp(p_mod_output,"bd_dt_m_r.tif"))

facet_r_all <- brick(fp(p_mod_output,"facet_r_all.tif"))
facet_r_bp <- brick(fp(p_mod_output,"facet_r_bp.tif"))
facet_r_b <- brick(fp(p_mod_output,"facet_r_b.tif"))
facet_r_z50 <- brick(fp(p_mod_output,"facet_r_z50.tif"))

# add the layer names back again
names(dt_bp_r) <- runs # paste0(runs, "_bp")
names(dt_b_r) <- runs # paste0(runs, "_b")
names(dt_by_r) <- runs # paste0(runs, "_by")
names(dt_bc_r) <- runs # paste0(runs, "_bc")
names(dt_bt_r) <- runs # paste0(runs, "_bt")
names(dt_byct_r) <- runs # paste0(runs, "_byct")
names(dt_z50_r) <- runs # paste0(runs, "_z50")
names(bd_dt_r) <- runs #names(bd_dt)[-c(1:2)]
names(bd_dt_m_r) <- names(bd_dt_m)[-c(1:2)]
names(facet_r_all) <- facet_names_distill_w_threat
names(facet_r_bp) <- grep("_bp$", facet_names, value = TRUE)
names(facet_r_b) <- grep("_b$", facet_names, value = TRUE)
names(facet_r_z50) <- grep("_z50$", facet_names, value = TRUE)




# -------------------------------------------------------------------
# construct conv_r
# -------------------------------------------------------------------
conv_r <- list(
  "bp" = dt_bp_r, "b" = dt_b_r, "by" = dt_by_r, "bc" = dt_bc_r, "bt" = dt_bt_r, 
  "byct" = dt_byct_r, "z50" = dt_z50_r, 
  "bd" = bd_dt_r, "bd_m" = bd_dt_m_r, 
  "facet_r" = facet_r, "facet_r_bp" = facet_r_bp, "facet_r_b" = facet_r_b
  )

# 
# for(i in 1:length(conv_r)) {print(nlayers(conv_r[[i]]))}
# plot(conv_r[[1]][[1]], main = names(conv_r[[1]][[1]]))
```



## Weighted jaccard similarity index

```{r facet_names}
# first, set groups of runs, and individual facets (referred to as "factors" in our manuscript) witin each decision category


runs # see "runs" chunk in "3_Model_Runs.Rmd"

facet_names_distill_w_threat <- c("all", "endemism", "threat", "small", "mam", "bird", "amp", "rep", # all
                         "average", "geometric", "max", "multi", "res1", "res10", "res110",
                         "vert_endemism", "plants", "estes", "laurance", "habitats",  # mean composites
                         "bird_composite", "damania",
                         "bp", "b", "by", "bc", "bt", "byct", "z50" # weights
                         )

facet_names_distill <- grep("threat", facet_names_distill, value = T, invert = T)

composites_names <- c("vert_endemism", "plants", "estes", "laurance", "habitats", "bird_composite", "damania")

types_names <- c("all", "endemism", "small")
taxa_names <- c("mam", "bird", "amp", "rep")
methods_names <- c("average", "geometric", "max", "multi")
resolution_names <- c("res1", "res10", "res110")

names(conv_r$bp)




# facet_names_distill <- grep("[_]+", names(dt_m), invert = TRUE, value = TRUE)[-c(1:2)] # old
facet_names <- names(dt_m)[-c(1:2)] # 22*8 + 7
facet_names_bp <- grep("_bp$", names(dt_m), value = TRUE) # facet_names[1:15] # 
facet_names_b <- grep("_b$", names(dt_m), value = TRUE)
facet_names_composites <- c("vert_endemism", "plants", "estes", "laurance", "habitats",  # mean composites
                         "bird_composite", "damania") #runs[sort(ensembles_list$en5_composites)]

# test grep()
grep("_b$", facet_names, value = TRUE)
grep("_bp$", names(dt_m), value = TRUE)[1:4]


comparison_names <- list(
  "types_bp" = grep("_bp$", names(dt_m), value = TRUE)[1:4], 
  "taxa_bp" = grep("_bp$", names(dt_m), value = TRUE)[5:8],
  "methods_bp" = grep("_bp$", names(dt_m), value = TRUE)[9:12], 
  "resolution_bp" = grep("_bp$", names(dt_m), value = TRUE)[13:15],

  "types_b" = grep("_b$", names(dt_m), value = TRUE)[1:4], 
  "taxa_b" = grep("_b$", names(dt_m), value = TRUE)[5:8],
  "methods_b" = grep("_b$", names(dt_m), value = TRUE)[9:12], 
  "resolution_b" = grep("_b$", names(dt_m), value = TRUE)[13:15],
  
  "types_by" = grep("_by$", names(dt_m), value = TRUE)[1:4], 
  "taxa_by" = grep("_by$", names(dt_m), value = TRUE)[5:8],
  "methods_by" = grep("_by$", names(dt_m), value = TRUE)[9:12], 
  "resolution_by" = grep("_by$", names(dt_m), value = TRUE)[13:15],
  
  "types_bc" = grep("_bc$", names(dt_m), value = TRUE)[1:4], 
  "taxa_bc" = grep("_bc$", names(dt_m), value = TRUE)[5:8],
  "methods_bc" = grep("_bc$", names(dt_m), value = TRUE)[9:12], 
  "resolution_bc" = grep("_bc$", names(dt_m), value = TRUE)[13:15],
  
  "types_bt" = grep("_bt$", names(dt_m), value = TRUE)[1:4], 
  "taxa_bt" = grep("_bt$", names(dt_m), value = TRUE)[5:8],
  "methods_bt" = grep("_bt$", names(dt_m), value = TRUE)[9:12], 
  "resolution_bt" = grep("_bt$", names(dt_m), value = TRUE)[13:15],
  
  "types_byct" = grep("_byct$", names(dt_m), value = TRUE)[1:4], 
  "taxa_byct" = grep("_byct$", names(dt_m), value = TRUE)[5:8],
  "methods_byct" = grep("_byct$", names(dt_m), value = TRUE)[9:12], 
  "resolution_byct" = grep("_byct$", names(dt_m), value = TRUE)[13:15],
  
  "types_z50" = grep("_z50$", names(dt_m), value = TRUE)[1:4], 
  "taxa_z50" = grep("_z50$", names(dt_m), value = TRUE)[5:8],
  "methods_z50" = grep("_z50$", names(dt_m), value = TRUE)[9:12], 
  "resolution_z50" = grep("_z50$", names(dt_m), value = TRUE)[13:15],
  
  # averages (without z50, but including bp, b, by, bc, bt, byct)
  "types" = facet_names_distill[1:4], 
  "taxa" = facet_names_distill[5:8],
  "methods" = facet_names_distill[9:12], 
  "resolution" = facet_names_distill[13:15],
  
  # with all layers
  "weights" = facet_names_distill[16:22]
)

facet_names[22*0 + (1:22)] # bp
facet_names[22*1 + (1:22)] # b
facet_names[22*2 + (1:22)] # by
facet_names[22*3 + (1:22)] # bc
facet_names[22*4 + (1:22)] # bt
facet_names[22*5 + (1:22)] # byct
facet_names[22*6 + (1:22)] # z50
facet_names[22*7 + (1:22)] # all
facet_names[22*8 + (1:7)] # weights
```

```{r weighted_jaccard}
# Calculate the weighted jaccard similarity index across all permutations within each decision category:

# ------------------------------------------------------------------
# create empty dataframe
# ------------------------------------------------------------------

length(facet_names)
jac_w <- matrix(
  nrow = length(facet_names), 
  ncol = length(facet_names))
colnames(jac_w) <- facet_names

jac_w <- data.frame(
  facet = facet_names,
  jac_w
)
jac_w <- jac_w %>% mutate(facet = fct_relevel(facet, facet_names))
rownames(jac_w) <- facet_names




# ------------------------------------------------------------------
# calculate weighted jaccard matrix: final codes
# ------------------------------------------------------------------
# the full set of permutations, even across decsision categories (caution: this can take a long time, > 1 hr) 
# tic()
# for(i in seq_along(facet_names)){
#   for(j in seq_along(facet_names)){
#     jac_w[i, 1 + j] <- dt_m_convertible[, c(2 + i, 2 + j), with = FALSE
#                           ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
#   }
# }
# toc()

names(dt_m_convertible)
# ------------------------------------------------------------------
# calculate weighted jaccard matrix: for only a subset of comparisons, within each decision category
# ------------------------------------------------------------------

tic()
for (group in 0:7) { # 8 groups of 22 (15 facets plus 7 composites), plus 7 weights at the end

  # for the first four: richness metrics  
  for(i in 1:4){
    for(j in 1:4){
      jac_w[22*group + i, 22*group + 1 + j] <- dt_m_convertible[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: taxonomic groups  
  for(i in 5:8){
    for(j in 5:8){
      jac_w[22*group + i, 22*group + 1 + j] <- dt_m_convertible[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: methods for combining layers
  for(i in 9:12){
    for(j in 9:12){
      jac_w[22*group + i, 22*group + 1 + j] <- dt_m_convertible[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next three: resolutions of inputs
  for(i in 13:15){
    for(j in 13:15){
      jac_w[22*group + i, 22*group + 1 + j] <- dt_m_convertible[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next 7: existing biodiversity indices, composites
  for(i in 16:22){
    for(j in 16:22){
      jac_w[22*group + i, 22*group + 1 + j] <- dt_m_convertible[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
}
toc() # 82 sec


tic() 
# 8 groups of 22 (15 facets plus 7 composites), 
# then 7 weights at the end
for(i in 1:7){
  for(j in 1:7){
    jac_w[8*22 + i, 8*22 + 1 + j] <- dt_m_convertible[
      , c(2 + 8*22 + i, 2 + 8*22 + j), with = FALSE
      ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
  }
}
toc() # 5.559 seconds


# remove self similarities
jac_w[jac_w == 1] <- NA



# ---------------------------------------------------------------------------------------------
# save weighted jaccard matrix to file
# ---------------------------------------------------------------------------------------------
fwrite(jac_w, file = fp(p_mod_output, "jac_w.csv"))
fwrite(jac_w_w_threat, file = fp(p_mod_output, "jac_w_w_threat.csv"))






# ---------------------------------------------------------------------------------------------
# check to make sure the loop worked. 
dt_m_convertible[, c("all", "small"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["all", "small"] # need to have the rows named
jac_w %>% filter(facet == "all") %>% select("small")
names(jac_w)

dt_m_convertible[, c("damania", "estes"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["damania", "estes"] # need to have the rows named

# checks out!

dt_m_convertible[, c("all_b", "threat_b"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["all_b", "threat_b"]

dt_m[, c("all_by", "threat_by"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["all_by", "threat_by"]

dt_m[, c("mam_byct", "rep_byct"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["mam_byct", "rep_byct"]

dt_m[, c("b", "by"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["b", "by"]



```


```{r jac_melt}
# Pivot (melt) the wide jaccard index matrix to a long form data frame, for use in analysis and plotting.
# This chunk results in three files:



jac_w_clean <- jac_w[facet_names, facet_names] # 63x63


jac_w_melt_full <- jac_w %>% 
  mutate(
    facet_full = facet,
    facet = gsub("_bp|_b|_by|_bc|_bt|_byct|_z50", "", facet_full)
      # c(rep(facet_names_distill_w_threat[1:22], 8),
      #   facet_names_distill_w_threat[23:29])
    ,
    comparison = c(
      rep(
        c(rep("types", 4),
          rep("taxa", 4),
          rep("methods", 4),
          rep("resolution", 3),
          rep("composites", 7)), 
        8), # repeat the 22 string 8 times (7 weights plus all)
      rep("weights", 7) # seven weights
      ),
    weight = c(
      rep("bp", 22),
      rep("b", 22),
      rep("by", 22),
      rep("bc", 22),
      rep("bt", 22),
      rep("byct", 22),
      rep("z50", 22),
      rep("all", 22), # all, except z50
      rep("all", 7) # for the 7 weights, since I don't know what else to call them
      )) %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair_full", value.name = "jac_w", na.rm = TRUE) %>%
  mutate(pair = gsub("_bp|_b|_by|_bc|_bt|_byct|_z50", "", pair_full))

# ---------------------------------------------------------------------------------------------
# exclude the three existing composites that we do not use in our final analysis
# ---------------------------------------------------------------------------------------------
jac_w_melt <- jac_w_melt_full %>%
  filter(!facet %in% c("bird_composite", "habitats", "plants"),
         !pair %in% c("bird_composite", "habitats", "plants"))

# ---------------------------------------------------------------------------------------------
# relevel certain things
jac_w_melt <- jac_w_melt %>% 
  mutate(
    facet = fct_relevel(facet, facet_names_distill),
    facet_full = fct_relevel(facet_full, facet_names),
    pair_full = fct_relevel(pair_full, facet_names),
    pair = fct_relevel(pair, facet_names_distill),
    comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
    comparison = fct_recode(comparison, "indices" = "composites"),
    weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all"))) %>%
  arrange(facet) %>%
  as_tibble()

# ---------------------------------------------------------------------------------------------
# Write melted tibble to file:
# ---------------------------------------------------------------------------------------------
fwrite(jac_w_melt, file = fp(p_mod_output, "jac_w_melt.csv"))
fwrite(jac_w_melt_full, file = fp(p_mod_output, "jac_w_melt_full.csv")) # containing additional unused composites (existing indices)
fwrite(jac_w_melt_w_threat, file = fp(p_mod_output, "jac_w_melt_w_threat.csv"))





# ---------------------------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------

### 

summary(jac_w_melt$jac_w)
arrange(jac_w_melt, jac_w)
arrange(jac_w_melt, facet)
# pairs
6+6+6+3+3

levels(jac_w_melt$facet)
levels(jac_w_melt$comparison)
levels(jac_w_melt$weight)
levels(jac_w_melt$pair)
unique(jac_w_melt$facet)
unique(jac_w_melt$comparison)
unique(jac_w_melt$weight)
unique(jac_w_melt$pair)
```

## Calculate summary statistics ("facet_stats")

```{r facet_stats}
# ---------------------------------------------------------------------------------------------
# Calculate summary statistics from the weighted jaccard similarity indices, and
# remove extra (unused) existing indices (composites)
# ---------------------------------------------------------------------------------------------

facet_stats <- jac_w_melt %>%
  mutate(pair_full = pair,
         pair = gsub("_bp|_b|_by|_bc|_bt|_byct|_z50", "", jac_w_melt$pair)) %>%
  filter(!facet %in% c("bird_composite", "habitats", "plants"),
         !pair %in% c("bird_composite", "habitats", "plants")) %>% 
  rename(facet_names = facet_full) %>%
  group_by(facet_names) %>% 
  summarise(
    facet = unique(facet),
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w)))) #%>%
    #mutate(facet = fct_relevel(facet, facet_names_distill))

# ---------------------------------------------------------------------------------------------
# save

fwrite(facet_stats, file = fp(p_mod_output, "facet_stats.csv"))


#---------------------------------------------------------------------------------------------
# load it back in
# ---------------------------------------------------------------------------------------------
facet_stats <- read_csv(file = fp(p_mod_output, "facet_stats.csv"))
facet_stats <- facet_stats %>%
  mutate(facet = fct_relevel(facet, facet_names_distill),
         comparison = fct_relevel(comparison, 
                                  c("composites", "types", "taxa", "methods", "resolution", "weights")),
         comparison = fct_recode(comparison, "indices" = "composites"),
         weight = fct_relevel(weight, 
                              c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all")))
```

```{r facet_stats_full}
# facet_stats, but including all runs, including the ones that do not make it into the final analysis
# see also jac_w_melt_combo


# note, the area_conv calculation requires the full jac_w_melt_full file, 
# which includes composites that do not make it into the final analysis

facet_stats_full <- jac_w_melt_full %>%
  rename(facet_names = facet_full) %>%
  group_by(facet_names) %>% 
  summarise(
    count = n(),
    facet = unique(facet),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w)))) %>%
  mutate(
    # facet = c(
    #   rep(facet_names_distill[1:21], 8), # formerly 1:22
    #   facet_names_distill[22:28]), # formerly 23:29
    
    # area_conv is adjusted by the proportion of land that is convertible
    name = grep("threat", names(dt_m_convertible)[-(1:2)], invert = T, value = T),
    
    area_conv = as.numeric(dt_m_convertible[, c("x", "y", grep("threat", names(dt_m_convertible)[-(1:2)], 
                                                               invert = T, value = T)), with = FALSE
                                            ][, lapply(.SD, sum)][,-(1:2)])) %>%
    
  mutate(facet = fct_relevel(facet, facet_names_distill),
         comparison = fct_relevel(comparison, 
                                  # note, some of these may have been renamed (indices = composites, richness = types)
                                  c("indices", "richness", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, 
                              c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all"))) %>%
  select(facet_names, count, comparison, weight, mean_jac_w, se_jac_w, facet, name, area_conv)


# ---------------------------------------------------------------------------------------------
# save
# ---------------------------------------------------------------------------------------------
fwrite(facet_stats_full, file = fp(p_mod_output, "facet_stats_full.csv"))
fwrite(facet_stats_w_threat, file = fp(p_mod_output, "facet_stats_w_threat.csv"))

# ---------------------------------------------------------------------------------------------
# load it back in
# ---------------------------------------------------------------------------------------------
facet_stats_full <- read_csv(file = fp(p_mod_output, "facet_stats_full.csv"))
```


```{r extract_results}
#---------------------------------------------------------------------------------------------
# load facet_stats back in
# ---------------------------------------------------------------------------------------------
facet_stats <- read_csv(file = fp(p_mod_output, "facet_stats.csv"))
facet_stats <- facet_stats %>%
  mutate(facet = fct_relevel(facet, facet_names_distill),
         comparison = fct_relevel(comparison, 
                                  c("composites", "types", "taxa", "methods", "resolution", "weights")),
         comparison = fct_recode(comparison, "indices" = "composites"),
         weight = fct_relevel(weight, 
                              c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all")))


# extract various statistics:

filter(facet_stats, weight == "all", comparison == "weights") %>% select(facet, weight, comparison, mean_jac_w) %>%
  print(n = 21) #%>%
  #group_by(comparison) %>%
  #summary()
  #summarise(mean_mean = mean(mean_jac_w))
  
filter(facet_stats, weight == "byct", comparison == "indices") %>% select(mean_jac_w) %>% summary
filter(facet_stats, weight == "bp", comparison == "indices") %>% select(mean_jac_w) %>% summary
filter(facet_stats, weight == "z50", comparison == "indices") %>% select(mean_jac_w) %>% summary

filter(facet_stats, weight == "bp") %>% group_by(comparison) %>% 
  summarise(mean = round(mean(mean_jac_w, na.rm = TRUE)*100, 1),
            min = round(min(mean_jac_w, na.rm = TRUE)*100, 1),
            max = round(max(mean_jac_w, na.rm = TRUE)*100, 1))


jac_w_melt %>%
  filter(weight == "bp",
         comparison == "resolution")

filter(facet_stats, weight == "z50") %>% group_by(comparison) %>% 
  summarise(mean = round(mean(mean_jac_w, na.rm = TRUE)*100, 1),
            min = round(min(mean_jac_w, na.rm = TRUE)*100, 1),
            max = round(max(mean_jac_w, na.rm = TRUE)*100, 1))

filter(facet_stats, weight == "byct") %>% group_by(comparison) %>% 
  summarise(mean = round(mean(mean_jac_w, na.rm = TRUE)*100, 1),
            min = round(min(mean_jac_w, na.rm = TRUE)*100, 1),
            max = round(max(mean_jac_w, na.rm = TRUE)*100, 1))

# with threat:
facet_stats_threat %>% group_by(comparison) %>% 
  summarise(mean = mean(mean_jac_w, na.rm = TRUE),
            min = min(mean_jac_w, na.rm = TRUE),
            max = max(mean_jac_w, na.rm = TRUE))


# go look for and replace numbers related to all, taxa. 
filter(facet_stats, weight == "all") %>% print(n = 28)
filter(jac_w_melt, weight == "all", comparison == "weights") %>% print(n = 28)

jac_w_melt %>%
  filter(weight == "bp",
         comparison == "composites",
         facet %in% c("laurance", "damania", "estes", "vert_endemism"),
         pair %in% c("laurance", "damania", "estes", "vert_endemism")) %>% 
  group_by(facet_full) %>% summarise(mean = mean(jac_w, na.rm = TRUE))

facet_stats %>% filter(comparison == "composites", weight == "bp") %>% select(mean_jac_w)
mean(c(0.0223, 0.0271, 0.0367, 0.00310))

filter(facet_stats, weight == "bp") %>% group_by(comparison) %>% summarise(mean = mean(mean_jac_w, na.rm = TRUE))
facet_stats$comparison %>% unique

jac_w_melt %>%
  filter(weight == "z50", 
         comparison %in% c("composites")) %>% select(jac_w) %>% summary()



# similarity
# ---------------------------------------------------------------------------
jac_w_melt %>% 
  filter(weight == "all") %>% 
  group_by(comparison, weight) %>% 
  summarise(mean_jac_w = mean(jac_w), 
            se_jac_w = sqrt(var(jac_w) / sum(jac_w)))

jac_w_melt %>% filter(weight == "all", comparison == "resolution") 
facet_stats %>% filter(weight == "all", comparison == "methods") 


facet_stats %>% filter(weight == "all") %>% .$mean_jac_w %>% summary()

facet_stats %>% filter(comparison == "types", weight == "all") %>% select(mean_jac_w) %>% colMeans(.)

facet_stats_full %>% filter(comparison == "types", weight != "all") %>% .$area_conv %>% summary()
facet_stats_full %>% filter(comparison == "types", weight == "all") %>% .$area_conv %>% summary()
```


```{r area_conv}
# ---------------------------------------------------------------------------
# area converted:
# ---------------------------------------------------------------------------
facet_stats_full %>% filter(weight != "z50", facet != "z50") %>% arrange(desc(area_conv))

# the bird facet is crazy high...
plot(conv_r$facet_r[[5:8]])
cellStats(conv_r$facet_r$bird, "sum")

dt_m_convertible[, c("x", "y", grep("threat", names(dt_m_convertible)[-(1:2)], invert = T, value = T)), with = FALSE][, lapply(.SD, sum)][,-(1:2)]


facet_stats_full %>% select(area_conv)
filter(facet_stats_full, weight == "all") %>% group_by(comparison)


# area converted
# ---------------------------------------------------------------------------
summary(facet_stats_full$area_conv)

facet_stats_full %>% filter(weight == "all", facet != c("amp"), comparison != "weights") %>% .$area_conv %>% summary()
facet_stats_full %>% filter(weight == "all", comparison == "taxa") %>% .$area_conv %>% summary()
32135.08/26853

test <- facet_stats_full %>% filter(weight == "all", facet != c("amp"), comparison == "weights")

(filter(test, facet == "byct") %>% .$area_conv - 
  filter(test, facet == "by") %>% .$area_conv  ) / 
  filter(test, facet == "by") %>% .$area_conv


jac_w_melt %>% filter(comparison == "types", weight == "b")

```

```{r w_threat}
# save data.tables with threat runs

save(dt_w_threat, dt_m_w_threat, dt_m_convertible_w_threat, jac_w_w_threat, jac_w_melt_w_threat, facet_stats_w_threat, bd_dt_m_w_threat, order_jac_w_melt_w_threat, facet_stats_order_w_threat,
  file = fp(p_mod_output, "runs_w_threat_531.RData")
)

rm(dt_w_threat, dt_m_w_threat, dt_m_convertible_w_threat, jac_w_w_threat, jac_w_melt_w_threat, facet_stats_w_threat, bd_dt_m_w_threat, order_jac_w_melt_w_threat, facet_stats_order_w_threat)

load(file = fp(p_mod_output, "runs_w_threat_531.RData"), verbose = TRUE)
```


```{r load_data}
dt <- fread(file = fp(p_mod_output, "dt.csv"))
dt_m <- fread(file = fp(p_mod_output, "dt_m.csv"))
dt_m_convertible <- fread(file = fp(p_mod_output, "dt_m_convertible.csv"))
jac_w <- fread(file = fp(p_mod_output, "jac_w.csv"))
facet_stats <- fread(file = fp(p_mod_output, "facet_stats.csv")) %>% 
  mutate(facet = fct_relevel(facet, facet_names_distill),
         pair = fct_relevel(pair, facet_names),
         comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all"))
         )

jac_w_melt <- fread(file = fp(p_mod_output, "jac_w_melt.csv")) %>% 
  mutate(facet = fct_relevel(facet, facet_names_distill),
         pair = fct_relevel(pair, facet_names),
         comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all"))) %>%
  arrange(facet)


facet_stats$weight
as_tibble(facet_stats)

bd_dt_m <- fread(file = fp(p_mod_output, "bd_dt_m.csv"))

```

## Robustness Checks:

1. Adjacency: nearest neighbor distance
2. Threatened species richness
3. Increasing the production target (z50)
4. Normalization order
5. Directly comparing the order of conversion
6. Additional composites
7. Incorporating non-biodiversity constraints

Unused: also comparing similarity for:
8. Raw biodiversity inputs themselves
9. The unconverted areas

```{r 1.nn_calc}
# --------------------------------------------------------------------------
# Calculate nearest neighbor distances, as a measure of adjacency
# --------------------------------------------------------------------------
# 
# Calculate adjacency between ensemble means
# 
# In other words, for two rasters a and b, calculate the distance between each pixel on a (selected for conversion) and the nearest neighbor pixel on b (selected for conversion). This is simpler for completely categorical rasters (i.e. either converted, or not). Perhaps I could weight the "distance" based on the value of the cell that is the nearest neighbor. 
# 
# Adapt code from Lyndon, using `spatstat::nncross()`
# 
# First, I recreate this workflow with categorical rasters. Then comes the hard part: figuring out how to calculate the nearest neighbor for the continuous ensemble means.
# We have two options: 
# 1. just calculate the average distance, assuming each cell has the same value, or.
# 2. calculate a weighted average, based on the value of the cells
# 
# conceptually:
# - convert raster to points.
# - this has the value of the cell associated with the point
# - create the ppp objects, which are points objects
# - from this, calculate the distance to the nearest neighbor in Y of each point in X (therefore, we put whichever of the layers has more points in as X)
# - then, we take the average of all of these distances (this is approach 1)
# - Approach 2: what we could do instead is to weight the average based on the value in the cell and the value it is matched to. The values represent the proportion of models that select that particular cell. Therefore, weighting the average distance by the two values means that the distances for the cells where the model more frequently converted are given greater weight. The key thing is for the average to be calculated based not on the number of cells, but instead on the sum of cell values. (i.e. dividing by the sum of cell values, rather than the total number of cells). If we don't do this, the average distance would be artificially lower).
# 
# To do that, I'll need to multiply the distance by a) the ensemble mean value, or b) the mean value between the two matching cells.
# - then sum the weighted distances
# - then divide by the sum of a) ensemble mean cell values or b) the mean value of each pair.



# --------------------------------------------------------------------------
# load relevant libraries and data 
library(spatstat)
vignette('getstart')
# calculate nearest neighbor distance, using spatstat::nncross()


rl <- lapply(1:nlayers(facet_r_bp), function(x) {facet_r_bp[[x]]})
names(rl) <- names(facet_r_bp)

nndat <- jac_w_melt %>%
#  as_tibble() %>% 
  filter(weight == "bp") %>%
  select(comparison, weight, facet_full, pair_full, pair, facet) %>%
  arrange(facet_full) # this sorts correctly, because facet is a factor in the correct order

# create an "observation window" (i.e. owin) of analysis in spatstat
zam_owin <- owin(xrange = bbox(zambia)[1, ], yrange = bbox(zambia)[2, ],
                 unitname = "meter")

tic()
nnl <- lapply(1:nrow(nndat), function(i) {
  # select indices to grab from rl
  ind <- c(
    which(names(rl) == nndat$facet_full[i]), 
    which(names(rl) == nndat$pair_full[i])
    )
  
  # select the two rasters of interest, save as a new list with those two rasters
  rl_ind <- rl[ind]
  
  # convert those rasters to points. 
  rxy <- lapply(rl_ind, function(x) rasterToPoints(x, fun = function(x) x > 0)) # selecting a subset of raster values (those larger than 0), using a simple function returning a logical values
  
  pps <- lapply(rxy, function(x) {
    ppp(x = x[, 1], y = x[, 2], window = zam_owin)
  })
  
  ppnn <- nncross(pps[[names(rl)[ind[1]]]], pps[[names(rl)[ind[2]]]]) %>%
    as_tibble() %>% mutate(surrogate_key = row_number())
  
  # ------------------------------------------------
  # join ppnn to the rxy values
  rxy_tbl <- lapply(rxy, function(x) mutate(as_tibble(x), surrogate_key = row_number()))
  
  ppnn_join <- ppnn %>% 
    # join ppnn to the rxy values
    left_join(rxy_tbl[[1]], by = "surrogate_key") %>% 
    select(-c(x, y)) %>%
    left_join(rxy_tbl[[2]], 
              by = c("which" = "surrogate_key")) %>% 
    select(-c(x, y)) %>%
    
    # with joined table, calculate the average ensemble value
    mutate(
      mean_value = rowMeans(cbind(.[, 4], .[, 5]), na.rm=T),
      adj_dist = dist * mean_value)
})
toc() # 155.906 sec

nnl_sums <- lapply(nnl, function(x) {
  summarise(x, 
          dist_sum = sum(dist), 
          npoints = nrow(x),
          adj_dist_sum = sum(adj_dist),
          mean_value_sum = sum(mean_value))
})
nnl_sums <- do.call("rbind", nnl_sums) 
nnl_sums <- nnl_sums %>%
  mutate(raw_mean_dist = dist_sum/npoints,
         adj_mean_dist = adj_dist_sum/mean_value_sum)

nndat_full <- nndat %>% cbind(nnl_sums)

nndat <- nndat_full %>%
  filter(!facet %in% c("bird_composite", "habitats", "plants"),
         !pair %in% c("bird_composite", "habitats", "plants")) %>%
  mutate(
    comparison = fct_relevel(comparison, c("indices", "taxa", "types", "methods", "resolution", "weights")),
    comparison = fct_recode(comparison, "richness" = "types"))

as_tibble(nndat)


# calculate mean distance for each facet
# facet_stats_order
nndat_facet_stats <- nndat %>%
  group_by(facet_full) %>% 
  summarise(
    count = n(),
    facet = unique(facet),
    pair = unique(pair),
    pair_full = unique(pair_full),
    comparison = unique(comparison),
    weight = unique(weight),
    facet_mean_dist = mean(adj_mean_dist, na.rm = TRUE))


# rename layers:
nndat <- nndat %>% 
  mutate(facet = fct_recode(facet,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep",
            "arith. mean"    = "average",
            "geom. mean"     = "geometric",
            "maximum"        = "max",
            "multiply"       = "multi",
            "1 km grid"      = "res1",
            "10 km grid"     = "res10",
            "110 km grid"    = "res110",
            "vert. endemism" = "vert_endemism",
            "estes"          = "estes",
            "laurance"       = "laurance",
            "damania"        = "damania"),
         pair = fct_recode(pair,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep",
            "arith. mean"    = "average",
            "geom. mean"     = "geometric",
            "maximum"        = "max",
            "multiply"       = "multi",
            "1 km grid"      = "res1",
            "10 km grid"     = "res10",
            "110 km grid"    = "res110",
            "vert. endemism" = "vert_endemism",
            "estes"          = "estes",
            "laurance"       = "laurance",
            "damania"        = "damania")
         )

nndat_facet_stats <- nndat_facet_stats %>%
  mutate(facet = fct_recode(facet,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep",
            "arith. mean"    = "average",
            "geom. mean"     = "geometric",
            "maximum"        = "max",
            "multiply"       = "multi",
            "1 km grid"      = "res1",
            "10 km grid"     = "res10",
            "110 km grid"    = "res110",
            "vert. endemism" = "vert_endemism",
            "estes"          = "estes",
            "laurance"       = "laurance",
            "damania"        = "damania"),
         pair = fct_recode(pair,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep",
            "arith. mean"    = "average",
            "geom. mean"     = "geometric",
            "maximum"        = "max",
            "multiply"       = "multi",
            "1 km grid"      = "res1",
            "10 km grid"     = "res10",
            "110 km grid"    = "res110",
            "vert. endemism" = "vert_endemism",
            "estes"          = "estes",
            "laurance"       = "laurance",
            "damania"        = "damania")
         )

nndat_facet_stats

object_size(nndat, nnl, nnl_sums, nndat_facet_stats)
save(nndat, nnl, nnl_sums, nndat_facet_stats, file = fp(p_mod_output, "nnd_files.RData"))

load(file = fp(p_mod_output, "nnd_files.RData"), verbose = TRUE)


# --------------------------------------------------------------------------
# plot ---------------------------------------------------------------------
# --------------------------------------------------------------------------

gg_nnd_pairs <- ggplot(nndat, aes(x = facet_full, y = adj_mean_dist / 1000, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Adjusted Average Distance \nto Nearest Neighbor (km)") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")
gg_nnd_pairs

gg_nnd <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + 
  ylab("Mean Distance to Nearest Neighbor (km)") + #fct_relevel(facet, facet_names_distill)
  geom_point(data = nndat_facet_stats,
             mapping = aes(x = facet, y = facet_mean_dist / 1000, color = comparison),
             size = 2) +
  geom_point(data = nndat, 
             mapping = aes(x = facet, y = adj_mean_dist / 1000),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  
  scale_colour_viridis("Mean Values", discrete = T) # for color blindness

gg_nnd



# save:
png(paste0(p_plots, "/si/", "SI_fig_nnd_bp", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    gg_nnd + 
      #ggtitle("Pure biodiversity (100% weight on bd, with average yields)") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 1, 0.2, 0.2), "cm"))
  )
dev.off()

```

```{r 2.threatened-species-richness}
conv_extras_bp_dt
env_size(ls())
# --------------------------------------------------------------------------
# save new version of the dt, with threatened species richness, just for bp for now
dt_bp_threat <- fread(file = fp(p_mod_output, "dt_bp.csv"))
dt_bp_threat
conv_extras_bp_dt
names(conv_extras_bp_dt) <- c("x", "y", paste0(extra_runs, "_bp"))
names(dt_bp_threat)

names(conv_extras_bp_dt)


# --------------------------------------------------------------------------
# cut out layers I don't use, including reptiles
grep("mam|bird_[^c]|amp", names(dt_bp_threat), value = TRUE, invert = FALSE)

dt_bp_threat
dt_bp_threat[, grep("mam|bird|amp", names(dt_bp_threat)), with = FALSE] %>% length # 5*7*3 # 5 (4 taxa plus combo) * 3 resolutions * 7 weights
length(dt_bp_threat)
dt_bp_threat[, (grep("mam|bird_[^c]|amp", names(dt_bp_threat), value = TRUE, invert = TRUE)) := NULL]



# merge with new extra runs:
dt_bp_threat <- cbind(
  dt_bp_threat, 
  conv_extras_bp_dt[, grep("sum_norm", names(conv_extras_bp_dt[, -c(1:2)]), invert = TRUE, value= TRUE)
        , with = FALSE]
  )

dt_bp_threat_m <- conv_extras_bp_dt[, 1:2]

# --------------------------------------------------------------------------
# re calculate the ensemble means to just include mammals, birds, and amphibians.
# richness type averages

dt_bp_threat_m[, all_bp := rowMeans(dt_bp_threat[, grep("_all.+bp$", names(dt_bp_threat)), with = FALSE])]
dt_bp_threat_m[, endemism_bp := rowMeans(dt_bp_threat[, grep("_endemism.+bp$", names(dt_bp_threat)), with = FALSE])]
dt_bp_threat_m[, threat_bp := rowMeans(dt_bp_threat[, grep("_threat.+bp$", names(dt_bp_threat)), with = FALSE])]
dt_bp_threat_m[, small_bp := rowMeans(dt_bp_threat[, grep("_small.+bp$", names(dt_bp_threat)), with = FALSE])]

# taxa averages
dt_bp_threat_m[, mam_bp := rowMeans(dt_bp_threat[, grep("mam.+bp$", names(dt_bp_threat)), with = FALSE])]
dt_bp_threat_m[, bird_bp := rowMeans(dt_bp_threat[, grep("bird.[^c]+bp$", names(dt_bp_threat)), with = FALSE])]
dt_bp_threat_m[, amp_bp := rowMeans(dt_bp_threat[, grep("amp.+bp$", names(dt_bp_threat)), with = FALSE])]
# dt_bp_threat_m[, rep_bp := rowMeans(dt_bp_threat[, grep("rep.+bp$", names(dt_bp_threat)), with = FALSE])]



# --------------------------------------------------------------------------
# adjust by convertible areas
dt_bp_threat_m_convertible <- dt_bp_threat_m[, lapply(.SD, function(x) {
  il$convertible[valinds, ]$convertible * x})]

dt_bp_threat_m_convertible[, x := dt_bp_threat_m$x]
dt_bp_threat_m_convertible[, y := dt_bp_threat_m$y]

# --------------------------------------------------------------------------
# run loop to calculate the weighted jaccard

jac_w_threat <- matrix(
  nrow = 7,  # facets plus composites
  ncol = 7)
colnames(jac_w_threat) <- gsub("_bp", "", names(dt_bp_threat_m_convertible)[-c(1:2)])

jac_w_threat <- data.frame(
  facet = gsub("_bp", "", names(dt_bp_threat_m_convertible)[-c(1:2)]),
  jac_w_threat
)
jac_w_threat <- jac_w_threat %>% 
  mutate(facet = fct_relevel(facet,
                             gsub("_bp", "", names(dt_bp_threat_m_convertible)[-c(1:2)])))
rownames(jac_w_threat) <- gsub("_bp", "", names(dt_bp_threat_m_convertible)[-c(1:2)])


# ------------------------------------------------------------------
tic()
  # for the first four: types  
for(i in 1:4){
  for(j in 1:4){
      jac_w_threat[i, 1 + j] <- dt_bp_threat_m_convertible[, c(2 + i, 2 + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
}

for(i in 5:7){
  for(j in 5:7){
      jac_w_threat[i, 1 + j] <- dt_bp_threat_m_convertible[, c(2 + i, 2 + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
toc() # 10.755 sec.


# remove self similarities
jac_w_threat[jac_w_threat == 1] <- NA

# ------------------------------------------------------------------
# prep and melt
# ------------------------------------------------------------------
nrow(jac_w_threat)
jac_w_threat_melt <- jac_w_threat %>% 
  mutate(
    comparison = c(
      rep("richness", 4), # formerly 4
      rep("taxa", 3)),
    weight = "bp") %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE) %>% 
  mutate(comparison = fct_relevel(comparison, c("taxa", "richness"))) %>%
  arrange(facet)

fwrite(jac_w_threat_melt, file = fp(p_mod_output, "jac_w_threat_melt.csv"))
jac_w_threat_melt <- read_csv(file = fp(p_mod_output, "jac_w_threat_melt.csv"))


# ------------------------------------------------------------------
# facet_stats_threat
facet_stats_threat <- jac_w_threat_melt %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))

fwrite(facet_stats_threat, file = fp(p_mod_output, "facet_stats_threat.csv"))
facet_stats_threat <- read_csv(file = fp(p_mod_output, "facet_stats_threat.csv"))


# rename:

facet_stats_threat <- facet_stats_threat %>%
  mutate(facet = 
           fct_recode(facet,
                      "all sp."        = "all",
                      "endemism"       = "endemism",
                      "threatened sp." = "threat",
                      "small-ranged sp."      = "small",
                      "mammals"        = "mam",
                      "birds"          = "bird",
                      "amphibians"     = "amp", 
                      "reptiles"       = "rep"))

jac_w_threat_melt <- jac_w_threat_melt %>%
  mutate(facet = fct_recode(facet,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "threatened sp." = "threat",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep"),
        
         pair = fct_recode(pair,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "threatened sp." = "threat",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep")
      )
# --------------------------------------------------------
# --------------------------------------------------------
# condensed plot
SI_fig_jac_w_threat <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  labs(x = "Factor", y = "Jaccard Similarity", color = "Mean Values") +
  geom_point(data = facet_stats_threat,
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = jac_w_threat_melt,
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_viridis(discrete = T, begin = 0, end = 0.8)


SI_fig_jac_w_threat + 
  labs(title = "With Threatened Species Richness") + 
  coord_cartesian(ylim=c(0, 1.0))

# ------------------------------------------------------------------------------ #
# save:
# ------------------------------------------------------------------------------ #
png(paste0(p_plots, "/si/", "SI_fig_jac_w_threat", ".png"), 
    width = 4, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_threat + 
      #labs(title = "Including Threatened Species Richness") + 
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()


# maps:
facet_r_threat <- writeRaster(
  dt_to_raster(dt_bp_threat_m_convertible, CRSobj),
  overwrite=TRUE, fp(p_mod_output,"facet_r_threat.tif"))
plot(facet_r_threat)

# ------------------------------------------------------------------------------ #
# ------------------------------------------------------------------------------ #

facet_r_threat <- brick(fp(p_mod_output,"facet_r_threat.tif"))
names(facet_r_threat) <- gsub("_bp", "", names(dt_bp_threat_m_convertible)[-c(1:2)])


pixels <- 5000000
  
p1 <- gplot(facet_r_threat[[c("mam", "bird", "amp")]], maxpixels = pixels) + 
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1, labeller = labeller(variable = new_labels_lookup)) + 
      scale_fill_gradientn(colors = map_colors, na.value = "white", limits = c(0, 1)) + 
      labs(y = "Taxonomic Groups", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), 
            axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.title = element_blank()) + 
      coord_equal()

p2 <- gplot(facet_r_threat[[c("all", "endemism", "threat", "small")]], maxpixels = pixels) + # or facet_r[[comparison_names$types]] for just the four ensemble means
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1, labeller = labeller(variable = new_labels_lookup)) + 
      scale_fill_gradientn(colors = map_colors, na.value = "white", limits = c(0, 1)) + 
      labs(y = "Richness Types", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.position = "none") + 
      coord_equal()



# ------------------------------------------------------------------------------ #
# start png call here. 
# ------------------------------------------------------------------------------ #
png(paste0(p_plots, "/si/","SI_fig_facet_r_threat", "_combo.png"),    
    width = 5, height = 6,
    units = "in", res = 300)

plot_grid(
  p1, p2, 
  SI_fig_jac_w_threat + 
    theme(legend.position = "top"),
  labels = "auto",
  ncol = 1, rel_heights = c(1.3, 1.2, 2.5))

dev.off()
```

```{r 4.norm_order}
# Normalization Order


# first get mean of all vert richness across four types and 3 weights:
# first collect and merge dt_b, dt_by, and dt_byct, but just the vert and the sum_norm columns
names(dt_bp)
conv_extras_bp_dt %>% names
grep("sum_norm", names(conv_extras_bp_dt), value = TRUE)
grep("vert_[^t]", names(dt_bp), value = TRUE)


dt <- merge(dt_b[, c(1:6, 53:56)], dt_by[, c(1:6, 53:56)], by = c("x","y"))
dt <- merge(dt, dt_byct[, c(1:6, 53:56)], by = c("x","y"))

dt %>% ncol()

dt_norm <- cbind(
  conv_extras_bp_dt[, 1:2],
  conv_extras_bp_dt[, grep("sum_norm", names(conv_extras_bp_dt), value = TRUE), with = FALSE],
  dt_bp[, grep("vert_[^t]", names(dt_bp), value = TRUE), with = FALSE]
  )
names(dt_norm)

grep("sum_norm", names(dt), invert = TRUE, value = TRUE)
grep("sum_norm", names(dt), value = TRUE)

grep("sum_norm", names(dt_norm[, -c(1:2)]), invert = TRUE, value= TRUE)

dt_norm[, grep("sum_norm", names(dt_norm[, -c(1:2)]), invert = TRUE, value= TRUE)
        , with = FALSE]


dt_norm[, norm_first := rowMeans(
  dt_norm[, grep("sum_norm", names(dt_norm[, -c(1:2)]), invert = TRUE, value= TRUE), with = FALSE]  
  )]
dt_norm[, sum_first := rowMeans(
  dt_norm[, grep("sum_norm", names(dt_norm)), with = FALSE])]

dt_norm[, difference := norm_first - sum_first]
names(dt_norm)

norm_r <- dt_to_raster(dt_norm[, .(x, y, norm_first, sum_first, difference)], CRSobj)
plot(norm_r)
#norm_r[norm_r <= 0] <- NA # set all 0s to NA


png(file = fp(p_plots, "/ms_v5/norm_r.png"), 
    width = 6, height = 6, units = "in", res = 300)
plot(norm_r[[1]] - norm_r[[2]], #main = "norm first - sum first", 
     box = FALSE, axes = FALSE)

plot(pas, col = col_pas_all, border = "gray", add=T)
legend("bottomright", legend= c("GMA", "Nat'l Park"), fill=col_pas, cex = 1.1, bty = "n")
plot(msk_shp, add = TRUE)
dev.off()

dt_norm[, .(norm_first, sum_first) # select the two columns you're interested in... (this works with column names in quotes, or as column indices)
   ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))] # then calculate the weighted Jaccard

# 0.789

p1 <- gplot(norm_r[[c("norm_first", "sum_first")]], maxpixels = 5000000) + 
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = map_colors, na.value = "white", limits = c(0, 1)) + 
      labs(y = "Normalization Order", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.title = element_blank()) + 
      coord_equal()

p2 <- gplot(norm_r[["difference"]], maxpixels = 5000000) + 
      geom_raster(aes(fill = value)) +
      #facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = map_colors, na.value = "white"#, limits = c(0, 1)
                           ) + 
      labs(y = "Difference", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.title = element_blank()) + 
      coord_equal()

png(paste0(p_plots, "/si/","SI_norm_order_plots.png"),    
    width = 4, height = 5,
    units = "in", res = 300)
plot_grid(p1, p2, ncol = 1, rel_heights = c(1, 2))
dev.off()

rm(p1, p2)
```

```{r 5.conversion_order_jac}
length(bd_dt_m)
names(bd_dt_m)
dt_order <- bd_dt_m[, 1:24]

# first set a key
dt_order[, key := 1:.N]



# then update each column based on the order of that column
# note that the results are essentially the same if we compare based on areas to save vs. areas to convert

for (i in 1:22) {
  setorderv(dt_order, cols = names(dt_order)[2 + i], order = c(-1)) # set to (-1) for descending order (high biodiversity cells first, therefore with low priority value). Use the opposite (1) to list low bd first, therefore giving higher values to high biodiversity (analogous to selecting high biodiversity areas)
  dt_order[, names(dt_order)[2 + i] := (1:.N)/.N] # replace value with 1:N, normalized to 1, so that high values indicate cells that get converted first
  setorder(dt_order, key) # return to original ordering
}

# check it out
dt_order[, 1:6] %>% dt_to_raster(CRSobj) %T>% plot()
dt_order[, key := NULL]

length(dt_order)

# now, run the jac_w

order_jac_w <- matrix(
  nrow = 22,  # facets plus composites
  ncol = 22)
colnames(order_jac_w) <- facet_names_distill_w_threat[1:22]

order_jac_w <- data.frame(
  facet = facet_names_distill_w_threat[1:22],
  order_jac_w
)
order_jac_w <- order_jac_w %>% mutate(facet = fct_relevel(facet, 
                                                    facet_names_distill_w_threat[1:22]))
rownames(order_jac_w) <- facet_names_distill_w_threat[1:22]


# ------------------------------------------------------------------
tic()
for (group in 0) { # just 1 group of 22 (15 facets plus 7 composites)

  # for the first four: types  
  for(i in 1:4){
    for(j in 1:4){
      order_jac_w[22*group + i, 22*group + 1 + j] <- dt_order[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: taxonomic groups  
  for(i in 5:8){
    for(j in 5:8){
      order_jac_w[22*group + i, 22*group + 1 + j] <- dt_order[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: methods
  for(i in 9:12){
    for(j in 9:12){
      order_jac_w[22*group + i, 22*group + 1 + j] <- dt_order[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next three: resolutions
  for(i in 13:15){
    for(j in 13:15){
      order_jac_w[22*group + i, 22*group + 1 + j] <- dt_order[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next 7: composites
  for(i in 16:22){
    for(j in 16:22){
      order_jac_w[22*group + i, 22*group + 1 + j] <- dt_order[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
}
toc() # 10.755 sec.



# remove self similarities
order_jac_w[order_jac_w == 1] <- NA

order_jac_w["threat", ] <- NA
order_jac_w[, "threat"] <- NA

# ------------------------------------------------------------------
# prep and melt
# ------------------------------------------------------------------
nrow(order_jac_w)
order_jac_w_melt <- order_jac_w %>% 
  mutate(
    comparison = c(
      rep("richness", 4), # formerly 4
      rep("taxa", 4),
      rep("methods", 4),
      rep("resolution", 3),
      rep("indices", 7)),
    weight = "order") %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE) %>% 
  mutate(comparison = fct_relevel(comparison, c("indices", "taxa", "richness", "methods", "resolution"))) %>%
  arrange(facet)

# order_jac_w_melt_conv <- order_jac_w_melt
# fwrite(order_jac_w_melt_conv, file = fp(p_mod_output, "order_jac_w_melt_conv.csv"))

# order_jac_w_melt_protect <- order_jac_w_melt
# fwrite(order_jac_w_melt_protect, file = fp(p_mod_output, "order_jac_w_melt_protect.csv"))


# ------------------------------------------------------------------
# facet_stats_order
facet_stats_order_conv <- order_jac_w_melt_conv %>%
  filter(!facet %in% c("bird_composite", "habitats", "plants"),
         !pair %in% c("bird_composite", "habitats", "plants")) %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))

facet_stats_order_protect <- order_jac_w_melt_protect %>%
  filter(!facet %in% c("bird_composite", "habitats", "plants"),
         !pair %in% c("bird_composite", "habitats", "plants")) %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))

fwrite(facet_stats_order_conv, file = fp(p_mod_output, "facet_stats_order_conv.csv"))
fwrite(facet_stats_order_protect, file = fp(p_mod_output, "facet_stats_order_protect.csv"))

# --------------------------------------------------------
# --------------------------------------------------------
# reload files
order_jac_w_melt_conv <- read_csv(file = fp(p_mod_output, "order_jac_w_melt_conv.csv")) %>%
  mutate(facet = fct_relevel(facet, grep("bird_composite|habitats|plants", facet_names_distill, 
                                         value = TRUE, invert = TRUE)),
         comparison = fct_relevel(comparison, c("indices", "taxa", "richness", "methods", "resolution")),
  )

order_jac_w_melt_protect <- read_csv(file = fp(p_mod_output, "order_jac_w_melt_protect.csv")) %>%
  mutate(facet = fct_relevel(facet, grep("bird_composite|habitats|plants", facet_names_distill, 
                                         value = TRUE, invert = TRUE)),
         comparison = fct_relevel(comparison, c("indices", "taxa", "richness", "methods", "resolution")),
  )

facet_stats_order_conv <- read_csv(file = fp(p_mod_output, "facet_stats_order_conv.csv")) %>%
    mutate(facet = fct_relevel(facet, grep("bird_composite|habitats|plants", facet_names_distill, 
                                         value = TRUE, invert = TRUE)),
           comparison = fct_relevel(comparison, c("indices", "taxa", "richness", "methods", "resolution")),
  )
facet_stats_order_protect <- read_csv(file = fp(p_mod_output, "facet_stats_order_protect.csv")) %>%
  mutate(facet = fct_relevel(facet, grep("bird_composite|habitats|plants", facet_names_distill, 
                                         value = TRUE, invert = TRUE)),
         comparison = fct_relevel(comparison, c("indices", "taxa", "richness", "methods", "resolution")),
  )

# update names:
facet_stats_order_protect <- facet_stats_order_protect %>%
  mutate(facet = 
           fct_recode(facet,
                      "all sp."        = "all",
                      "endemism"       = "endemism",
                      "small-ranged sp."      = "small",
                      "mammals"        = "mam",
                      "birds"          = "bird",
                      "amphibians"     = "amp", 
                      "reptiles"       = "rep",
                      "arith. mean"    = "average",
                      "geom. mean"     = "geometric",
                      "maximum"        = "max",
                      "multiply"       = "multi",
                      "1 km grid"      = "res1",
                      "10 km grid"     = "res10",
                      "110 km grid"    = "res110",
                      "vert. endemism" = "vert_endemism",
                      "estes"          = "estes",
                      "laurance"       = "laurance",
                      "damania"        = "damania"
                      ))

facet_stats_order_conv <- facet_stats_order_conv %>%
  mutate(facet = 
           fct_recode(facet,
                      "all sp."        = "all",
                      "endemism"       = "endemism",
                      "small-ranged sp."      = "small",
                      "mammals"        = "mam",
                      "birds"          = "bird",
                      "amphibians"     = "amp", 
                      "reptiles"       = "rep",
                      "arith. mean"    = "average",
                      "geom. mean"     = "geometric",
                      "maximum"        = "max",
                      "multiply"       = "multi",
                      "1 km grid"      = "res1",
                      "10 km grid"     = "res10",
                      "110 km grid"    = "res110",
                      "vert. endemism" = "vert_endemism",
                      "estes"          = "estes",
                      "laurance"       = "laurance",
                      "damania"        = "damania"
                      ))

order_jac_w_melt_protect <- order_jac_w_melt_protect %>%
  mutate(facet = fct_recode(facet,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep",
            "arith. mean"    = "average",
            "geom. mean"     = "geometric",
            "maximum"        = "max",
            "multiply"       = "multi",
            "1 km grid"      = "res1",
            "10 km grid"     = "res10",
            "110 km grid"    = "res110",
            "vert. endemism" = "vert_endemism",
            "estes"          = "estes",
            "laurance"       = "laurance",
            "damania"        = "damania"),
         
         pair = fct_recode(pair,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep",
            "arith. mean"    = "average",
            "geom. mean"     = "geometric",
            "maximum"        = "max",
            "multiply"       = "multi",
            "1 km grid"      = "res1",
            "10 km grid"     = "res10",
            "110 km grid"    = "res110",
            "vert. endemism" = "vert_endemism",
            "estes"          = "estes",
            "laurance"       = "laurance",
            "damania"        = "damania")
         )

order_jac_w_melt_conv <- order_jac_w_melt_conv %>%
  mutate(facet = fct_recode(facet,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep",
            "arith. mean"    = "average",
            "geom. mean"     = "geometric",
            "maximum"        = "max",
            "multiply"       = "multi",
            "1 km grid"      = "res1",
            "10 km grid"     = "res10",
            "110 km grid"    = "res110",
            "vert. endemism" = "vert_endemism",
            "estes"          = "estes",
            "laurance"       = "laurance",
            "damania"        = "damania"),
         
         pair = fct_recode(pair,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep",
            "arith. mean"    = "average",
            "geom. mean"     = "geometric",
            "maximum"        = "max",
            "multiply"       = "multi",
            "1 km grid"      = "res1",
            "10 km grid"     = "res10",
            "110 km grid"    = "res110",
            "vert. endemism" = "vert_endemism",
            "estes"          = "estes",
            "laurance"       = "laurance",
            "damania"        = "damania")
         )


# ------------------------------------------------------------------------------ #
# ------------------------------------------------------------------------------ #
# ------------------------------------------------------------------------------ #
# condensed plot - order of conversion
# ------------------------------------------------------------------------------ #
SI_fig_jac_w_order_conv <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_order_conv,
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(order_jac_w_melt_conv, 
                           !facet %in% c("bird_composite", "habitats", "plants"),
                           !pair %in% c("bird_composite", "habitats", "plants")),
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_viridis("Mean Values", discrete = T) # for color blindness

SI_fig_jac_w_order_conv + 
  labs(title = "Similarity of Conversion Order") + 
  coord_cartesian(ylim=c(0.4, 1.0)) + 
  theme(legend.position = "none")

# ------------------------------------------------------------------------------ #
# save:
# ------------------------------------------------------------------------------ #
png(paste0(p_plots, "/si/", "SI_fig_jac_w_order_conv", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_order_conv + 
      labs(title = "Similarity of Conversion Order") + 
      coord_cartesian(ylim=c(0.4, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.9, 0.2, 0.2), "cm"))
  )
dev.off()



# ------------------------------------------------------------------------------ #
# condensed plot - order of protection
# ------------------------------------------------------------------------------ #
SI_fig_jac_w_order_protect <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_order_protect,
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(order_jac_w_melt_protect, 
                           !facet %in% c("bird_composite", "habitats", "plants"),
                           !pair %in% c("bird_composite", "habitats", "plants")),
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_viridis("Mean Values", discrete = T) # for color blindness


SI_fig_jac_w_order_protect + 
  labs(title = "Similarity of Protection Order") + 
  coord_cartesian(ylim=c(0.4, 1.0)) + 
  theme(legend.position = "none")

# ------------------------------------------------------------------------------ #
# save:
# ------------------------------------------------------------------------------ #
png(paste0(p_plots, "/si/", "SI_fig_jac_w_order_protect", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_order_protect + 
      labs(title = "Similarity of Protection Order") + 
      coord_cartesian(ylim=c(0.4, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.9, 0.2, 0.2), "cm"))
  )
dev.off()

```

```{r 6.additional-composites}
# Note: code to create this figure is contained directly within "5_SI.Rmd", in code chunk: "print-composites-fig"
```

```{r 8.bd_jac_w}
# calculate weighted jaccard similarity for bidoiversity inputs themselves

bd_dt_m %>% ncol() 
names(bd_dt_m)
bd_dt_m[, 1:18] %>% dt_to_raster(CRSobj) %T>% plot()

# create dataframe
length(facet_names)

bd_jac_w <- matrix(
  nrow = 15 + 7,  # facets plus composites
  ncol = 15 + 7)
colnames(bd_jac_w) <- facet_names_distill_w_threat[1:22]

bd_jac_w <- data.frame(
  facet = facet_names_distill_w_threat[1:22],
  bd_jac_w
)
bd_jac_w <- bd_jac_w %>% mutate(facet = fct_relevel(facet, 
                                                    facet_names_distill_w_threat[1:22]))
rownames(bd_jac_w) <- facet_names_distill_w_threat[1:22]


# ------------------------------------------------------------------
# calculate weighted jaccard matrix: final codes, with only a subset of stuff
# ------------------------------------------------------------------

tic()
for (group in 0) { # just 1 group of 22 (15 facets plus 7 composites)

  # for the first four: types  
  for(i in 1:4){
    for(j in 1:4){
      bd_jac_w[22*group + i, 22*group + 1 + j] <- bd_dt_m[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: taxonomic groups  
  for(i in 5:8){
    for(j in 5:8){
      bd_jac_w[22*group + i, 22*group + 1 + j] <- bd_dt_m[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: methods
  for(i in 9:12){
    for(j in 9:12){
      bd_jac_w[22*group + i, 22*group + 1 + j] <- bd_dt_m[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next three: resolutions
  for(i in 13:15){
    for(j in 13:15){
      bd_jac_w[22*group + i, 22*group + 1 + j] <- bd_dt_m[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next 7: composites
  for(i in 16:22){
    for(j in 16:22){
      bd_jac_w[22*group + i, 22*group + 1 + j] <- bd_dt_m[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
}
toc() # 




# remove self similarities
bd_jac_w[bd_jac_w == 1] <- NA

object_size(bd_jac_w)
class(bd_jac_w)

# save it to file
fwrite(bd_jac_w, file = fp(p_mod_output, "bd_jac_w.csv"))

# check to make sure the loop worked. 
bd_dt_m[, c("all", "endemism"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
bd_jac_w["all", "endemism"] # need to have the rows named
bd_jac_w %>% filter(facet == "all") %>% select("endemism")
names(bd_jac_w)



# ------------------------------------------------------------------
# melt bd_jac_w ----------------------------------------------------
# ------------------------------------------------------------------
nrow(bd_jac_w)
bd_jac_w_melt <- bd_jac_w %>% 
  mutate(
    comparison = c(
      rep("types", 4),
      rep("taxa", 4),
      rep("methods", 4),
      rep("resolution", 3),
      rep("composites", 7)),
    weight = "bd") %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE)

bd_jac_w_melt <- bd_jac_w_melt %>% 
  mutate(comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all", "bd"))) %>%
  arrange(facet)


fwrite(bd_jac_w_melt, file = fp(p_mod_output, "bd_jac_w_melt.csv"))


# facet_stats_bd


facet_stats_bd <- bd_jac_w_melt %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))



# ------------------------------------------------------------------
# plot the results -------------------------------------------------
# ------------------------------------------------------------------
gg_jac_w_bd <- ggplot(data = filter(facet_stats_bd)) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet (raw biodiversity inputs)") + ylab("Jaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")

gg_jac_w_bd + labs(title = "Similarity between raw biodiversity inputs",
                   caption = "Note: in raw biodiversity inputs, values of 1 indicate high biodiversity. \nTherefore, this analysis assesses similarity of areas of high biodiversity, \nnot areas of conversion (i.e. low biodiversity).")


gg_jac_w_bd_pairs <- ggplot(filter(bd_jac_w_melt#, !comparison %in% c("resolution", "composites")
                                   ), 
                            aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")
gg_jac_w_bd_pairs


# ----------------------------
# save plot, with error bars
# ----------------------------
png(paste0(p_plots, "/ms_v5/", "jac_w_plot_SI_raw_bd_inputs_title", ".png"), 
    width = 6, height = 3.8, units = "in", res = 400)
print(
    gg_jac_w_bd + 
      labs(title = "Similarity between raw biodiversity inputs",
           caption = "Note: in raw biodiversity inputs, values of 1 indicate high biodiversity. \nTherefore, this analysis assesses similarity of areas of high biodiversity, \nnot areas of conversion (i.e. low biodiversity).") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()


# condensed plot
SI_fig_jac_w_bd <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_bd, 
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = bd_jac_w_melt,
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")


# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_bd", ".png"), 
    width = 6, height = 6, units = "in", res = 400)
print(
    SI_fig_jac_w_bd + 
      labs(title = "Similarity between raw biodiversity inputs",
           caption = "Note: in raw biodiversity inputs, values of 1 indicate high biodiversity. \nTherefore, this analysis assesses similarity of areas of high biodiversity, \nnot areas of conversion (i.e. low biodiversity).") + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

```

```{r 9.unconverted_jac}
# comparing the similarity of areas that are *not selected*. 
# ------------------------------------------------------------------
dt_inverse <- (dt_m_convertible[, c("x", "y", grep("_bp$", facet_names, value = TRUE)), 
                                with = FALSE] - 1) * -1
dt_inverse[, x := dt_m$x]
dt_inverse[, y := dt_m$y]

names(dt_inverse) %>% length

inverse_jac_w <- matrix(
  nrow = 15 + 7,  # facets plus composites
  ncol = 15 + 7)
colnames(inverse_jac_w) <- facet_names_distill_w_threat[1:22]

inverse_jac_w <- data.frame(
  facet = facet_names_distill_w_threat[1:22],
  inverse_jac_w
)
inverse_jac_w <- inverse_jac_w %>% mutate(facet = fct_relevel(facet, 
                                                    facet_names_distill_w_threat[1:22]))
rownames(inverse_jac_w) <- facet_names_distill_w_threat[1:22]


# ------------------------------------------------------------------
tic()
for (group in 0) { # 0 groups of 15 

  # for the first four: types  
  for(i in 1:4){
    for(j in 1:4){
      inverse_jac_w[15*group + i, 15*group + 1 + j] <- dt_inverse[, c(2 + 15*group + i, 2 + 15*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: taxonomic groups  
  for(i in 5:8){
    for(j in 5:8){
      inverse_jac_w[15*group + i, 15*group + 1 + j] <- dt_inverse[, c(2 + 15*group + i, 2 + 15*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: methods
  for(i in 9:12){
    for(j in 9:12){
      inverse_jac_w[15*group + i, 15*group + 1 + j] <- dt_inverse[, c(2 + 15*group + i, 2 + 15*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the last three: resolutions
  for(i in 13:15){
    for(j in 13:15){
      inverse_jac_w[15*group + i, 15*group + 1 + j] <- dt_inverse[, c(2 + 15*group + i, 2 + 15*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
}
toc() # 6 sec


tic() 
  for(i in 1:7){
    for(j in 1:7){
      inverse_jac_w[15 + i, 15 + 1 + j] <- dt_inverse[
        , c(2 + 15 + i, 2 + 15 + j), with = FALSE
        ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }

toc() # 5 seconds


# remove self similarities
inverse_jac_w[inverse_jac_w == 1] <- NA


# ------------------------------------------------------------------
# prep and melt
# ------------------------------------------------------------------
nrow(inverse_jac_w)
inverse_jac_w_melt <- inverse_jac_w %>% 
  mutate(
    comparison = c(
      rep("types", 4),
      rep("taxa", 4),
      rep("methods", 4),
      rep("resolution", 3),
      rep("composites", 7)),
    weight = "inverse") %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE) %>% 
  mutate(comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all", "all_lite", "bd"))) %>%
  arrange(facet)

fwrite(inverse_jac_w_melt, file = fp(p_mod_output, "inverse_jac_w_melt.csv"))


# ------------------------------------------------------------------
# facet_stats_inverse
facet_stats_inverse <- inverse_jac_w_melt %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))



# ------------------------------------------------------------------
# plot the results -------------------------------------------------
# ------------------------------------------------------------------
gg_jac_w_inverse <- ggplot(data = filter(facet_stats_inverse#, comparison != "composites"
                                        )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")

gg_jac_w_inverse + ggtitle("Similarity of Areas ~Not~ Selected for Conversion \n(Inverse of Conversion Areas)")


gg_jac_w_inverse_pairs <- ggplot(filter(inverse_jac_w_melt#, !comparison %in% c("resolution", "composites")
                                   ), 
                            aes(x = facet, y = jac_w, fill = pair)) +
  coord_cartesian(ylim = c(0.9, 1.02)) + 
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")
gg_jac_w_inverse_pairs


gg_jac_w_inverse_wt
gg_jac_w_inverse_pairs_wt

# ----------------------------
# save plot, with error bars
# ----------------------------
png(paste0(p_plots, "/ms_v5/", "jac_w_SI_inverse", ".png"), 
    width = 6, height = 3.4, units = "in", res = 400)
print(
    gg_jac_w_inverse + 
      ggtitle("Similarity of Areas ~Not~ Selected for Conversion \n(Inverse of Conversion Areas)") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

png(paste0(p_plots, "/ms_v5/", "jac_w_SI_inverse_w_threat", ".png"), 
    width = 6, height = 3.4, units = "in", res = 400)
print(
    gg_jac_w_inverse_wt + 
      ggtitle("Similarity of Areas ~Not~ Selected for Conversion \n(Inverse of Conversion Areas, with threat)") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

# pairs
png(paste0(p_plots, "/ms_v5/", "jac_w_SI_inverse_pairs", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_jac_w_inverse_pairs + theme(legend.position = "bottom"))
dev.off()

png(paste0(p_plots, "/ms_v5/", "jac_w_SI_inverse_pairs_w_threat", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_jac_w_inverse_pairs_wt + theme(legend.position = "bottom"))
dev.off()



# --------------------------------------------------------
# --------------------------------------------------------
# condensed plot
SI_fig_jac_w_inverse <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_inverse,
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = inverse_jac_w_melt,
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")


# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_inverse", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_inverse + 
      labs(title = "Similarity of Areas Not Selected for Conversion") + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()
```

```{r random_checks}
# does normalizing the facet ensemble means affect the jaccard values? 
# yes, from this test it looks like normalizing the facet ensemble means before running the jaccard similarity causes the Jaccard Similarity to decline

# pre-normalization
test_dt <- as.data.table(facet_r_bp[[c("res1_bp", "res10_bp")]], xy = FALSE, keep.rownames=TRUE)
test_dt <- na.omit(test_dt)
test_dt[, c("res1_bp", "res10_bp"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
test_dt %>% summary()

# normalization
test_dt2 <- as.data.table(normalize(facet_r_bp[[c("res1_bp")]]), xy = FALSE, keep.rownames=TRUE)
test_dt3 <- as.data.table(normalize(facet_r_bp[[c("res10_bp")]]), xy = FALSE, keep.rownames=TRUE)

identical(na.omit(test_dt3), agroEcoTradeoff::standardize(test_dt[, 2]))

test_dt2 <- na.omit(cbind(test_dt2, test_dt3))
test_dt2 %>% summary()
test_dt2[, c("res1_bp", "res10_bp"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]


filter(facet_stats, weight == "bp") %>% print(n = 21)

jac_w_melt %>% filter(weight == "bp", comparison %in% c("methods", "resolution")) #%>%  select(jac_w) %>%  summary()


# normalize the rasters before running the similarities:
dt_norm_pre <- dt_m_convertible[, 1:2]
dt_norm_pre <- cbind(dt_norm_pre, dt_m_convertible[, grep("_bp$", names(dt_m_convertible), value = TRUE), with = FALSE])
dt_norm <- dt_norm_pre[, lapply(.SD, standardize)]
dt_norm
dt_norm[, x := dt_norm_pre$x]
dt_norm[, y := dt_norm_pre$y]

# now, run the jac_w

norm_jac_w <- matrix(
  nrow = 22,  # facets plus composites
  ncol = 22)
colnames(norm_jac_w) <- facet_names_distill_w_threat[1:22]

norm_jac_w <- data.frame(
  facet = facet_names_distill_w_threat[1:22],
  norm_jac_w
)
norm_jac_w <- norm_jac_w %>% mutate(facet = fct_relevel(facet, 
                                                    facet_names_distill_w_threat[1:22]))
rownames(norm_jac_w) <- facet_names_distill_w_threat[1:22]


# ------------------------------------------------------------------
tic()
for (group in 0) { # just 1 group of 22 (15 facets plus 7 composites)

  # for the first four: types  
  for(i in 1:4){
    for(j in 1:4){
      norm_jac_w[22*group + i, 22*group + 1 + j] <- dt_norm[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: taxonomic groups  
  for(i in 5:8){
    for(j in 5:8){
      norm_jac_w[22*group + i, 22*group + 1 + j] <- dt_norm[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: methods
  for(i in 9:12){
    for(j in 9:12){
      norm_jac_w[22*group + i, 22*group + 1 + j] <- dt_norm[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next three: resolutions
  for(i in 13:15){
    for(j in 13:15){
      norm_jac_w[22*group + i, 22*group + 1 + j] <- dt_norm[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next 7: composites
  for(i in 16:22){
    for(j in 16:22){
      norm_jac_w[22*group + i, 22*group + 1 + j] <- dt_norm[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
}
toc() # 



# remove self similarities
norm_jac_w[norm_jac_w == 1] <- NA

# ------------------------------------------------------------------
# prep and melt
# ------------------------------------------------------------------
nrow(norm_jac_w)
norm_jac_w_melt <- norm_jac_w %>% 
  mutate(
    comparison = c(
      rep("types", 4), # formerly 4
      rep("taxa", 4),
      rep("methods", 4),
      rep("resolution", 3),
      rep("composites", 7)),
    weight = "norm") %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE) %>% 
  mutate(comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all", "bd", "norm"))) %>%
  arrange(facet)

fwrite(norm_jac_w_melt, file = fp(p_mod_output, "norm_jac_w_melt.csv"))


# ------------------------------------------------------------------
# facet_stats_norm
facet_stats_norm <- norm_jac_w_melt %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))



# ------------------------------------------------------------------
# plot the results -------------------------------------------------
# ------------------------------------------------------------------
# condensed plot
SI_fig_jac_w_norm <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_norm,
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = norm_jac_w_melt,
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")


# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_norm", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_norm + 
      labs(title = "Similarities, after normalizing each facet raster (0-1)") + 
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

```




```{r explore-endemism-richness}
# what drives the vert_endemism conversion map? 
# is it birds, or the order of combining layers? Let's look at plots and histograms

# Note, this was informed by discussions that took place during peer review.

par(mfrow=c(2, 3))

plot(vert_r$endemism_richness$norm_sum, main = "vert_endemism")
plot(vert_r$endemism_richness$mam, main = "mam_endemism")
plot(vert_r$endemism_richness$bird, main = "bird_endemism")
plot(vert_r$endemism_richness$amp, main = "amp_endemism")
plot(vert_r$endemism_richness$rep, main = "rep_endemism")

# explore rep map more
ext <- drawExtent(show = TRUE, col = "red")
plot(vert_r$endemism_richness$rep, main = "rep_endemism", ext = ext)
1/0.1001044 # = 9.9, corresponding to the range of Acontias schmitzi: http://reptile-database.reptarium.cz/species?genus=Acontias&species=schmitzi
plot(NULL)

dev.off()

# maximum cell values
cellStats(vert_r$endemism_richness$mam, "max") # 0.003901685
cellStats(vert_r$endemism_richness$bird, "max") # 0.000462951
cellStats(vert_r$endemism_richness$amp, "max") # 0.002567186
cellStats(vert_r$endemism_richness$rep, "max") # 0.1001044

# histograms
ncell(vert_r$endemism_richness$norm_sum)
maxpixels <- 50000000
par(mfrow=c(2, 4))
hist(vert_r$endemism_richness$mam, 
     main = "mam_endemism", maxpixels = maxpixels)
hist(vert_r$endemism_richness$bird, 
     main = "bird_endemism", maxpixels = maxpixels)
hist(vert_r$endemism_richness$amp, 
     main = "amp_endemism", maxpixels = maxpixels)
hist(vert_r$endemism_richness$rep, 
     main = "rep_endemism", maxpixels = maxpixels)
hist(vert_r$endemism_richness$norm_sum, 
     main = "vert_endemism", maxpixels = maxpixels)
plot(vert_r$endemism_richness$norm_sum, main = "vert_endemism")
plot(vert_r$endemism_richness$mam, main = "mam_endemism")
plot(vert_r$endemism_richness$bird, main = "bird_endemism")

dev.off()


# mam
plot(vert_r$endemism_richness$mam, 
     main = "mam_endemism", maxpixels = maxpixels)
hist(vert_r$endemism_richness$mam, 
     main = "mam_endemism", maxpixels = maxpixels)

hist(normalize(vert_r$endemism_richness$mam), 
     main = "mam_endemism", maxpixels = maxpixels)
hist(log(vert_r$endemism_richness$mam), 
     main = "mam_endemism", maxpixels = maxpixels)


# rep
hist(vert_r$endemism_richness$rep, 
     main = "rep_endemism", maxpixels = maxpixels)
hist(normalize(vert_r$endemism_richness$rep), 
     main = "rep_endemism", maxpixels = maxpixels)
hist(log(vert_r$endemism_richness$rep), 
     main = "rep_endemism", maxpixels = maxpixels)

# ------------------------------------------------ #
# note about what's driving the rep_endemism map
# ------------------------------------------------ #

load(file = "/Users/christophercrawford/Google_Drive/_Projects/Zambia/agroEcoTradeoff/external/data_new/1_IUCN_dev/gard_prep.RData", verbose = TRUE) # contains gard_prep, which is gard, made valid, joined to IUCN table, and prepped for use in small species, endemism, etc. This entailed joining the table of red list categories, changing some of the column names, adding a column for area, totalling area for parts of the range we're using, and adding a column ranking the range size to allow things to be subset for small ranged species analyses.

load(file = "/Users/christophercrawford/Google_Drive/_Projects/Zambia/agroEcoTradeoff/external/data_new/1_IUCN_dev/gard_list.RData", verbose = TRUE)
gard_list$filtered_small %>%
  st_drop_geometry() %>%
  filter(range_size_quantile < 0.5) %>% # do <= if nrow is even, and < if nrow is odd.
  arrange(area_km2)

# Acontias schmitzi is a lizard endemic to Zambia, with a tiny range of basically 10 km2. It's only locality is from near Mongu, at 15°23.015’S, 23°23.729’E. 
# see: http://reptile-database.reptarium.cz/species?genus=Acontias&species=schmitzi

# plot
plot(vert_r$endemism_richness$rep, main = "rep_endemism")

ext <- drawExtent(show = TRUE, col = "red")
plot(vert_r$endemism_richness$rep, main = "rep_endemism", ext = ext)

# maximum cell values
cellStats(vert_r$endemism_richness$rep, "max") # 0.1001044
hist(vert_r$endemism_richness$rep, 
     main = "rep_endemism", maxpixels = maxpixels)


1/0.1001044 # = 9.9, corresponding to the range of Acontias schmitzi: http://reptile-database.reptarium.cz/species?genus=Acontias&species=schmitzi

# if you remove the values associated with Acontias schmitzi, the distribution of values looks much more "reasonable"
hist(vert_r$endemism_richness$rep[vert_r$endemism_richness$rep < 0.09])
max(vert_r$endemism_richness$rep[vert_r$endemism_richness$rep < 0.09]) # 0.000538
```


# Figures

## Manuscript figures
The final figures for the manuscript are:

Figure 1 - methods schematic (see ppt)
Figure 2 - ensemble rasters (chunk: "*ms_fig_2_raster_bp")
Figure 3 - jaccard similarity (chunk: "*ms_fig_3_jaccard_similarity")
Figure 4 - comparing production levels (chunk: "*ms_fig_4_z50-bp-comp")

```{r new-labels}
facet_stats %>% 
  filter(weight == "bp") %>%
  select(facet, comparison)

levels(facet_stats$comparison)
levels(facet_stats$facet)

facet_stats <- facet_stats %>%
  mutate(facet = 
           fct_recode(facet,
                      "all sp."        = "all",
                      "endemism"       = "endemism",
                      "small-ranged sp."      = "small",
                      "mammals"        = "mam",
                      "birds"          = "bird",
                      "amphibians"     = "amp", 
                      "reptiles"       = "rep",
                      "arith. mean"    = "average",
                      "geom. mean"     = "geometric",
                      "maximum"        = "max",
                      "multiply"       = "multi",
                      "1 km grid"      = "res1",
                      "10 km grid"     = "res10",
                      "110 km grid"    = "res110",
                      "vert. endemism" = "vert_endemism",
                      "estes"          = "estes",
                      "laurance"       = "laurance",
                      "damania"        = "damania"
                      ))

jac_w_melt <- jac_w_melt %>%
  mutate(facet = fct_recode(facet,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep",
            "arith. mean"    = "average",
            "geom. mean"     = "geometric",
            "maximum"        = "max",
            "multiply"       = "multi",
            "1 km grid"      = "res1",
            "10 km grid"     = "res10",
            "110 km grid"    = "res110",
            "vert. endemism" = "vert_endemism",
            "estes"          = "estes",
            "laurance"       = "laurance",
            "damania"        = "damania"),
        
         pair = fct_recode(pair,
            "all sp."        = "all",
            "endemism"       = "endemism",
            "small-ranged sp."      = "small",
            "mammals"        = "mam",
            "birds"          = "bird",
            "amphibians"     = "amp", 
            "reptiles"       = "rep",
            "arith. mean"    = "average",
            "geom. mean"     = "geometric",
            "maximum"        = "max",
            "multiply"       = "multi",
            "1 km grid"      = "res1",
            "10 km grid"     = "res10",
            "110 km grid"    = "res110",
            "vert. endemism" = "vert_endemism",
            "estes"          = "estes",
            "laurance"       = "laurance",
            "damania"        = "damania")
      )


# new labels, in the format c(old = "new")
new_labels_lookup <- c(
  all = "all sp.",
  endemism = "endemism",
  threat = "threatened sp.",
  small = "small-ranged sp.",
  mam = "mammals",
  bird = "birds",
  amp = "amphibians",
  rep = "reptiles",
  average = "arith. mean",
  geometric = "geom. mean" ,
  max = "maximum",
  multi = "multiply" ,
  res1 = "1 km grid",
  res10 = "10 km grid",
  res110 = "110 km grid",
  vert_endemism = "vert. endemism",
  estes = "estes",
  laurance = "laurance",
  damania = "damania"
  )

```

```{r color-palettes}
# primary mapping palettes
# terrain.colors(50, rev = TRUE) # original plotting colors
map_colors <- c("#F2F2F2", viridis(50, direction = -1))  # colorblindness-safe

map_colors_rev <- c("#F2F2F2", viridis(50, direction = 1)) # unused



# cc_plot_things:

load(file = fp(p_ZA,"parks_roads.rda"), verbose = TRUE) # includes roads (a SpatialLinesDataFrame),
# pas (SpatialPolygonsDataFrame, a shapefile that includes both national parks and GMAs), and
# zambia (SpatialPolygonsDataFrame, outline of Zambia)
msk_shp <- readOGR(fp(p_datnew,"msk.shp")) %>%
  spTransform(CRS("+proj=aea +lat_1=20 +lat_2=-23 +lat_0=0 +lon_0=25 +x_0=0 +y_0=0 +ellps=WGS84 +datum=WGS84 +units=m +no_defs"))
rm(zambia, roads)

# plot colors

pacols <- c("grey80", "grey70") # colors for NPs and GMAs
col_pas <- c("grey80", "grey70")
col_pas_all <- col_pas[pas$type]

col_overlap <- c(
  "grey90", # grey # no conversion
#  "#1F78B4", # blue # Mod 1 only
  "#FF7F00", # orange # Mod 1 only
  "#FDBF6F", # yellow # Mod 2 only
#  "#E31A1C", # red # Mod 2 only
  "#33A02C" # green # Both Models
) # light purple # both soy

#display.brewer.all(n=9, type="all", select=NULL, exact.n=TRUE, colorblindFriendly=FALSE)

# old colors:

## main color scheme for plots (0 = green / high bd, 1 = pink / convert)
# col_main <- colorRampPalette(brewer.pal(n=11,name='PiYG'))(100) #pink-yellow-green
# col_main2 <- col_main[15:95] # slightly muted on both ends, for s4,5,6,7
# col_main3 <- col_main[16:100] # toned down pink, for s8
# col_main_legend <- c(col_main[15],col_main[85])
#
# col_grad0 <- colorRampPalette(brewer.pal(n=9,name='YlOrRd'))(100) # for graduated plot of tradeoff_mod results rasters
# col_grad <- col_grad0[1:75] # more mellow red at the top end
# col_grad1 <- col_grad0[30:100] # darker yellow at the bottom
# col_grad2 <- col_grad
# col_grad2[76] <- "#662506"



#col_overlap <- rev(brewer.pal(n=9,name='RdYlGn')) # for diverging plot of overlapping results rasters
#col_overlap[1] <- "grey90" # removing the dark green color from the front

#col_overlap <- brewer.pal(n=9,name='Paired')
# col_overlap <- c(
#   "grey90", # grey # no conversion
#   "#1F78B4", # blue # estes maize only
#   "#B2DF8A", # light green # estes soy only
#   "#E31A1C", # red # laurance maize only
#   "#33A02C", # green # both maize
#   "#FF7F00", # orange # L maize, E soy
#   "#FDBF6F", # yellow # laurance soy only
#   "#FB9A99", # pink # Laurance soy, Estes maize
#   "#CAB2D6") # light purple # both soy
#
# col_overlap_maize <- c("grey90","#fec44f","#e31a1c","#41ab5d") # yellow (E), red (L), green (overlap)
# #col_overlap_maize <- c("grey90",brewer.pal(n=3,name='Paired'))

```


```{r ms_fig_2_raster_bp}
facet_r_bp %>% names
names(facet_r_bp) <- gsub("_bp", "", names(facet_r_bp))
facet_r_bp <- dropLayer(facet_r_bp, 3)

facet_r_z50 %>% names
names(facet_r_z50) <- gsub("_z50", "", names(facet_r_z50))
facet_r_z50 <- dropLayer(facet_r_z50, 3)

facet_r_bp
eval(parse(text = paste0("facet_r_","bp")))[[1:3]]


# ----------------------------------------
# put the main figure together, for bp
# ----------------------------------------

# write function to save facet maps
cc_print_facet_maps <- function(weight, drop_threat = TRUE, pixels = 5000000,
                                custom_colors = map_colors,
                                label = "") {
  
  # for producing manuscript figure 2, and corresponding figures for "all" and "z50" weighting specifications
  
  # load in the correct raster brick
  brick <- eval(parse(text = paste0("facet_r_", weight)))
  names(brick) <- gsub(paste0("_", weight), "", names(brick))
  if (drop_threat) {brick <- dropLayer(brick, which(names(brick) == "threat"))}
  
  
  # make the components of the plot
  p1 <- gplot(brick[[c("mam", "bird", "amp", "rep")]], maxpixels = pixels) + 
        geom_raster(aes(fill = value)) +
        facet_wrap(~ variable, nrow = 1, labeller = labeller(variable = new_labels_lookup)) + 
        scale_fill_gradientn(colors = custom_colors, na.value = "white", limits = c(0, 1)) + 
        labs(y = "Taxonomic Groups", x = NULL) + 
        theme(rect = element_blank(), line = element_blank(), 
              axis.line = element_blank(), 
              axis.ticks = element_blank(), 
              axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
              legend.position = "none") + 
        coord_equal()
  
  p2 <- gplot(brick[[c("all", "endemism", "small")]], maxpixels = pixels) + # or facet_r[[comparison_names$types]] for just the four ensemble means
        geom_raster(aes(fill = value)) +
        facet_wrap(~ variable, nrow = 1, labeller = labeller(variable = new_labels_lookup)) + 
        scale_fill_gradientn(colors = custom_colors, na.value = "white", limits = c(0, 1)) + 
        labs(y = "Richness Metrics", x = NULL) + 
        theme(rect = element_blank(), line = element_blank(), 
              axis.line = element_blank(), axis.ticks = element_blank(), 
              axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
              legend.position = "none") + 
        coord_equal()
      
  p3 <- gplot(brick[[c("average", "geometric", "max", "multi")]], maxpixels = pixels) + 
        geom_raster(aes(fill = value)) +
        facet_wrap(~ variable, nrow = 1, labeller = labeller(variable = new_labels_lookup)) + 
        scale_fill_gradientn(colors = custom_colors, na.value = "white", limits = c(0, 1)) + 
        labs(y = "Methods", x = NULL) + 
        theme(rect = element_blank(), line = element_blank(), 
              axis.line = element_blank(), axis.ticks = element_blank(), 
              axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
              legend.position = "none") + 
        coord_equal()
      
  p4 <- gplot(brick[[c("res1", "res10", "res110")]], maxpixels = pixels) + 
        geom_raster(aes(fill = value)) +
        facet_wrap(~ variable, nrow = 1, labeller = labeller(variable = new_labels_lookup)) + 
        scale_fill_gradientn(colors = custom_colors, na.value = "white", limits = c(0, 1)
                             ) + 
        labs(y = "Resolution", x = NULL) + 
        theme(rect = element_blank(), line = element_blank(), 
              axis.line = element_blank(), axis.ticks = element_blank(), 
              axis.ticks.length = unit(0, "pt"), axis.text = element_blank(), legend.position = "none"
              ) + 
        coord_equal()
      
  p5 <- gplot(brick[[c("vert_endemism", #"plants", 
                       "estes", "laurance", #"habitats", "bird_composite", 
                       "damania")]], 
              maxpixels = pixels) + 
        geom_raster(aes(fill = value)) +
        facet_wrap(~ variable, nrow = 1, labeller = labeller(variable = new_labels_lookup)) + 
        scale_fill_gradientn(colors = custom_colors, na.value = "white", limits = c(0, 1)) + 
        labs(y = "Indices", x = NULL) + 
        theme(rect = element_blank(), line = element_blank(), 
              axis.line = element_blank(), axis.ticks = element_blank(), 
              axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
              legend.title = element_blank()) + 
        coord_equal()
      
      
  # p6 <- gplot(brick[[c("plants", "habitats", "bird_composite")]], maxpixels = pixels) + 
  #       geom_raster(aes(fill = value)) +
  #       facet_wrap(~ variable, nrow = 1) + 
  #       scale_fill_gradientn(colors = custom_colors, na.value = "white") + 
  #       labs(y = "Composites", x = NULL) + 
  #       theme(rect = element_blank(), line = element_blank(), 
  #             axis.line = element_blank(), axis.ticks = element_blank(), 
  #             axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  #       coord_equal()
  
  # start pdf call here. 
  
  if (weight == "bp") {
    pdf(paste0(p_plots, "/ms_final/","ms_fig_2_facet_r_", weight, label, ".pdf"),
      width = 8, height = 5)
  }
  
  
  if (weight == "z50" | weight == "all") {
    png(paste0(p_plots, "/si/","SI_fig_facet_r_", weight, label, ".png"),
      width = 8, height = 5, units = "in", res = 400)
  }
  
  print(plot_grid(
    plot_grid(p5, nrow = 1, labels = c("a")),
    plot_grid(p1, NULL, p2, nrow = 1, labels = c("b", "", "c"), rel_widths = c(4, 0.1, 3.1)), 
    plot_grid(p3, NULL, p4, nrow = 1, labels = c("d", "", "e"), rel_widths = c(4, 0.1, 3.1)),
    ncol = 1, rel_heights = c(1.2, 1, 1)))
  
  dev.off()
  
  cat("Success! Saved facet ensemble maps for weight:", weight)
}

cc_print_facet_maps(weight = "bp", custom_colors = map_colors)
cc_print_facet_maps(weight = "bp", custom_colors = map_colors_rev, label = "_rev", pixels = 5000000) # trying the color palette reversed
cc_print_facet_maps(weight = "all", custom_colors = map_colors)
cc_print_facet_maps(weight = "z50", custom_colors = map_colors)
```


```{r ms_fig_3_jaccard_similarity}
ms_fig_jac_w_bp <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "bp"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "bp"), 
             mapping = aes(x = facet, y = jac_w), #color = "black", show.legend = FALSE,
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x",
             labeller = labeller(new_labels_lookup))

ms_fig_jac_w_bp + ggtitle("Pure biodiversity (100% weight on bd, with average yields)")
ms_fig_jac_w_bp + scale_colour_viridis("Mean Values", discrete = T) # for color blindness


gg_jac_w_bp_pairs <- ggplot(filter(jac_w_melt, weight == "bp"), 
                            aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_bp_pairs + scale_fill_viridis("Mean Values", discrete = T) # manually placed in SI, see chunk: "pairwise-jaccard"


# save:
pdf(paste0(p_plots, "/ms_final/", "ms_fig_3_jac_w_bp", ".pdf"), 
    width = 7, height = 4#, units = "in", res = 400
    )
print(
    ms_fig_jac_w_bp + 
      scale_colour_viridis("Mean Values", discrete = T) +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(#legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()



# ------------------- #
# combo jac_w & nnd:
png(paste0(p_plots, "/ms_final/", "ms_fig_combo_jac_w_nnd_bp", ".png"), 
    width = 7, height = 6, units = "in", res = 400)

plot_grid(
  plot_grid(
    ms_fig_jac_w_bp + 
      coord_cartesian(ylim=c(0, 1.0)) +
      theme(strip.background = element_blank(), strip.text.x = element_blank(),
            axis.title.x = element_blank(), axis.text.x = element_blank(), legend.position = "none"),
    gg_nnd + 
      # coord_cartesian(ylim=c(0, 200))
      ylab("Mean Distance to \nNearest Neight (km)") + 
      theme(legend.position = "none"),
    ncol = 1, align = "v", rel_heights = c(1, 1.2), labels = "auto"
    ),
  get_legend(ms_fig_jac_w_bp + theme(legend.position = "right")),
  ncol = 2, rel_widths = c(1, 0.2)
  )

dev.off()
```

```{r ms_fig_4_z50-bp-comp, fig.cap = '(ref:caption-z50-bp-comparison)', fig.width = 7, fig.height = 4, out.width  = "1\\textwidth"}

# caption from when this was in the SI:
# (ref:caption-z50-bp-comparison) Comparing the effect of production target on similarity results. Our main analysis (*bp*) assumes a production target of ~5% of Zambia. For comparison, we show model results assuming a much larger production target (*z50*), which converts ~50% of Zambia. Both model runs place 100% model weight on biodiversity and using average, constant yields.

# add in this line to the caption, if I add order back in...
# *order* refers to similarity of the order in which cells are selected for conversion (or protection) based on biodiversity value.


# -------------------------------------------------------
# create gg object:
# -------------------------------------------------------
gg_fig4 <- ggplot() +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "bp"),
             mapping = aes(x = facet, y = mean_jac_w, 
                           group = comparison, color = weight), 
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "bp"), 
             mapping = aes(x = facet, y = jac_w, color = weight), 
             #color = "black",
             #show.legend = FALSE,
             alpha = 0.25) + 
  
  geom_point(data = filter(facet_stats, weight == "z50"),
             mapping = aes(x = facet, y = mean_jac_w, 
                           group = comparison, color = weight), size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "z50"), 
             mapping = aes(x = facet, y = jac_w, color = weight), #color = "black", show.legend = FALSE,
             alpha = 0.25) + 

  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x",
             space = "free_x") +
  scale_colour_viridis(name = "Production \nTarget",
                       labels = c("bp" = "5% of Zambia",
                                "z50" = "50% of Zambia"),
                       # labels = c("bp" = "\n5% of Zambia \n(100% bd, \nmean yield, bp) \n ",
                       #          "z50" = "\n50% of Zambia \n(100% bd, \nmean yield, z50) \n "),
                       discrete = T, begin = 0, end = 0.8
                       ) +
  coord_cartesian(ylim=c(0, 1.0))


# -------------------------------------------------------
# save version for MS
# -------------------------------------------------------
pdf(paste0(p_plots, "/ms_final/", "ms_fig_4_robustness", ".pdf"),
    width = 7, height = 4#, units = "in", res = 400
    )
gg_fig4

dev.off()


# -------------------------------------------------------
# save version for SI
# -------------------------------------------------------
png(paste0(p_plots, "/si/", "ms_fig_4_robustness_SI", ".png"), # for SI
    width = 7, height = 4, units = "in", res = 400
    )
gg_fig4 + scale_colour_viridis(name = "Production \nTarget",
                               labels = c("bp" = "\n5% of Zambia \n(100% bd, \nmean yield, bp) \n ",
                                          "z50" = "\n50% of Zambia \n(100% bd, \nmean yield, z50) \n "), 
                               discrete = T, begin = 0, end = 0.8)
dev.off()

```

```{r SI_jac_w}
# Figures for use in SI:
# These replicate Figure 3 but for specific weighting specifications,
# showing the jaccard similarity across decision categories

# --------------------------------------------------------
# b ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_b <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "b"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "b"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_viridis("Mean Values", discrete = T) # for color blindness

# save:
png(paste0(p_plots, "/si/", "SI_fig_jac_w_b", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_b + 
      ggtitle("100% weight on biodiversity, accurate (dynamic) yields") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.9, 0.2, 0.2), "cm"))
  )
dev.off()



# --------------------------------------------------------
# z50 ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_z50 <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "z50"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "z50"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_viridis("Mean Values", discrete = T) # for color blindness

# save:
png(paste0(p_plots, "/si/", "SI_fig_jac_w_z50", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_z50 + 
      labs(title = "Converting 50% of Zambia", 
       subtitle = "100% weight on biodiversity, mean yields") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.9, 0.2, 0.2), "cm"))
  )
dev.off()

# --------------------------------------------------------
# by ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_by <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "by"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "by"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_viridis("Mean Values", discrete = T) # for color blindness

# save:
png(paste0(p_plots, "/si/", "SI_fig_jac_w_by", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_by + 
      labs(title = "Incorporating Yields", 
       subtitle = "50% weight on yield, 50% on biodiversity") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.9, 0.2, 0.2), "cm"))
  )
dev.off()

# --------------------------------------------------------
# bc ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_bc <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "bc"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "bc"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_viridis("Mean Values", discrete = T) # for color blindness

# save:
png(paste0(p_plots, "/si/", "SI_fig_jac_w_bc", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_bc + 
      labs(title = "Incorporating Carbon", 
       subtitle = "50% weight on carbon loss, 50% on biodiversity") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.9, 0.2, 0.2), "cm"))
  )
dev.off()

# --------------------------------------------------------
# bt ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_bt <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "bt"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "bt"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_viridis("Mean Values", discrete = T) # for color blindness

# save:
png(paste0(p_plots, "/si/", "SI_fig_jac_w_bt", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_bt + 
      labs(title = "Incorporating Travel Cost", 
       subtitle = "50% weight on Travel Cost, 50% on biodiversity") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.9, 0.2, 0.2), "cm"))
  )
dev.off()



# --------------------------------------------------------
# byct ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_byct <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "byct"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "byct"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_viridis("Mean Values", discrete = T) # for color blindness

# save:
png(paste0(p_plots, "/si/", "SI_fig_jac_w_byct", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_byct + 
      ggtitle("Equal weights on biodiversity, yield, carbon, and travel cost") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.9, 0.2, 0.2), "cm"))
  )
dev.off()

# --------------------------------------------------------
# all ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_all <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "all"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "all"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_viridis("Mean Values", discrete = T) # for color blindness

# save:
png(paste0(p_plots, "/si/", "SI_fig_jac_w_all", ".png"), 
    width = 7, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_all + 
      ggtitle("Similarity between facets, averaged across all model weights") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.9, 0.2, 0.2), "cm"))
  )
dev.off()


```



## Raster plots:

```{r SI-print-basic-conv-maps}
# --------------------------------------------------------------------------------------------------------
# This function plots all of the conversion maps for each bd input run, for the different model specifications
# in the current iteration, it amounts to a 7 x 8 grid of 56 plots, including the reference plots.
#
# See the next chunk for all conversion maps, shown by decision category, 
# including the raw biodiversity input, and a distribution of the values.
#
# These are produced at 1 km2 resolution for illustrative purposes only.
# These are referenced to in the SI in two places: 
# Conversion maps for "bp" in this format in Appendix Section S1.4 and S1.5
#
# See Appendix Section S3.1 for the rest of the weighting specifications:
# --------------------------------------------------------------------------------------------------------

save_basic_conv_plots_all <- function(runs, i, tag, fig_width = 12, fig_height = 13,
                                      custom_colors = map_colors) {
  
  png(paste0(p_plots, "/si/conv_maps/", "basic_conv_maps_", names(conv_r)[i], tag, ".png"),    
      width = fig_width, height = fig_height, units = "in", res = 300)
  
  par(mfrow=c(6,7), mar=c(1,1,2,1), oma = c(1, 1, 1, 1))
  
  for (j in runs) {
    plot(conv_r[[i]][[j]], 
         main = paste0(j, "_", names(conv_r[i])),
         axes = FALSE, legend = FALSE, box = FALSE,
         col = custom_colors)
    
    plot(pas, col = col_pas_all, border = "gray", add=TRUE)
    #legend("bottomright", legend= c("GMA", "Nat'l Park"), fill=col_pas, cex = 1.1, bty = "n")
    plot(msk_shp, add = TRUE)
    
  }
  
  # add standalone legend at the end
  plot.new() # must add a new plot window
  plot(conv_r[[1]][[1]], col = map_colors,
     legend.only = TRUE,
     legend.width = 3,
     legend.shrink = 1.4, cex = 5,
     smallplot=c(0.2, 0.35, 0.15, 0.85))#; par(mar = par("mar")) 
  # small plot works as follows:
  # smallplot=c(min % from left, max % from left, min % from bottom, max % from bottom).
  
  dev.off()
}

# 
# # test on just i = 1
# save_basic_conv_plots_all(i = 1, runs = runs_1, tag = "_1")
# save_basic_conv_plots_all(i = 1, runs = runs_10, tag = "_10")
# save_basic_conv_plots_all(i = 1, runs = runs_110, tag = "_110")
# 


for (i in 1:7) { 
  save_basic_conv_plots_all(i = i, runs = runs_1, tag = "_1")
  save_basic_conv_plots_all(i = i, runs = runs_10, tag = "_10")
  save_basic_conv_plots_all(i = i, runs = runs_110, tag = "_110")
  }

```

```{r SI-print-bd-input-maps}
save_bd_input_plots <- function(runs = runs_1, tag = "_1", fig_width = 12, fig_height = 13,
                                custom_colors = map_colors) {
  png(paste0(p_plots, "/si/", "bd_input_maps", tag, ".png"),
      width = fig_width, height = fig_height, units = "in", res = 300)

  par(mfrow=c(6,7), mar=c(1,1,2,1), oma = c(1, 1, 1, 1))
  for (j in runs) {
    plot(bd_inputs_brick[[j]],
         main = names(bd_inputs_brick[[j]]),
         axes = FALSE, legend = FALSE, box = FALSE,
         col = custom_colors)

    #plot(pas, col = col_pas_all, border = "gray", add=TRUE)
    #legend("bottomright", legend= c("GMA", "Nat'l Park"), fill=col_pas, cex = 1.1, bty = "n")
    plot(msk_shp, add = TRUE)

  }
  
  # add standalone legend at the end
  plot.new() # must add a new plot window
  plot(bd_inputs_brick[[runs_1[8]]], col = map_colors,
     legend.only = TRUE,
     legend.width = 3,
     legend.shrink = 1.4, cex = 5,
     smallplot=c(0.2, 0.35, 0.15, 0.85)); par(mar = par("mar")) 
  # small plot works as follows:
  # smallplot=c(min % from left, max % from left, min % from bottom, max % from bottom).

  dev.off()
}




save_bd_input_plots(runs = runs_1, tag = "_1")
save_bd_input_plots(runs = runs_10, tag = "_10")
save_bd_input_plots(runs = runs_110, tag = "_110")
```


```{r SI-conv-with-dist-by-group}
# --------------------------------------------------------------------------------------------------------
# This chunk saves figures of modeled conversion maps, producing two figures for each decision category.
# The first includes the distribution of values in the biodiversity inputs, the raw biodiversity inputs themselves,
# and three weighting specifications: bp, b, and z50. 
# The second figure includes the b, and the remaining four weighting scenarios (by, bc, bt, and byct).

# These are produced at 1 km2 resolution for illustrative purposes only.
# See Appendix Section S3.2
# --------------------------------------------------------------------------------------------------------
indices <- 1:4

save_conv_plots_by_category <- function(i, runs = runs_1, indices = 1:4, tag = "",
                                fig_width = 7, fig_height = 10, pixels = 100000) {
  row_density <- densityplot(conv_r$bd[[runs[indices]]], layout = c(4, 1))
  # row_1 <- histogram(bd_dt_r[[ensembles_list[[2]]]], layout = c(4, 1))

  row_bd_raw <- gplot(conv_r$bd[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = map_colors, na.value = "white") + 
    labs(y = "Raw BD Inputs", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_bp <- gplot(conv_r$bp[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = map_colors, na.value = "white") + 
    labs(y = "Pure Biodiversity \n100% weight, mean yields", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_b <- gplot(conv_r$b[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = map_colors, na.value = "white") + 
    labs(y = "100% weight on bd \nvariable yields", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_by <- gplot(conv_r$by[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = map_colors, na.value = "white") + 
    labs(y = "50% weight on bd,\n50% yield", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_bc <- gplot(conv_r$bc[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = map_colors, na.value = "white") + 
    labs(y = "50% weight on bd,\n50% carbon", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_bt <- gplot(conv_r$bt[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = map_colors, na.value = "white") + 
    labs(y = "50% weight on bd,\n50% travel cost", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_byct <- gplot(conv_r$byct[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = map_colors, na.value = "white") + 
    labs(y = "equal weights", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_z50 <- gplot(conv_r$z50[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = map_colors, na.value = "white") + 
    labs(y = "Pure biodiversity \n convert 50%", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  
  png(paste0(p_plots, "/si/conv_maps_by_category/", tag, 
             "_conv_maps.png"),    
      width = fig_width, height = fig_height, 
      units = "in", res = 300)
  # pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
  #            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
  print(
    plot_grid(row_density, row_bd_raw, row_bp, row_b, row_z50, NULL,
              ncol = 1, rel_heights = c(1.5, 1, 1, 1, 1, 0.1))
    )
  dev.off()
  
  png(paste0(p_plots, "/si/conv_maps_by_category/", tag, 
             "_conv_maps2.png"),    
      width = fig_width, height = fig_height, 
      units = "in", res = 300)
  # pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
  #            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
  print(
    plot_grid(row_b, row_by, row_bc, row_bt, row_byct, NULL,
              ncol = 1, rel_heights = c(1, 1, 1, 1, 1, 0.1))
    )
  dev.off()
}





# --------------------------------------------------------------------------------------------------------
# Save plots:
# --------------------------------------------------------------------------------------------------------

tic()
# types
save_conv_plots_by_category(runs = runs_1, indices = 1:4, tag = "types_1")
save_conv_plots_by_category(runs = runs_10, indices = 1:4, tag = "types_10")
save_conv_plots_by_category(runs = runs_110, indices = 1:4, tag = "types_110")

# taxa_all
save_conv_plots_by_category(runs = runs_1, indices = 5:8, tag = "taxa_all_1")
save_conv_plots_by_category(runs = runs_10, indices = 5:8, tag = "taxa_all_10")
save_conv_plots_by_category(runs = runs_110, indices = 5:8, tag = "taxa_all_110")

# taxa_endemism
save_conv_plots_by_category(runs = runs_1, indices = 10:13, tag = "taxa_endemism_1")
save_conv_plots_by_category(runs = runs_10, indices = 10:13, tag = "taxa_endemism_10")
save_conv_plots_by_category(runs = runs_110, indices = 10:13, tag = "taxa_endemism_110")

# taxa_threat
save_conv_plots_by_category(runs = runs_1, indices = 14:17, tag = "taxa_threat_1")
save_conv_plots_by_category(runs = runs_10, indices = 14:17, tag = "taxa_threat_10")
save_conv_plots_by_category(runs = runs_110, indices = 14:17, tag = "taxa_threat_110")

# taxa_small
save_conv_plots_by_category(runs = runs_1, indices = 18:21, tag = "taxa_small_1")
save_conv_plots_by_category(runs = runs_10, indices = 18:21, tag = "taxa_small_10")
save_conv_plots_by_category(runs = runs_110, indices = 18:21, tag = "taxa_small_110")

# methods_mb
save_conv_plots_by_category(runs = runs_1, indices = c(22, 25, 28, 31), tag = "methods_mb_1")
save_conv_plots_by_category(runs = runs_10, indices = c(22, 25, 28, 31), tag = "methods_mb_10")
save_conv_plots_by_category(runs = runs_110, indices = c(22, 25, 28, 31), tag = "methods_mb_110")

# methods_vp
save_conv_plots_by_category(runs = runs_1, indices = 1 + c(22, 25, 28, 31), tag = "methods_vp_1")
save_conv_plots_by_category(runs = runs_10, indices = 1 + c(22, 25, 28, 31), tag = "methods_vp_10")
save_conv_plots_by_category(runs = runs_110, indices = 1+ c(22, 25, 28, 31), tag = "methods_vp_110")

# methods_ae
save_conv_plots_by_category(runs = runs_1, indices = 2 + c(22, 25, 28, 31), tag = "methods_ae_1")
save_conv_plots_by_category(runs = runs_10, indices = 2+ c(22, 25, 28, 31), tag = "methods_ae_10")
save_conv_plots_by_category(runs = runs_110, indices = 2 + c(22, 25, 28, 31), tag = "methods_ae_110")

# methods_ae
save_conv_plots_by_category(runs = runs_1, indices = 2 + c(22, 25, 28, 31), tag = "methods_ae_1")
save_conv_plots_by_category(runs = runs_10, indices = 2+ c(22, 25, 28, 31), tag = "methods_ae_10")
save_conv_plots_by_category(runs = runs_110, indices = 2 + c(22, 25, 28, 31), tag = "methods_ae_110")


# composites
save_conv_plots_by_category(runs = runs_1, indices = c(2, 9, 34:38), tag = "composites_1", 
                    fig_width = 10, fig_height = 9)
save_conv_plots_by_category(runs = runs_10, indices = c(2, 9, 34:38), tag = "composites_10", 
                    fig_width = 10, fig_height = 9)
save_conv_plots_by_category(runs = runs_110, indices = c(2, 9, 34:38), tag = "composites_110",
                    fig_width = 10, fig_height = 9)

toc()




# --------------------------------------------------------------------------------------------------------
# testing the size --------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------
tic()
save_conv_plots_by_category(i = 1, fig_width = 7, fig_height = 9, pixels = 100000) # tester for 1, think I did 7 and 9 earlier. 
toc()

names(ensembles_list)[c(1, 3:9)]
for (i in c(2, 4:9)) save_conv_plots_by_category(i, fig_width = 7, fig_height = 9) # four comparisons in the ensemble
save_conv_plots_by_category(3, fig_width = 8, fig_height = 9) # 5 inputs
save_conv_plots_by_category(14, fig_width = 10, fig_height = 8) # 7 inputs

for (i in c(10:13)) save_conv_plots_by_category(i, fig_width = 7, fig_height = 11) # 3 inputs # these are fine
for (i in c(15:18)) save_conv_plots_by_category(i, fig_width = 7, fig_height = 11) # 2 inputs # these are also fine

```


## Methods panel (ms fig. 1)

```{r methods-panel-manual}
# Produce small thumbnail raster maps for use in MS Figure 1, the methods panel

# set up:
mp_height <- 300
mp_width <- 300
mp_units <- "px"
mp_res <- 300

col_pas <- c("gray88","gray78")
col_pas_all <- col_pas[pas$type] # this sets up the colors based on a particular attribute, in this case, "type" . See levels(pas$type) to view the order in which the colors will be assigned to the values. 
dev.off()

# legend:
plot(bd_inputs_brick$bird_all, box = F, axes = F, legend = F, col = map_colors)
addRasterLegend(bd_inputs_brick$bird_all, ramp = map_colors, nTicks = 0, side = "none")



# ------------------------------------------------------------------------------------
# base Zambia
# ------------------------------------------------------------------------------------
png(file = fp(p_plots,"methods_panel/zambia_pas_legend.png"), 
    width = 900, height = 900, units = "px")
par(bg=NA, mar=c(0, 0, 0, 0), oma=c(0, 0, 0, 0))
plot(msk_shp, border = NA, col = "white")
plot(pas, col = col_pas_all, border = "gray", add=T)
legend("topleft", legend= c("Game Mgmt. Area", "National Park"), fill=col_pas, cex = 1, bty = "n")
plot(msk_shp, add = TRUE, lwd = 5)
dev.off()

# ------------------------------------------------------------------------------------
# Africa
# ------------------------------------------------------------------------------------
png(file = fp(p_plots,"methods_panel/africa.png"), 
    width = 900, height = 900, units = "px")
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
africa %>% st_union() %>% st_geometry() %>% st_transform(crs = aaeac) %T>% plot()
plot(msk_shp, border = "black", add = TRUE)
dev.off()

# ------------------------------------------------------------------------------------
# agroEcoTradeoff model inputs
# ------------------------------------------------------------------------------------
load(file = fp(p_mod_inputs, "yct_constraint_inputs.Rdata"), verbose = TRUE)
estes_bd_input_dt
yield_input_dt
carbon_input_dt
travel_input_dt
msk_csv
estes_bd_input %T>% plot()
yield_input %T>% plot()
carbon_input %T>% plot()
travel_input %T>% plot()
msk_no_pas
yield_input_no_pas %T>% plot()
carbon_input_no_pas %T>% plot()
travel_input_no_pas %T>% plot()

yield_dt <- fread(file = fp(p_mod_output, "yield_dt.csv"))
yield_dt_r <- dt_to_raster(yield_dt, CRSobj)
yield_dt[, x := bd_dt[, .(x)]]
yield_dt[, y := bd_dt[, .(y)]]



#
bd_dt[, 3:6]
bd_scores_vert_all_conv_bd100_dt <- bd_dt[, 3:6]
bd_scores_vert_all_conv_bd100_dt[,1] <- bd_scores_vert_all_conv_bd100_dt[, 1] * conv_bd100_dt[, 3]
bd_scores_vert_all_conv_bd100_dt[,2] <- bd_scores_vert_all_conv_bd100_dt[, 2] * conv_bd100_dt[, 3]
bd_scores_vert_all_conv_bd100_dt[,3] <- bd_scores_vert_all_conv_bd100_dt[, 3] * conv_bd100_dt[, 3]
bd_scores_vert_all_conv_bd100_dt[,4] <- bd_scores_vert_all_conv_bd100_dt[, 4] * conv_bd100_dt[, 3]
```

```{r methods-panel-function-loop}
# Produce small thumbnail raster maps for use in MS Figure 1, the methods panel

# see cc_functions.R for 
save_thumbnails()


panel_r_model <- list(
  "yield_input_maize" = yield_input$maize,
  "carbon_input" = carbon_input,
  "travel_input" = travel_input
  # plus the bird_all raster that's created below
)

panel_r_bd <- list(
  "bird_all_1" = bd_inputs_brick$bird_all,
  "bird_all_10" = bd_inputs_brick$bird_all_10,
  "bird_all_110" = bd_inputs_brick$bird_all_110,
  "bird_endemism_1" = bd_inputs_brick$bird_endemism,
  "bird_endemism_10" = bd_inputs_brick$bird_endemism_10,
  "bird_endemism_110" = bd_inputs_brick$bird_endemism_110,
  "bird_small_1" = bd_inputs_brick$bird_small,
  "bird_small_10" = bd_inputs_brick$bird_small_10,
  "bird_small_110" = bd_inputs_brick$bird_small_110
)
panel_r_conv <- list(
  "conv_bird_all_1" = conv_r$bp$bird_all,
  "conv_bird_all_10" = conv_r$bp$bird_all_10,
  "conv_bird_all_110" = conv_r$bp$bird_all_110,
  "conv_bird_endemism_1" = conv_r$bp$bird_endemism,
  "conv_bird_endemism_10" = conv_r$bp$bird_endemism_10,
  "conv_bird_endemism_110" = conv_r$bp$bird_endemism_110,
  "conv_bird_small_1" = conv_r$bp$bird_small,
  "conv_bird_small_10" = conv_r$bp$bird_small_10,
  "conv_bird_small_110" = conv_r$bp$bird_small_110
)
panel_r_ensemble <- list(
  "mam" = conv_r$facet_r_bp$mam_bp,
  "bird" = conv_r$facet_r_bp$bird_bp,
  "amp" = conv_r$facet_r_bp$amp_bp,
  "rep" = conv_r$facet_r_bp$rep_bp
)





for (i in seq_along(panel_r_model)) {
  save_thumbnails(raster = panel_r_model[[i]], raster_names = names(panel_r_model)[i], 
                  no_pas = FALSE, label = "",
                  mp_width = 900, mp_height = 900, mp_units = "px"
                  )
}

for (i in seq_along(panel_r_bd)) {
  save_thumbnails(raster = panel_r_bd[[i]], raster_names = names(panel_r_bd)[i], 
                  no_pas = FALSE, label = "",
                  mp_width = 900, mp_height = 900, mp_units = "px"
                  )
}

for (i in seq_along(panel_r_conv)) {
  save_thumbnails(raster = panel_r_conv[[i]], raster_names = names(panel_r_conv)[i], 
                  no_pas = TRUE, label = "",
                  mp_width = 900, mp_height = 900, mp_units = "px"
                  )
}

for (i in seq_along(panel_r_ensemble)) {
  save_thumbnails(raster = panel_r_ensemble[[i]], raster_names = names(panel_r_ensemble)[i], 
                  no_pas = TRUE, label = "",
                  mp_width = 900, mp_height = 900, mp_units = "px"
                  )
}

```

```{r convprob_r}
# create rasters for conversion priority

# b
vert_all_convprob_r_b <- toff_bd100$vert_all %>%
    list(Y = .$inputs$y_std,
         C = .$inputs$carbon_p,
         BD = .$inputs$cons_p,
         COST = .$inputs$cost_p) %>%
    constraints(inlist = ., cbetas = cbetas_bd100, silent = FALSE) %>%
    cbind(toff_bd100$vert_all$conv[, .(x, y)], .) %>%
    dt_to_raster(., CRSobj)

vert_all_convprob_r_b %T>% plot()

rm(toff_bd100)


# by
vert_all_convprob_r_by <- toff_bd50_y50$vert_all %>%
    list(Y = .$inputs$y_std,
         C = .$inputs$carbon_p,
         BD = .$inputs$cons_p,
         COST = .$inputs$cost_p) %>%
    constraints(inlist = ., cbetas = cbetas_bd50_y50, silent = FALSE) %>%
    cbind(toff_bd50_y50$vert_all$conv[, .(x, y)], .) %>%
    dt_to_raster(., CRSobj)

vert_all_convprob_r_by %T>% plot()

rm(toff_bd50_y50)

# byct
vert_all_convprob_r_byct <- toff_eq$vert_all %>%
    list(Y = .$inputs$y_std,
         C = .$inputs$carbon_p,
         BD = .$inputs$cons_p,
         COST = .$inputs$cost_p) %>%
    constraints(inlist = ., cbetas = cbetas, silent = FALSE) %>%
    cbind(toff_eq$vert_all$conv[, .(x, y)], .) %>%
    dt_to_raster(., CRSobj)

vert_all_convprob_r_byct %T>% plot()

object_size(toff_eq)
rm(toff_eq)

## conversion probabilities raster:
m4_vert_all_toff_bd100_outputs
plot(m4_vert_all_toff_bd100_outputs$convprob_r$maize)
plot(m4_vert_all_toff_bd100_outputs$bd_input) # vert_all
plot(m4_vert_all_toff_bd100_outputs$convprob_r)

m4_vert_all_toff_bd100_outputs$convprob_r$maize

save_thumbnails(raster = vert_all_convprob_r_b$maize,
                raster_names = "vert_all_convprob_r_b", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )
save_thumbnails(raster = vert_all_convprob_r_by$maize,
                raster_names = "vert_all_convprob_r_by", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )
save_thumbnails(raster = vert_all_convprob_r_byct$maize,
                raster_names = "vert_all_convprob_r_byct", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )
```

```{r facet_averages}
# not ultimately used, but perhaps useful for a future project.

dt_m$all

facet_r$all %T>% plot()
facet_r$bird %T>% plot()
facet_r$res110 %T>% plot()

save_thumbnails(raster = facet_r$all,
                raster_names = "facet_r_all", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$mam,
                raster_names = "facet_r_mam", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$bird,
                raster_names = "facet_r_bird", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$amp,
                raster_names = "facet_r_amp", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$rep,
                raster_names = "facet_r_rep", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$res110,
                raster_names = "facet_r_res110", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$b,
                raster_names = "facet_r_b", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$by,
                raster_names = "facet_r_by", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$byct,
                raster_names = "facet_r_byct", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

dev.off()
raster::plot(facet_r$all, legend = FALSE)
rangeBuilder::addRasterLegend(facet_r$all, location = 'right', side = 3, nTicks = 0)#, mixmax = c(0,2))
addRasterLegend(s1, location = "bottom", direction = "horizontal", side=1,
                nTicks = 0, ramp=col_main)

```

## Extra plots

```{r gg_theme}
# define new theme:
cc_theme3 <- theme(
  #legend.position = "none",
  plot.title = element_blank(),
  plot.subtitle = element_blank(),
  plot.caption = element_blank(),
  axis.title.x = element_blank(),
  #axis.title.y = element_text(size=9),
  axis.text.x = element_text(size=9)
)

cc_theme3_print <- cc_theme3 + theme(axis.text.x = element_text(size=9))

cc_theme3_bottom <- theme(legend.position = "bottom")
cc_theme3_none <- theme(legend.position = "none")

cc_theme3_trim <-  theme(axis.text.x = element_text(angle = 0, vjust = 0, hjust = 0.5))


# ------------------------------------------------------------------------------------------------------------------------
# final the color scheme
gg_jac_w_comp_colors <- scale_color_manual(#name = "Weights",
                     labels = c("all" = "average",
                                "b" = "b",
                                "by" = "by",
                                "byct" = "byct"),
                     values = c("all" = "black",
                                "b" = hue_pal()(3)[2], # "green"
                                "by" = hue_pal()(3)[3], #"blue"
                                "byct" = hue_pal()(3)[1])) #"red"

```


```{r gg_jac_w_all}
# next up: plot the results
names(facet_stats)

gg_jac_w_base <- ggplot(data = facet_stats) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Weighted Jaccard Similarity \n(Mean Within Comparison)") + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  labs(title = "Mean Weighted \nJaccard Index", 
       subtitle = "between each facet and the group",
       caption = "Error bars represent 95% confidence intervals")


# ------------------------------------------------------------------------------------------------------------------------
# this shows all four comparisons, with all four weights - but it's too much for one figure. 
gg_jac_w_all_weights <- gg_jac_w_base +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, 
                           color = weight), 
             position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = facet, ymin = mean_jac_w - 1.96*se_jac_w, ymax = mean_jac_w + 1.96*se_jac_w, 
                              color = weight), position = position_dodge(0.6), width = 0.4) +
  cc_theme3 +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+
  #gg_jac_w_comp_colors

gg_jac_w_all_weights
gg_jac_w_all_weights0

# just the average weights
gg_jac_w_all <- gg_jac_w_all_weights %+% filter(facet_stats, weight == "all"#, comparison != "weights"
                                               ) + theme(legend.position = "none") + gg_jac_w_comp_colors

# just composites
gg_jac_w_all_weights %+% filter(facet_stats, comparison == "composites")
gg_jac_w_all_weights %+% filter(facet_stats, weight == "all", comparison == "composites")

facet_stats %>% filter(comparison == "composites")

# all weights averaged together, with weights.

gg_jac_w_all_by_comp <- ggplot(data = filter(facet_stats, weight == "all"#, comparison != "weights"
                                             )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")
gg_jac_w_all_by_comp


# 
gg_jac_w_all_weights %+% filter(facet_stats, weight %in% c("bp", "by", "byct", "all_lite"), comparison != "composites")
# whhy is bp less similar than by for types and taxa, but by is less similar than bp for many of the methods and resolutions?
gg_jac_w_all_weights %+% filter(facet_stats, comparison == "composites")


filter(facet_stats, weight == "bp", comparison %in% c("methods", "resolution"))
gg_jac_w_b_pure_wt # <- gg_jac_w_b_pure
gg_jac_w_b_pure <- ggplot(data = filter(facet_stats, weight == "bp"#, comparison != "composites"
                                        )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")

gg_jac_w_b_pure + ggtitle("Pure biodiversity (100% weight on bd, with average yields)")



gg_jac_w_bd100_by_comp0
gg_jac_w_bd100_by_comp <- ggplot(data = filter(facet_stats, weight == "b"# comparison != "composites"
                                               )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")
gg_jac_w_bd100_by_comp + ggtitle("100% weight on bd, with accurate, variable yields)")
gg_jac_w_bd100_by_comp0

# 50/50 biodiversity and yield:
gg_jac_w_by <- ggplot(data = filter(facet_stats, weight == "by"# comparison != "composites"
                                               )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")
gg_jac_w_by + ggtitle("Weight split equally between bd and yield \n(50% on each, assuming accurate, variable yields)")


gg_jac_w_z50 <- ggplot(data = filter(facet_stats, weight == "z50"#, comparison != "composites"
                                     )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Factor") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")
gg_jac_w_z50 + ggtitle("Converting 50% of Zambia \n(100% weight on bd, accurate, variable yields)")



# ------------------------------------------------------------------------------------------------------------------------
# just the standard errors as the error bars, not the 95% confidence intervals. 
gg_jac_w_all_just_se <- gg_jac_w_base %+% filter(facet_stats, weight == "all") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, #color = comparison
                           ), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = facet,
                              ymin = mean_jac_w - se_jac_w,
                              ymax = mean_jac_w + se_jac_w,
                              #color = comparison
                              ),
                position = position_dodge(0.6), width = 0.4) +
  cc_theme3 + cc_theme3_bottom +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x")
gg_jac_w_all_just_se
```

```{r gg_jac_by_comparison}
# just a single value for each decision category:

# all weights
mean_jac_w_by_comparison <- jac_w_melt %>% 
  filter(weight == "all") %>% 
  group_by(comparison, weight) %>% 
  summarise(mean_jac_w = mean(jac_w), 
            se_jac_w = sqrt(var(jac_w) / sum(jac_w)))

gg_mean_jac_w_by_comparison <- ggplot(data = mean_jac_w_by_comparison) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Comparison") + ylab("Mean Weighted \nJaccard Similarity") + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  geom_point(mapping = aes(x = comparison, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = comparison, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.3)



# b pure :
mean_jac_w_b_pure_by_comparison <- jac_w_melt %>% 
  filter(weight == "bp") %>% 
  group_by(comparison, weight) %>% 
  summarise(mean_jac_w = mean(jac_w), 
            se_jac_w = sqrt(var(jac_w) / sum(jac_w)))

gg_mean_jac_w_b_pure_by_comparison <- ggplot(data = mean_jac_w_b_pure_by_comparison) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Comparison") + ylab("Mean Weighted \nJaccard Similarity") + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  geom_point(mapping = aes(x = comparison, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = comparison, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.3)

# b weights only:
mean_jac_w_bd100_by_comparison <- jac_w_melt %>% 
  filter(weight == "b") %>% 
  group_by(comparison, weight) %>% 
  summarise(mean_jac_w = mean(jac_w), 
            se_jac_w = sqrt(var(jac_w) / sum(jac_w)))

gg_mean_jac_w_bd100_by_comparison <- ggplot(data = mean_jac_w_bd100_by_comparison) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Comparison") + ylab("Mean Weighted \nJaccard Similarity") + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  geom_point(mapping = aes(x = comparison, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = comparison, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.3)
```




```{r gg_jac_indiv_comparisons}

# ------------------------------------------------------------------------------------------------------------------------
# Individual comparisons, colored by weight:
gg_jac_w_types <- gg_jac_w_all_weights %+% 
  filter(facet_stats, comparison == "types") + #, weight %in% c("all", "b", "by", "byct")
  facet_grid(labeller = NULL)# + cc_theme3_trim
gg_jac_w_types

# just the taxa comparison, colored by weight:
gg_jac_w_taxa  <- gg_jac_w_all_weights %+% 
  filter(facet_stats, comparison == "taxa") + 
  facet_grid(labeller = NULL) #+ cc_theme3_trim
gg_jac_w_taxa

# just the methods comparison, colored by weight:
gg_jac_w_methods  <- gg_jac_w_all_weights %+% 
  filter(facet_stats, comparison == "methods") + 
  facet_grid(labeller = NULL) + cc_theme3_trim
gg_jac_w_methods

# just the resolution comparison, colored by weight:
gg_jac_w_resolution  <- gg_jac_w_all_weights %+% 
  filter(facet_stats, comparison == "resolution") + 
  facet_grid(labeller = NULL) + cc_theme3_trim
gg_jac_w_resolution

# just the weights comparison, colored by weight:
gg_jac_w_weights  <- gg_jac_w_all_weights %+% 
  filter(facet_stats, comparison == "weights") + 
  facet_grid(labeller = NULL) + cc_theme3_trim
gg_jac_w_weights



# old, types, as a bar chart - I don't like this one
ggplot(filter(facet_stats, comparison == "types"), 
       aes(x = facet, y = mean_jac_w, fill = weight)) +
  theme_classic() + 
  xlab(NULL) + ylab("Mean Weighted Jaccard Index") + 
  geom_bar(position = position_dodge(0.9), stat = "identity") +
  geom_errorbar(mapping = aes(ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w, 
                              color = weight), position = position_dodge(0.9), width = 0.4) +
  cc_theme3 + cc_theme3_trim


```


```{r gg_jac_w_pairs}
# Now trying to produce a plot showing the pairwise similarities, to show the relative similarities between decisions. 

# ------------------------------------------------------------------
# plotting pairwise jaccard weighted values
# ------------------------------------------------------------------
gg_jac_w_pairs <- ggplot(filter(jac_w_melt, weight == "all"), 
                         aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  #ylim(-0.1, 1.2) +
  #coord_cartesian(ylim=c(0, 1.0)) + #cale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  #labs(title = "Pairwise overlap")
  #filter(jac_w_melt, comparison %in% c("types", "taxa")) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_bp_pairs_wt# <- gg_jac_w_bp_pairs
gg_jac_w_bp_pairs
gg_jac_w_bp_pairs <- ggplot(filter(jac_w_melt, weight == "bp"#, !comparison %in% c("resolution", "composites")
                                   ), 
                            aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_b_pairs <- ggplot(filter(jac_w_melt, weight == "b"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_by_pairs <- ggplot(filter(jac_w_melt, weight == "by"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_bc_pairs <- ggplot(filter(jac_w_melt, weight == "bc"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_bt_pairs <- ggplot(filter(jac_w_melt, weight == "bt"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_byct_pairs <- ggplot(filter(jac_w_melt, weight == "byct"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_z50_pairs <- ggplot(filter(jac_w_melt, weight == "z50"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_pairs
gg_jac_w_bp_pairs
gg_jac_w_b_pairs
gg_jac_w_by_pairs
gg_jac_w_bc_pairs
gg_jac_w_bt_pairs
gg_jac_w_byct_pairs
gg_jac_w_z50_pairs


gg_jac_w_pairs # + scale_fill_viridis(discrete = TRUE)

gg_jac_w_pairs %+% filter(jac_w_melt, comparison %in% c("types","taxa")) + cc_theme3_trim
gg_jac_w_pairs %+% filter(jac_w_melt, comparison %in% c("methods","resolution", "weights")) + cc_theme3_trim
gg_jac_w_pairs %+% filter(jac_w_melt, comparison == "types")
gg_jac_w_pairs %+% filter(jac_w_melt, comparison == "types")


jac_w_melt$facet
facet_names


# just pairs of types:
png(paste0(p_plots, "/ms_v5/", "jac_w_pairs_types", ".png"), 
    width = 9, height = 5, 
    units = "in", res = 400)

plot_grid(
  ggplot(filter(jac_w_melt, comparison == "types"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  #ylim(-0.1, 1.2) +
  #coord_cartesian(ylim=c(0, 1.0)) + #cale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  #labs(title = "Pairwise overlap")
  #filter(jac_w_melt, comparison %in% c("types", "taxa")) + 
  facet_grid(cols = vars(weight), scales = "free_x", switch = "x", 
             space = "free_x") + 
  theme(legend.position = "bottom"),
  NULL, ncol = 2, rel_widths = c(1, 0.05))

dev.off()
```

```{r gg_weights_pairs}
jac_w_melt$comparison

gg_jac_w_weights_pairs <- ggplot(filter(jac_w_melt, comparison == "weights"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  #ylim(-0.1, 1.2) +
  #coord_cartesian(ylim=c(0, 1.0)) + #cale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  #labs(title = "Pairwise overlap")
  #filter(jac_w_melt, comparison %in% c("types", "taxa")) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_weights_pairs

# this shows that bp and b are very similar, but still only 
jac_w_melt %>% 
  filter(comparison == "weights",
         facet %in% c("bp", "b"),
         pair %in% c("bp", "b"))

```


```{r gg_area_conv}
# ------------------------------------------------------------------
# area converted - not used in final analysis
# ------------------------------------------------------------------
gg_area_conv <- ggplot(data = facet_stats_full) + # note, requires facet_stats_full, which includes unused composites
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +

  #xlab("Facet") + 
  ylab(expression("Adj. Area Converted (km"^{2}*")")) +
  geom_point(mapping = aes(x = facet, y = area_conv, color = weight), position = position_dodge(0.6)) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+ 
  #gg_jac_w_comp_colors

gg_area_conv %+% filter(facet_stats_full, facet != "z50", weight != "z50")


gg_area_conv %+% filter(facet_stats_full, weight == "bp") # basically all around 21888


gg_area_conv %+% filter(facet_stats_full, weight == "bp") + theme(legend.position = "none") + xlab(NULL) + scale_color_manual(values = c("bp" = "black"))

# ------------------------------------------------------------------
# show the jaccard index and the area converted one above each other
# ------------------------------------------------------------------
facet_stats_melt <- facet_stats_full %>%
  select(-facet_names) %>% 
  melt(id.vars = c("facet", "comparison", "weight"), variable.name = "variable", value.name = "value")

# show the weighted jaccard and the area converted as a facet grid
ggplot(data = filter(facet_stats_melt, weight == "bp", !variable %in% c("count", "se_jac_w", "name", "area_conv_raw"))) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  #xlab("Facet") + 
  ylab(expression("Area Converted (km"^{2}*")")) +
  geom_point(mapping = aes(x = facet, y = value), position = position_dodge(0.6)) +
  facet_grid(cols = vars(comparison), rows = vars(variable), scales = "free", switch = "x")
# ------------------------------------------------------------------

```


```{r save-extra-plots}
gg_jac_w_all
gg_jac_w_all_weights
gg_jac_w_types
gg_jac_w_taxa
gg_jac_w_pairs
gg_jac_w_bp_pairs

gg_area_conv

gg_jac_w_all_by_comp
gg_jac_w_b_pure + ggtitle("Pure biodiversity (100% weight on bd, with average yields)")
gg_jac_w_bd100_by_comp + ggtitle("100% weight on bd (accurate, variable yields)")
gg_jac_w_z50 + ggtitle("Converting 50% of Zambia (100% weight on bd, accurate, variable yields)")

# ------------------------------------------------------------------
# ------------------------------------------------------------------
# 0. mean jac_w across all decision categories comparison, and for each facet within comparison
# ------------------------------------------------------------------
png(paste0(p_plots, "/ms_v5/", "jac_w_plot_by_comp_all_a_b", ".png"), 
    width = 7.5, height = 3, units = "in", res = 400)
print(
  plot_grid(
    gg_jac_w_all_by_comp + 
      ggtitle("All weights averaged") + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.2, 0.2, 0.2), "cm")),
    gg_mean_jac_w_by_comparison + coord_cartesian(ylim=c(-0.15, 1.05)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.6, 0.35, 0), "cm"), 
            axis.title.y = element_blank()), 
    ncol = 2, rel_widths = c(2.5,1), labels = "auto")
  )
dev.off()

# ----------------------------
# just panel a: all weights averaged
png(paste0(p_plots, "/ms_v5/", "jac_w_plot_by_comp_all", ".png"), 
    width = 6, height = 3, units = "in", res = 400)
print(gg_jac_w_all_by_comp + 
        #ggtitle("All weights averaged") + 
        #coord_cartesian(ylim=c(0, 1.0)) + 
        theme(legend.position = "none", 
              plot.margin = unit(c(0.4, 0.2, 0.2, 0.2), "cm"))
      )
dev.off()


# ----------------------------
# pure biodiversity (bp)
png(paste0(p_plots, "/ms_v5/", "jac_w_plot_by_comp_bp", ".png"), 
    width = 6, height = 3, units = "in", res = 400)
print(
    gg_jac_w_b_pure + 
      #ggtitle("Pure biodiversity (100% weight on bd, with average yields)") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

gg_jac_w_b_pure + ggtitle("Pure biodiversity (100% weight on bd, with average yields)")




# ----------------------------
# just for 100% biodiversity weights (b)
gg_jac_w_bd100_by_comp + ggtitle("100% weight on bd (accurate, variable yields)")

png(paste0(p_plots, "/ms_v5/", "jac_w_plot_by_comp_b", ".png"), 
    width = 6, height = 3, units = "in", res = 400)
print(
    gg_jac_w_bd100_by_comp + 
      #ggtitle("100% Weight on Biodiversity (original, with accurate yields)") + 
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

# ----------------------------
# converting 50% of Zambia (z50)

gg_jac_w_z50 + ggtitle("Converting 50% of Zambia (100% weight on bd, accurate, variable yields)")

png(paste0(p_plots, "/ms_v5/", "jac_w_plot_by_comp_z50", ".png"), 
    width = 6, height = 3, units = "in", res = 400)
print(
    gg_jac_w_z50 + 
      #ggtitle("Converting 50% of Zambia \n(100% weight on bd, accurate, variable yields)") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

# see test figures in the test section directly


# ------------------------------------------------------------------
# ------------------------------------------------------------------
# 1. all, mean weighted jaccard
# ------------------------------------------------------------------
png(paste0(p_plots, "/ms_v5/", "jac_w_plot_all", ".png"), 
    width = 7, height = 3, 
    units = "in", res = 400)
print(gg_jac_w_all)
dev.off()

# ----------------------------
# 2. pairs, for the SI
png(paste0(p_plots, "/ms_v5/", "jac_w_pairs_all", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_jac_w_pairs + theme(legend.position = "bottom"))
dev.off()


# ----------------------------
# 2.5 pairs just bd, for the SI
png(paste0(p_plots, "/ms_v5/", "jac_w_b_pairs", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_jac_w_bd100_pairs + theme(legend.position = "bottom"))
dev.off()

png(paste0(p_plots, "/ms_v5/", "jac_w_bp_pairs", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_jac_w_bp_pairs + theme(legend.position = "bottom"))
dev.off()

# ------------------------------------------------------------------
# ------------------------------------------------------------------
# 3. weights plot
# ------------------------------------------------------------------
png(paste0(p_plots, "/ms_v5/", "weights_fig", ".png"), 
    width = 8, height = 6, 
    units = "in", res = 400)
print(
  plot_grid(gg_weight_plot_1, gg_weight_plot_2, ncol = 1)
  )
dev.off()


# ------------------------------------------------------------------
# ------------------------------------------------------------------
# 4. mean weighted jaccard, across all weights
# ------------------------------------------------------------------
gg_jac_w_weights_legend_b <- get_legend(gg_jac_w_weights + theme(legend.position = "bottom", legend.margin = margin(b = 3)))

png(paste0(p_plots, "/ms_v5/", "jac_w_plot_all_w_weights", ".png"), 
    width = 7, height = 4, 
    units = "in", res = 400)
print(
  gg_jac_w_all_weights + theme(legend.position = "bottom") + coord_cartesian(ylim=c(0, 1.05))
  )
dev.off()


# ------------------------------------------------------------------
# ------------------------------------------------------------------
# 5. area converted, with weights:
# ------------------------------------------------------------------
# with weights
png(paste0(p_plots, "/ms_v5/", "area_conv_w_weights", ".png"), 
    width = 7, height = 3, 
    units = "in", res = 400)
print(
  gg_area_conv %+% filter(facet_stats) + theme(legend.position = "right") + xlab(NULL)  
)
dev.off()

# ----------------------------
# area conv, all
png(paste0(p_plots, "/ms_v5/", "area_conv_all", ".png"), 
    width = 7, height = 3, 
    units = "in", res = 400)
print(gg_area_conv %+% filter(facet_stats, weight == "all") + theme(legend.position = "none") + xlab(NULL))
dev.off()

# ----------------------------
# area conv, bd100
png(paste0(p_plots, "/ms_v5/", "area_conv_bd100", ".png"), 
    width = 7, height = 3, 
    units = "in", res = 400)
print(gg_area_conv %+% filter(facet_stats, weight == "b") + theme(legend.position = "none") + xlab(NULL) + scale_color_manual(values = c("b" = "black")))
dev.off()


# ----------------------------
# also included the composites comparison, see gg_composites
  
# --------
gg_jac_w_pairs_leg_b <- get_legend(gg_jac_w_pairs + theme(legend.position = "bottom", legend.margin = margin(b = 3)))


gg_jac_w_all_legend_b <- get_legend(gg_jac_w_all + theme(legend.position = "bottom", legend.margin = margin(b = 3)))

    
```


```{r yield_maps}
yield_input_dt
yield_dt
# yield_dt <- toff_eq$reference_y$inputs$p_yield
yield_dt <- fread(file = fp(p_mod_output, "yield_dt.csv"))

# add x and y columns.
yield_dt[, x := bd_dt[, .(x)]]
yield_dt[, y := bd_dt[, .(y)]]

# convert to raster
yield_dt_r <- dt_to_raster(yield_dt, CRSobj)

pas_sf <- st_as_sf(pas) %>%
  mutate(type = fct_recode(type, 
                           "Game Mgmt. Area" = "gma", 
                           "National Park" = "npark"))



row_maize <- ggplot() +
  geom_raster(data = yield_dt, aes(x = x, y = y, fill = maize)) +
  scale_fill_gradientn(colors = map_colors, na.value = "white") + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
        plot.title = element_text(hjust = 0.5)) + 
  coord_equal() + 
  geom_sf(data = pas_sf, mapping = aes(alpha = type), lwd = 0.1) + 
  labs(y = NULL, x = NULL, fill = "Yield (tons/ha)", title = "Maize", alpha = "Protected Areas")


row_soy <- ggplot() +
         geom_raster(data = yield_dt, aes(x = x, y = y, fill = soy)) +
  scale_fill_gradientn(colors = map_colors, na.value = "white") + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
        plot.title = element_text(hjust = 0.5)) + 
  coord_equal() + 
  geom_sf(data = pas_sf, mapping = aes(alpha = type), lwd = 0.1) +
  labs(y = NULL, x = NULL, fill = "Yield (tons/ha)", title = "Soy", alpha = "Protected Areas")
  
  

# ------------------------------------------------------------ #
# put the figure together
png(paste0(p_plots, "/si/","yield_maps.png"),    
      width = 10, height = 5, 
      units = "in", res = 300)
# pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
#            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
print(
  plot_grid(row_maize, row_soy,
            ncol = 2, rel_heights = c(1, 1))
  )
dev.off()
```

