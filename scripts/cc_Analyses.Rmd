---
title: "Analyses: Crawford Zambia MS"
output: html_notebook
editor_options: 
  chunk_output_type: console
---
See: scripts/cc_Start.Rmd 

```{r save_or_load_workspace}
save.image(file = fp(p_proj, "Backups/workspace_2020_4_5.RData"))

load(file = fp(p_proj, "Backups/workspace_2020_3_30.RData"))
load(file = fp(p_proj, "Backups/workspace_2020_4_5.RData"))
```


# Construct conversion data.tables

```{r bd_dt}
# -----------
# bd_input biodiversity scores for all unprotected areas in Zambia
# -----------

# append with _bd, for use creating the bd_dt
bd_input_names <- paste0(runs, "_bd")


bd_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates

tic()
for (i in 1:length(runs)) {
  bd_dt_temp <- fread(file = paste0(p_dat, .Platform$file.sep,
                    runs[i], .Platform$file.sep,
                    runs[i], "-cons-priorities.csv"))
  
  bd_dt[, bd_input_names[i] := bd_dt_temp[valinds]]
}
toc()

# bd_dt[, 1:18] %>% dt_to_raster(CRSobj) %T>% plot()
length(bd_dt)
object_size(bd_dt)

fwrite(bd_dt, file = fp(p_mod_output, "bd_dt.csv"))



# -----------------------------------------------
# -------- add raw richness and endemism scores ----------------------------------------
# -----------------------------------------------
library(raster)
# build data.table of raw biodiversity scores for all, endemism, threatened, and small-ranged richness, to manipulate.
bd_raw_dt <- dtraster::as.data.table(vert_r$all_richness$sum, xy = TRUE)
names(bd_raw_dt)[3] <- "all"
bd_raw_dt[, "endemism" := as.data.table(vert_r$endemism_richness$sum, xy = FALSE)]
bd_raw_dt[, "threat" := as.data.table(vert_r$threat_richness$sum, xy = FALSE)]
bd_raw_dt[, "small" := as.data.table(vert_r$small_richness$sum, xy = FALSE)]
bd_raw_dt[, "threat_weighted" := as.data.table(vert_r$threat_weighted_richness$sum, xy = FALSE)]
bd_raw_dt[, "small_threat" := as.data.table(vert_r$small_threat_richness$sum, xy = FALSE)]
bd_raw_dt[, "small_zam" := as.data.table(vert_r$small_zam_richness$sum, xy = FALSE)]
bd_raw_dt[, "endemism_zam" := as.data.table(vert_r$endemism_zam_richness$sum, xy = FALSE)]
bd_raw_dt <- na.omit(bd_raw_dt) # omit NAs (this is critical)

names(bd_raw_dt)[3:10] <- paste0(runs[1:8], "_raw")

# see cc_Start.rmd, inputs and input_handler
bd_raw_dt <- bd_raw_dt[valinds, ] 
# check it out.
bd_raw_dt %>% dt_to_raster(., CRSobj) %T>% plot()

colSums(bd_raw_dt[, "endemism"])

# 
#
#
length(bd_dt)
names(bd_dt)
bd_dt <- bd_dt[,1:56]
bd_dt <- cbind(bd_dt, bd_raw_dt[, 3:10])

# total length should be: 64, the first two of which are x and y. 



# 

```


```{r conv_b_pure_dt}
toff_b_pure
length(toff_b_pure)
conv_b_pure_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates

# -----------------------------------
# run through each model, summing maize and soy to create the conversion model.
# -----------------------------------
for (i in 1:length(runs)) {
  conv_b_pure_dt[, runs[i] := rowSums(toff_b_pure[[i]][,3:4])]
}

conv_b_pure_dt
object_size(conv_b_pure_dt)

# # -----------------------------------
# # make data.table of biodiversity scores in conversion areas:
# # -----------------------------------
# bd_conv_b_pure_dt <- conv_b_pure_dt[, 3:(2+length(runs))] * bd_dt[, 3:(2+length(runs))]
# bd_conv_b_pure_dt <- cbind(
#   il$mask[, .(x, y)][valinds], 
#   bd_conv_b_pure_dt
#   )

rm(toff_b_pure)
```

```{r conv_b_dt}
toff_b
length(toff_b)
conv_b_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates

# -----------------------------------
# run through each model, summing maize and soy to create the conversion model.
# -----------------------------------
for (i in 1:length(runs)) {
  conv_b_dt[, runs[i] := rowSums(toff_b[[i]][,3:4])]
}

conv_b_dt
object_size(conv_b_dt)

# # -----------------------------------
# # make data.table of biodiversity scores in conversion areas:
# # -----------------------------------
# bd_conv_b_dt <- conv_b_dt[, 3:(2+length(runs))] * bd_dt[, 3:(2+length(runs))]
# bd_conv_b_dt <- cbind(
#   il$mask[, .(x, y)][valinds], 
#   bd_conv_b_dt
#   )

rm(toff_b)
```


```{r conv_by_dt}
toff_by
length(toff_by)
conv_by_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates

# -----------------------------------
# run through each model, summing maize and soy to create the conversion model.
# -----------------------------------
for (i in 1:length(runs)) {
  conv_by_dt[, runs[i] := rowSums(toff_by[[i]][,3:4])]
}

conv_by_dt
object_size(conv_by_dt)

# # -----------------------------------
# # make data.table of biodiversity scores in conversion areas:
# # -----------------------------------
# bd_conv_by_dt <- conv_by_dt[, 3:(2+length(runs))] * bd_dt[, 3:(2+length(runs))]
# bd_conv_by_dt <- cbind(
#   il$mask[, .(x, y)][valinds], 
#   bd_conv_by_dt
#   )

rm(toff_by)
```

```{r conv_bc_dt}
toff_bc
conv_bc_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates

# -----------------------------------
# run through each model, summing maize and soy to create the conversion model.
# -----------------------------------
for (i in 1:length(runs)) {
  conv_bc_dt[, runs[i] := rowSums(toff_bc[[i]][,3:4])]
}

# -----------------------------------
# make data.table of biodiversity scores in conversion areas:
# -----------------------------------
bd_conv_bc_dt <- conv_bc_dt[, 3:(2+length(runs))] * bd_dt[, 3:(2+length(runs))]
bd_conv_bc_dt <- cbind(
  il$mask[, .(x, y)][valinds], 
  bd_conv_bc_dt
  )

rm(toff_bc)

```

```{r conv_bt_dt}
toff_bt
conv_bt_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates

# -----------------------------------
# run through each model, summing maize and soy to create the conversion model.
# -----------------------------------
for (i in 1:length(runs)) {
  conv_bt_dt[, runs[i] := rowSums(toff_bt[[i]][,3:4])]
}

# -----------------------------------
# make data.table of biodiversity scores in conversion areas:
# -----------------------------------
bd_conv_bt_dt <- conv_bt_dt[, 3:(2+length(runs))] * bd_dt[, 3:(2+length(runs))]
bd_conv_bt_dt <- cbind(
  il$mask[, .(x, y)][valinds], 
  bd_conv_bt_dt
  )

rm(toff_bt)

```

```{r conv_byct_dt}
toff_byct
length(toff_byct)
conv_byct_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates

# -----------------------------------
# run through each model, summing maize and soy to create the conversion model.
# -----------------------------------
for (i in 1:length(runs)) {
  conv_byct_dt[, runs[i] := rowSums(toff_byct[[i]][,3:4])]
}

conv_byct_dt
object_size(conv_byct_dt)

# # -----------------------------------
# # make data.table of biodiversity scores in conversion areas:
# # -----------------------------------
# bd_conv_byct_dt <- conv_byct_dt[, 3:(2+length(runs))] * bd_dt[, 3:(2+length(runs))]
# bd_conv_byct_dt <- cbind(
#   il$mask[, .(x, y)][valinds], 
#   bd_conv_byct_dt
#   )

rm(toff_byct)
```

```{r conv_z50_dt}
toff_z50
conv_z50_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates

# -----------------------------------
# run through each model, summing maize and soy to create the conversion model.
# -----------------------------------
for (i in 1:length(runs)) {
  conv_z50_dt[, runs[i] := rowSums(toff_z50[[i]][,3:4])]
}

# # -----------------------------------
# # make data.table of biodiversity scores in conversion areas:
# # -----------------------------------
# bd_conv_z50_dt <- conv_z50_dt[, 3:(2+length(runs))] * bd_dt[, 3:(2+length(runs))]
# bd_conv_z50_dt <- cbind(
#   il$mask[, .(x, y)][valinds], 
#   bd_conv_z50_dt
#   )
# 

rm(toff_z50)

```



```{r save_data.tables}
bd_dt # showing all bd scores, for unprotected areas 

conv_eq_dt # showing converted areas, using full model, equal weights on all four constraints
bd_conv_eq_dt # showing only bd scores in converted areas, equal weights

conv_bd50_y50_dt # converting areas with, 100% of the tradeoff weight on biodiversity
bd_conv_bd50_y50_dt # bd scores in converted areas, 100% weight on biodiversity

conv_bd100_dt # converting areas with, 100% of the tradeoff weight on biodiversity
bd_conv_bd100_dt # bd scores in converted areas, 100% weight on biodiversity

conv_10p_bd_dt # converting just the lowest 10% of cells assuming constant yields.
bd_conv_10p_bd_dt # biodiversity scores in lowest 10% of cells

conv_bc_dt
conv_bt_dt
conv_b_pure_dt
conv_z50_dt

# save data.tables:
save(bd_dt, # showing all bd scores 
     conv_b_dt,
     conv_by_dt,
     conv_byct_dt,
     conv_bc_dt,
     conv_bt_dt,
     conv_b_pure_dt,
     conv_z50_dt,
     
     #conv_10p_bd_dt, # converting just the lowest 10% of cells, assuming constant yields.
     #bd_conv_10p_bd_dt, # biodiversity scores in lowest 10% of cells
     
     file = fp(p_mod_output, "conv_data.tables.RData")
)

fwrite(bd_dt, file = fp(p_mod_output, "bd_dt.csv"))

fwrite(conv_eq_dt, file = fp(p_mod_output, "conv_eq_dt.csv"))
fwrite(bd_conv_eq_dt, file = fp(p_mod_output, "bd_conv_eq_dt.csv"))

fwrite(conv_bd50_y50_dt, file = fp(p_mod_output, "conv_bd50_y50_dt.csv"))
fwrite(bd_conv_bd50_y50_dt, file = fp(p_mod_output, "bd_conv_bd50_y50_dt.csv"))

fwrite(conv_bd100_dt, file = fp(p_mod_output, "conv_bd100_dt.csv"))
fwrite(bd_conv_bd100_dt, file = fp(p_mod_output, "bd_conv_bd100_dt.csv"))

# fwrite(conv_10p_bd_dt, file = fp(p_mod_output, "conv_10p_bd_dt.csv"))
# fwrite(bd_conv_10p_bd_dt, file = fp(p_mod_output, "bd_conv_10p_bd_dt.csv"))


fwrite(conv_bc_dt, file = fp(p_mod_output, "conv_bc_dt.csv"))
fwrite(conv_bt_dt, file = fp(p_mod_output, "conv_bt_dt.csv"))
fwrite(conv_b_pure_dt, file = fp(p_mod_output, "conv_b_pure_dt.csv"))
fwrite(conv_z50_dt, file = fp(p_mod_output, "conv_z50_dt.csv"))


# conv_10p_bd_dt_og <- fread(file = fp(p_mod_output, "conv_10p_bd_dt_old.csv"))

```


### old:

```{r conv_eq_dt}
# create blank data.table to use:
# xy_dt <- il$mask[, .(x, y)][valinds]


# append with _conv, for use 
mod_conv_eq_names <- runs_w_ref # create vector to modify
for (i in 1:length(runs_w_ref)) {
  mod_conv_eq_names[i] <- paste0(runs_w_ref[i], "_conv_eq")
}

# load in toff_eq and re-run
# -----------
# run through each model, summing maize and soy to create the conversion model.
# not that this includes the 33 mod runs in runs, but also the two reference scenarios.
# -----------
toff_eq[[1]]$conv

conv_eq_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates
for (i in 1:length(runs_w_ref)) {
  conv_eq_dt[, mod_conv_eq_names[i] := rowSums(toff_eq[[i]]$conv[,3:4])]
}

length(conv_eq_dt) # x, y, plus 54 models, plus 2 reference = 58

names(conv_eq_dt[, c(3:56)]) # only the 54 models.
names(conv_eq_dt)

length(bd_dt[, (1+2):(2+length(runs))]); nrow(bd_dt[, (1+2):(2+length(runs))])
length(bd_dt[, (1+2):(2+length(runs))]); nrow(bd_dt[, (1+2):(2+length(runs))])

bd_dt[, c(3:35)] # this works
bd_dt[, c(2+seq_along(runs))] # this doesn't work
bd_dt[, 3:(2+length(runs))] # this works. 
bd_dt[, 3:(2+length(runs_w_raw))] # this works. 

bd_dt[, -(1:2)] # this also works, but includes the raw columns. 


length(conv_eq_dt[, 3:(2+length(runs))]); nrow(conv_eq_dt[, 3:(2+length(runs))])

length(conv_eq_dt[, 3:(2+length(runs))])
length(bd_dt[, 3:(2+length(runs))])

# -----------
# biodiversity scores in areas being converted 
# -----------
bd_conv_eq_dt <- conv_eq_dt[, 3:(2+length(runs))] * bd_dt[, 3:(2+length(runs))] # multiply column by column, but after dropping x, y, and the reference columns. These need to be the same dimensions.
bd_conv_eq_dt <- cbind(
  il$mask[, .(x, y)][valinds], # add the x and y columns back
  bd_conv_eq_dt
  )


# -----------
# two main data.tables:
# -----------
conv_eq_dt # showing converted areas, using full model, equal weights on all four constraints
bd_dt # showing all bd scores 
bd_conv_eq_dt # showing only bd scores in converted areas

object_size(conv_eq_dt)
object_size(bd_dt)

# can sum like so:
sum(conv_eq_dt$vert_all_conv_eq) # just one column, this is the area
conv_eq_dt[, .(sum(vert_all_conv_eq),
            sum(vert_threat_conv_eq),
            sum(vert_small_conv_eq))]
colSums(conv_eq_dt[, -c(1:2)]) # all of the total areas converted

```

```{r conv_bd50_y50_dt}
conv_bd50_y50_dt <- il$mask[, .(x, y)][valinds] # just x and y coordinates

mod_conv_bd50_y50_names <- runs_w_ref # create vector to modify
for (i in 1:length(runs_w_ref)) {
  mod_conv_bd50_y50_names[i] <- paste0(runs_w_ref[i], "_conv_bd50_y50")
}

# -----------------------------------
# run through each model, summing maize and soy to create the conversion model.
# -----------------------------------
for (i in 1:length(runs_w_ref)) {
  conv_bd50_y50_dt[, mod_conv_bd50_y50_names[i] := rowSums(toff_bd50_y50[[i]]$conv[,3:4])]
}


# -----------------------------------
# make data.table of biodiversity scores in conversion areas:
# -----------------------------------
bd_conv_bd50_y50_dt <- conv_bd50_y50_dt[, 3:(2+length(runs))] * bd_dt[, 3:(2+length(runs))]
bd_conv_bd50_y50_dt <- cbind(
  toff_bd50_y50[[1]]$inputs$mask[, .(x, y)], 
  bd_conv_bd50_y50_dt
  )


conv_bd50_y50_dt
rm(toff_bd50_y50)
```

```{r conv_10p_bd_dt}
# no longer used

conv_10p_bd_dt <- fread(file = fp(p_mod_output, "conv_10p_bd_dt.csv"))

mod_conv_10p_bd_names <- runs_w_ref # create vector to modify
for (i in 1:length(runs_w_ref)) {
  mod_conv_10p_bd_names[i] <- paste0(runs_w_ref[i], "_conv_10p_bd")
}

# drop the key and order_update columns
conv_10p_bd_dt[, key := NULL]
conv_10p_bd_dt[, order_update := NULL]

# add the reference_yct_conv_10p_bd, and reference_y_conv_10p_bd, columns to the data.table

conv_10p_bd_dt[, mod_conv_10p_bd_names[34] := conv_eq_dt[,36]]
conv_10p_bd_dt[, mod_conv_10p_bd_names[35] := conv_eq_dt[,37]]
length(conv_10p_bd_dt)



# -----------------------------------
# make data.table of biodiversity scores in conversion areas:
# -----------------------------------
bd_conv_10p_bd_dt <- conv_10p_bd_dt[, 3:(2+length(runs))] * bd_dt[, 3:(2+length(runs))]
bd_conv_10p_bd_dt <- cbind(
  il$mask[, .(x, y)][valinds], # just x y coordinates
  bd_conv_10p_bd_dt
  )
```

```{r conv_dt_list}
conv_dt_list <- list(
  "eq" = conv_eq_dt,
  "bd50_y50" = conv_bd50_y50_dt,
  "bd100" = conv_bd100_dt,
  "10p_bd" = conv_10p_bd_dt
)

object_size(conv_dt_list)

conv_dt_list$eq
names(conv_dt_list)

conv_eq_dt
conv_bd50_y50_dt
conv_bd100_dt
conv_10p_bd_dt


# ---------------------------------------
# new ensembles list
# ---------------------------------------
ensembles_r <- list(conv_eq_dt_ensembles_r, conv_bd50_y50_dt_ensembles_r, conv_bd100_dt_ensembles_r, conv_10p_bd_dt_ensembles_r)
names(ensembles_r) <- c("eq", "bd50_y50", "bd100", "10p_bd")
```


```{r dt_to_raster}


# # # #
conv_eq_dt_r <- dt_to_raster(conv_eq_dt, CRSobj) # should be the same as conv_eq_brick
names(conv_eq_dt_r) <- runs_w_ref
bd_conv_eq_dt_r <- dt_to_raster(bd_conv_eq_dt, CRSobj) # this is a RasterBrick of all of the biodiversity scores in converted areas for all of the model runs.

conv_bd50_y50_dt_r <- dt_to_raster(conv_bd50_y50_dt, CRSobj)
names(conv_bd50_y50_dt_r) <- runs_w_ref
bd_conv_bd50_y50_dt_r <- dt_to_raster(bd_conv_bd50_y50_dt, CRSobj)

conv_bd100_dt_r <- dt_to_raster(conv_bd100_dt, CRSobj)
names(conv_bd100_dt_r) <- runs_w_ref
bd_conv_bd100_dt_r <- dt_to_raster(bd_conv_bd100_dt, CRSobj)

conv_10p_bd_dt_r <- dt_to_raster(conv_10p_bd_dt, CRSobj) #
names(conv_10p_bd_dt_r) <- runs_w_ref
bd_conv_10p_bd_dt_r <- dt_to_raster(bd_conv_10p_bd_dt, CRSobj)

#### to test the 10p results...they are suspicious.
test_10p_r <- dt_to_raster(conv_10p_bd_dt_og, CRSobj)
plot(test_10p_r$key)
plot(test_10p_r$order_update)
plot(test_10p_r$m24_laurance_not_norm_conv_10p_bd)
plot(bd_dt_r$m24_laurance_not_norm)



conv_eq_dt_r
conv_bd50_y50_dt_r
conv_bd100_dt_r
conv_10p_bd_dt_r

# plots

plot(conv_eq_dt_r$m6_bird_threat_conv_eq)

plot(bd_inputs_no_pas_brick, 1:5, zlim = c(0,1))
plot(bd_conv_eq_dt_r, 1:5, zlim = c(0,1))

plot(bd_dt_r, 3, zlim = c(0, 0.01))

plot(conv_bd50_y50_dt_r, 1:5)
plot(bd_conv_bd50_y50_dt_r, 1:5)

plot(conv_bd100_dt_r, 3 )
plot(bd_conv_bd100_dt_r, 3)

plot(conv_10p_bd_dt_r, 3 )
plot(conv_10p_bd_dt_r$m7_amp_threat)
all.equal(conv_10p_bd_dt_r$m7_amp_threat, conv_10p_bd_dt_r$m8_rep_threat)

plot(bd_conv_10p_bd_dt_r, 3)

plot(conv_bd100_dt_r[[3]] * bd_conv_bd100_dt_r[[3]])

plot(bd_conv_eq_dt_r, 1:5, zlim = c(0,1))

rm(bd_dt_r, conv_eq_dt_r, bd_conv_eq_dt_r, conv_bd50_y50_dt_r, bd_conv_bd50_y50_dt_r, conv_bd100_dt_r, bd_conv_bd100_dt_r, conv_10p_bd_dt_r, bd_conv_10p_bd_dt_r)

#plots to compare all four:
plot(test_r)
object_size(overlaps_by_bd_input)
names(overlaps_by_bd_input) <- runs_w_ref
overlaps_by_bd_input <- (conv_eq_dt_r +
       conv_bd50_y50_dt_r +
       conv_bd100_dt_r +
       conv_10p_bd_dt_r)

plot(overlaps_by_bd_input, 1:4)

par(mfrow=c(2,2))
plot(conv_eq_dt_r$m1_vert_all_conv_eq)
plot(conv_bd50_y50_dt_r$m1_vert_all_conv_bd50_y50)
plot(conv_bd100_dt_r$m1_vert_all_conv_bd100)
plot(conv_10p_bd_dt_r$m1_vert_all_conv_10p_bd)
```





# Results data.frames

```{r results-eq}
# ----------------------------------------------------------------
### Calculate % unprotected bd loss in each conversion model
# ----------------------------------------------------------------
bd_loss_names <- runs_w_raw
for (i in 1:length(runs_w_raw)) {
  bd_loss_names[i] <- paste0(runs_w_raw[i], "_bd_loss")
}

length(bd_loss_names) # 62 = 54 models plus 8 raw biodiversity scores

# % of total unprotected biodiversity lost in converted areas 
bd_loss_conv_eq_list <- vector("list", length = length(runs_w_raw)) # must create an empty list first. Can also do this with simply list()
names(bd_loss_conv_eq_list) <- bd_loss_names

#### add names to this vector, for the four raw scores
#### then, add bd layers to the bd_dt data.table, so that the code below goes through the process of multiplying the raw bd inputs by each of the conversion maps, to then sum to come up with a 

tic()
for (i in 1:length(runs_w_raw)) {
  bd_loss_conv_eq_list[[i]] <- bd_dt[[i + 2]] * conv_eq_dt[, -c(1:2)]
  bd_loss_conv_eq_list[[i]] <- colSums(bd_loss_conv_eq_list[[i]])
}
toc() # 130.152 seconds when overwriting itself.
object_size(bd_loss_conv_eq_list)

# this list is created by first multiplying each single bd input by all of the conversion maps, to find the bd scores in the cells that are chosen for conversion. Then, it calculates the bd loss score by summing all of the scores in the converted cells. So, each element of the list is the bd loss for each conversion map (produced with the full range of biodiversity inputs) for a particular biodiversity input.

bd_loss_conv_eq_list$vert_all_bd_loss
bd_loss_conv_eq_list[1]
bd_loss_conv_eq_list$vert_all_raw_bd_loss
length(bd_loss_conv_eq_list)
# ----------------------------------------------------------------
### construct results data.frame
# ----------------------------------------------------------------
results_eq <- data.frame(
  # mod_run = mod_conv_eq_names,
  mod_spec = "eq",
  area_conv = colSums(conv_eq_dt[, -c(1:2)]),
  unprotected_bd = c(colSums(bd_dt[, 3:(2+length(runs))]), "reference_yct" = NA, "reference_y" = NA),
  bd_conv = c(colSums(bd_conv_eq_dt[, -c(1:2)]), "reference_yct" = NA, "reference_y" = NA),
  # bd100_conv = c(colSums(bd_conv_bd100_dt[, -c(1:2)]), "reference_yct" = NA, "reference_y" = NA),
  bd_loss_conv_eq_list[seq_along(runs_w_raw)]
)

length(results_eq[ , 2]) # 56 (54 models plus reference runs)

head(results_eq)[, 1:8]
rownames(results_eq)
colnames(results_eq)


results_eq <- results_eq %>%
  rownames_to_column("mod_run") %>% # mutate silently removes the row names; this makes rownames into a new column
  mutate(bd_conv_norm = bd_conv / unprotected_bd,
         mod_run = runs_w_ref,
         mod_run = fct_relevel(mod_run, runs_w_ref)) %>%
  select(mod_run, mod_spec, area_conv, bd_conv, unprotected_bd, bd_conv_norm, #bd100_conv, 
         everything())

levels(as.factor(results_eq$mod_run)) # check to see if things are ordered correctly.

# rownames(results_eq) <- mod_conv_eq_names # add the row names back in

fwrite(results_eq, file = fp(p_mod_output, "results_eq.csv"))
# save(results_eq, file = fp(p_mod_output, "results_eq.RData")) # alternative save method

length(results_eq)

# ----------------------------------------------------------------
### Normalize the results data.frame by the amount of unprotected biodiversity 
# ----------------------------------------------------------------
## IMPORTANT - Update the value that the columns are being divided by to be colsums of the new bd list

head(results_eq[, 6 + seq_along(runs_w_raw)])  %>% length() # to be divided
colSums(bd_dt[, 3:(2+length(runs_w_raw))]) %>% as.numeric() %>% length() # to be divided by; the column of unprotected biodviersity scores per bd input


results_eq_norm <- mapply('/', 
       results_eq[, 6 + seq_along(runs_w_raw)], # to be divided, column by column
       as.numeric(colSums(bd_dt[, 3:(2+length(runs_w_raw))])) # to be divided by, each element applied to each column in order). this needs to be updated to include the four extra colsums for the raw scores. The lengths need to be exactly the same.
)

# now add the mod_run and mod_spec columns
results_eq_norm <- results_eq_norm %>%
  as.data.frame() %>%
  mutate(mod_run = results_eq$mod_run,
         mod_spec = results_eq$mod_spec,
         area_conv = results_eq$area_conv,
         bd_conv = results_eq$bd_conv,
         unprotected_bd = results_eq$unprotected_bd,
         percent_bd_loss_control = results_eq$bd_conv_norm) %>%
  select(mod_run, mod_spec, everything())


# ----------------------------------------------------------------
# Calculate summary statistics 
# ----------------------------------------------------------------
head(results_eq_norm[, 3:(2+length(runs))])
results_eq_norm <- results_eq_norm %>%
  mutate(
    mean_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    var_from_control = c(mapply(
      FUN = cc_var, 
      transpose(.[seq_along(runs), 3:(2+length(runs))]),  # transposed df, so that each conv result is a column, rather than a row. This is iterated through by column. This is "x" in the cc_var formula.
      results_eq$bd_conv_norm[seq_along(runs)] # second vector, with the bd loss in controlling layer. This is "y" in the cc_var formula.
      ), NA, NA)
    )


# rownames(results_eq_norm) <- mod_conv_eq_names # add in row names again (optional)


head(results_eq_norm)
# save
fwrite(results_eq_norm, file = fp(p_mod_output, "results_eq_norm.csv"))

# ----------------------------------------------------------------
### Calculate the variance from the normalized biodiversity loss in the controlling biodiversity layer
# ----------------------------------------------------------------
# subtract from each column in results_eq_norm the value of results_eq$bd_conv_norm
head(results_eq_norm)[, 1:4]
results_eq$bd_conv_norm[1:4]

results_eq_norm_var <- mapply('-', 
       results_eq_norm[, 2 + seq_along(runs)], # to be subtracted from, column by column
       results_eq$bd_conv_norm[seq_along(runs)] # to be subtracted)
)

head(results_eq_norm_var)[, 1:4]
# head(transpose(results_eq_norm_var))[, 1:4]

# now add the mod_run column
results_eq_norm_var <- results_eq_norm_var %>%
  as.data.frame() %>%
  mutate(mod_run = results_eq$mod_run,
         mod_spec = results_eq$mod_spec) %>%
  select(mod_run, mod_spec, everything())


fwrite(results_eq_norm_var, file = fp(p_mod_output, "results_eq_norm_var.csv"))
```

```{r results-bd50_y50}
# ----------------------------------------------------------------
### Calculate % unprotected bd loss in each conversion model
# ----------------------------------------------------------------
bd_loss_conv_bd50_y50_list <- vector("list", length = length(runs_w_raw)) # must create an empty list first. Can also do this with simply list()
names(bd_loss_conv_bd50_y50_list) <- bd_loss_names # or runs

for (i in 1:length(runs_w_raw)) {
  bd_loss_conv_bd50_y50_list[[i]] <- bd_dt[[i + 2]] * conv_bd50_y50_dt[, -c(1:2)]
  bd_loss_conv_bd50_y50_list[[i]] <- colSums(bd_loss_conv_bd50_y50_list[[i]])
}

# ----------------------------------------------------------------
### construct results data.frame
# ----------------------------------------------------------------

results_bd50_y50 <- data.frame(
  # mod_run = mod_conv_bd50_y50_names,
  mod_spec = "bd50_y50",
  area_conv = colSums(conv_bd50_y50_dt[, -c(1:2)]),
  unprotected_bd = c(colSums(bd_dt[, 3:(2+length(runs))]), "reference_yct" = NA, "reference_y" = NA),
  bd_conv = c(colSums(bd_conv_bd50_y50_dt[, -c(1:2)]), "reference_yct" = NA, "reference_y" = NA),
  bd_loss_conv_bd50_y50_list[seq_along(runs_w_raw)]
)

head(results_bd50_y50)
rownames(results_bd50_y50)

results_bd50_y50 <- results_bd50_y50 %>%
  rownames_to_column("mod_run") %>% # mutate silently removes the column names; this makes rownames into a new column
  mutate(bd_conv_norm = bd_conv / unprotected_bd,
         mod_run = runs_w_ref,
         mod_run = fct_relevel(mod_run, runs_w_ref)) %>%
  select(mod_run, mod_spec, area_conv, bd_conv, unprotected_bd, bd_conv_norm, everything())

# rownames(results_bd50_y50) <- mod_conv_bd50_y50_names # add the row names back in

fwrite(results_bd50_y50, file = fp(p_mod_output, "results_bd50_y50.csv"))

length(results_bd50_y50)
nrow(results_bd50_y50)

# ----------------------------------------------------------------
### Normalize the results data.frame by the amount of unprotected biodiversity 
# ----------------------------------------------------------------
head(results_bd50_y50[, 6 + seq_along(runs_w_raw)]) #%>% length()# to be divided
head(results_bd50_y50[, 7:(6 + length(runs_w_raw))]) # to be divided
colSums(bd_dt[, 3:(2+length(runs_w_raw))]) %>% as.numeric() #%>% length() # to be divided by; the column of unprotected biodviersity scores per bd input

results_bd50_y50_norm <- mapply('/', 
       results_bd50_y50[, 6 + seq_along(runs_w_raw)], # to be divided, column by column
       as.numeric(colSums(bd_dt[, 3:(2+length(runs_w_raw))])) # to be divided by, each element applied to each column in order)
)

# now add the mod_run column
results_bd50_y50_norm <- results_bd50_y50_norm %>%
  as.data.frame() %>%
  mutate(mod_run = results_bd50_y50$mod_run,
         mod_spec = results_bd50_y50$mod_spec,
         area_conv = results_bd50_y50$area_conv,
         bd_conv = results_bd50_y50$bd_conv,
         unprotected_bd = results_bd50_y50$unprotected_bd,
         percent_bd_loss_control = results_bd50_y50$bd_conv_norm) %>%
  select(mod_run, mod_spec, everything())

# ----------------------------------------------------------------
# Calculate summary statistics 
# ----------------------------------------------------------------
results_bd50_y50_norm <- results_bd50_y50_norm %>%
  mutate(
    mean_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    var_from_control = c(mapply(FUN = cc_var,
                              transpose(.[seq_along(runs), 3:(2+length(runs))]),  # transposed df, so that each conv result is a column, rather than a row. This is iterated through by column
                              results_bd50_y50$bd_conv_norm[seq_along(runs)] # second vector, with the bd loss in controlling layer
                              ), NA, NA)
    )

# rownames(results_bd50_y50_norm) <- mod_conv_bd50_y50_names


# save
fwrite(results_bd50_y50_norm, file = fp(p_mod_output, "results_bd50_y50_norm.csv"))

# ----------------------------------------------------------------
### Calculate the variance from the normalized biodiversity loss in the controlling biodiversity layer
# ----------------------------------------------------------------
# subtract from each column in results_bd50_y50_norm the value of results_bd50_y50$bd_conv_norm
head(results_bd50_y50_norm)[, 1:4]
results_bd50_y50$bd_conv_norm[1:4]

results_bd50_y50_norm_var <- mapply('-', 
       results_bd50_y50_norm[, 2 + seq_along(runs)], # to be subtracted from, column by column
       results_bd50_y50$bd_conv_norm[seq_along(runs)] # to be subtracted)
)

# now add the mod_run column
results_bd50_y50_norm_var <- results_bd50_y50_norm_var %>%
  as.data.frame() %>%
  mutate(mod_run = results_bd50_y50$mod_run,
         mod_spec = results_bd50_y50$mod_spec) %>%
  select(mod_run, mod_spec, everything())



fwrite(results_bd50_y50_norm_var, file = fp(p_mod_output, "results_bd50_y50_norm_var.csv"))
```

```{r results-bd100}
# ----------------------------------------------------------------
### Calculate % unprotected bd loss in each conversion model
# ----------------------------------------------------------------
bd_loss_conv_bd100_list <- vector("list", length = length(runs_w_raw)) # must create an empty list first. Can also do this with simply list()
names(bd_loss_conv_bd100_list) <- bd_loss_names # or runs

for (i in 1:length(runs_w_raw)) {
  bd_loss_conv_bd100_list[[i]] <- bd_dt[[i + 2]] * conv_bd100_dt[, -c(1:2)]
  bd_loss_conv_bd100_list[[i]] <- colSums(bd_loss_conv_bd100_list[[i]])
}

# ----------------------------------------------------------------
### construct results data.frame
# ----------------------------------------------------------------

results_bd100 <- data.frame(
  # mod_run = mod_conv_bd100_names,
  mod_spec = "bd100",
  area_conv = colSums(conv_bd100_dt[, -c(1:2)]),
  unprotected_bd = c(colSums(bd_dt[, 3:(2+length(runs))]), "reference_yct" = NA, "reference_y" = NA),
  bd_conv = c(colSums(bd_conv_bd100_dt[, -c(1:2)]), "reference_yct" = NA, "reference_y" = NA),
  bd_loss_conv_bd100_list[seq_along(runs_w_raw)]
)

head(results_bd100)
rownames(results_bd100)

results_bd100 <- results_bd100 %>%
  rownames_to_column("mod_run") %>% # mutate silently removes the column names; this makes rownames into a new column
  mutate(bd_conv_norm = bd_conv / unprotected_bd,
         mod_run = runs_w_ref,
         mod_run = fct_relevel(mod_run, runs_w_ref)) %>%
  select(mod_run, mod_spec, area_conv, bd_conv, unprotected_bd, bd_conv_norm, everything())

# rownames(results_bd100) <- mod_conv_bd100_names # add the row names back in

fwrite(results_bd100, file = fp(p_mod_output, "results_bd100.csv"))

length(results_bd100)


# ----------------------------------------------------------------
### Normalize the results data.frame by the amount of unprotected biodiversity 
# ----------------------------------------------------------------
head(results_bd100[, 6 + seq_along(runs_w_raw)]) # to be divided
as.numeric(colSums(bd_dt[, 3:(2+length(runs_w_raw))])) # to be divided by; the column of unprotected biodviersity scores per bd input

results_bd100_norm <- mapply('/', 
       results_bd100[, 6 + seq_along(runs_w_raw)], # to be divided, column by column
       as.numeric(colSums(bd_dt[, 3:(2+length(runs_w_raw))])) # to be divided by, each element applied to each column in order)
)

# now add the mod_run column
results_bd100_norm <- results_bd100_norm %>%
  as.data.frame() %>%
  mutate(mod_run = results_bd100$mod_run,
         mod_spec = results_bd100$mod_spec,
         area_conv = results_bd100$area_conv,
         bd_conv = results_bd100$bd_conv,
         unprotected_bd = results_bd100$unprotected_bd,
         percent_bd_loss_control = results_bd100$bd_conv_norm) %>%
  select(mod_run, mod_spec, everything())


# ----------------------------------------------------------------
# Calculate summary statistics 
# ----------------------------------------------------------------
results_bd100_norm <- results_bd100_norm %>%
  mutate(
    mean_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    var_from_control = c(mapply(FUN = cc_var,
                              transpose(.[seq_along(runs), 3:(2+length(runs))]),  # transposed df, so that each conv result is a column, rather than a row. This is iterated through by column
                              results_bd100$bd_conv_norm[seq_along(runs)] # second vector, with the bd loss in controlling layer
                              ), NA, NA)
    )

# rownames(results_bd100_norm) <- mod_conv_bd100_names # optional


# save
fwrite(results_bd100_norm, file = fp(p_mod_output, "results_bd100_norm.csv"))

# ----------------------------------------------------------------
### Calculate the variance from the normalized biodiversity loss in the controlling biodiversity layer
# ----------------------------------------------------------------
# subtract from each column in results_bd100_norm the value of results_bd100$bd_conv_norm
head(results_bd100_norm)[, 1:6]
results_bd100$bd_conv_norm[1:4]

results_bd100_norm_var <- mapply('-', 
       results_bd100_norm[, 2 + seq_along(runs)], # to be subtracted from, column by column
       results_bd100$bd_conv_norm[seq_along(runs)] # to be subtracted)
)

# now add the mod_run column
results_bd100_norm_var <- results_bd100_norm_var %>%
  as.data.frame() %>%
  mutate(mod_run = results_bd100$mod_run,
         mod_spec = results_bd100$mod_spec) %>%
  select(mod_run, mod_spec, everything())


fwrite(results_bd100_norm_var, file = fp(p_mod_output, "results_bd100_norm_var.csv"))
```


```{r results-10p_bd}
# ----------------------------------------------------------------
### Calculate % unprotected bd loss in each conversion model
# ----------------------------------------------------------------
bd_loss_conv_10p_bd_list <- vector("list", length = length(runs_w_raw)) # must create an empty list first. Can also do this with simply list()
names(bd_loss_conv_10p_bd_list) <- bd_loss_names # or runs
names(conv_10p_bd_dt)

for (i in 1:length(runs_w_raw)) {
  bd_loss_conv_10p_bd_list[[i]] <- bd_dt[[i + 2]] * conv_10p_bd_dt[, -c(1:2)] # remove x, y
  bd_loss_conv_10p_bd_list[[i]] <- colSums(bd_loss_conv_10p_bd_list[[i]])
}

# ----------------------------------------------------------------
### construct results data.frame
# ----------------------------------------------------------------

results_10p_bd <- data.frame(
  # mod_run = mod_conv_10p_bd_names,
  mod_spec = "10p_bd",
  area_conv = colSums(conv_10p_bd_dt[, -c(1:2)]),
  unprotected_bd = c(colSums(bd_dt[, 3:(2+length(runs))]), "reference_yct" = NA, "reference_y" = NA),
  bd_conv = c(colSums(bd_conv_10p_bd_dt[, -c(1:2)]), "reference_yct" = NA, "reference_y" = NA),
  bd_loss_conv_10p_bd_list[seq_along(runs_w_raw)]
)

head(results_10p_bd)
rownames(results_10p_bd)

results_10p_bd <- results_10p_bd %>%
  rownames_to_column("mod_run") %>% # mutate silently removes the column names; this makes rownames into a new column
  mutate(bd_conv_norm = bd_conv / unprotected_bd,
         mod_run = runs_w_ref,
         mod_run = fct_relevel(mod_run, runs_w_ref)) %>%
  select(mod_run, mod_spec, area_conv, bd_conv, unprotected_bd, bd_conv_norm, everything())

# rownames(results_10p_bd) <- mod_conv_10p_bd_names # add the row names back in

fwrite(results_10p_bd, file = fp(p_mod_output, "results_10p_bd.csv"))

length(results_10p_bd)


# ----------------------------------------------------------------
### Normalize the results data.frame by the amount of unprotected biodiversity 
# ----------------------------------------------------------------
head(results_10p_bd[, 6 + seq_along(runs_w_raw)]) # to be divided
as.numeric(colSums(bd_dt[, 3:(2+length(runs_w_raw))])) # to be divided by; the column of unprotected biodviersity scores per bd input

results_10p_bd_norm <- mapply('/', 
       results_10p_bd[, 6 + seq_along(runs_w_raw)], # to be divided, column by column
       as.numeric(colSums(bd_dt[, 3:(2+length(runs_w_raw))])) # to be divided by, each element applied to each column in order)
)

# now add the mod_run column
results_10p_bd_norm <- results_10p_bd_norm %>%
  as.data.frame() %>%
  mutate(mod_run = results_10p_bd$mod_run,
         mod_spec = results_10p_bd$mod_spec,
         area_conv = results_10p_bd$area_conv,
         bd_conv = results_10p_bd$bd_conv,
         unprotected_bd = results_10p_bd$unprotected_bd,
         percent_bd_loss_control = results_10p_bd$bd_conv_norm) %>%
  select(mod_run, mod_spec, everything())


# ----------------------------------------------------------------
# Calculate summary statistics 
# ----------------------------------------------------------------
results_10p_bd_norm <- results_10p_bd_norm %>%
  mutate(
    mean_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_bd_loss = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    var_from_control = c(mapply(FUN = cc_var,
                              transpose(.[seq_along(runs), 3:(2+length(runs))]),  # transposed df, so that each conv result is a column, rather than a row. This is iterated through by column
                              results_10p_bd$bd_conv_norm[seq_along(runs)] # second vector, with the bd loss in controlling layer
                              ), NA, NA)
    )

# rownames(results_10p_bd_norm) <- mod_conv_10p_bd_names # optional.

levels(as.factor(results_10p_bd_norm$mod_run)) # this is why things get misordered
results_10p_bd_norm$mod_run <- factor(results_10p_bd_norm$mod_run, levels = runs_w_ref) # set levels, in the correct order
levels(results_10p_bd_norm$mod_run) # it works.

head(results_10p_bd_norm)
# save
fwrite(results_10p_bd_norm, file = fp(p_mod_output, "results_10p_bd_norm.csv"))

# ----------------------------------------------------------------
### Calculate the variance from the normalized biodiversity loss in the controlling biodiversity layer
# ----------------------------------------------------------------
# subtract from each column in results_10p_bd_norm the value of results_10p_bd$bd_conv_norm
head(results_10p_bd_norm)[, 1:4]
results_10p_bd$bd_conv_norm[1:4]

results_10p_bd_norm_var <- mapply('-', 
       results_10p_bd_norm[, 2 + seq_along(runs)], # to be subtracted from, column by column
       results_10p_bd$bd_conv_norm[seq_along(runs)] # to be subtracted)
)

# now add the mod_run column
results_10p_bd_norm_var <- results_10p_bd_norm_var %>%
  as.data.frame() %>%
  mutate(mod_run = results_10p_bd$mod_run,
         mod_spec = results_10p_bd$mod_spec) %>%
  select(mod_run, mod_spec, everything())


head(results_10p_bd_norm_var)[, 1:4]
levels(results_10p_bd_norm_var$mod_run)
levels(as.factor(results_10p_bd_norm_var$mod_run)) # this is why things get misordered
results_10p_bd_norm_var$mod_run <- factor(results_10p_bd_norm_var$mod_run, levels = runs_w_ref)
levels(results_10p_bd_norm_var$mod_run)

fwrite(results_10p_bd_norm_var, file = fp(p_mod_output, "results_10p_bd_norm_var.csv"))
```


```{r save+load_results_df}
results_eq
results_eq_norm
results_eq_norm_var

results_bd50_y50
results_bd50_y50_norm
results_bd50_y50_norm_var

results_bd100
results_bd100_norm
results_bd100_norm_var

results_10p_bd
results_10p_bd_norm
results_10p_bd_norm_var

save(results_eq, 
     results_eq_norm, 
     results_eq_norm_var, 
     results_bd50_y50, 
     results_bd50_y50_norm, 
     results_bd50_y50_norm_var, 
     results_bd100, 
     results_bd100_norm, 
     results_bd100_norm_var, 
     # results_10p_bd,
     # results_10p_bd_norm,
     # results_10p_bd_norm_var,
     file = fp(p_mod_output, "results_data_frames.RData")
)


# load back in all together
load(file = fp(p_mod_output, "results_data_frames.RData"), verbose = TRUE)
```


```{r testing_df}
test_df <- data.frame(
  a = c(2, 3, 4, 5, 6),
  v1 = 1:5,
  v2 = 6:10,
  v3 = 11:15,
  v4 = 16:20,
  v5 = 21:25
)
test_df[2:6] / test_df$a

t(t(test_df[2:6]) / test_df$a) # this works, but is unnecessariily complicated. 

test_df$a[1]
test_df2 <- data.frame(
  test_df$v1 / test_df$a[1], 
  test_df$v2 / test_df$a[2], 
  test_df$v3 / test_df$a[3],
  test_df$v4 / test_df$a[4],
  test_df$v5 / test_df$a[5])

# testing mapply:
mapply('/', test_df[2:6], test_df$a) # function to be applied, the main thing to be operated on, and the second thing to be used, in this case, to be divided by.

############################
############################
############################
m1_conv_bd_impacts_r <- dt_to_raster(cbind(dt, m1_conv_bd_impacts), CRSobj)
m1_estes_bd_impacts


cellStats(new_dt_r$m2_laurance_conv - bd_impacts_brick$m2_laurance, stat = "sum")


length(m1_estes_toff$inputs$cons$cons.priorities)
length(rowSums(m1_estes_toff$conv[,3:4]))

# converting to raster to double check that all checks out.
test_r2 <- dt_to_raster(dt, CRSobj)

colSums(dt[,-c(1:2)]) # to get total area

dt


# ok, figuring out how to sum data.table rows, 
zambia_no_pas <- m1_estes_toff$inputs$mask[, .(x, y)] # just x and y coordinates
CRS_obj <- m1_estes_toff$inputs$sp$crs

m1_estes_toff$conv[,3]
t1 <- m1_estes_toff$conv$maize + m1_estes_toff$conv$soy
t2 <- rowSums(m1_estes_toff$conv[,3:4])

mod_conv_dt <- zambia_no_pas
mod_conv_dt$m1_estes <- m1_estes_toff$conv$maize + m1_estes_toff$conv$soy


mod_bd_scores_dt <- zambia_no_pas
mod_bd_scores_dt[, newcol := m1_estes_toff$inputs$cons$cons.priorities * mod_conv_dt$m1_estes]
mod_bd_scores_dt <- m1_estes_toff$inputs$cons$cons.priorities * mod_conv_dt$m1_estes

test_r <- dt_to_raster(m1_estes_toff$conv, CRSobj)




plot(test_r$conv)
cellStats(test_r$conv - test_r$maize - test_r$soy, stat = "sum")

test

tic()
m1_estes_bd_impacts <- conv_eq_brick$m1_estes * bd_inputs_brick
toc()


extent(conv_eq_brick)
extent(bd_inputs_brick)
test_impacts <- conv_eq_brick[[1]] * bd_inputs_brick[[1]]
plot(test_impacts)
plot(biodiversity_impacts_brick[[4]])
plot(conv_eq_brick[[4]])
plot(bd_inputs_brick[[4]])

ensemble <- calc(conv_eq_brick, fun = mean)
plot(ensemble)

plot(conv_eq_brick$m5_vert_threat_conv)
plot(conv_eq_brick$m5.5_vert_threat_sum_norm_conv)

plot(conv_eq_brick$m2_laurance_conv)
plot(conv_eq_brick$m2.5_laurance_not_norm_conv)

plot(conv_eq_brick$m12_average_mb_conv)
plot(conv_eq_brick$m13_max_mb_conv)
plot(conv_eq_brick$m14_multi_mb_conv)

plot(conv_eq_brick$m4_vert_all_conv)
plot(conv_eq_brick$m15.1_vert_all_10_conv)
plot(conv_eq_brick$m16.1_vert_all_110_conv)

plot(conv_eq_brick$m5_vert_threat_conv)
plot(conv_eq_brick$m15.2_vert_threat_10_conv)
plot(conv_eq_brick$m16.2_vert_threat_110_conv)

plot(conv_eq_brick$m6_vert_small_conv)
plot(conv_eq_brick$m15.3_vert_small_10_conv)
plot(conv_eq_brick$m16.3_vert_small_110_conv)

plot(conv_eq_brick$m7_vert_small_threat_conv)
plot(conv_eq_brick$m15.4_vert_small_threat_10_conv)
plot(conv_eq_brick$m16.4_vert_small_threat_110_conv)

```


# % overlap + jaccard
```{r overlap_jaccard_eq}
overlap_eq <- matrix(nrow = 56, ncol = 56)
colnames(overlap_eq) <- runs_w_ref

overlap_eq <- data.frame(
  bd_input = runs_w_ref,
  mod_spec = "eq",
  overlap_eq
)

jaccard_eq <- overlap_eq

# overlaps_eq_sums <-  vector("list", length = length(runs_w_ref))
# names(overlaps_eq_sums) <- mod_conv_eq_names

# Note: each row should be a single input, and each column is that input's overlap with the other inputs. So, I should be having rows with the overlaps, not columns. This code has two for loops: the first one creates the temporary overlap data.table, by taking a single input's conversion map, and adding to it all 56 conversion maps. Areas of overlap have a value of 2. Then, the second for loop calculates the percent overlap (percent of A also contained by B, which is # cells in both A and B / # cells in A). 

for (i in seq_along(runs_w_ref)) {
  temp_overlaps_dt <- conv_eq_dt[, get(mod_conv_eq_names[i])] + conv_eq_dt[, 3:(2 + length(runs_w_ref))] # create a temp dt of the overlaps between the one specific conversion model (model i) and all other models. 
  
  for (j in seq_along(runs_w_ref)) { # now, another for loop, to calculate the overlap and jaccard
    overlap_eq[i, (2 + j)] <-     # fill in each value in the overlap matrix
      temp_overlaps_dt[, sum(get(mod_conv_eq_names[j]) == 2)] /  # the first sum, the number of cells with value of 2 (overlap bewteen model i and model j)
      conv_eq_dt[, sum(get(mod_conv_eq_names[i]) == 1)] # divided by the total number of cells converted by model i
    
    jaccard_eq[i, (2 + j)] <- 
      temp_overlaps_dt[, sum(get(mod_conv_eq_names[j]) == 2)] /  # the intersection, or where the two data.tables overlap (== 2)
      temp_overlaps_dt[, sum(get(mod_conv_eq_names[j]) >= 1)] # the union, or all cells that are 1 or 2 (selected by either model)
  }
}

# -------------------------
# add stats 
# note that these have not had the self-comparison removed (na.rm), and are recalculated later (combo_overlap)
overlap_eq <- overlap_eq %>%
  mutate( 
    mean_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x)))
    ) %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref)) # reorder the levels to match runs_w_ref


jaccard_eq <- jaccard_eq %>%
  mutate(
    mean_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x)))
    ) %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref)) # reorder the levels to match runs_w_ref


fwrite(overlap_eq, file = fp(p_mod_output, "overlap_eq.csv"))
fwrite(jaccard_eq, file = fp(p_mod_output, "jaccard_eq.csv"))

# started at 3:12 pm...finished at 3:14pm.
```

```{r overlap_jaccard_bd50_y50}
overlap_bd50_y50 <- matrix(nrow = 56, ncol = 56)
colnames(overlap_bd50_y50) <- runs_w_ref

overlap_bd50_y50 <- data.frame(
  bd_input = runs_w_ref,
  mod_spec = "bd50_y50",
  overlap_bd50_y50
)

jaccard_bd50_y50 <- overlap_bd50_y50

for (i in seq_along(runs_w_ref)) {
  temp_overlaps_dt <- conv_bd50_y50_dt[, get(mod_conv_bd50_y50_names[i])] + conv_bd50_y50_dt[, 3:(2 + length(runs_w_ref))] # create a temp dt of the overlaps between the one specific conversion model (model i) and all other models. 
  
  for (j in seq_along(runs_w_ref)) { # now, another for loop, to calculate the overlap and jaccard
    overlap_bd50_y50[i, (2 + j)] <-     # fill in each value in the overlap matrix
      temp_overlaps_dt[, sum(get(mod_conv_bd50_y50_names[j]) == 2)] /  # the first sum, the number of cells with value of 2 (overlap bewteen model i and model j)
      conv_bd50_y50_dt[, sum(get(mod_conv_bd50_y50_names[i]) == 1)] # divided by the total number of cells converted by model i
    
    jaccard_bd50_y50[i, (2 + j)] <- 
      temp_overlaps_dt[, sum(get(mod_conv_bd50_y50_names[j]) == 2)] /  # the intersection, or where the two data.tables overlap (== 2)
      temp_overlaps_dt[, sum(get(mod_conv_bd50_y50_names[j]) >= 1)] # the union, or all cells that are 1 or 2 (selected by either model)
  }
}

# -------------------------
# add stats
overlap_bd50_y50 <- overlap_bd50_y50 %>%
  mutate( 
    mean_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x)))
    ) %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref)) # reorder the levels to match runs_w_ref


jaccard_bd50_y50 <- jaccard_bd50_y50 %>%
  mutate(
    mean_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x)))
    ) %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref)) # reorder the levels to match runs_w_ref


fwrite(overlap_bd50_y50, file = fp(p_mod_output, "overlap_bd50_y50.csv"))
fwrite(jaccard_bd50_y50, file = fp(p_mod_output, "jaccard_bd50_y50.csv"))


```

```{r overlap_jaccard_bd100}
overlap_bd100 <- matrix(nrow = 56, ncol = 56)
colnames(overlap_bd100) <- runs_w_ref

overlap_bd100 <- data.frame(
  bd_input = runs_w_ref,
  mod_spec = "bd100",
  overlap_bd100
)

jaccard_bd100 <- overlap_bd100

for (i in seq_along(runs_w_ref)) {
  temp_overlaps_dt <- conv_bd100_dt[, get(mod_conv_bd100_names[i])] + conv_bd100_dt[, 3:(2 + length(runs_w_ref))] # create a temp dt of the overlaps between the one specific conversion model (model i) and all other models. 
  
  for (j in seq_along(runs_w_ref)) { # now, another for loop, to calculate the overlap and jaccard
    overlap_bd100[i, (2 + j)] <-     # fill in each value in the overlap matrix
      temp_overlaps_dt[, sum(get(mod_conv_bd100_names[j]) == 2)] /  # the first sum, the number of cells with value of 2 (overlap bewteen model i and model j)
      conv_bd100_dt[, sum(get(mod_conv_bd100_names[i]) == 1)] # divided by the total number of cells converted by model i
    
    jaccard_bd100[i, (2 + j)] <- 
      temp_overlaps_dt[, sum(get(mod_conv_bd100_names[j]) == 2)] /  # the intersection, or where the two data.tables overlap (== 2)
      temp_overlaps_dt[, sum(get(mod_conv_bd100_names[j]) >= 1)] # the union, or all cells that are 1 or 2 (selected by either model)
  }
}

# -------------------------
# add stats
overlap_bd100 <- overlap_bd100 %>%
  mutate( 
    mean_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x)))
    ) %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref)) # reorder the levels to match runs_w_ref


jaccard_bd100 <- jaccard_bd100 %>%
  mutate(
    mean_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x)))
    ) %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref)) # reorder the levels to match runs_w_ref


fwrite(overlap_bd100, file = fp(p_mod_output, "overlap_bd100.csv"))
fwrite(jaccard_bd100, file = fp(p_mod_output, "jaccard_bd100.csv"))


```


```{r overlap_jaccard_10p_bd}
overlap_10p_bd <- matrix(nrow = 56, ncol = 56)
colnames(overlap_10p_bd) <- runs_w_ref

overlap_10p_bd <- data.frame(
  bd_input = runs_w_ref,
  mod_spec = "10p_bd",
  overlap_10p_bd
)

jaccard_10p_bd <- overlap_10p_bd

for (i in seq_along(runs_w_ref)) {
  temp_overlaps_dt <- conv_10p_bd_dt[, get(mod_conv_10p_bd_names[i])] + conv_10p_bd_dt[, 3:(2 + length(runs_w_ref))] # create a temp dt of the overlaps between the one specific conversion model (model i) and all other models. 
  
  for (j in seq_along(runs_w_ref)) { # now, another for loop, to calculate the overlap and jaccard
    overlap_10p_bd[i, (2 + j)] <-     # fill in each value in the overlap matrix
      temp_overlaps_dt[, sum(get(mod_conv_10p_bd_names[j]) == 2)] /  # the first sum, the number of cells with value of 2 (overlap bewteen model i and model j)
      conv_10p_bd_dt[, sum(get(mod_conv_10p_bd_names[i]) == 1)] # divided by the total number of cells converted by model i
    
    jaccard_10p_bd[i, (2 + j)] <- 
      temp_overlaps_dt[, sum(get(mod_conv_10p_bd_names[j]) == 2)] /  # the intersection, or where the two data.tables overlap (== 2)
      temp_overlaps_dt[, sum(get(mod_conv_10p_bd_names[j]) >= 1)] # the union, or all cells that are 1 or 2 (selected by either model)
  }
}

# -------------------------
# add stats
overlap_10p_bd <- overlap_10p_bd %>%
  mutate( 
    mean_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x)))
    ) %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref)) # reorder the levels to match runs_w_ref


jaccard_10p_bd <- jaccard_10p_bd %>%
  mutate(
    mean_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = mean),
    sum_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sum),
    var_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = var),
    sd_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = sd),
    se_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x)))
    ) %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref)) # reorder the levels to match runs_w_ref


fwrite(overlap_10p_bd, file = fp(p_mod_output, "overlap_10p_bd.csv"))
fwrite(jaccard_10p_bd, file = fp(p_mod_output, "jaccard_10p_bd.csv"))
```

```{r save+load_overlap_jaccard}
save(
  overlap_eq,
  jaccard_eq,  
  overlap_bd50_y50,
  jaccard_bd50_y50, 
  overlap_bd100,
  jaccard_bd100,  
  # overlap_10p_bd,
  # jaccard_10p_bd, 
     file = fp(p_mod_output, "overlap_and_jaccard_df.RData"))





# load files
overlap_eq <- fread(file = fp(p_mod_output, "overlap_eq.csv"))
jaccard_eq <- fread(file = fp(p_mod_output, "jaccard_eq.csv"))
overlap_bd100 <- fread(file = fp(p_mod_output, "overlap_bd100.csv"))
jaccard_bd100 <- fread(file = fp(p_mod_output, "jaccard_bd100.csv"))
overlap_bd50_y50 <- fread(file = fp(p_mod_output, "overlap_bd50_y50.csv"))
jaccard_bd50_y50 <- fread(file = fp(p_mod_output, "jaccard_bd50_y50.csv"))
overlap_10p_bd <- fread(file = fp(p_mod_output, "overlap_10p_bd.csv"))
jaccard_10p_bd <- fread(file = fp(p_mod_output, "jaccard_10p_bd.csv"))
```



```{r testing-overlaps-jaccard}
# ---------------------------------------------------------
# testing
# ---------------------------------------------------------
mod_conv_eq_names[1]
results_eq
ov_test9 <- conv_eq_dt[, get(mod_conv_eq_names[9])] + conv_eq_dt[, 3:(2+length(runs_w_ref))]
test <- ov_test9$bird_threat_conv_eq
ov_test9 <- conv_eq_dt[, get(mod_conv_eq_names[9])] + conv_eq_dt[, get(mod_conv_eq_names[19])]
ov_test9 <- data.table(ov_test9)
names(ov_test9) <- "v1"
# testing the overlap between mod_conv_eq_names[9] and mod_conv_eq_names[19]


ov_test9[, sum(v1 == 2)] /  # the first sum, the number of cells with value of 2 (overlap)
  conv_eq_dt[, sum(get(mod_conv_eq_names[9]) == 1)] # the number of cells converted by each specific model

6794 / 27898 # % overlap
0.24353

ov_test9[, sum(get(mod_conv_eq_names[19]) == 2)] /  # the first sum, the number of cells with value of 2 (overlap)
  ov_test9[, sum(get(mod_conv_eq_names[19]) >= 1)] # the number of cells converted by each specific model

6794 / 56480 # 0.1202904
ov_test9[, sum(v1 == 1)]

select(overlap_eq, mod_run, m9_mam_all_conv)[19, ]
select(jaccard_eq, mod_run, m9_mam_all_conv)[19, ]

      
overlaps[[1]][, sum(m1_vert_all_conv == 2)]
overlaps[[1]][, sum(get(mod_conv_eq_names[1]) == 2)]

overlaps[[1]][, sum(get(mod_conv_eq_names[1]) == 2)] /  # the intersection, or where the two data.tables overlap (with a value of 2)
  overlaps[[1]][, sum(get(mod_conv_eq_names[1]) >= 1)] # the union

jaccard_eq


# calculate using rasters, with my self-made function
tic()
m1_vert_all_raster_stats <- cc_raster_stats_lite(conv_eq_brick$m1_vert_all, conv_eq_brick)
toc()
jaccard_eq$m1_vert_all_conv

m2_laurance_raster_stats <- cc_raster_stats_lite(conv_eq_brick$m2_laurance, conv_eq_brick)
names(m2_laurance_raster_stats$jaccard) <- names(conv_eq_brick)


test <- cc_dt_stats(conv_eq_dt$m1_estes_conv, conv_eq_dt$m2_laurance_conv)
```

```{r plot-jaccard-per-ensemble}

# all
plot(m2_laurance_raster_stats$jaccard, main = "Jaccard Similarity Index relative to Laurance", 
     xlab = "Model Run", ylab = "Jaccard Index")
plot(m2_laurance_raster_stats$overlap_r1, main = "Percent Overlap with Laurance", 
     xlab = "Model Run", ylab = "% Overlap")



# ensemble 2:
plot(m2_laurance_raster_stats$jaccard, main = "Jaccard Similarity Index relative to Laurance", 
     xlab = "Model Run", ylab = "Jaccard Index")
plot(m2_laurance_raster_stats$overlap_r1, main = "Percent Overlap with Laurance", 
     xlab = "Model Run", ylab = "% Overlap")

# ensemble 3:
plot(m2_laurance_raster_stats$jaccard, main = "Jaccard Similarity Index relative to Laurance", 
     xlab = "Model Run", ylab = "Jaccard Index")
plot(m2_laurance_raster_stats$overlap_r1, main = "Percent Overlap with Laurance", 
     xlab = "Model Run", ylab = "% Overlap")



```

# Combos
```{r results_combo}
# total_area_converted <- colSums(conv_eq_dt[,-c(1:2)]) # to get total area across all columns
# colSums(bd_dt[,-c(1:2)]) # to get total biodiversity scores across all columns
# colSums(bd_conv_eq_dt[,-c(1:2)]) # to get total biodiversity score lost in converted areas across all columns
head(results_eq_norm)
head(results_bd100_norm)
head(results_bd50_y50_norm)
head(results_10p_bd_norm)

results_combo <- rbind(results_eq_norm, results_bd100_norm, results_bd50_y50_norm)
results_combo_raw <- rbind(results_eq, results_bd100, results_bd50_y50) %>%
  rename(bd_input = mod_run) %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref),
         mod_spec = fct_relevel(mod_spec, c("bd100", "bd50_y50", "eq")))

# results_combo_w10p <- rbind(results_eq_norm, results_bd100_norm, results_bd50_y50_norm, results_10p_bd_norm)
names(results_combo)
head(results_combo[, c(1:2, 45)])

results_combo$mod_spec

head(results_combo)
names(results_combo)


results_combo <- results_combo %>%
# results_combo_w10p <- results_combo_w10p %>% # to use when including 10p_bd
  rename(bd_input = mod_run) %>% 
  mutate(
    mean_bd_loss_en1_types = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en1_types_b = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en2_taxa_all = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en2_taxa_endemism = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en2_taxa_threat = apply(.[, c(2 + ensembles_list[[5]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en2_taxa_small = apply(.[, c(2 + ensembles_list[[6]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en3_mb = apply(.[, c(2 + ensembles_list[[7]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en3_vp = apply(.[, c(2 + ensembles_list[[8]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en3_ae = apply(.[, c(2 + ensembles_list[[9]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en4_all = apply(.[, c(2 + ensembles_list[[10]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en4_endemism = apply(.[, c(2 + ensembles_list[[11]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en4_threat = apply(.[, c(2 + ensembles_list[[12]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en4_small = apply(.[, c(2 + ensembles_list[[13]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en5_composites = apply(.[, c(2 + ensembles_list[[14]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en6_norm_all = apply(.[, c(2 + ensembles_list[[15]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en6_norm_endemism = apply(.[, c(2 + ensembles_list[[16]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en6_norm_threat = apply(.[, c(2 + ensembles_list[[17]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_en6_norm_small = apply(.[, c(2 + ensembles_list[[18]])], MARGIN = 1, FUN = mean),
    mean_bd_loss_all = apply(.[, c(2 + ensembles_list[[19]])], MARGIN = 1, FUN = mean),
    
    sd_bd_loss_en1_types = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en1_types_b = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en2_taxa_all = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en2_taxa_endemism = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en2_taxa_threat = apply(.[, c(2 + ensembles_list[[5]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en2_taxa_small = apply(.[, c(2 + ensembles_list[[6]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en3_mb = apply(.[, c(2 + ensembles_list[[7]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en3_vp = apply(.[, c(2 + ensembles_list[[8]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en3_ae = apply(.[, c(2 + ensembles_list[[9]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en4_all = apply(.[, c(2 + ensembles_list[[10]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en4_endemism = apply(.[, c(2 + ensembles_list[[11]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en4_threat = apply(.[, c(2 + ensembles_list[[12]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en4_small = apply(.[, c(2 + ensembles_list[[13]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en5_composites = apply(.[, c(2 + ensembles_list[[14]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en6_norm_all = apply(.[, c(2 + ensembles_list[[15]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en6_norm_endemism = apply(.[, c(2 + ensembles_list[[16]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en6_norm_threat = apply(.[, c(2 + ensembles_list[[17]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_en6_norm_small = apply(.[, c(2 + ensembles_list[[18]])], MARGIN = 1, FUN = sd),
    sd_bd_loss_all = apply(.[, c(2 + ensembles_list[[19]])], MARGIN = 1, FUN = sd),
    
    cv_bd_loss = sd_bd_loss/mean_bd_loss,
    cv_bd_loss_en1_types = sd_bd_loss_en1_types/mean_bd_loss_en1_types,
    cv_bd_loss_en1_types_b = sd_bd_loss_en1_types_b/mean_bd_loss_en1_types_b,
    cv_bd_loss_en2_taxa_all = sd_bd_loss_en2_taxa_all/mean_bd_loss_en2_taxa_all,
    cv_bd_loss_en2_taxa_endemism = sd_bd_loss_en2_taxa_endemism/mean_bd_loss_en2_taxa_endemism,
    cv_bd_loss_en2_taxa_threat = sd_bd_loss_en2_taxa_threat/mean_bd_loss_en2_taxa_threat,
    cv_bd_loss_en2_taxa_small = sd_bd_loss_en2_taxa_small/mean_bd_loss_en2_taxa_small,
    cv_bd_loss_en3_mb = sd_bd_loss_en3_mb/mean_bd_loss_en3_mb,
    cv_bd_loss_en3_vp = sd_bd_loss_en3_vp/mean_bd_loss_en3_vp,
    cv_bd_loss_en3_ae = sd_bd_loss_en3_ae/mean_bd_loss_en3_ae,
    cv_bd_loss_en4_all = sd_bd_loss_en4_all/mean_bd_loss_en4_all,
    cv_bd_loss_en4_endemism = sd_bd_loss_en4_endemism/mean_bd_loss_en4_endemism,
    cv_bd_loss_en4_threat = sd_bd_loss_en4_threat/mean_bd_loss_en4_threat,
    cv_bd_loss_en4_small = sd_bd_loss_en4_small/mean_bd_loss_en4_small,
    cv_bd_loss_en5_composites = sd_bd_loss_en5_composites/mean_bd_loss_en5_composites,
    cv_bd_loss_en6_norm_all = sd_bd_loss_en6_norm_all/mean_bd_loss_en6_norm_all,
    cv_bd_loss_en6_norm_endemism = sd_bd_loss_en6_norm_endemism/mean_bd_loss_en6_norm_endemism,
    cv_bd_loss_en6_norm_threat = sd_bd_loss_en6_norm_threat/mean_bd_loss_en6_norm_threat,
    cv_bd_loss_en6_norm_small = sd_bd_loss_en6_norm_small/mean_bd_loss_en6_norm_small,
    cv_bd_loss_all = sd_bd_loss_all/mean_bd_loss_all,
    
    se_bd_loss_en1_types = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en1_types_b = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en2_taxa_all = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en2_taxa_endemism = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en2_taxa_threat = apply(.[, c(2 + ensembles_list[[5]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en2_taxa_small = apply(.[, c(2 + ensembles_list[[6]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en3_mb = apply(.[, c(2 + ensembles_list[[7]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en3_vp = apply(.[, c(2 + ensembles_list[[8]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en3_ae = apply(.[, c(2 + ensembles_list[[9]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en4_all = apply(.[, c(2 + ensembles_list[[10]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en4_endemism = apply(.[, c(2 + ensembles_list[[11]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en4_threat = apply(.[, c(2 + ensembles_list[[12]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en4_small = apply(.[, c(2 + ensembles_list[[13]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en5_composites = apply(.[, c(2 + ensembles_list[[14]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en6_norm_all = apply(.[, c(2 + ensembles_list[[15]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en6_norm_endemism = apply(.[, c(2 + ensembles_list[[16]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en6_norm_threat = apply(.[, c(2 + ensembles_list[[17]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_en6_norm_small = apply(.[, c(2 + ensembles_list[[18]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x))),
    se_bd_loss_all = apply(.[, c(2 + ensembles_list[[19]])], MARGIN = 1, FUN = function(x) sqrt(var(x)/length(x)))
    )

levels(as.factor(results_combo$bd_input))
#levels(as.factor(results_combo_w10p$bd_input))

results_combo <- results_combo %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref),
         mod_spec = fct_relevel(mod_spec, c("bd100", "bd50_y50", "eq"))) # reorder the levels to match runs_w_ref

levels(results_combo$bd_input)
levels(results_combo$mod_spec)

# write to file:
fwrite(results_combo, file = fp(p_mod_output, "results_combo.csv"))
fwrite(results_combo_raw, file = fp(p_mod_output, "results_combo_raw.csv"))

results_combo <- read.csv(file = fp(p_mod_output, "results_combo.csv"))


# results_combo with the 10p data.
fwrite(results_combo_w10p, file = fp(p_mod_output, "results_combo_w10p.csv"))
results_combo_w10p <- read.csv(file = fp(p_mod_output, "results_combo_w10p.csv"))
```

results_combo_old
```{r}
# combine dfs

head(results_eq_norm)
results_combo2 <- rbind(results_eq_norm, results_bd100_norm, results_bd50_y50_norm, results_10p_bd_norm) %>%
  melt(id.vars = c("mod_run", "mod_spec"))

levels(as.factor(results_combo2$variable))

results_eq_norm_melt <- results_eq_norm %>% 
  mutate(bd_input = runs_w_ref,
         ensemble = c(ensemble_col, "NA", "NA", "NA", "NA")) %>% 
  select(bd_input, ensemble, mean_bd_loss, sum_bd_loss, var_bd_loss, sd_bd_loss, se_bd_loss, var_from_control) %>% 
  melt(id.vars = c("bd_input", "ensemble")) %>% 
  mutate(mod_spec = "eq")

results_bd100_norm_melt <- results_bd100_norm %>% 
  mutate(bd_input = runs_w_ref,
         ensemble = c(ensemble_col, "NA", "NA", "NA", "NA")) %>% 
  select(bd_input, ensemble, mean_bd_loss, sum_bd_loss, var_bd_loss, sd_bd_loss, se_bd_loss, var_from_control) %>% 
  melt(id.vars = c("bd_input", "ensemble")) %>% 
  mutate(mod_spec = "bd100")

results_bd50_y50_norm_melt <- results_bd50_y50_norm %>% 
  mutate(bd_input = runs_w_ref,
         ensemble = c(ensemble_col, "NA", "NA", "NA", "NA")) %>% 
  select(bd_input, ensemble, mean_bd_loss, sum_bd_loss, var_bd_loss, sd_bd_loss, se_bd_loss, var_from_control) %>% 
  melt(id.vars = c("bd_input", "ensemble")) %>% 
  mutate(mod_spec = "bd50_y50")

results_10p_bd_norm_melt <- results_10p_bd_norm %>% 
  mutate(bd_input = runs_w_ref,
         ensemble = c(ensemble_col, "NA", "NA", "NA", "NA")) %>% 
  select(bd_input, ensemble, mean_bd_loss, sum_bd_loss, var_bd_loss, sd_bd_loss, se_bd_loss, var_from_control) %>% 
  melt(id.vars = c("bd_input", "ensemble")) %>% 
  mutate(mod_spec = "10p_bd")

# combine melted dfs and then cast back to long-form
results_combo <- rbind(results_eq_norm_melt, results_bd100_norm_melt, results_bd50_y50_norm_melt, results_10p_bd_norm_melt) %>%
  dcast(bd_input + ensemble + mod_spec ~ variable, value.var = "value") %>%
  mutate(bd_input = fct_relevel(bd_input, runs_w_ref)) # reorder the levels to match runs_w_ref

levels(as.factor(results_combo$bd_input))

names(results_combo)
```

```{r overlap_combo}
# final product, with NAs.
overlap_combo <- read.csv(file = fp(p_mod_output, "overlap_combo.csv"))
# ------------------------------------------------------------------

head(results_eq_norm)
head(overlap_eq)
# jaccard_eq

identical(names(overlap_eq)[3:(2+length(runs_w_ref))], runs_w_ref)
identical(names(overlap_bd100)[3:(2+length(runs_w_ref))], runs_w_ref)
identical(names(overlap_bd50_y50)[3:(2+length(runs_w_ref))], runs_w_ref)
# names(overlap_bd100)[3:(2+length(runs_w_ref))] <- runs_w_ref
# names(overlap_bd50_y50)[3:(2+length(runs_w_ref))] <- runs_w_ref
# names(overlap_10p_bd)[3:(2+length(runs_w_ref))] <- runs_w_ref

overlap_combo <- rbind(overlap_eq, overlap_bd100, overlap_bd50_y50)
# overlap_combo_w10p <- rbind(overlap_eq, overlap_bd100, overlap_bd50_y50, overlap_10p_bd)

# ---------------------------------
# set the diagonal to NA: 
# note that the stats for the full set of biodiversity inputs were calculated with 1 for the diagonal still in the data.frame. I haven't updated them (as of 1/7/20) because I don't plan to use these statistics.
# ---------------------------------
overlap_combo[1, 3]
overlap_combo[,1:4]
head(overlap_combo)[, 1:8]

i
j
for (j in 0:2) { # run from 0:3 when including 10p_bd
  for (i in seq_along(runs_w_ref)) {
    print(overlap_combo[i + j*length(runs_w_ref), i + 2])
    if (overlap_combo[i + j*length(runs_w_ref), i + 2] == 1) {
      overlap_combo[i + j*length(runs_w_ref), i + 2] <- NA
      }
  }
}
head(overlap_combo)[, 1:8]
# can also use this: overlap_combo[overlap_combo == 1] <- NA


overlap_eq %>% head()
length(runs)
overlap_eq[1, 3:56] %>%
  as.numeric() %>%
  mean()

overlap_eq %>% select(bd_input, mod_spec, mean_overlap) %>% head()

overlap_combo %>%
  filter(mod_spec == "eq",
         bd_input == "vert_all") %>% 
  .$mean_overlap_en1_types


# ---------------------------------
# run code to calculate mean, standard error, sd, cv, etc. 
# ---------------------------------

overlap_combo$mod_spec
head(overlap_combo[, c(2 + ensembles_list[[10]])])

overlap_combo <- overlap_combo %>% 
# overlap_combo_w10p <- overlap_combo_w10p %>% 
  mutate(
    # redoing the stats to remove NAs first:
    mean_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    sum_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sum(x, na.rm = TRUE)),
    var_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) var(x, na.rm = TRUE)),
    sd_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    se_overlap = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    
    mean_overlap_en1_types = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en1_types_b = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en2_taxa_all = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en2_taxa_endemism = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en2_taxa_threat = apply(.[, c(2 + ensembles_list[[5]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en2_taxa_small = apply(.[, c(2 + ensembles_list[[6]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en3_mb = apply(.[, c(2 + ensembles_list[[7]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en3_vp = apply(.[, c(2 + ensembles_list[[8]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en3_ae = apply(.[, c(2 + ensembles_list[[9]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en4_all = apply(.[, c(2 + ensembles_list[[10]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en4_endemism = apply(.[, c(2 + ensembles_list[[11]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en4_threat = apply(.[, c(2 + ensembles_list[[12]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en4_small = apply(.[, c(2 + ensembles_list[[13]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en5_composites = apply(.[, c(2 + ensembles_list[[14]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en6_norm_all = apply(.[, c(2 + ensembles_list[[15]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en6_norm_endemism = apply(.[, c(2 + ensembles_list[[16]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en6_norm_threat = apply(.[, c(2 + ensembles_list[[17]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en6_norm_small = apply(.[, c(2 + ensembles_list[[18]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_all = apply(.[, c(2 + ensembles_list[[19]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    
    sd_overlap_en1_types = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en1_types_b = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en2_taxa_all = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en2_taxa_endemism = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en2_taxa_threat = apply(.[, c(2 + ensembles_list[[5]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en2_taxa_small = apply(.[, c(2 + ensembles_list[[6]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en3_mb = apply(.[, c(2 + ensembles_list[[7]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en3_vp = apply(.[, c(2 + ensembles_list[[8]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en3_ae = apply(.[, c(2 + ensembles_list[[9]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en4_all = apply(.[, c(2 + ensembles_list[[10]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en4_endemism = apply(.[, c(2 + ensembles_list[[11]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en4_threat = apply(.[, c(2 + ensembles_list[[12]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en4_small = apply(.[, c(2 + ensembles_list[[13]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en5_composites = apply(.[, c(2 + ensembles_list[[14]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en6_norm_all = apply(.[, c(2 + ensembles_list[[15]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en6_norm_endemism = apply(.[, c(2 + ensembles_list[[16]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en6_norm_threat = apply(.[, c(2 + ensembles_list[[17]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_en6_norm_small = apply(.[, c(2 + ensembles_list[[18]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_overlap_all = apply(.[, c(2 + ensembles_list[[19]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    
    cv_overlap = sd_overlap/mean_overlap,
    cv_overlap_en1_types = sd_overlap_en1_types/mean_overlap_en1_types,
    cv_overlap_en1_types_b = sd_overlap_en1_types_b/mean_overlap_en1_types_b,
    cv_overlap_en2_taxa_all = sd_overlap_en2_taxa_all/mean_overlap_en2_taxa_all,
    cv_overlap_en2_taxa_endemism = sd_overlap_en2_taxa_endemism/mean_overlap_en2_taxa_endemism,
    cv_overlap_en2_taxa_threat = sd_overlap_en2_taxa_threat/mean_overlap_en2_taxa_threat,
    cv_overlap_en2_taxa_small = sd_overlap_en2_taxa_small/mean_overlap_en2_taxa_small,
    cv_overlap_en3_mb = sd_overlap_en3_mb/mean_overlap_en3_mb,
    cv_overlap_en3_vp = sd_overlap_en3_vp/mean_overlap_en3_vp,
    cv_overlap_en3_ae = sd_overlap_en3_ae/mean_overlap_en3_ae,
    cv_overlap_en4_all = sd_overlap_en4_all/mean_overlap_en4_all,
    cv_overlap_en4_endemism = sd_overlap_en4_endemism/mean_overlap_en4_endemism,
    cv_overlap_en4_threat = sd_overlap_en4_threat/mean_overlap_en4_threat,
    cv_overlap_en4_small = sd_overlap_en4_small/mean_overlap_en4_small,
    cv_overlap_en5_composites = sd_overlap_en5_composites/mean_overlap_en5_composites,
    cv_overlap_en6_norm_all = sd_overlap_en6_norm_all/mean_overlap_en6_norm_all,
    cv_overlap_en6_norm_endemism = sd_overlap_en6_norm_endemism/mean_overlap_en6_norm_endemism,
    cv_overlap_en6_norm_threat = sd_overlap_en6_norm_threat/mean_overlap_en6_norm_threat,
    cv_overlap_en6_norm_small = sd_overlap_en6_norm_small/mean_overlap_en6_norm_small,
    cv_overlap_all = sd_overlap_all/mean_overlap_all,
    
    se_overlap_en1_types = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en1_types_b = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en2_taxa_all = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en2_taxa_endemism = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en2_taxa_threat = apply(.[, c(2 + ensembles_list[[5]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en2_taxa_small = apply(.[, c(2 + ensembles_list[[6]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en3_mb = apply(.[, c(2 + ensembles_list[[7]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en3_vp = apply(.[, c(2 + ensembles_list[[8]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en3_ae = apply(.[, c(2 + ensembles_list[[9]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en4_all = apply(.[, c(2 + ensembles_list[[10]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en4_endemism = apply(.[, c(2 + ensembles_list[[11]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en4_threat = apply(.[, c(2 + ensembles_list[[12]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en4_small = apply(.[, c(2 + ensembles_list[[13]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en5_composites = apply(.[, c(2 + ensembles_list[[14]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en6_norm_all = apply(.[, c(2 + ensembles_list[[15]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en6_norm_endemism = apply(.[, c(2 + ensembles_list[[16]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en6_norm_threat = apply(.[, c(2 + ensembles_list[[17]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en6_norm_small = apply(.[, c(2 + ensembles_list[[18]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_all = apply(.[, c(2 + ensembles_list[[19]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x))))
    )

head(overlap_combo)

levels(overlap_combo$mod_spec)
levels(overlap_combo$bd_input)

overlap_combo <- overlap_combo %>% 
  mutate(mod_spec = fct_relevel(mod_spec, c("bd100", "bd50_y50", "eq")))

# write to file:
fwrite(overlap_combo, file = fp(p_mod_output, "overlap_combo.csv"))
overlap_combo <- read.csv(file = fp(p_mod_output, "overlap_combo.csv"))


# overlap_combo with the 10p data.
fwrite(overlap_combo_w10p, file = fp(p_mod_output, "overlap_combo_w10p.csv"))
overlap_combo_w10p <- read.csv(file = fp(p_mod_output, "overlap_combo_w10p.csv"))


# ----------------------------------------------------------------
# old
# ----------------------------------------------------------------
# combine dfs
# overlap_eq_melt <- overlap_eq %>% 
#   mutate(bd_input = runs_w_ref,
#          ensemble = c(ensemble_col, "NA", "NA", "NA", "NA")) %>% 
#   select(bd_input, ensemble, mean_overlap, sum_overlap, var_overlap, sd_overlap, se_overlap) %>% 
#   melt(id.vars = c("bd_input", "ensemble")) %>% 
#   mutate(mod_spec = "eq")
# 
# overlap_bd100_melt <- overlap_bd100 %>% 
#   mutate(bd_input = runs_w_ref,
#          ensemble = c(ensemble_col, "NA", "NA", "NA", "NA")) %>% 
#   select(bd_input, ensemble, mean_overlap, sum_overlap, var_overlap, sd_overlap, se_overlap) %>% 
#   melt(id.vars = c("bd_input", "ensemble")) %>% 
#   mutate(mod_spec = "bd100")
# 
# overlap_bd50_y50_melt <- overlap_bd50_y50 %>% 
#   mutate(bd_input = runs_w_ref,
#          ensemble = c(ensemble_col, "NA", "NA", "NA", "NA")) %>% 
#   select(bd_input, ensemble, mean_overlap, sum_overlap, var_overlap, sd_overlap, se_overlap) %>% 
#   melt(id.vars = c("bd_input", "ensemble")) %>% 
#   mutate(mod_spec = "bd50_y50")
# 
# overlap_10p_bd_melt <- overlap_10p_bd %>% 
#   mutate(bd_input = runs_w_ref,
#          ensemble = c(ensemble_col, "NA", "NA", "NA", "NA")) %>% 
#   select(bd_input, ensemble, mean_overlap, sum_overlap, var_overlap, sd_overlap, se_overlap) %>% 
#   melt(id.vars = c("bd_input", "ensemble")) %>% 
#   mutate(mod_spec = "10p_bd")
# 
# # combine melted dfs and then cast back to long-form
# overlap_combo <- rbind(overlap_eq_melt, overlap_bd100_melt, overlap_bd50_y50_melt, overlap_10p_bd_melt) %>%
#   dcast(bd_input + ensemble + mod_spec ~ variable, value.var = "value") %>%
#   mutate(bd_input = fct_relevel(bd_input, runs_w_ref)) # reorder the levels to match runs_w_ref
# 
# levels(as.factor(overlap_combo$bd_input))
# 
# names(overlap_combo)
```

```{r jaccard_combo}
jaccard_bd100

# final product, with NAs.
jaccard_combo <- read.csv(file = fp(p_mod_output, "jaccard_combo.csv"))
# ------------------------------------------------------------------

head(results_eq_norm)
head(jaccard_eq)
# jaccard_eq

identical(names(jaccard_eq)[3:(2+length(runs_w_ref))], runs_w_ref)
identical(names(jaccard_bd100)[3:(2+length(runs_w_ref))], runs_w_ref)
identical(names(jaccard_bd50_y50)[3:(2+length(runs_w_ref))], runs_w_ref)
# names(jaccard_bd100)[3:(2+length(runs_w_ref))] <- runs_w_ref
# names(jaccard_bd50_y50)[3:(2+length(runs_w_ref))] <- runs_w_ref
# names(jaccard_10p_bd)[3:(2+length(runs_w_ref))] <- runs_w_ref

jaccard_combo <- rbind(jaccard_eq, jaccard_bd100, jaccard_bd50_y50)
# jaccard_combo_w10p <- rbind(jaccard_eq, jaccard_bd100, jaccard_bd50_y50, jaccard_10p_bd)

# ---------------------------------
# set the diagonal to NA: 
# note that the stats for the full set of biodiversity inputs were calculated with 1 for the diagonal still in the data.frame. I haven't updated them (as of 1/7/20) because I don't plan to use these statistics.
# ---------------------------------
jaccard_combo[1, 3]
jaccard_combo[,1:4]
head(jaccard_combo)[, 1:8]

i
j
for (j in 0:2) { # run from 0:3 when including 10p_bd
  for (i in seq_along(runs_w_ref)) {
    print(jaccard_combo[i + j*length(runs_w_ref), i + 2])
    if (jaccard_combo[i + j*length(runs_w_ref), i + 2] == 1) {
      jaccard_combo[i + j*length(runs_w_ref), i + 2] <- NA
      }
  }
}
head(jaccard_combo)[, 1:8]

jaccard_eq %>% head()
length(runs)
jaccard_eq[1, 3:56] %>%
  as.numeric() %>%
  mean()

which(names(jaccard_combo) == "mean_jaccard")
names(jaccard_combo)[59]
jaccard_combo %>% select(bd_input, mod_spec, mean_jaccard) %>% head()

jaccard_combo %>%
  filter(mod_spec == "eq",
         bd_input == "vert_all") %>% 
  .$mean_jaccard_en1_types


# ---------------------------------
# run code to calculate mean, standard error, sd, cv, etc. 
# ---------------------------------

jaccard_combo$mod_spec
head(jaccard_combo[, c(2 + ensembles_list[[10]])])

jaccard_combo <- jaccard_combo %>% 
# jaccard_combo_w10p <- jaccard_combo_w10p %>% 
  mutate(
    # redoing the stats to remove NAs first:
    mean_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    sum_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sum(x, na.rm = TRUE)),
    var_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) var(x, na.rm = TRUE)),
    sd_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    se_jaccard = apply(.[, 3:(2+length(runs))], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    
    mean_jaccard_en1_types = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en1_types_b = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en2_taxa_all = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en2_taxa_endemism = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en2_taxa_threat = apply(.[, c(2 + ensembles_list[[5]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en2_taxa_small = apply(.[, c(2 + ensembles_list[[6]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en3_mb = apply(.[, c(2 + ensembles_list[[7]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en3_vp = apply(.[, c(2 + ensembles_list[[8]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en3_ae = apply(.[, c(2 + ensembles_list[[9]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en4_all = apply(.[, c(2 + ensembles_list[[10]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en4_endemism = apply(.[, c(2 + ensembles_list[[11]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en4_threat = apply(.[, c(2 + ensembles_list[[12]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en4_small = apply(.[, c(2 + ensembles_list[[13]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en5_composites = apply(.[, c(2 + ensembles_list[[14]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en6_norm_all = apply(.[, c(2 + ensembles_list[[15]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en6_norm_endemism = apply(.[, c(2 + ensembles_list[[16]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en6_norm_threat = apply(.[, c(2 + ensembles_list[[17]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_en6_norm_small = apply(.[, c(2 + ensembles_list[[18]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    mean_jaccard_all = apply(.[, c(2 + ensembles_list[[19]])], MARGIN = 1, FUN = function(x) mean(x, na.rm = TRUE)),
    
    sd_jaccard_en1_types = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en1_types_b = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en2_taxa_all = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en2_taxa_endemism = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en2_taxa_threat = apply(.[, c(2 + ensembles_list[[5]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en2_taxa_small = apply(.[, c(2 + ensembles_list[[6]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en3_mb = apply(.[, c(2 + ensembles_list[[7]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en3_vp = apply(.[, c(2 + ensembles_list[[8]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en3_ae = apply(.[, c(2 + ensembles_list[[9]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en4_all = apply(.[, c(2 + ensembles_list[[10]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en4_endemism = apply(.[, c(2 + ensembles_list[[11]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en4_threat = apply(.[, c(2 + ensembles_list[[12]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en4_small = apply(.[, c(2 + ensembles_list[[13]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en5_composites = apply(.[, c(2 + ensembles_list[[14]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en6_norm_all = apply(.[, c(2 + ensembles_list[[15]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en6_norm_endemism = apply(.[, c(2 + ensembles_list[[16]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en6_norm_threat = apply(.[, c(2 + ensembles_list[[17]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_en6_norm_small = apply(.[, c(2 + ensembles_list[[18]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    sd_jaccard_all = apply(.[, c(2 + ensembles_list[[19]])], MARGIN = 1, FUN = function(x) sd(x, na.rm = TRUE)),
    
    cv_jaccard = sd_jaccard/mean_jaccard,
    cv_jaccard_en1_types = sd_jaccard_en1_types/mean_jaccard_en1_types,
    cv_jaccard_en1_types_b = sd_jaccard_en1_types_b/mean_jaccard_en1_types_b,
    cv_jaccard_en2_taxa_all = sd_jaccard_en2_taxa_all/mean_jaccard_en2_taxa_all,
    cv_jaccard_en2_taxa_endemism = sd_jaccard_en2_taxa_endemism/mean_jaccard_en2_taxa_endemism,
    cv_jaccard_en2_taxa_threat = sd_jaccard_en2_taxa_threat/mean_jaccard_en2_taxa_threat,
    cv_jaccard_en2_taxa_small = sd_jaccard_en2_taxa_small/mean_jaccard_en2_taxa_small,
    cv_jaccard_en3_mb = sd_jaccard_en3_mb/mean_jaccard_en3_mb,
    cv_jaccard_en3_vp = sd_jaccard_en3_vp/mean_jaccard_en3_vp,
    cv_jaccard_en3_ae = sd_jaccard_en3_ae/mean_jaccard_en3_ae,
    cv_jaccard_en4_all = sd_jaccard_en4_all/mean_jaccard_en4_all,
    cv_jaccard_en4_endemism = sd_jaccard_en4_endemism/mean_jaccard_en4_endemism,
    cv_jaccard_en4_threat = sd_jaccard_en4_threat/mean_jaccard_en4_threat,
    cv_jaccard_en4_small = sd_jaccard_en4_small/mean_jaccard_en4_small,
    cv_jaccard_en5_composites = sd_jaccard_en5_composites/mean_jaccard_en5_composites,
    cv_jaccard_en6_norm_all = sd_jaccard_en6_norm_all/mean_jaccard_en6_norm_all,
    cv_jaccard_en6_norm_endemism = sd_jaccard_en6_norm_endemism/mean_jaccard_en6_norm_endemism,
    cv_jaccard_en6_norm_threat = sd_jaccard_en6_norm_threat/mean_jaccard_en6_norm_threat,
    cv_jaccard_en6_norm_small = sd_jaccard_en6_norm_small/mean_jaccard_en6_norm_small,
    cv_jaccard_all = sd_jaccard_all/mean_jaccard_all,
    
    se_jaccard_en1_types = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en1_types_b = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en2_taxa_all = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en2_taxa_endemism = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en2_taxa_threat = apply(.[, c(2 + ensembles_list[[5]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en2_taxa_small = apply(.[, c(2 + ensembles_list[[6]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en3_mb = apply(.[, c(2 + ensembles_list[[7]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en3_vp = apply(.[, c(2 + ensembles_list[[8]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en3_ae = apply(.[, c(2 + ensembles_list[[9]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en4_all = apply(.[, c(2 + ensembles_list[[10]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en4_endemism = apply(.[, c(2 + ensembles_list[[11]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en4_threat = apply(.[, c(2 + ensembles_list[[12]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en4_small = apply(.[, c(2 + ensembles_list[[13]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en5_composites = apply(.[, c(2 + ensembles_list[[14]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en6_norm_all = apply(.[, c(2 + ensembles_list[[15]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en6_norm_endemism = apply(.[, c(2 + ensembles_list[[16]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en6_norm_threat = apply(.[, c(2 + ensembles_list[[17]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_en6_norm_small = apply(.[, c(2 + ensembles_list[[18]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_jaccard_all = apply(.[, c(2 + ensembles_list[[19]])], MARGIN = 1, FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x))))
    )

head(jaccard_combo)

levels(jaccard_combo$mod_spec)
levels(jaccard_combo$bd_input)

jaccard_combo <- jaccard_combo %>% 
  mutate(mod_spec = fct_relevel(mod_spec, c("bd100", "bd50_y50", "eq")))

# write to file:
fwrite(jaccard_combo, file = fp(p_mod_output, "jaccard_combo.csv"))
jaccard_combo <- read.csv(file = fp(p_mod_output, "jaccard_combo.csv"))


# jaccard_combo with the 10p data.
fwrite(jaccard_combo_w10p, file = fp(p_mod_output, "jaccard_combo_w10p.csv"))
jaccard_combo_w10p <- read.csv(file = fp(p_mod_output, "jaccard_combo_w10p.csv"))


```


Testing the new NA, overlap_combo codes
```{r}
tester <- overlap_combo %>%
  select(bd_input, mod_spec, 
         runs[en1_types], 
         grep("mean_overlap_en1_types", names(overlap_combo), value = TRUE),
         grep("se_overlap_en1_types", names(overlap_combo), value = TRUE)
         ) %>%
  filter(bd_input %in% runs[en1_types], mod_spec == c("eq"))


tester <- overlap_combo[ , 1:37]

grep("mean_overlap_en1", names(overlap_combo), value = TRUE)
grep("se_overlap_en1", names(overlap_combo), value = TRUE)

mean(as.numeric(tester[1, 2+ensembles_list$en1_taxa_threat]))

# set the diagonal to NA:
tester[1, 3]
tester[,1:4]

for (j in 0:3) {
  for (i in seq_along(runs_w_ref)) {
    print(tester[i + j*35, i + 2])
    tester[i + j*35, i + 2] <- NA
  }
}

tester <- tester %>%
  mutate(
    mean_overlap_en1 = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, 
                             FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en1_types = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, 
                                   FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en1_taxa_threat = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, 
                                         FUN = function(x) mean(x, na.rm = TRUE)),
    mean_overlap_en1_taxa_all = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, 
                                      FUN = function(x) mean(x, na.rm = TRUE)),
    
    se_overlap_en1 = apply(.[, c(2 + ensembles_list[[1]])], MARGIN = 1, 
                           FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en1_types = apply(.[, c(2 + ensembles_list[[2]])], MARGIN = 1, 
                                 FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en1_taxa_threat = apply(.[, c(2 + ensembles_list[[3]])], MARGIN = 1, 
                                       FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x)))),
    se_overlap_en1_taxa_all = apply(.[, c(2 + ensembles_list[[4]])], MARGIN = 1, 
                                    FUN = function(x) sqrt(var(x, na.rm = TRUE)/sum(!is.na(x))))
  )

tester[, c(2 + ensembles_list[[1]])][1,] %>% as.numeric() %>% mean(., na.rm = TRUE)
sqrt(var(as.numeric(tester[, c(2 + ensembles_list[[1]])][1,]), na.rm = TRUE)
     /sum(!is.na(as.numeric(tester[, c(2 + ensembles_list[[1]])][1,]))))

tester[, c(2 + ensembles_list[[2]])][1,] %>% as.numeric() %>% mean(., na.rm = TRUE)
sqrt(var(as.numeric(tester[, c(2 + ensembles_list[[2]])][1,]), na.rm = TRUE)
     /sum(!is.na(as.numeric(tester[, c(2 + ensembles_list[[2]])][1,]))))

tester[, c(2 + ensembles_list[[1]])][36,] %>% as.numeric() %>% mean(., na.rm = TRUE)
sqrt(var(as.numeric(tester[, c(2 + ensembles_list[[1]])][36,]), na.rm = TRUE)
     /sum(!is.na(as.numeric(tester[, c(2 + ensembles_list[[1]])][36,]))))

tester[, c(2 + ensembles_list[[2]])][36,] %>% as.numeric() %>% mean(., na.rm = TRUE)
sqrt(var(as.numeric(tester[, c(2 + ensembles_list[[2]])][36,]), na.rm = TRUE)
     /sum(!is.na(as.numeric(tester[, c(2 + ensembles_list[[2]])][36,]))))


tester[c(1, 36), c(38:39, 42:43)]

# checks out

m
length(m)
sum(!is.na(m))
m[1] <- 1
```


# Construct ensembles:
```{r create_ensembles}
# eq
conv_eq_dt_ensembles <- copy(conv_eq_dt)
length(conv_eq_dt_ensembles)
names(conv_eq_dt_ensembles)
names(conv_eq_dt_ensembles) <- c("x", "y", runs_w_ref)

runs[ensembles_list[[1]]]
names(ensembles_list)


conv_eq_dt_ensembles[, ':=' (
  en1_types = rowSums(.SD[, runs[ensembles_list$en1_types], with = FALSE]),
  en1_types_b = rowSums(.SD[, runs[ensembles_list$en1_types_b], with = FALSE]),
  en2_taxa_all = rowSums(.SD[, runs[ensembles_list$en2_taxa_all], with = FALSE]),
  en2_taxa_endemism = rowSums(.SD[, runs[ensembles_list$en2_taxa_endemism], with = FALSE]),
  en2_taxa_threat = rowSums(.SD[, runs[ensembles_list$en2_taxa_threat], with = FALSE]),
  en2_taxa_small = rowSums(.SD[, runs[ensembles_list$en2_taxa_small], with = FALSE]),
  en3_mb = rowSums(.SD[, runs[ensembles_list$en3_mb], with = FALSE]),
  en3_vp = rowSums(.SD[, runs[ensembles_list$en3_vp], with = FALSE]),
  en3_ae = rowSums(.SD[, runs[ensembles_list$en3_ae], with = FALSE]),
  en4_all = rowSums(.SD[, runs[ensembles_list$en4_all], with = FALSE]),
  en4_endemism = rowSums(.SD[, runs[ensembles_list$en4_endemism], with = FALSE]),
  en4_threat = rowSums(.SD[, runs[ensembles_list$en4_threat], with = FALSE]),
  en4_small = rowSums(.SD[, runs[ensembles_list$en4_small], with = FALSE]),
  en5_composites = rowSums(.SD[, runs[ensembles_list$en5_composites], with = FALSE]),
  en6_norm_all = rowSums(.SD[, runs[ensembles_list$en6_norm_all], with = FALSE]),
  en6_norm_endemism = rowSums(.SD[, runs[ensembles_list$en6_norm_endemism], with = FALSE]),
  en6_norm_threat = rowSums(.SD[, runs[ensembles_list$en6_norm_threat], with = FALSE]),
  en6_norm_small = rowSums(.SD[, runs[ensembles_list$en6_norm_small], with = FALSE]),
  all = rowSums(.SD[, runs[ensembles_list$all], with = FALSE])
  )]

names(conv_eq_dt)
names(conv_eq_dt_ensembles)
conv_eq_dt_ensembles[, (3+length(runs_w_ref)):(2+length(runs_w_ref)+length(ensembles_list))]
conv_eq_dt_ensembles_r <- dt_to_raster(conv_eq_dt_ensembles, CRSobj)
plot(conv_eq_dt_ensembles_r, 57:60)
names(conv_eq_dt_ensembles_r)

# bd50_y50
conv_bd50_y50_dt_ensembles <- copy(conv_bd50_y50_dt)
length(conv_bd50_y50_dt_ensembles)
names(conv_bd50_y50_dt_ensembles)
names(conv_bd50_y50_dt_ensembles) <- c("x", "y", runs_w_ref)

conv_bd50_y50_dt_ensembles[, ':=' (
  en1_types = rowSums(.SD[, runs[ensembles_list$en1_types], with = FALSE]),
  en1_types_b = rowSums(.SD[, runs[ensembles_list$en1_types_b], with = FALSE]),
  en2_taxa_all = rowSums(.SD[, runs[ensembles_list$en2_taxa_all], with = FALSE]),
  en2_taxa_endemism = rowSums(.SD[, runs[ensembles_list$en2_taxa_endemism], with = FALSE]),
  en2_taxa_threat = rowSums(.SD[, runs[ensembles_list$en2_taxa_threat], with = FALSE]),
  en2_taxa_small = rowSums(.SD[, runs[ensembles_list$en2_taxa_small], with = FALSE]),
  en3_mb = rowSums(.SD[, runs[ensembles_list$en3_mb], with = FALSE]),
  en3_vp = rowSums(.SD[, runs[ensembles_list$en3_vp], with = FALSE]),
  en3_ae = rowSums(.SD[, runs[ensembles_list$en3_ae], with = FALSE]),
  en4_all = rowSums(.SD[, runs[ensembles_list$en4_all], with = FALSE]),
  en4_endemism = rowSums(.SD[, runs[ensembles_list$en4_endemism], with = FALSE]),
  en4_threat = rowSums(.SD[, runs[ensembles_list$en4_threat], with = FALSE]),
  en4_small = rowSums(.SD[, runs[ensembles_list$en4_small], with = FALSE]),
  en5_composites = rowSums(.SD[, runs[ensembles_list$en5_composites], with = FALSE]),
  en6_norm_all = rowSums(.SD[, runs[ensembles_list$en6_norm_all], with = FALSE]),
  en6_norm_endemism = rowSums(.SD[, runs[ensembles_list$en6_norm_endemism], with = FALSE]),
  en6_norm_threat = rowSums(.SD[, runs[ensembles_list$en6_norm_threat], with = FALSE]),
  en6_norm_small = rowSums(.SD[, runs[ensembles_list$en6_norm_small], with = FALSE]),
  all = rowSums(.SD[, runs[ensembles_list$all], with = FALSE])
  )]

conv_bd50_y50_dt_ensembles[, (3+length(runs_w_ref)):(2+length(runs_w_ref)+length(ensembles_list))]
conv_bd50_y50_dt_ensembles_r <- dt_to_raster(conv_bd50_y50_dt_ensembles, CRSobj)
plot(conv_bd50_y50_dt_ensembles_r, 1:8)

# bd100
conv_bd100_dt_ensembles <- copy(conv_bd100_dt)
length(conv_bd100_dt_ensembles)
names(conv_bd100_dt_ensembles)
names(conv_bd100_dt_ensembles) <- c("x", "y", runs_w_ref)

conv_bd100_dt_ensembles[, ':=' (
  en1_types = rowSums(.SD[, runs[ensembles_list$en1_types], with = FALSE]),
  en1_types_b = rowSums(.SD[, runs[ensembles_list$en1_types_b], with = FALSE]),
  en2_taxa_all = rowSums(.SD[, runs[ensembles_list$en2_taxa_all], with = FALSE]),
  en2_taxa_endemism = rowSums(.SD[, runs[ensembles_list$en2_taxa_endemism], with = FALSE]),
  en2_taxa_threat = rowSums(.SD[, runs[ensembles_list$en2_taxa_threat], with = FALSE]),
  en2_taxa_small = rowSums(.SD[, runs[ensembles_list$en2_taxa_small], with = FALSE]),
  en3_mb = rowSums(.SD[, runs[ensembles_list$en3_mb], with = FALSE]),
  en3_vp = rowSums(.SD[, runs[ensembles_list$en3_vp], with = FALSE]),
  en3_ae = rowSums(.SD[, runs[ensembles_list$en3_ae], with = FALSE]),
  en4_all = rowSums(.SD[, runs[ensembles_list$en4_all], with = FALSE]),
  en4_endemism = rowSums(.SD[, runs[ensembles_list$en4_endemism], with = FALSE]),
  en4_threat = rowSums(.SD[, runs[ensembles_list$en4_threat], with = FALSE]),
  en4_small = rowSums(.SD[, runs[ensembles_list$en4_small], with = FALSE]),
  en5_composites = rowSums(.SD[, runs[ensembles_list$en5_composites], with = FALSE]),
  en6_norm_all = rowSums(.SD[, runs[ensembles_list$en6_norm_all], with = FALSE]),
  en6_norm_endemism = rowSums(.SD[, runs[ensembles_list$en6_norm_endemism], with = FALSE]),
  en6_norm_threat = rowSums(.SD[, runs[ensembles_list$en6_norm_threat], with = FALSE]),
  en6_norm_small = rowSums(.SD[, runs[ensembles_list$en6_norm_small], with = FALSE]),
  all = rowSums(.SD[, runs[ensembles_list$all], with = FALSE])
  )]

conv_bd100_dt_ensembles[, (3+length(runs_w_ref)):(2+length(runs_w_ref)+length(ensembles_list))]
conv_bd100_dt_ensembles_r <- dt_to_raster(conv_bd100_dt_ensembles, CRSobj)
plot(conv_bd100_dt_ensembles_r, 1:8)

# 10p_bd - unused
conv_10p_bd_dt_ensembles <- copy(conv_10p_bd_dt)
length(conv_10p_bd_dt_ensembles)
names(conv_10p_bd_dt_ensembles)
names(conv_10p_bd_dt_ensembles) <- c("x", "y", runs_w_ref)

conv_10p_bd_dt_ensembles[, ':=' (
  en1_types = rowSums(.SD[, runs[ensembles_list$en1_types], with = FALSE]),
  en1_types_b = rowSums(.SD[, runs[ensembles_list$en1_types_b], with = FALSE]),
  en2_taxa_all = rowSums(.SD[, runs[ensembles_list$en2_taxa_all], with = FALSE]),
  en2_taxa_endemism = rowSums(.SD[, runs[ensembles_list$en2_taxa_endemism], with = FALSE]),
  en2_taxa_threat = rowSums(.SD[, runs[ensembles_list$en2_taxa_threat], with = FALSE]),
  en2_taxa_small = rowSums(.SD[, runs[ensembles_list$en2_taxa_small], with = FALSE]),
  en3_mb = rowSums(.SD[, runs[ensembles_list$en3_mb], with = FALSE]),
  en3_vp = rowSums(.SD[, runs[ensembles_list$en3_vp], with = FALSE]),
  en3_ae = rowSums(.SD[, runs[ensembles_list$en3_ae], with = FALSE]),
  en4_all = rowSums(.SD[, runs[ensembles_list$en4_all], with = FALSE]),
  en4_endemism = rowSums(.SD[, runs[ensembles_list$en4_endemism], with = FALSE]),
  en4_threat = rowSums(.SD[, runs[ensembles_list$en4_threat], with = FALSE]),
  en4_small = rowSums(.SD[, runs[ensembles_list$en4_small], with = FALSE]),
  en5_composites = rowSums(.SD[, runs[ensembles_list$en5_composites], with = FALSE]),
  en6_norm_all = rowSums(.SD[, runs[ensembles_list$en6_norm_all], with = FALSE]),
  en6_norm_endemism = rowSums(.SD[, runs[ensembles_list$en6_norm_endemism], with = FALSE]),
  en6_norm_threat = rowSums(.SD[, runs[ensembles_list$en6_norm_threat], with = FALSE]),
  en6_norm_small = rowSums(.SD[, runs[ensembles_list$en6_norm_small], with = FALSE]),
  all = rowSums(.SD[, runs[ensembles_list$all], with = FALSE])
  )]

conv_10p_bd_dt_ensembles[, (3+length(runs_w_ref)):(2+length(runs_w_ref)+length(ensembles_list))]
length(conv_10p_bd_dt_ensembles)
conv_10p_bd_dt_ensembles_r <- dt_to_raster(conv_10p_bd_dt_ensembles, CRSobj)
plot(conv_10p_bd_dt_ensembles_r)

names(conv_10p_bd_dt_ensembles_r)


# ---------------------------------------
# final steps
# ---------------------------------------
# save ensembles data.tables
fwrite(conv_eq_dt_ensembles, file = fp(p_mod_output, "conv_eq_dt_ensembles.csv"))
fwrite(conv_bd100_dt_ensembles, file = fp(p_mod_output, "conv_bd100_dt_ensembles.csv"))
fwrite(conv_bd50_y50_dt_ensembles, file = fp(p_mod_output, "conv_bd50_y50_dt_ensembles.csv"))
fwrite(conv_10p_bd_dt_ensembles, file = fp(p_mod_output, "conv_10p_bd_dt_ensembles.csv"))


# save raster bricks:
conv_eq_dt_ensembles_r <- writeRaster(conv_eq_dt_ensembles_r,  overwrite=TRUE,
                               fp(p_mod_output,"conv_eq_dt_ensembles_r.tif"))

conv_bd50_y50_dt_ensembles_r <- writeRaster(conv_bd50_y50_dt_ensembles_r,  overwrite=TRUE,
                               fp(p_mod_output,"conv_bd50_y50_dt_ensembles_r.tif"))

conv_bd100_dt_ensembles_r <- writeRaster(conv_bd100_dt_ensembles_r,  overwrite=TRUE,
                               fp(p_mod_output,"conv_bd100_dt_ensembles_r.tif"))

names(dt_to_raster(conv_b_pure_dt, CRSobj))
runs
conv_b_pure_dt_r <- writeRaster(dt_to_raster(conv_b_pure_dt, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"conv_b_pure_dt_r.tif"))

# conv_10p_bd_dt_ensembles_r <- writeRaster(conv_10p_bd_dt_ensembles_r,  overwrite=TRUE,
#                                fp(p_mod_output,"conv_10p_bd_dt_ensembles_r.tif"))

# load it back in:
conv_eq_dt_ensembles_r <- brick(fp(p_mod_output,"conv_eq_dt_ensembles_r.tif"))
conv_bd50_y50_dt_ensembles_r <- brick(fp(p_mod_output,"conv_bd50_y50_dt_ensembles_r.tif"))
conv_bd100_dt_ensembles_r <- brick(fp(p_mod_output,"conv_bd100_dt_ensembles_r.tif"))
# conv_10p_bd_dt_ensembles_r <- brick(fp(p_mod_output,"conv_10p_bd_dt_ensembles_r.tif"))

# add the layer names back again
names(conv_eq_dt_ensembles_r) <- c("x", "y", runs_w_ensembles)
names(conv_bd50_y50_dt_ensembles_r) <- c("x", "y", runs_w_ensembles)
names(conv_bd100_dt_ensembles_r) <- c("x", "y", runs_w_ensembles)
# names(conv_10p_bd_dt_ensembles_r) <- c("x", "y", runs_w_ensembles)

```



```{r conv_r}
# ---------------------------------------
# create new ensembles list
# ---------------------------------------
conv_r <- list(
  "b_pure" = conv_b_pure_dt_ensembles_r,
  "z50" = conv_z50_dt_ensembles_r,
  "bd100" = conv_bd100_dt_ensembles_r, 
  "bc" = conv_bc_dt_ensembles_r,
  "bd50_y50" = conv_bd50_y50_dt_ensembles_r, 
  "eq" = conv_eq_dt_ensembles_r#, 
#  "10p_bd" = conv_10p_bd_dt_ensembles_r
  )


names(dt_to_raster(conv_bc_dt, CRSobj))

names(conv_eq_dt_ensembles_r)
names(conv_r$`bd100`)
object_size(conv_r)

par(mfrow = c(7, 5))
plot(conv_r$eq, c(1:length(runs_w_ref)))
plot(conv_r$bd50_y50)
plot(conv_r$bd100)
plot(conv_r$`10p_bd`$m8_rep_threat)

save(conv_r,
     file = fp(p_mod_output, "conv_r.RData"))

### --- conv_r
load(file = fp(p_mod_output, "conv_r.RData"), verbose = TRUE)

### --- bd_dt_r
load(file = fp(p_mod_output, "bd_dt_r.RData"), verbose = TRUE)
# or load it directly
bd_dt_r <- brick(fp(p_mod_output,"bd_dt_r.tif"))
names(bd_dt_r) <- bd_dt_r_names #c(runs_w_raw, ensemble_names)

```

```{r bd_dt_ensemble}

# ---------------------------------------------------------------------------------------
# do this directly with data.tables. It's much faster
# ---------------------------------------------------------------------------------------
bd_dt <- fread(file = fp(p_mod_output, "bd_dt.csv"))

names(bd_dt)
bd_dt_ensembles <- copy(bd_dt)
length(bd_dt_ensembles)
names(bd_dt_ensembles)
names(bd_dt_ensembles) <- c("x", "y", runs_w_raw)


bd_dt_ensembles[, ':=' (
  en1_types = rowSums(.SD[, runs[ensembles_list$en1_types], with = FALSE]),
  en1_types_b = rowSums(.SD[, runs[ensembles_list$en1_types_b], with = FALSE]),
  en2_taxa_all = rowSums(.SD[, runs[ensembles_list$en2_taxa_all], with = FALSE]),
  en2_taxa_endemism = rowSums(.SD[, runs[ensembles_list$en2_taxa_endemism], with = FALSE]),
  en2_taxa_threat = rowSums(.SD[, runs[ensembles_list$en2_taxa_threat], with = FALSE]),
  en2_taxa_small = rowSums(.SD[, runs[ensembles_list$en2_taxa_small], with = FALSE]),
  en3_mb = rowSums(.SD[, runs[ensembles_list$en3_mb], with = FALSE]),
  en3_vp = rowSums(.SD[, runs[ensembles_list$en3_vp], with = FALSE]),
  en3_ae = rowSums(.SD[, runs[ensembles_list$en3_ae], with = FALSE]),
  en4_all = rowSums(.SD[, runs[ensembles_list$en4_all], with = FALSE]),
  en4_endemism = rowSums(.SD[, runs[ensembles_list$en4_endemism], with = FALSE]),
  en4_threat = rowSums(.SD[, runs[ensembles_list$en4_threat], with = FALSE]),
  en4_small = rowSums(.SD[, runs[ensembles_list$en4_small], with = FALSE]),
  en5_composites = rowSums(.SD[, runs[ensembles_list$en5_composites], with = FALSE]),
  en6_norm_all = rowSums(.SD[, runs[ensembles_list$en6_norm_all], with = FALSE]),
  en6_norm_endemism = rowSums(.SD[, runs[ensembles_list$en6_norm_endemism], with = FALSE]),
  en6_norm_threat = rowSums(.SD[, runs[ensembles_list$en6_norm_threat], with = FALSE]),
  en6_norm_small = rowSums(.SD[, runs[ensembles_list$en6_norm_small], with = FALSE]),
  all = rowSums(.SD[, runs[ensembles_list$all], with = FALSE])
  )]

bd_dt_ensembles[, 65:83]
bd_dt_r <- dt_to_raster(bd_dt_ensembles, CRSobj)
plot(bd_dt_r, 63:81)


bd_dt_r <- writeRaster(bd_dt_r, overwrite=TRUE, fp(p_mod_output,"bd_dt_r.tif"))

bd_dt_r <- brick(fp(p_mod_output,"bd_dt_r.tif"))
names(bd_dt_r) <- bd_dt_r_names #c(runs_w_raw, ensemble_names)
save(bd_dt_r, file = fp(p_mod_output, "bd_dt_r.RData"))


fwrite(bd_dt_ensembles, file = fp(p_mod_output, "bd_dt_ensembles.csv"))
bd_dt_ensembles <- fread(file = fp(p_mod_output, "bd_dt_ensembles.csv"))

rm(bd_dt_ensembles)
length(bd_dt_ensembles)







# ---------------------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------
# alternative method, though much slower.
# create overlays of each ensemble. raster::overlay() is another function I could use to accomplish this. I divide the sum by the number of layers being added together, to get a value between 0-1. Basically, this is the percent of layers that occur there. 
bd_dt_r
length(bd_dt[, -c(1:2)])

for (i in seq_along(ensembles_list)) {
  bd_dt_r[[length(bd_dt[, -c(1:2)]) + i]] <- sum(bd_dt_r[[ensembles_list[[i]]]]) # / length(ensembles_list[[i]])
  names(bd_dt_r[[length(bd_dt[, -c(1:2)]) + i]]) <- names(ensembles_list)[i]
}

plot(bd_dt_r$en1_types)
plot(bd_dt_ensembles_r$en1_types)
plot(4-bd_dt_r$en1_types)


length(ensembles_list[[2]])

plot(bd_dt_r$en2_mb)
plot(sum(bd_dt_r[[ensembles_list$en2_mb]]))



# to display with better breaks
plot(bd_dt_r$en1_taxa_threat)
plot(log(bd_dt_r$en1_taxa_threat))
plot(bd_dt_r$en1_taxa_threat, zlim = c(0.2, 0.45))


## 

test <- overlay(
  bd_dt_r[[1:4]],
  fun = function(a, b, c, d){
    (a + b + c + d)/4
    }
  )


```


```{r weighted_ensemble}
# weight by the following options:
# 1. inverse of the sum of the variances from the controlling layer. So, the smaller the sum of variances from the controlling layer, the better the layer acts as a proxy. 
# 2. add up the total percent biodiversity loss across the 12 layers, and then weight by the inverse of the proportion of biodviersity loss
# 3. weight by the mean biodiversity loss across the 12 layers, for each controlling layer. The inverse?
# The weights need to add to one. So, first I do the inverse of the mean bd loss for that layer, then add all those inverses together, then divide each individual inverse by the sum of inverses, so that the weights all add to one.  

runs

# comparing the results of the combination m2_vert_threat to the individual layers, mammals, birds, amphibians, and reptiles.
# this would involve looking at the overlap between m2 and m5, m6, m7, and m8, and the relative bd loss in those layers. Maybe just reporting the statistics. 
# the natural way to compare these is to say how much worse the averaging layer is for that taxa than the conversion map determined specifically for that specific taxa. 
conversion_brick
plot(ensembles_r$bd100)

```


# Final Analysis Work Flow
AKA Xingli's approach:
Five facets:
1. Types - average across the a) three resolutions, and the b) weights. 
2. Taxa - average across a) all four types of richness for each taxa, and b) across the weights
3. Methods - average across a) mb, ae, and vp, b) weights
4. Resolution - average across a) four types of richness for each resolution, b) weights
5. Composites (should be dropped)

(6. Weighting) - can also average across the three weights for any particular one of these averagings.

Two phases:
1. Average taxa, methods, and resolutions.
2. Average taxa, methods, and resolutions, but also for all weights. 

The plan:
- first calculate the average for taxa
- then calculate the weighted jaccard.
- make a data-table of bd100 to calculate the averages within taxa, methods, and resolutions
- do this for all 3 weights
- and then do this to average across the three weights too
- calculate

```{r expl_grep}
# Goal: write code that will create new columns using rowSums and rowMeans to select only a few columns. 

conv_bd100_dt
conv_bd100_dt[, .(x, y)]
bd100_dt <- conv_bd100_dt[, .(x, y)]

dt <- copy(conv_bd100_dt[, c(1:2, # make sure to select x and y
                             grep("mam|bird|amp|rep", names(conv_bd100_dt))), with = FALSE])
dt
names(dt) <- gsub("_conv_bd100", "", names(dt))
dt[, bird_composite := NULL]
dt

grep("mam", names(dt), value = TRUE)
dt[, grep("mam", names(dt)), with = FALSE]
dt[, grep("mam", names(dt), value = TRUE), with = FALSE]
dt[, c("mam_all", "mam_threat")]
dt[, c("x","y", grep("mam", names(dt), value = TRUE)), with = FALSE]


names(dt)
# testing different ways to calculate the row mean
dt[, A := rowMeans(dt[, c(3,7,11,15)])]
dt[, A1 := rowMeans(dt[, .(mam_all, mam_endemism, mam_threat, mam_small)])]
dt[, A2 := rowMeans(dt[, grep("mam", names(dt)), with = FALSE])]
identical(dt[, A], dt[, A1]); identical(dt[, A], dt[, A2])


dt[, -c(3:5)]
names(dt)
# selecting all that do not match:
dt[, grep("all|endemism|threat", names(dt), invert = TRUE), with = FALSE]
# or:
dt[, .(x, y, A, A1, A2)]




# ------------------------------------------------------------------ final method

# create taxa averages
dt[, mam := rowMeans(dt[, grep("mam", names(dt)), with = FALSE])]
dt[, bird := rowMeans(dt[, grep("bird", names(dt)), with = FALSE])]
dt[, amp := rowMeans(dt[, grep("amp", names(dt)), with = FALSE])]
dt[, rep := rowMeans(dt[, grep("rep", names(dt)), with = FALSE])]
dt

# test it
dt_r <- dt_to_raster(dt[, grep("all|endemism|threat", names(dt), invert = TRUE), with = FALSE], CRSobj)
plot(dt_r)
```

```{r load data.tables}
# read them back in:
bd_dt <- fread(file = fp(p_mod_output, "bd_dt.csv")) # just the biodiversity inputs. Note that I can also load in directly a data.table with ensembles added, etc. See "bd_dt_ensemble"

conv_b_pure_dt <- fread(file = fp(p_mod_output, "conv_b_pure_dt.csv"))
conv_b_dt <- fread(file = fp(p_mod_output, "conv_b_dt.csv"))
conv_by_dt <- fread(file = fp(p_mod_output, "conv_by_dt.csv"))
conv_bc_dt <- fread(file = fp(p_mod_output, "conv_bc_dt.csv"))
conv_bt_dt <- fread(file = fp(p_mod_output, "conv_bt_dt.csv"))
conv_byct_dt <- fread(file = fp(p_mod_output, "conv_byct_dt.csv"))
conv_z50_dt <- fread(file = fp(p_mod_output, "conv_z50_dt.csv"))

object_size(conv_b_dt)
object_size(conv_b_dt, conv_b_pure_dt, conv_bc_dt, conv_bt_dt, conv_by_dt, conv_byct_dt, conv_z50_dt)

```

```{r load_prep_dt}
# rename and merge data.tables
# load the data.tables: see chunk {r load data.tables}

dt_bp <- copy(conv_b_pure_dt)
dt_b <- copy(conv_b_dt) 
dt_bc <- copy(conv_bc_dt)
dt_bt <- copy(conv_bt_dt)
dt_by <- copy(conv_by_dt)
dt_byct <- copy(conv_byct_dt)
dt_z50 <- copy(conv_z50_dt)

rm(conv_b_pure_dt, conv_b_dt, conv_bc_dt, conv_bt_dt, conv_by_dt, conv_byct_dt, conv_z50_dt)
object_size(dt_bp, dt_b, dt_by, dt_bc, dt_bt, dt_byct, dt_z50)
rm(dt_bp, dt_b, dt_by, dt_bc, dt_bt, dt_byct, dt_z50)

# dt_byct <- copy(conv_eq_dt[, c(1:2)]) # copy, selecting only x and y

# update column names
names(dt_b)

names(dt_bp) <- c("x", "y", paste0(runs, "_bp"))
names(dt_b) <- c("x", "y", paste0(runs, "_b"))
names(dt_by) <- c("x", "y", paste0(runs, "_by"))
names(dt_bc) <- c("x", "y", paste0(runs, "_bc"))
names(dt_bt) <- c("x", "y", paste0(runs, "_bt"))
names(dt_byct) <- c("x", "y", paste0(runs, "_byct"))
names(dt_z50) <- c("x", "y", paste0(runs, "_z50"))


# remove runs not included in averages (leaving in composites for now)
# names(dt_b)[c(7:10,53:58)]
# 
# dt_b[, c(7:10, 53:58) := NULL] # or: dt[, names(dt)[48:58] := NULL]
# dt_by[, c(7:10, 53:58) := NULL]
# dt_byct[, c(7:10, 53:58) := NULL]
# 
# dt_bp[, c(7:10, 53:56) := NULL]
# dt_bc[, c(7:10, 53:56) := NULL]
# dt_bt[, c(7:10, 53:56) := NULL]
# dt_z50[, c(7:10, 53:56) := NULL]

dt_bp %>% length
dt_b %>% length
dt_by %>% length
dt_bc %>% length
dt_bt %>% length
dt_byct %>% length
dt_z50 %>% length

ncol(dt_b)
# dt_bp[, key := 1:.N] # optional, to test the ordering. 

# merge the data.tables into a single data.table
# without sort = FALSE, things get out of order.
dt <- merge(dt_bp, dt_b, by = c("x","y"), sort = FALSE)
dt <- merge(dt, dt_by, by = c("x","y"), sort = FALSE)
dt <- merge(dt, dt_bc, by = c("x","y"), sort = FALSE)
dt <- merge(dt, dt_bt, by = c("x","y"), sort = FALSE)
dt <- merge(dt, dt_byct, by = c("x","y"), sort = FALSE)
dt <- merge(dt, dt_z50, by = c("x","y"), sort = FALSE)

(ncol(dt) - 2) / 7 # 46 each, plus x and y
object_size(dt)

# save the dt
dt_w_threat <- dt
fwrite(dt_w_threat, file = fp(p_mod_output, "dt_w_threat.csv")) # with 800 columns, including the threatened species runs
fwrite(dt_bp, file = fp(p_mod_output, "dt_bp.csv"))
fwrite(dt_b, file = fp(p_mod_output, "dt_b.csv"))
fwrite(dt_by, file = fp(p_mod_output, "dt_by.csv"))
fwrite(dt_bc, file = fp(p_mod_output, "dt_bc.csv"))
fwrite(dt_bt, file = fp(p_mod_output, "dt_bt.csv"))
fwrite(dt_byct, file = fp(p_mod_output, "dt_byct.csv"))
fwrite(dt_z50, file = fp(p_mod_output, "dt_z50.csv"))


rm(dt_bp, dt_b, dt_by, dt_bc, dt_bt, dt_byct, dt_z50)



# to remove all threat runs:
dt[, grep("threat", names(dt)), with = FALSE] %>% length # 5*7*3 # 5 (4 taxa plus combo) * 3 resolutions * 7 weights
length(dt)
dt[, (grep("threat", names(dt), value = TRUE)) := NULL]

fwrite(dt, file = fp(p_mod_output, "dt.csv")) # this is the file I'll use going forward


# load it back in
dt <- fread(file = fp(p_mod_output, "dt.csv"))  # note: this has threatened species removed. 
dt %>% length

dt_w_threat <- fread(file = fp(p_mod_output, "dt_w_threat.csv")) 
dt_bp <- fread(file = fp(p_mod_output, "dt_bp.csv"))
dt_b <- fread(file = fp(p_mod_output, "dt_b.csv"))
dt_by <- fread(file = fp(p_mod_output, "dt_by.csv"))
dt_bc <- fread(file = fp(p_mod_output, "dt_bc.csv"))
dt_bt <- fread(file = fp(p_mod_output, "dt_bt.csv"))
dt_byct <- fread(file = fp(p_mod_output, "dt_byct.csv"))
dt_z50 <- fread(file = fp(p_mod_output, "dt_z50.csv"))
```


Calculating the ensemble averages for each facet within each decision category.
```{r dt_m_ensemble_means}
# for each comparison, average within each weight first, then across all weights.  
dt_m <- copy(dt[, x:y])
dt_m %>% length

# ---------------------------------------------------------------------------------------------------------
# Pure Biodiversity (_bp), 100% weight on biodiversity with mean yields -----------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_bp := rowMeans(dt[, grep("_all.+bp$", names(dt)), with = FALSE])]
dt_m[, endemism_bp := rowMeans(dt[, grep("_endemism.+bp$", names(dt)), with = FALSE])]
dt_m[, threat_bp := rowMeans(dt[, grep("_threat.+bp$", names(dt)), with = FALSE])]
dt_m[, small_bp := rowMeans(dt[, grep("_small.+bp$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_bp := rowMeans(dt[, grep("mam.+bp$", names(dt)), with = FALSE])]
dt_m[, bird_bp := rowMeans(dt[, grep("bird.[^c]+bp$", names(dt)), with = FALSE])]
dt_m[, amp_bp := rowMeans(dt[, grep("amp.+bp$", names(dt)), with = FALSE])]
dt_m[, rep_bp := rowMeans(dt[, grep("rep.+bp$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_bp := rowMeans(dt[, grep("^average.+bp$", names(dt)), with = FALSE])]
dt_m[, geometric_bp := rowMeans(dt[, grep("^geometric.+bp$", names(dt)), with = FALSE])]
dt_m[, max_bp := rowMeans(dt[, grep("^max.+bp$", names(dt)), with = FALSE])]
dt_m[, multi_bp := rowMeans(dt[, grep("^multi.+bp$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_bp := rowMeans(dt[, grep("^[^1]+bp$", names(dt)), with = FALSE])]
dt_m[, res10_bp := rowMeans(dt[, grep("_10.bp$", names(dt)), with = FALSE])]
dt_m[, res110_bp := rowMeans(dt[, grep("_110.bp$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_bp := rowMeans(dt[, grep("vert_endemism.+bp$", names(dt)), with = FALSE])]
dt_m[, plants_bp := rowMeans(dt[, grep("plants.+bp$", names(dt)), with = FALSE])]
dt_m[, estes_bp := rowMeans(dt[, grep("estes.+bp$", names(dt)), with = FALSE])]
dt_m[, laurance_bp := rowMeans(dt[, grep("laurance.+bp$", names(dt)), with = FALSE])]
dt_m[, habitats_bp := rowMeans(dt[, grep("habitats.+bp$", names(dt)), with = FALSE])]
dt_m[, bird_composite_bp := rowMeans(dt[, grep("bird_composite.+bp$", names(dt)), with = FALSE])]
dt_m[, damania_bp := rowMeans(dt[, grep("damania.+bp$", names(dt)), with = FALSE])]


# ---------------------------------------------------------------------------------------------------------
# 100% weight on biodiversity (_b) with accurate, dynamic yields ------------------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_b := rowMeans(dt[, grep("_all.+b$", names(dt)), with = FALSE])]
dt_m[, endemism_b := rowMeans(dt[, grep("_endemism.+b$", names(dt)), with = FALSE])]
dt_m[, threat_b := rowMeans(dt[, grep("_threat.+b$", names(dt)), with = FALSE])]
dt_m[, small_b := rowMeans(dt[, grep("_small.+b$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_b := rowMeans(dt[, grep("mam.+b$", names(dt)), with = FALSE])]
dt_m[, bird_b := rowMeans(dt[, grep("bird.[^c]+b$", names(dt)), with = FALSE])]
dt_m[, amp_b := rowMeans(dt[, grep("amp.+b$", names(dt)), with = FALSE])]
dt_m[, rep_b := rowMeans(dt[, grep("rep.+b$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_b := rowMeans(dt[, grep("^average.+b$", names(dt)), with = FALSE])]
dt_m[, geometric_b := rowMeans(dt[, grep("^geometric.+b$", names(dt)), with = FALSE])]
dt_m[, max_b := rowMeans(dt[, grep("^max.+b$", names(dt)), with = FALSE])]
dt_m[, multi_b := rowMeans(dt[, grep("^multi.+b$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_b := rowMeans(dt[, grep("^[^1]+b$", names(dt)), with = FALSE])]
dt_m[, res10_b := rowMeans(dt[, grep("_10.b$", names(dt)), with = FALSE])]
dt_m[, res110_b := rowMeans(dt[, grep("_110.b$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_b := rowMeans(dt[, grep("vert_endemism.+b$", names(dt)), with = FALSE])]
dt_m[, plants_b := rowMeans(dt[, grep("plants.+b$", names(dt)), with = FALSE])]
dt_m[, estes_b := rowMeans(dt[, grep("estes.+b$", names(dt)), with = FALSE])]
dt_m[, laurance_b := rowMeans(dt[, grep("laurance.+b$", names(dt)), with = FALSE])]
dt_m[, habitats_b := rowMeans(dt[, grep("habitats.+b$", names(dt)), with = FALSE])]
dt_m[, bird_composite_b := rowMeans(dt[, grep("bird_composite.+b$", names(dt)), with = FALSE])]
dt_m[, damania_b := rowMeans(dt[, grep("damania.+b$", names(dt)), with = FALSE])]

# ---------------------------------------------------------------------------------------------------------
# 50% biodiversity, 50% yield (productivity) (dynamic yields) _by ---------------------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_by := rowMeans(dt[, grep("_all.+by$", names(dt)), with = FALSE])]
dt_m[, endemism_by := rowMeans(dt[, grep("_endemism.+by$", names(dt)), with = FALSE])]
dt_m[, threat_by := rowMeans(dt[, grep("_threat.+by$", names(dt)), with = FALSE])]
dt_m[, small_by := rowMeans(dt[, grep("_small.+by$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_by := rowMeans(dt[, grep("mam.+by$", names(dt)), with = FALSE])]
dt_m[, bird_by := rowMeans(dt[, grep("bird.[^c]+by$", names(dt)), with = FALSE])]
dt_m[, amp_by := rowMeans(dt[, grep("amp.+by$", names(dt)), with = FALSE])]
dt_m[, rep_by := rowMeans(dt[, grep("rep.+by$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_by := rowMeans(dt[, grep("^average.+by$", names(dt)), with = FALSE])]
dt_m[, geometric_by := rowMeans(dt[, grep("^geometric.+by$", names(dt)), with = FALSE])]
dt_m[, max_by := rowMeans(dt[, grep("^max.+by$", names(dt)), with = FALSE])]
dt_m[, multi_by := rowMeans(dt[, grep("^multi.+by$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_by := rowMeans(dt[, grep("^[^1]+by$", names(dt)), with = FALSE])]
dt_m[, res10_by := rowMeans(dt[, grep("_10.by$", names(dt)), with = FALSE])]
dt_m[, res110_by := rowMeans(dt[, grep("_110.by$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_by := rowMeans(dt[, grep("vert_endemism.+by$", names(dt)), with = FALSE])]
dt_m[, plants_by := rowMeans(dt[, grep("plants.+by$", names(dt)), with = FALSE])]
dt_m[, estes_by := rowMeans(dt[, grep("estes.+by$", names(dt)), with = FALSE])]
dt_m[, laurance_by := rowMeans(dt[, grep("laurance.+by$", names(dt)), with = FALSE])]
dt_m[, habitats_by := rowMeans(dt[, grep("habitats.+by$", names(dt)), with = FALSE])]
dt_m[, bird_composite_by := rowMeans(dt[, grep("bird_composite.+by$", names(dt)), with = FALSE])]
dt_m[, damania_by := rowMeans(dt[, grep("damania.+by$", names(dt)), with = FALSE])]

# ---------------------------------------------------------------------------------------------------------
# 50% biodiversity, 50% carbon loss (dynamic yields) ------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_bc := rowMeans(dt[, grep("_all.+bc$", names(dt)), with = FALSE])]
dt_m[, endemism_bc := rowMeans(dt[, grep("_endemism.+bc$", names(dt)), with = FALSE])]
dt_m[, threat_bc := rowMeans(dt[, grep("_threat.+bc$", names(dt)), with = FALSE])]
dt_m[, small_bc := rowMeans(dt[, grep("_small.+bc$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_bc := rowMeans(dt[, grep("mam.+bc$", names(dt)), with = FALSE])]
dt_m[, bird_bc := rowMeans(dt[, grep("bird.[^c]+bc$", names(dt)), with = FALSE])]
dt_m[, amp_bc := rowMeans(dt[, grep("amp.+bc$", names(dt)), with = FALSE])]
dt_m[, rep_bc := rowMeans(dt[, grep("rep.+bc$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_bc := rowMeans(dt[, grep("^average.+bc$", names(dt)), with = FALSE])]
dt_m[, geometric_bc := rowMeans(dt[, grep("^geometric.+bc$", names(dt)), with = FALSE])]
dt_m[, max_bc := rowMeans(dt[, grep("^max.+bc$", names(dt)), with = FALSE])]
dt_m[, multi_bc := rowMeans(dt[, grep("^multi.+bc$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_bc := rowMeans(dt[, grep("^[^1]+bc$", names(dt)), with = FALSE])]
dt_m[, res10_bc := rowMeans(dt[, grep("_10.bc$", names(dt)), with = FALSE])]
dt_m[, res110_bc := rowMeans(dt[, grep("_110.bc$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_bc := rowMeans(dt[, grep("vert_endemism.+bc$", names(dt)), with = FALSE])]
dt_m[, plants_bc := rowMeans(dt[, grep("plants.+bc$", names(dt)), with = FALSE])]
dt_m[, estes_bc := rowMeans(dt[, grep("estes.+bc$", names(dt)), with = FALSE])]
dt_m[, laurance_bc := rowMeans(dt[, grep("laurance.+bc$", names(dt)), with = FALSE])]
dt_m[, habitats_bc := rowMeans(dt[, grep("habitats.+bc$", names(dt)), with = FALSE])]
dt_m[, bird_composite_bc := rowMeans(dt[, grep("bird_composite.+bc$", names(dt)), with = FALSE])]
dt_m[, damania_bc := rowMeans(dt[, grep("damania.+bc$", names(dt)), with = FALSE])]

# ---------------------------------------------------------------------------------------------------------
# 50% biodiversity, 50% travel cost (dynamic yields) ------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_bt := rowMeans(dt[, grep("_all.+bt$", names(dt)), with = FALSE])]
dt_m[, endemism_bt := rowMeans(dt[, grep("_endemism.+bt$", names(dt)), with = FALSE])]
dt_m[, threat_bt := rowMeans(dt[, grep("_threat.+bt$", names(dt)), with = FALSE])]
dt_m[, small_bt := rowMeans(dt[, grep("_small.+bt$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_bt := rowMeans(dt[, grep("mam.+bt$", names(dt)), with = FALSE])]
dt_m[, bird_bt := rowMeans(dt[, grep("bird.[^c]+bt$", names(dt)), with = FALSE])]
dt_m[, amp_bt := rowMeans(dt[, grep("amp.+bt$", names(dt)), with = FALSE])]
dt_m[, rep_bt := rowMeans(dt[, grep("rep.+bt$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_bt := rowMeans(dt[, grep("^average.+bt$", names(dt)), with = FALSE])]
dt_m[, geometric_bt := rowMeans(dt[, grep("^geometric.+bt$", names(dt)), with = FALSE])]
dt_m[, max_bt := rowMeans(dt[, grep("^max.+bt$", names(dt)), with = FALSE])]
dt_m[, multi_bt := rowMeans(dt[, grep("^multi.+bt$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_bt := rowMeans(dt[, grep("^[^1]+bt$", names(dt)), with = FALSE])]
dt_m[, res10_bt := rowMeans(dt[, grep("_10.bt$", names(dt)), with = FALSE])]
dt_m[, res110_bt := rowMeans(dt[, grep("_110.bt$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_bt := rowMeans(dt[, grep("vert_endemism.+bt$", names(dt)), with = FALSE])]
dt_m[, plants_bt := rowMeans(dt[, grep("plants.+bt$", names(dt)), with = FALSE])]
dt_m[, estes_bt := rowMeans(dt[, grep("estes.+bt$", names(dt)), with = FALSE])]
dt_m[, laurance_bt := rowMeans(dt[, grep("laurance.+bt$", names(dt)), with = FALSE])]
dt_m[, habitats_bt := rowMeans(dt[, grep("habitats.+bt$", names(dt)), with = FALSE])]
dt_m[, bird_composite_bt := rowMeans(dt[, grep("bird_composite.+bt$", names(dt)), with = FALSE])]
dt_m[, damania_bt := rowMeans(dt[, grep("damania.+bt$", names(dt)), with = FALSE])]

# ---------------------------------------------------------------------------------------------------------
# equal weights, 25% on each constraint (biodiversity, yield, carbon, travel cost), with dynamic yields ---
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_byct := rowMeans(dt[, grep("_all.+byct$", names(dt)), with = FALSE])]
dt_m[, endemism_byct := rowMeans(dt[, grep("_endemism.+byct$", names(dt)), with = FALSE])]
dt_m[, threat_byct := rowMeans(dt[, grep("_threat.+byct$", names(dt)), with = FALSE])]
dt_m[, small_byct := rowMeans(dt[, grep("_small.+byct$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_byct := rowMeans(dt[, grep("mam.+byct$", names(dt)), with = FALSE])]
dt_m[, bird_byct := rowMeans(dt[, grep("bird.[^c]+byct$", names(dt)), with = FALSE])]
dt_m[, amp_byct := rowMeans(dt[, grep("amp.+byct$", names(dt)), with = FALSE])]
dt_m[, rep_byct := rowMeans(dt[, grep("rep.+byct$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_byct := rowMeans(dt[, grep("^average.+byct$", names(dt)), with = FALSE])]
dt_m[, geometric_byct := rowMeans(dt[, grep("^geometric.+byct$", names(dt)), with = FALSE])]
dt_m[, max_byct := rowMeans(dt[, grep("^max.+byct$", names(dt)), with = FALSE])]
dt_m[, multi_byct := rowMeans(dt[, grep("^multi.+byct$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_byct := rowMeans(dt[, grep("^[^1]+byct$", names(dt)), with = FALSE])]
dt_m[, res10_byct := rowMeans(dt[, grep("_10.byct$", names(dt)), with = FALSE])]
dt_m[, res110_byct := rowMeans(dt[, grep("_110.byct$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_byct := rowMeans(dt[, grep("vert_endemism.+byct$", names(dt)), with = FALSE])]
dt_m[, plants_byct := rowMeans(dt[, grep("plants.+byct$", names(dt)), with = FALSE])]
dt_m[, estes_byct := rowMeans(dt[, grep("estes.+byct$", names(dt)), with = FALSE])]
dt_m[, laurance_byct := rowMeans(dt[, grep("laurance.+byct$", names(dt)), with = FALSE])]
dt_m[, habitats_byct := rowMeans(dt[, grep("habitats.+byct$", names(dt)), with = FALSE])]
dt_m[, bird_composite_byct := rowMeans(dt[, grep("bird_composite.+byct$", names(dt)), with = FALSE])]
dt_m[, damania_byct := rowMeans(dt[, grep("damania.+byct$", names(dt)), with = FALSE])]

# ---------------------------------------------------------------------------------------------------------
# z50 - converting 50% of Zambia --------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------
# richness type averages
dt_m[, all_z50 := rowMeans(dt[, grep("_all.+z50$", names(dt)), with = FALSE])]
dt_m[, endemism_z50 := rowMeans(dt[, grep("_endemism.+z50$", names(dt)), with = FALSE])]
dt_m[, threat_z50 := rowMeans(dt[, grep("_threat.+z50$", names(dt)), with = FALSE])]
dt_m[, small_z50 := rowMeans(dt[, grep("_small.+z50$", names(dt)), with = FALSE])]

# taxa averages
dt_m[, mam_z50 := rowMeans(dt[, grep("mam.+z50$", names(dt)), with = FALSE])]
dt_m[, bird_z50 := rowMeans(dt[, grep("bird.[^c]+z50$", names(dt)), with = FALSE])]
dt_m[, amp_z50 := rowMeans(dt[, grep("amp.+z50$", names(dt)), with = FALSE])]
dt_m[, rep_z50 := rowMeans(dt[, grep("rep.+z50$", names(dt)), with = FALSE])]

# methods averages
dt_m[, average_z50 := rowMeans(dt[, grep("^average.+z50$", names(dt)), with = FALSE])]
dt_m[, geometric_z50 := rowMeans(dt[, grep("^geometric.+z50$", names(dt)), with = FALSE])]
dt_m[, max_z50 := rowMeans(dt[, grep("^max.+z50$", names(dt)), with = FALSE])]
dt_m[, multi_z50 := rowMeans(dt[, grep("^multi.+z50$", names(dt)), with = FALSE])]

# resolution averages
dt_m[, res1_z50 := rowMeans(dt[, grep("^[^1]+z50$", names(dt)), with = FALSE])]
dt_m[, res10_z50 := rowMeans(dt[, grep("_10.z50$", names(dt)), with = FALSE])]
dt_m[, res110_z50 := rowMeans(dt[, grep("_110.z50$", names(dt)), with = FALSE])]

# composites averages
dt_m[, vert_endemism_z50 := rowMeans(dt[, grep("vert_endemism.+z50$", names(dt)), with = FALSE])]
dt_m[, plants_z50 := rowMeans(dt[, grep("plants.+z50$", names(dt)), with = FALSE])]
dt_m[, estes_z50 := rowMeans(dt[, grep("estes.+z50$", names(dt)), with = FALSE])]
dt_m[, laurance_z50 := rowMeans(dt[, grep("laurance.+z50$", names(dt)), with = FALSE])]
dt_m[, habitats_z50 := rowMeans(dt[, grep("habitats.+z50$", names(dt)), with = FALSE])]
dt_m[, bird_composite_z50 := rowMeans(dt[, grep("bird_composite.+z50$", names(dt)), with = FALSE])]
dt_m[, damania_z50 := rowMeans(dt[, grep("damania.+z50$", names(dt)), with = FALSE])]

# -------------------------------------------------------------------------------------
# averages across all weights ---------------------------------------------------------
# -------------------------------------------------------------------------------------
# # subsetting dt to include only some of the runs, not all.
## exclude z50

# richness type averages -----------------------------------------------------------------
dt_m[, all := rowMeans(dt_m[, grep("^all.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, endemism := rowMeans(dt_m[, grep("^endemism.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, threat := rowMeans(dt_m[, grep("^threat.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, small := rowMeans(dt_m[, grep("^small.[^z]+", names(dt_m)), with = FALSE])]

# taxa averages -----------------------------------------------------------------
dt_m[, mam := rowMeans(dt_m[, grep("^mam.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, bird := rowMeans(dt_m[, grep("^bird.[^sz]+$", names(dt_m)), with = FALSE])] # must remove bird_composite
dt_m[, amp := rowMeans(dt_m[, grep("^amp.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, rep := rowMeans(dt_m[, grep("^rep.[^z]+", names(dt_m)), with = FALSE])]

# methods averages -----------------------------------------------------------------
dt_m[, average := rowMeans(dt_m[, grep("^average.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, geometric := rowMeans(dt_m[, grep("^geometric.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, max := rowMeans(dt_m[, grep("^max.[^z]+", names(dt_m)), with = FALSE])]
dt_m[, multi := rowMeans(dt_m[, grep("^multi.[^z]+", names(dt_m)), with = FALSE])]

# resolution averages -----------------------------------------------------------------
dt_m[, res1 := rowMeans(dt_m[, grep("^res1_[^z]+", names(dt_m)), with = FALSE])]
dt_m[, res10 := rowMeans(dt_m[, grep("^res10_[^z]+", names(dt_m)), with = FALSE])]
dt_m[, res110 := rowMeans(dt_m[, grep("^res110_[^z]+", names(dt_m)), with = FALSE])]

# composites --------------------------------------------------------------------------
# excluding z50 (to keep the production target constant)
dt_m[, vert_endemism := rowMeans(dt[, grep("vert_endemism[^z]+$", names(dt)), with = FALSE])]
dt_m[, plants := rowMeans(dt[, grep("plants[^z]+$", names(dt)), with = FALSE])]
dt_m[, estes := rowMeans(dt[, grep("estes[^z]+$", names(dt)), with = FALSE])]
dt_m[, laurance := rowMeans(dt[, grep("laurance[^z]+$", names(dt)), with = FALSE])]
dt_m[, habitats := rowMeans(dt[, grep("habitats[^z]+$", names(dt)), with = FALSE])]
dt_m[, bird_composite := rowMeans(dt[, grep("bird_composite[^z]+$", names(dt)), with = FALSE])]
dt_m[, damania := rowMeans(dt[, grep("damania[^z]+$", names(dt)), with = FALSE])]


# -------------------------------------------------------------------------------------
# individual weights ------------------------------------------------------------------
# -------------------------------------------------------------------------------------
dt_m[, bp := rowMeans(dt[, grep("_bp$", names(dt)), with = FALSE])]
dt_m[, b := rowMeans(dt[, grep("_b$", names(dt)), with = FALSE])]
dt_m[, by := rowMeans(dt[, grep("_by$", names(dt)), with = FALSE])]
dt_m[, bc := rowMeans(dt[, grep("_bc$", names(dt)), with = FALSE])]
dt_m[, bt := rowMeans(dt[, grep("_bt$", names(dt)), with = FALSE])]
dt_m[, byct := rowMeans(dt[, grep("_byct$", names(dt)), with = FALSE])]
dt_m[, z50 := rowMeans(dt[, grep("_z50$", names(dt)), with = FALSE])]



# # to remove all threat runs: (note that this messes up the code at the end, weighted jaccard, which needs 22, not 21)
# dt_m[, grep("threat", names(dt_m)), with = FALSE] %>% length # 7 weights plus all
# length(dt_m)
# dt_m[, (grep("threat", names(dt_m), value = TRUE)) := NULL]


# --------------------------------------------------------------------------------
names(dt_m)
length(dt_m)

# save the dt_m
object_size(dt_m)
fwrite(dt_m, file = fp(p_mod_output, "dt_m.csv"))
fwrite(dt_m_w_threat, file = fp(p_mod_output, "dt_m_w_threat.csv"))


# load in dt_m, the data.table consisting of only the averages across the facets within each of the four comparisons
dt_m <- fread(file = fp(p_mod_output, "dt_m.csv"))
dt_m0 <- fread(file = fp(p_mod_output, "dt_m0.csv")) # original dt_m file, with just dt_b, dt_by, and dt_byct.


```

```{r adjust_by_convertible}
# see cc_Start.rmd chunk "load-basic-gis-files" for inputs, specifically the below
# il <- agroEcoTradeoff::fetch_inputs(path = p_ZA)

# ----------------------------------------------
# to calculate the total area converted, previously I had been calculating 
# area_conv = colSums(dt_m[, -c(1:2)])
# this should also be multiplied by the convertible area (i.e. the proportion of each cell that is currently non-ag and non-urban, or, what the proportion that is current convertible still)


# select just the indices where convertible is greater than 0, i.e. only cells that are at least partially convertible (i.e. outside of pas and entirely urban areas). This is the data.table method for masking:
valinds <- which(il$convertible > 0)
il$convertible[valinds, ] 

# -----------------------------------------------
# multiply ensemble means (dt_m) by the convertible proportions. Note: convertible not as a data.table column, but just the values
dt_m_convertible <- dt_m[, lapply(.SD, function(x) {
  il$convertible[valinds, ]$convertible * x})]

dt_m_convertible[, x := dt_m$x]
dt_m_convertible[, y := dt_m$y]


length(dt_m_convertible)
# write to file:
fwrite(dt_m_convertible, file = fp(p_mod_output, "dt_m_convertible.csv"))

fwrite(dt_m_convertible_w_threat, file = fp(p_mod_output, "dt_m_convertible_w_threat.csv"))


# load in dt_m, the data.table consisting of only the averages across the facets within each of the four comparisons
dt_m_convertible <- fread(file = fp(p_mod_output, "dt_m_convertible.csv"))


```


```{r facet_names}
facet_names_distill_w_threat <- c("all", "endemism", "threat", "small", "mam", "bird", "amp", "rep", # all
                         "average", "geometric", "max", "multi", "res1", "res10", "res110",
                         "vert_endemism", "plants", "estes", "laurance", "habitats",  # mean composites
                         "bird_composite", "damania",
                         "bp", "b", "by", "bc", "bt", "byct", "z50" # weights
                         )

facet_names_distill <- grep("threat", facet_names_distill, value = T, invert = T)

composites_names <- c("vert_endemism", "plants", "estes", "laurance", "habitats", "bird_composite", "damania")

types_names <- c("all", "endemism", "small")
taxa_names <- c("mam", "bird", "amp", "rep")
methods_names <- c("average", "geometric", "max", "multi")
resolution_names <- c("res1", "res10", "res110")

names(conv_r$bp)




# facet_names_distill <- grep("[_]+", names(dt_m), invert = TRUE, value = TRUE)[-c(1:2)] # old
facet_names <- names(dt_m)[-c(1:2)] # 22*8 + 7
facet_names_bp <- grep("_bp$", names(dt_m), value = TRUE) # facet_names[1:15] # 
facet_names_b <- grep("_b$", names(dt_m), value = TRUE)
facet_names_composites <- c("vert_endemism", "plants", "estes", "laurance", "habitats",  # mean composites
                         "bird_composite", "damania") #runs[sort(ensembles_list$en5_composites)]


grep("_b$", facet_names, value = TRUE)
grep("_bp$", names(dt_m), value = TRUE)[1:4]

comparison_names <- list(
  "types_bp" = grep("_bp$", names(dt_m), value = TRUE)[1:4], 
  "taxa_bp" = grep("_bp$", names(dt_m), value = TRUE)[5:8],
  "methods_bp" = grep("_bp$", names(dt_m), value = TRUE)[9:12], 
  "resolution_bp" = grep("_bp$", names(dt_m), value = TRUE)[13:15],

  "types_b" = grep("_b$", names(dt_m), value = TRUE)[1:4], 
  "taxa_b" = grep("_b$", names(dt_m), value = TRUE)[5:8],
  "methods_b" = grep("_b$", names(dt_m), value = TRUE)[9:12], 
  "resolution_b" = grep("_b$", names(dt_m), value = TRUE)[13:15],
  
  "types_by" = grep("_by$", names(dt_m), value = TRUE)[1:4], 
  "taxa_by" = grep("_by$", names(dt_m), value = TRUE)[5:8],
  "methods_by" = grep("_by$", names(dt_m), value = TRUE)[9:12], 
  "resolution_by" = grep("_by$", names(dt_m), value = TRUE)[13:15],
  
  "types_bc" = grep("_bc$", names(dt_m), value = TRUE)[1:4], 
  "taxa_bc" = grep("_bc$", names(dt_m), value = TRUE)[5:8],
  "methods_bc" = grep("_bc$", names(dt_m), value = TRUE)[9:12], 
  "resolution_bc" = grep("_bc$", names(dt_m), value = TRUE)[13:15],
  
  "types_bt" = grep("_bt$", names(dt_m), value = TRUE)[1:4], 
  "taxa_bt" = grep("_bt$", names(dt_m), value = TRUE)[5:8],
  "methods_bt" = grep("_bt$", names(dt_m), value = TRUE)[9:12], 
  "resolution_bt" = grep("_bt$", names(dt_m), value = TRUE)[13:15],
  
  "types_byct" = grep("_byct$", names(dt_m), value = TRUE)[1:4], 
  "taxa_byct" = grep("_byct$", names(dt_m), value = TRUE)[5:8],
  "methods_byct" = grep("_byct$", names(dt_m), value = TRUE)[9:12], 
  "resolution_byct" = grep("_byct$", names(dt_m), value = TRUE)[13:15],
  
  "types_z50" = grep("_z50$", names(dt_m), value = TRUE)[1:4], 
  "taxa_z50" = grep("_z50$", names(dt_m), value = TRUE)[5:8],
  "methods_z50" = grep("_z50$", names(dt_m), value = TRUE)[9:12], 
  "resolution_z50" = grep("_z50$", names(dt_m), value = TRUE)[13:15],
  
  # averages (without z50, but including bp, b, by, bc, bt, byct)
  "types" = facet_names_distill[1:4], 
  "taxa" = facet_names_distill[5:8],
  "methods" = facet_names_distill[9:12], 
  "resolution" = facet_names_distill[13:15],
  
  # with all layers
  "weights" = facet_names_distill[16:22]
)

facet_names[22*0 + (1:22)] # bp
facet_names[22*1 + (1:22)] # b
facet_names[22*2 + (1:22)] # by
facet_names[22*3 + (1:22)] # bc
facet_names[22*4 + (1:22)] # bt
facet_names[22*5 + (1:22)] # byct
facet_names[22*6 + (1:22)] # z50
facet_names[22*7 + (1:22)] # all
facet_names[22*8 + (1:7)] # weights
```


``` {r bd_dt_m_ensemble_means}
# averaging the biodiversity inputs themselves
bd_dt <- fread(file = fp(p_mod_output, "bd_dt.csv")) # just the biodiversity inputs.
names(bd_dt)

bd_dt_m <- copy(bd_dt)
rm(bd_dt)
object_size(bd_dt_m)
names(bd_dt_m)
length(bd_dt_m) # 116 (38*3 = 114 + x and y)

# remove threat layers:
bd_dt_m[, grep("threat", names(bd_dt_m)), with = FALSE] %>% length # 5*7*3 # 5 (4 taxa plus combo) * 3 resolutions * 7 weights
bd_dt_m[, grep("threat", names(bd_dt_m)), with = FALSE] %>% names # 5*7*3 # 5 (4 taxa plus combo) * 3 resolutions * 7 weights
length(bd_dt_m)
bd_dt_m[, (grep("threat", names(bd_dt_m), value = TRUE)) := NULL]

# richness type averages -----------------------------------------------------------------
bd_dt_m[, all := rowMeans(bd_dt_m[, grep("_all", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, endemism := rowMeans(bd_dt_m[, grep("endemism", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, threat := rowMeans(bd_dt_m[, grep("threat", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, small := rowMeans(bd_dt_m[, grep("_small", names(bd_dt_m)), with = FALSE])]

# taxa averages -----------------------------------------------------------------
bd_dt_m[, mam := rowMeans(bd_dt_m[, grep("mam", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, bird := rowMeans(bd_dt_m[, grep("bird.[^c]", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, amp := rowMeans(bd_dt_m[, grep("amp", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, rep := rowMeans(bd_dt_m[, grep("rep", names(bd_dt_m)), with = FALSE])]

# methods averages -----------------------------------------------------------------
bd_dt_m[, average := rowMeans(bd_dt_m[, grep("average", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, geometric := rowMeans(bd_dt_m[, grep("geometric", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, max := rowMeans(bd_dt_m[, grep("max", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, multi := rowMeans(bd_dt_m[, grep("multi", names(bd_dt_m)), with = FALSE])]

# resolution averages -----------------------------------------------------------------
bd_dt_m[, res1 := rowMeans(bd_dt_m[, grep("[^1]._bd$", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, res10 := rowMeans(bd_dt_m[, grep("_10_bd$", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, res110 := rowMeans(bd_dt_m[, grep("_110_bd$", names(bd_dt_m)), with = FALSE])]

# composites --------------------------------------------------------------------------
bd_dt_m[, vert_endemism := rowMeans(bd_dt_m[, grep("vert_endemism", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, plants := rowMeans(bd_dt_m[, grep("plants", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, estes := rowMeans(bd_dt_m[, grep("estes", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, laurance := rowMeans(bd_dt_m[, grep("laurance", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, habitats := rowMeans(bd_dt_m[, grep("habitats", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, bird_composite := rowMeans(bd_dt_m[, grep("bird_composite", names(bd_dt_m)), with = FALSE])]
bd_dt_m[, damania := rowMeans(bd_dt_m[, grep("damania", names(bd_dt_m)), with = FALSE])]

# not sure what's going on here....
# averages of entire comparisons: 
# average of all rasters, so that the only thing that changes is the weight:
bd_dt_m[, c("types", "taxa", "methods", "resolution") := .(
  rowMeans(bd_dt_m[, c("all", "endemism", "small"), with = FALSE]), # comparison_names$types
  rowMeans(bd_dt_m[, comparison_names$taxa, with = FALSE]),
  rowMeans(bd_dt_m[, comparison_names$methods, with = FALSE]),
  rowMeans(bd_dt_m[, comparison_names$resolution, with = FALSE])
  )
  ]

bd_dt_m[, weights := rowMeans(bd_dt_m[, 3:116])]

# --------------------------------------------------------------------------------
# remove the unncessary columns at the start of the dt
# bd_dt_m[, c(3:116) := NULL]
bd_dt_m[, c(3:101) := NULL] # without the threat layers

# --------------------------------------------------------------------------------
# save the dt_m
object_size(bd_dt_m)
fwrite(bd_dt_m, file = fp(p_mod_output, "bd_dt_m.csv"))

# load it back in
bd_dt_m <- fread(file = fp(p_mod_output, "bd_dt_m.csv"))
```

```{r rasters_simple}
dt_bp %>% length
dt_b %>% length #reference
dt_by %>% length
dt_bc %>% length
dt_bt %>% length
dt_byct %>% length
dt_z50  %>% length
dt_m_convertible %>% length
bd_dt_m %>% length
bd_dt %>% length

# save raster bricks:
dt_bp_r <- writeRaster(dt_to_raster(dt_bp, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_bp_r.tif"))
dt_b_r <- writeRaster(dt_to_raster(dt_b, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_b_r.tif"))
dt_by_r <- writeRaster(dt_to_raster(dt_by, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_by_r.tif"))
dt_bc_r <- writeRaster(dt_to_raster(dt_bc, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_bc_r.tif"))
dt_bt_r <- writeRaster(dt_to_raster(dt_bt, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_bt_r.tif"))
dt_byct_r <- writeRaster(dt_to_raster(dt_byct, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_byct_r.tif"))
dt_z50_r <- writeRaster(dt_to_raster(dt_z50, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"dt_z50_r.tif"))
bd_dt_m_r <- writeRaster(dt_to_raster(bd_dt_m, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"bd_dt_m_r.tif")) # bd means
bd_dt_r <- writeRaster(dt_to_raster(bd_dt, CRSobj),  overwrite=TRUE,
                               fp(p_mod_output,"bd_dt_r.tif")) # bd raw raster


# dt_m_convertible rasters, aka facet_r
facet_r_all <- writeRaster(
  dt_to_raster(dt_m_convertible[, c("x", "y", facet_names_distill_w_threat), with = FALSE], CRSobj),
  overwrite=TRUE, fp(p_mod_output,"facet_r_all.tif"))
  
facet_r_bp <- writeRaster(
  dt_to_raster(dt_m_convertible[, c("x", "y", grep("_bp$", facet_names, value = TRUE)), 
                                with = FALSE], CRSobj),
  overwrite=TRUE, fp(p_mod_output,"facet_r_bp.tif"))
  
facet_r_b <- writeRaster(
  dt_to_raster(dt_m_convertible[, c("x", "y", grep("_b$", facet_names, value = TRUE)), 
                                with = FALSE], CRSobj),
  overwrite=TRUE, fp(p_mod_output,"facet_r_b.tif"))

facet_r_z50 <- writeRaster(
  dt_to_raster(dt_m_convertible[, c("x", "y", grep("_z50$", facet_names, value = TRUE)), 
                                with = FALSE], CRSobj),
  overwrite=TRUE, fp(p_mod_output,"facet_r_z50.tif"))


# -------------------------------------------------------------------
# load it back in:
dt_bp_r <- brick(fp(p_mod_output,"dt_bp_r.tif"))
dt_b_r <- brick(fp(p_mod_output,"dt_b_r.tif"))
dt_by_r <- brick(fp(p_mod_output,"dt_by_r.tif"))
dt_bc_r <- brick(fp(p_mod_output,"dt_bc_r.tif"))
dt_bt_r <- brick(fp(p_mod_output,"dt_bt_r.tif"))
dt_byct_r <- brick(fp(p_mod_output,"dt_byct_r.tif"))
dt_z50_r <- brick(fp(p_mod_output,"dt_z50_r.tif"))

bd_dt_r <- brick(fp(p_mod_output,"bd_dt_r.tif"))
bd_dt_m_r <- brick(fp(p_mod_output,"bd_dt_m_r.tif"))

facet_r_all <- brick(fp(p_mod_output,"facet_r_all.tif"))
facet_r_bp <- brick(fp(p_mod_output,"facet_r_bp.tif"))
facet_r_b <- brick(fp(p_mod_output,"facet_r_b.tif"))
facet_r_z50 <- brick(fp(p_mod_output,"facet_r_z50.tif"))

# add the layer names back again
names(dt_bp_r) <- runs # paste0(runs, "_bp")
names(dt_b_r) <- runs # paste0(runs, "_b")
names(dt_by_r) <- runs # paste0(runs, "_by")
names(dt_bc_r) <- runs # paste0(runs, "_bc")
names(dt_bt_r) <- runs # paste0(runs, "_bt")
names(dt_byct_r) <- runs # paste0(runs, "_byct")
names(dt_z50_r) <- runs # paste0(runs, "_z50")
names(bd_dt_r) <- runs #names(bd_dt)[-c(1:2)]
names(bd_dt_m_r) <- names(bd_dt_m)[-c(1:2)]
names(facet_r_all) <- facet_names_distill_w_threat
names(facet_r_bp) <- grep("_bp$", facet_names, value = TRUE)
names(facet_r_b) <- grep("_b$", facet_names, value = TRUE)
names(facet_r_z50) <- grep("_z50$", facet_names, value = TRUE)

# conv_r
conv_r <- list(
  "bp" = dt_bp_r, "b" = dt_b_r, "by" = dt_by_r, "bc" = dt_bc_r, "bt" = dt_bt_r, 
  "byct" = dt_byct_r, "z50" = dt_z50_r, 
  "bd" = bd_dt_r, "bd_m" = bd_dt_m_r, 
  "facet_r" = facet_r, "facet_r_bp" = facet_r_bp, "facet_r_b" = facet_r_b
  )

for(i in 1:length(conv_r)) {print(nlayers(conv_r[[i]]))}
plot(conv_r[[1]][[1]], main = names(conv_r[[1]][[1]]))
```

```{r}

plot(facet_r_bp[[c("mam_bp", "bird_bp")]])

plot(min(facet_r_bp$mam_bp, facet_r_bp$bird_bp))
plot(max(facet_r_bp$mam_bp, facet_r_bp$bird_bp))

cellStats(min(facet_r_bp$mam_bp, facet_r_bp$bird_bp), "sum")/cellStats(max(facet_r_bp$mam_bp, facet_r_bp$bird_bp), "sum")

```


```{r weighted_jaccard}
dt_m %>% ncol() 

# create dataframe
length(facet_names)
jac_w <- matrix(
  nrow = length(facet_names), 
  ncol = length(facet_names))
colnames(jac_w) <- facet_names

jac_w <- data.frame(
  facet = facet_names,
  jac_w
)
jac_w <- jac_w %>% mutate(facet = fct_relevel(facet, facet_names))
rownames(jac_w) <- facet_names




# ------------------------------------------------------------------
# calculate weighted jaccard matrix: final codes
# ------------------------------------------------------------------
# the full set of permutations: this is likely to take a long time, likely more than an hour. 
# tic()
# for(i in seq_along(facet_names)){
#   for(j in seq_along(facet_names)){
#     jac_w[i, 1 + j] <- dt_m_convertible[, c(2 + i, 2 + j), with = FALSE
#                           ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
#   }
# }
# toc()

names(dt_m_convertible)
# ------------------------------------------------------------------
# calculate weighted jaccard matrix: final codes, with only a subset of stuff
# ------------------------------------------------------------------

tic()
for (group in 0:7) { # 8 groups of 22 (15 facets plus 7 composites), plus 7 weights at the end

  # for the first four: types  
  for(i in 1:4){
    for(j in 1:4){
      jac_w[22*group + i, 22*group + 1 + j] <- dt_m_convertible[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: taxonomic groups  
  for(i in 5:8){
    for(j in 5:8){
      jac_w[22*group + i, 22*group + 1 + j] <- dt_m_convertible[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: methods
  for(i in 9:12){
    for(j in 9:12){
      jac_w[22*group + i, 22*group + 1 + j] <- dt_m_convertible[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next three: resolutions
  for(i in 13:15){
    for(j in 13:15){
      jac_w[22*group + i, 22*group + 1 + j] <- dt_m_convertible[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next 7: composites
  for(i in 16:22){
    for(j in 16:22){
      jac_w[22*group + i, 22*group + 1 + j] <- dt_m_convertible[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
}
toc() # 82 sec


tic() 
# 8 groups of 22 (15 facets plus 7 composites), 
# then 7 weights at the end
for(i in 1:7){
  for(j in 1:7){
    jac_w[8*22 + i, 8*22 + 1 + j] <- dt_m_convertible[
      , c(2 + 8*22 + i, 2 + 8*22 + j), with = FALSE
      ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
  }
}
toc() # 5.559 seconds


# remove self similarities
jac_w[jac_w == 1] <- NA


object_size(jac_w)
class(jac_w)

# save it to file
fwrite(jac_w, file = fp(p_mod_output, "jac_w.csv"))
fwrite(jac_w_w_threat, file = fp(p_mod_output, "jac_w_w_threat.csv"))

# check to make sure the loop worked. 
dt_m_convertible[, c("all", "small"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["all", "small"] # need to have the rows named
jac_w %>% filter(facet == "all") %>% select("small")
names(jac_w)



dt_m_convertible[, c("damania", "estes"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["damania", "estes"] # need to have the rows named

# checks out!

dt_m_convertible[, c("all_b", "threat_b"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["all_b", "threat_b"]

dt_m[, c("all_by", "threat_by"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["all_by", "threat_by"]

dt_m[, c("mam_byct", "rep_byct"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["mam_byct", "rep_byct"]

dt_m[, c("b", "by"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
jac_w["b", "by"]


# testing if no zeros:
# what happens if rather than 0s, the cells that are not selected by either model are given some sort of value? Essentially, the weighted jaccard similarity goes up significantly. Not really sure what this means just yet though... the weighted jaccard similarity compares the cells that are selected by one model to the cells that are selected by another. 
test_dt <- dt_m_convertible[, c("x", "y", "all", "threat"), with = FALSE]
test_dt[, c("all", "threat"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
test_dt[, "all_plus" := all + 0.1]
test_dt[, "threat_plus" := threat + 0.1]
test_dt[, "all_inv" := (all - 1)*-1]
test_dt[, "threat_inv" := (threat - 1)*-1]
test_dt %>% dt_to_raster(CRSobj) %T>% plot()

test_dt[, c("all", "threat"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
test_dt[, c("all_plus", "threat_plus"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
test_dt[, c("all_inv", "threat_inv"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]




# original file:
jac_w0 <- fread(fp(p_mod_output, "jac_w0.csv"))


jac_w0[facet == "all_b", "threat_b"]
nrow(jac_w0)
head(jac_w0)
jac_w["all_b", "threat_b"] # pretty close - but remember, these now have been adjusted by convertible, so they should be slightly different. 

```


```{r jac_melt}
jac_w_clean <- jac_w[facet_names, facet_names] # 63x63

head(jac_w[, 1:10])
jac_w_melt0
jac_w_melt
identical(select(jac_w_melt, -facet_names), jac_w_melt0)

jac_w_melt_full <- jac_w %>% 
  mutate(
    facet_full = facet,
    facet = gsub("_bp|_b|_by|_bc|_bt|_byct|_z50", "", facet_full)
      # c(rep(facet_names_distill_w_threat[1:22], 8),
      #   facet_names_distill_w_threat[23:29])
    ,
    comparison = c(
      rep(
        c(rep("types", 4),
          rep("taxa", 4),
          rep("methods", 4),
          rep("resolution", 3),
          rep("composites", 7)), 
        8), # repeat the 22 string 8 times (7 weights plus all)
      rep("weights", 7) # seven weights
      ),
    weight = c(
      rep("bp", 22),
      rep("b", 22),
      rep("by", 22),
      rep("bc", 22),
      rep("bt", 22),
      rep("byct", 22),
      rep("z50", 22),
      rep("all", 22), # all, except z50
      rep("all", 7) # for the 7 weights, since I don't know what else to call them
      )) %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair_full", value.name = "jac_w", na.rm = TRUE) %>%
  mutate(pair = gsub("_bp|_b|_by|_bc|_bt|_byct|_z50", "", pair_full))

jac_w_melt <- jac_w_melt_full %>%
  filter(!facet %in% c("bird_composite", "habitats", "plants"),
         !pair %in% c("bird_composite", "habitats", "plants"))

names(jac_w_melt)
jac_w_melt <- jac_w_melt %>% 
  mutate(
    facet = fct_relevel(facet, facet_names_distill),
    facet_full = fct_relevel(facet_full, facet_names),
    pair_full = fct_relevel(pair_full, facet_names),
    pair = fct_relevel(pair, facet_names_distill),
    comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
    comparison = fct_recode(comparison, "indices" = "composites"),
    weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all"))) %>%
  arrange(facet) %>%
  as_tibble()


fwrite(jac_w_melt, file = fp(p_mod_output, "jac_w_melt.csv"))
fwrite(jac_w_melt_full, file = fp(p_mod_output, "jac_w_melt_full.csv"))
fwrite(jac_w_melt_w_threat, file = fp(p_mod_output, "jac_w_melt_w_threat.csv"))


### 

summary(jac_w_melt$jac_w)
arrange(jac_w_melt, jac_w)
arrange(jac_w_melt, facet)
# pairs
6+6+6+3+3

levels(jac_w_melt$facet)
levels(jac_w_melt$comparison)
levels(jac_w_melt$weight)
levels(jac_w_melt$pair)
unique(jac_w_melt$facet)
unique(jac_w_melt$comparison)
unique(jac_w_melt$weight)
unique(jac_w_melt$pair)
```




```{r facet_stats_full}
# create facet_stats
# see also jac_w_melt_combo
as_tibble(jac_w_melt)

facet_stats_full <- jac_w_melt %>%
  rename(facet_names = facet_full) %>%
  group_by(facet_names) %>% 
  summarise(
    count = n(),
    facet = unique(facet),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w)))) %>%
  mutate(
    # facet = c(
    #   rep(facet_names_distill[1:21], 8), # formerly 1:22
    #   facet_names_distill[22:28]), # formerly 23:29
    # # area_conv is adjusted by the proportion of land that is convertible
    name = grep("threat", names(dt_m_convertible)[-(1:2)], invert = T, value = T),
    
    area_conv = as.numeric(dt_m_convertible[, c("x", "y", grep("threat", names(dt_m_convertible)[-(1:2)], invert = T, value = T)), with = FALSE][, lapply(.SD, sum)][,-(1:2)]),    
    #area_conv_raw = as.numeric(dt_m[, lapply(.SD, sum)][,-(1:2)])  # unadjusted
) %>%
  mutate(facet = fct_relevel(facet, facet_names_distill))

select(facet_stats_full, facet_names, facet, comparison, weight, mean_jac_w, se_jac_w, area_conv, area_conv_raw)


facet_stats_full <- facet_stats_full %>%
  mutate(facet = fct_relevel(facet, facet_names_distill),
         comparison = fct_relevel(comparison, 
                                  c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, 
                              c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all", "order")))

head(facet_stats_full)
facet_stats_full %>% as_tibble()
levels(facet_stats_full$facet_names)
levels(facet_stats_full$comparison)
levels(facet_stats_full$weight)
levels(facet_stats_full$facet)

facet_stats_full$facet_names == facet_stats_full$name

fwrite(facet_stats_full, file = fp(p_mod_output, "facet_stats_full.csv"))
fwrite(facet_stats_w_threat, file = fp(p_mod_output, "facet_stats_w_threat.csv"))

# load it back in
facet_stats_full <- read_csv(file = fp(p_mod_output, "facet_stats_full.csv"))


# original files:
round(as.numeric(facet_stats$mean_jac_w[1:127]), 4) == round(as.numeric(facet_stats02$mean_jac_w), 4)
facet_stats02 <- fread(file = fp(p_mod_output, "facet_stats02.csv")) # more recent, original file (5/22)
facet_stats0 <- fread(file = fp(p_mod_output, "facet_stats0.csv"))
```

```{r facet_stats}
# remove extra composites
facet_stats <- jac_w_melt %>%
  mutate(pair_full = pair,
         pair = gsub("_bp|_b|_by|_bc|_bt|_byct|_z50", "", jac_w_melt$pair)) %>%
  filter(!facet %in% c("bird_composite", "habitats", "plants"),
         !pair %in% c("bird_composite", "habitats", "plants")) %>% 
  rename(facet_names = facet_full) %>%
  group_by(facet_names) %>% 
  summarise(
    facet = unique(facet),
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w)))) #%>%
    #mutate(facet = fct_relevel(facet, facet_names_distill))


fwrite(facet_stats, file = fp(p_mod_output, "facet_stats.csv"))
# load it back in
facet_stats <- read_csv(file = fp(p_mod_output, "facet_stats.csv"))
facet_stats <- facet_stats %>%
  mutate(facet = fct_relevel(facet, facet_names_distill),
         comparison = fct_relevel(comparison, 
                                  c("composites", "types", "taxa", "methods", "resolution", "weights")),
         comparison = fct_recode(comparison, "indices" = "composites"),
         weight = fct_relevel(weight, 
                              c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all")))
```


```{r extract_results}
filter(facet_stats, weight == "all", comparison == "weights") %>% select(facet, weight, comparison, mean_jac_w) %>%
  print(n = 21) #%>%
  #group_by(comparison) %>%
  #summary()
  #summarise(mean_mean = mean(mean_jac_w))
  

filter(facet_stats, weight == "byct", comparison == "indices") %>% select(mean_jac_w) %>% summary
filter(facet_stats, weight == "bp", comparison == "indices") %>% select(mean_jac_w) %>% summary
filter(facet_stats, weight == "z50", comparison == "indices") %>% select(mean_jac_w) %>% summary

filter(facet_stats, weight == "bp") %>% group_by(comparison) %>% 
  summarise(mean = mean(mean_jac_w, na.rm = TRUE),
            min = min(mean_jac_w, na.rm = TRUE),
            max = max(mean_jac_w, na.rm = TRUE))

# with threat:
facet_stats_threat %>% group_by(comparison) %>% 
  summarise(mean = mean(mean_jac_w, na.rm = TRUE),
            min = min(mean_jac_w, na.rm = TRUE),
            max = max(mean_jac_w, na.rm = TRUE))


# go look for and replace numbers related to all, taxa. 
filter(facet_stats, weight == "all") %>% print(n = 28)
filter(jac_w_melt, weight == "all", comparison == "weights") %>% print(n = 28)

jac_w_melt %>%
  filter(weight == "bp",
         comparison == "composites",
         facet %in% c("laurance", "damania", "estes", "vert_endemism"),
         pair %in% c("laurance", "damania", "estes", "vert_endemism")) %>% 
  group_by(facet_full) %>% summarise(mean = mean(jac_w, na.rm = TRUE))

facet_stats %>% filter(comparison == "composites", weight == "bp") %>% select(mean_jac_w)
mean(c(0.0223, 0.0271, 0.0367, 0.00310))

filter(facet_stats, weight == "bp") %>% group_by(comparison) %>% summarise(mean = mean(mean_jac_w, na.rm = TRUE))
facet_stats$comparison %>% unique

jac_w_melt %>%
  filter(weight == "z50", 
         comparison %in% c("composites")) %>% select(jac_w) %>% summary()

# area converted:
facet_stats %>% filter(weight != "z50", facet != "z50") %>% arrange(desc(area_conv))
# the bird facet is crazy high... I wonder why? 
plot(conv_r$facet_r[[5:8]])
cellStats(conv_r$facet_r$bird, "sum")

dt_m_convertible[, c("x", "y", grep("threat", names(dt_m_convertible)[-(1:2)], invert = T, value = T)), with = FALSE][, lapply(.SD, sum)][,-(1:2)]


facet_stats %>% select(area_conv)


filter(facet_stats, weight == "all") %>% group_by(comparison)

max
names(facet_stats)
head(facet_stats)



# similarity
# ---------------------------------------------------------------------------
jac_w_melt %>% 
  filter(weight == "all") %>% 
  group_by(comparison, weight) %>% 
  summarise(mean_jac_w = mean(jac_w), 
            se_jac_w = sqrt(var(jac_w) / sum(jac_w)))

jac_w_melt %>% filter(weight == "all", comparison == "resolution") 
facet_stats %>% filter(weight == "all", comparison == "methods") 


facet_stats %>% filter(weight == "all") %>% .$mean_jac_w %>% summary()

facet_stats %>% filter(comparison == "types", weight == "all") %>% select(mean_jac_w) %>% colMeans(.)

facet_stats %>% filter(comparison == "types", weight != "all") %>% .$area_conv %>% summary()
facet_stats %>% filter(comparison == "types", weight == "all") %>% .$area_conv %>% summary()


# area converted
# ---------------------------------------------------------------------------
summary(facet_stats$area_conv)

facet_stats %>% filter(weight == "all", facet != c("amp"), comparison != "weights") %>% .$area_conv %>% summary()
facet_stats %>% filter(weight == "all", comparison == "taxa") %>% .$area_conv %>% summary()
32135.08/26853

test <- facet_stats %>% filter(weight == "all", facet != c("amp"), comparison == "weights")

(filter(test, facet == "byct") %>% .$area_conv - 
  filter(test, facet == "by") %>% .$area_conv  ) / 
  filter(test, facet == "by") %>% .$area_conv


jac_w_melt %>% filter(comparison == "types", weight == "b")

```

```{r w_threat}

save(dt_w_threat, dt_m_w_threat, dt_m_convertible_w_threat, jac_w_w_threat, jac_w_melt_w_threat, facet_stats_w_threat, bd_dt_m_w_threat, order_jac_w_melt_w_threat, facet_stats_order_w_threat,
  file = fp(p_mod_output, "runs_w_threat_531.RData")
)

rm(dt_w_threat, dt_m_w_threat, dt_m_convertible_w_threat, jac_w_w_threat, jac_w_melt_w_threat, facet_stats_w_threat, bd_dt_m_w_threat, order_jac_w_melt_w_threat, facet_stats_order_w_threat)

load(file = fp(p_mod_output, "runs_w_threat_531.RData"), verbose = TRUE)



```


```{r load_data}
dt <- fread(file = fp(p_mod_output, "dt.csv"))
dt_m <- fread(file = fp(p_mod_output, "dt_m.csv"))
dt_m_convertible <- fread(file = fp(p_mod_output, "dt_m_convertible.csv"))
jac_w <- fread(file = fp(p_mod_output, "jac_w.csv"))
facet_stats <- fread(file = fp(p_mod_output, "facet_stats.csv")) %>% 
  mutate(facet = fct_relevel(facet, facet_names_distill),
         pair = fct_relevel(pair, facet_names),
         comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all"))
         )

jac_w_melt <- fread(file = fp(p_mod_output, "jac_w_melt.csv")) %>% 
  mutate(facet = fct_relevel(facet, facet_names_distill),
         pair = fct_relevel(pair, facet_names),
         comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all"))) %>%
  arrange(facet)


facet_stats$weight
as_tibble(facet_stats)

bd_dt_m <- fread(file = fp(p_mod_output, "bd_dt_m.csv"))

```
# Other Similarity Checks:
Comparing similarity for:
1. Raw biodiversity inputs themselves
2. The unconverted areas
3. The conversion order throughout all of Zambia, irrespective of the production target. 

```{r bd_jac_w}
bd_dt_m %>% ncol() 
names(bd_dt_m)
bd_dt_m[, 1:18] %>% dt_to_raster(CRSobj) %T>% plot()

# create dataframe
length(facet_names)

bd_jac_w <- matrix(
  nrow = 15 + 7,  # facets plus composites
  ncol = 15 + 7)
colnames(bd_jac_w) <- facet_names_distill_w_threat[1:22]

bd_jac_w <- data.frame(
  facet = facet_names_distill_w_threat[1:22],
  bd_jac_w
)
bd_jac_w <- bd_jac_w %>% mutate(facet = fct_relevel(facet, 
                                                    facet_names_distill_w_threat[1:22]))
rownames(bd_jac_w) <- facet_names_distill_w_threat[1:22]


# ------------------------------------------------------------------
# calculate weighted jaccard matrix: final codes, with only a subset of stuff
# ------------------------------------------------------------------

tic()
for (group in 0) { # just 1 group of 22 (15 facets plus 7 composites)

  # for the first four: types  
  for(i in 1:4){
    for(j in 1:4){
      bd_jac_w[22*group + i, 22*group + 1 + j] <- bd_dt_m[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: taxonomic groups  
  for(i in 5:8){
    for(j in 5:8){
      bd_jac_w[22*group + i, 22*group + 1 + j] <- bd_dt_m[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: methods
  for(i in 9:12){
    for(j in 9:12){
      bd_jac_w[22*group + i, 22*group + 1 + j] <- bd_dt_m[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next three: resolutions
  for(i in 13:15){
    for(j in 13:15){
      bd_jac_w[22*group + i, 22*group + 1 + j] <- bd_dt_m[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next 7: composites
  for(i in 16:22){
    for(j in 16:22){
      bd_jac_w[22*group + i, 22*group + 1 + j] <- bd_dt_m[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
}
toc() # 




# remove self similarities
bd_jac_w[bd_jac_w == 1] <- NA

object_size(bd_jac_w)
class(bd_jac_w)

# save it to file
fwrite(bd_jac_w, file = fp(p_mod_output, "bd_jac_w.csv"))

# check to make sure the loop worked. 
bd_dt_m[, c("all", "endemism"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
bd_jac_w["all", "endemism"] # need to have the rows named
bd_jac_w %>% filter(facet == "all") %>% select("endemism")
names(bd_jac_w)



# ------------------------------------------------------------------
# melt bd_jac_w ----------------------------------------------------
# ------------------------------------------------------------------
nrow(bd_jac_w)
bd_jac_w_melt <- bd_jac_w %>% 
  mutate(
    comparison = c(
      rep("types", 4),
      rep("taxa", 4),
      rep("methods", 4),
      rep("resolution", 3),
      rep("composites", 7)),
    weight = "bd") %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE)

bd_jac_w_melt <- bd_jac_w_melt %>% 
  mutate(comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all", "bd"))) %>%
  arrange(facet)


fwrite(bd_jac_w_melt, file = fp(p_mod_output, "bd_jac_w_melt.csv"))


# facet_stats_bd


facet_stats_bd <- bd_jac_w_melt %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))



# ------------------------------------------------------------------
# plot the results -------------------------------------------------
# ------------------------------------------------------------------
gg_jac_w_bd <- ggplot(data = filter(facet_stats_bd)) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet (raw biodiversity inputs)") + ylab("Jaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")

gg_jac_w_bd + labs(title = "Similarity between raw biodiversity inputs",
                   caption = "Note: in raw biodiversity inputs, values of 1 indicate high biodiversity. \nTherefore, this analysis assesses similarity of areas of high biodiversity, \nnot areas of conversion (i.e. low biodiversity).")


gg_jac_w_bd_pairs <- ggplot(filter(bd_jac_w_melt#, !comparison %in% c("resolution", "composites")
                                   ), 
                            aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")
gg_jac_w_bd_pairs


# ----------------------------
# save plot, with error bars
# ----------------------------
png(paste0(p_plots, "/ms_v5/", "jac_w_plot_SI_raw_bd_inputs_title", ".png"), 
    width = 6, height = 3.8, units = "in", res = 400)
print(
    gg_jac_w_bd + 
      labs(title = "Similarity between raw biodiversity inputs",
           caption = "Note: in raw biodiversity inputs, values of 1 indicate high biodiversity. \nTherefore, this analysis assesses similarity of areas of high biodiversity, \nnot areas of conversion (i.e. low biodiversity).") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()


# condensed plot
SI_fig_jac_w_bd <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_bd, 
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = bd_jac_w_melt,
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")


# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_bd", ".png"), 
    width = 6, height = 6, units = "in", res = 400)
print(
    SI_fig_jac_w_bd + 
      labs(title = "Similarity between raw biodiversity inputs",
           caption = "Note: in raw biodiversity inputs, values of 1 indicate high biodiversity. \nTherefore, this analysis assesses similarity of areas of high biodiversity, \nnot areas of conversion (i.e. low biodiversity).") + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

```

```{r conversion_order_jac}
length(bd_dt_m)
names(bd_dt_m)
dt_order <- bd_dt_m[, 1:24]

# first set a key
dt_order[, key := 1:.N]



# then update each column based on the order of that column
# note that the results are essentially the same if we compare based on areas to save vs. areas to convert

for (i in 1:22) {
  setorderv(dt_order, cols = names(dt_order)[2 + i], order = c(-1)) # set to (-1) for descending order (high biodiversity cells first, therefore with low priority value). Use the opposite (1) to list low bd first, therefore giving higher values to high biodiversity (analogous to selecting high biodiversity areas)
  dt_order[, names(dt_order)[2 + i] := (1:.N)/.N] # replace value with 1:N, normalized to 1, so that high values indicate cells that get converted first
  setorder(dt_order, key) # return to original ordering
}

# check it out
dt_order[, 1:6] %>% dt_to_raster(CRSobj) %T>% plot()
dt_order[, key := NULL]

length(dt_order)

# now, run the jac_w

order_jac_w <- matrix(
  nrow = 22,  # facets plus composites
  ncol = 22)
colnames(order_jac_w) <- facet_names_distill_w_threat[1:22]

order_jac_w <- data.frame(
  facet = facet_names_distill_w_threat[1:22],
  order_jac_w
)
order_jac_w <- order_jac_w %>% mutate(facet = fct_relevel(facet, 
                                                    facet_names_distill_w_threat[1:22]))
rownames(order_jac_w) <- facet_names_distill_w_threat[1:22]


# ------------------------------------------------------------------
tic()
for (group in 0) { # just 1 group of 22 (15 facets plus 7 composites)

  # for the first four: types  
  for(i in 1:4){
    for(j in 1:4){
      order_jac_w[22*group + i, 22*group + 1 + j] <- dt_order[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: taxonomic groups  
  for(i in 5:8){
    for(j in 5:8){
      order_jac_w[22*group + i, 22*group + 1 + j] <- dt_order[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: methods
  for(i in 9:12){
    for(j in 9:12){
      order_jac_w[22*group + i, 22*group + 1 + j] <- dt_order[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next three: resolutions
  for(i in 13:15){
    for(j in 13:15){
      order_jac_w[22*group + i, 22*group + 1 + j] <- dt_order[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next 7: composites
  for(i in 16:22){
    for(j in 16:22){
      order_jac_w[22*group + i, 22*group + 1 + j] <- dt_order[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
}
toc() # 10.755 sec.



# remove self similarities
order_jac_w[order_jac_w == 1] <- NA

order_jac_w["threat", ] <- NA
order_jac_w[, "threat"] <- NA

# ------------------------------------------------------------------
# prep and melt
# ------------------------------------------------------------------
nrow(order_jac_w)
order_jac_w_melt <- order_jac_w %>% 
  mutate(
    comparison = c(
      rep("richness", 4), # formerly 4
      rep("taxa", 4),
      rep("methods", 4),
      rep("resolution", 3),
      rep("indices", 7)),
    weight = "order") %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE) %>% 
  mutate(comparison = fct_relevel(comparison, c("indices", "taxa", "richness", "methods", "resolution"))) %>%
  arrange(facet)

# order_jac_w_melt_conv <- order_jac_w_melt
# fwrite(order_jac_w_melt_conv, file = fp(p_mod_output, "order_jac_w_melt_conv.csv"))

# order_jac_w_melt_protect <- order_jac_w_melt
# fwrite(order_jac_w_melt_protect, file = fp(p_mod_output, "order_jac_w_melt_protect.csv"))


# ------------------------------------------------------------------
# facet_stats_order
facet_stats_order_conv <- order_jac_w_melt_conv %>%
  filter(!facet %in% c("bird_composite", "habitats", "plants"),
         !pair %in% c("bird_composite", "habitats", "plants")) %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))

facet_stats_order_protect <- order_jac_w_melt_protect %>%
  filter(!facet %in% c("bird_composite", "habitats", "plants"),
         !pair %in% c("bird_composite", "habitats", "plants")) %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))

fwrite(facet_stats_order_conv, file = fp(p_mod_output, "facet_stats_order_conv.csv"))
fwrite(facet_stats_order_protect, file = fp(p_mod_output, "facet_stats_order_protect.csv"))

# --------------------------------------------------------
# --------------------------------------------------------
# condensed plot - order of conversion
SI_fig_jac_w_order_conv <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_order_conv,
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(order_jac_w_melt_conv, 
                           !facet %in% c("bird_composite", "habitats", "plants"),
                           !pair %in% c("bird_composite", "habitats", "plants")),
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")

SI_fig_jac_w_order_conv + 
  labs(title = "Similarity of Conversion Order") + 
  coord_cartesian(ylim=c(0.4, 1.0)) + 
  theme(legend.position = "none")

# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_order_conv", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_order_conv + 
      labs(title = "Similarity of Conversion Order") + 
      coord_cartesian(ylim=c(0.4, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()


# condensed plot - order of protection
SI_fig_jac_w_order_protect <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_order_protect,
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(order_jac_w_melt_protect, 
                           !facet %in% c("bird_composite", "habitats", "plants"),
                           !pair %in% c("bird_composite", "habitats", "plants")),
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")

SI_fig_jac_w_order_protect + 
  labs(title = "Similarity of Protection Order") + 
  coord_cartesian(ylim=c(0.4, 1.0)) + 
  theme(legend.position = "none")

# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_order_protect", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_order_protect + 
      labs(title = "Similarity of Protection Order") + 
      coord_cartesian(ylim=c(0.4, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

```


```{r unconverted_jac}
# comparing the similarity of areas that are *not selected*. 
# ------------------------------------------------------------------
dt_inverse <- (dt_m_convertible[, c("x", "y", grep("_bp$", facet_names, value = TRUE)), 
                                with = FALSE] - 1) * -1
dt_inverse[, x := dt_m$x]
dt_inverse[, y := dt_m$y]

names(dt_inverse) %>% length

inverse_jac_w <- matrix(
  nrow = 15 + 7,  # facets plus composites
  ncol = 15 + 7)
colnames(inverse_jac_w) <- facet_names_distill_w_threat[1:22]

inverse_jac_w <- data.frame(
  facet = facet_names_distill_w_threat[1:22],
  inverse_jac_w
)
inverse_jac_w <- inverse_jac_w %>% mutate(facet = fct_relevel(facet, 
                                                    facet_names_distill_w_threat[1:22]))
rownames(inverse_jac_w) <- facet_names_distill_w_threat[1:22]


# ------------------------------------------------------------------
tic()
for (group in 0) { # 0 groups of 15 

  # for the first four: types  
  for(i in 1:4){
    for(j in 1:4){
      inverse_jac_w[15*group + i, 15*group + 1 + j] <- dt_inverse[, c(2 + 15*group + i, 2 + 15*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: taxonomic groups  
  for(i in 5:8){
    for(j in 5:8){
      inverse_jac_w[15*group + i, 15*group + 1 + j] <- dt_inverse[, c(2 + 15*group + i, 2 + 15*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: methods
  for(i in 9:12){
    for(j in 9:12){
      inverse_jac_w[15*group + i, 15*group + 1 + j] <- dt_inverse[, c(2 + 15*group + i, 2 + 15*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the last three: resolutions
  for(i in 13:15){
    for(j in 13:15){
      inverse_jac_w[15*group + i, 15*group + 1 + j] <- dt_inverse[, c(2 + 15*group + i, 2 + 15*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
}
toc() # 6 sec


tic() 
  for(i in 1:7){
    for(j in 1:7){
      inverse_jac_w[15 + i, 15 + 1 + j] <- dt_inverse[
        , c(2 + 15 + i, 2 + 15 + j), with = FALSE
        ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }

toc() # 5 seconds


# remove self similarities
inverse_jac_w[inverse_jac_w == 1] <- NA


# ------------------------------------------------------------------
# prep and melt
# ------------------------------------------------------------------
nrow(inverse_jac_w)
inverse_jac_w_melt <- inverse_jac_w %>% 
  mutate(
    comparison = c(
      rep("types", 4),
      rep("taxa", 4),
      rep("methods", 4),
      rep("resolution", 3),
      rep("composites", 7)),
    weight = "inverse") %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE) %>% 
  mutate(comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all", "all_lite", "bd"))) %>%
  arrange(facet)

fwrite(inverse_jac_w_melt, file = fp(p_mod_output, "inverse_jac_w_melt.csv"))


# ------------------------------------------------------------------
# facet_stats_inverse
facet_stats_inverse <- inverse_jac_w_melt %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))



# ------------------------------------------------------------------
# plot the results -------------------------------------------------
# ------------------------------------------------------------------
gg_jac_w_inverse <- ggplot(data = filter(facet_stats_inverse#, comparison != "composites"
                                        )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")

gg_jac_w_inverse + ggtitle("Similarity of Areas ~Not~ Selected for Conversion \n(Inverse of Conversion Areas)")


gg_jac_w_inverse_pairs <- ggplot(filter(inverse_jac_w_melt#, !comparison %in% c("resolution", "composites")
                                   ), 
                            aes(x = facet, y = jac_w, fill = pair)) +
  coord_cartesian(ylim = c(0.9, 1.02)) + 
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")
gg_jac_w_inverse_pairs


gg_jac_w_inverse_wt
gg_jac_w_inverse_pairs_wt

# ----------------------------
# save plot, with error bars
# ----------------------------
png(paste0(p_plots, "/ms_v5/", "jac_w_SI_inverse", ".png"), 
    width = 6, height = 3.4, units = "in", res = 400)
print(
    gg_jac_w_inverse + 
      ggtitle("Similarity of Areas ~Not~ Selected for Conversion \n(Inverse of Conversion Areas)") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

png(paste0(p_plots, "/ms_v5/", "jac_w_SI_inverse_w_threat", ".png"), 
    width = 6, height = 3.4, units = "in", res = 400)
print(
    gg_jac_w_inverse_wt + 
      ggtitle("Similarity of Areas ~Not~ Selected for Conversion \n(Inverse of Conversion Areas, with threat)") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

# pairs
png(paste0(p_plots, "/ms_v5/", "jac_w_SI_inverse_pairs", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_jac_w_inverse_pairs + theme(legend.position = "bottom"))
dev.off()

png(paste0(p_plots, "/ms_v5/", "jac_w_SI_inverse_pairs_w_threat", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_jac_w_inverse_pairs_wt + theme(legend.position = "bottom"))
dev.off()



# --------------------------------------------------------
# --------------------------------------------------------
# condensed plot
SI_fig_jac_w_inverse <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_inverse,
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = inverse_jac_w_melt,
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")


# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_inverse", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_inverse + 
      labs(title = "Similarity of Areas Not Selected for Conversion") + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()


```

Calculate adjacency between ensemble means
In other words, for two rasters a and b, calculate the distance between each pixel on a (selected for conversion) and the nearest neighbor pixel on b (selected for conversion). This is simpler for completely categorical rasters (i.e. either converted, or not). Perhaps I could weight the "distance" based on the value of the cell that is the nearest neighbor. 

I'm planning to adapt code from Lyndon, using `spatstat::nncross()`

First, I recreate this workflow with categorical rasters. Then comes the hard part: figuring out how to calculate the nearest neighbor for the continuous ensemble means.
We have two options: 
1. just calculate the average distance, assuming each cell has the same value, or.
2. calculate a weighted average, based on the value of the cells

conceptually:
- convert raster to points.
- this has the value of the cell associated with the point
- create the ppp objects, which are points objects
- from this, calculate the distance to the nearest neighbor in Y of each point in X (therefore, we put whichever of the layers has more points in as X)
- then, we take the average of all of these distances (this is approach 1)
- Approach 2: what we could do instead is to weight the average based on the value in the cell and the value it is matched to. The values represent the proportion of models that select that particular cell. Therefore, weighting the average distance by the two values means that the distances for the cells where the model more frequently converted are given greater weight. The key thing is for the average to be calculated based not on the number of cells, but instead on the sum of cell values. (i.e. dividing by the sum of cell values, rather than the total number of cells). If we don't do this, the average distance would be artificially lower).

- ok... how do I do that? I'll need to multiply the distance by a) the ensemble mean value, or b) the mean value between the two matching cells.
- then sum the weighted distances
- then divide by the sum of a) ensemble mean cell values or b) the mean value of each pair.
```{r adjacency_exp}
# --------------------------------------------------------------------------
# load relevant libraries and data 
# --------------------------------------------------------------------------
library(spatstat)
beginner
vignette('getstart')

load(file = fp(p_ZA,"parks_roads.rda")) # includes roads (a SpatialLinesDataFrame), pas (SpatialPolygonsDataFrame, a shapefile that includes both national parks and GMAs), and zambia (SpatialPolygonsDataFrame, outline of Zambia)
zambia # could likely use msk_shp just as easily
plot(zambia)
plot(msk_shp)
plot(msk_sf$geometry)


# --------------------------------------------------------------------------
# figure out overlaps 
# --------------------------------------------------------------------------
# ok, I think I need the rasters: see chunk create_facet_rasters_save
plot(facet_r_b[[1:4]])
test <- lapply(facet_r_b[[1:4]], function(x) calc(x[[1:2]], sum))  # conv pixels
calc(facet_r_b[[1:2]], sum) %T>% plot()

plot(conv_r$bd100[[1:4]])



# sum across crops and multiply by convertible areas (I think x[[3]] is $convertible)

rs <- lapply(pure_r, function(x) calc(x[[1:2]], sum) * x[[3]])  # actual area
rs2 <- lapply(pure_r, function(x) calc(x[[1:2]], sum))  # conv pixels
# ^^ I think this is adding together the maize and soy results

# for testing, I'm setting rs2 to be the four vert richness types
# rs2 <- facet_r_b[[1:4]]
# rs2 <- conv_r$bd100[[1:4]] # as a stack, but this causes complications.
rs2 <- lapply(1:4, function(x) conv_r$bd100[[x]]) # load the rasters as individual elements of a list
names(conv_r$bd100[[1:4]])

cnames <- names(conv_r$bd100[[1:4]])
#cnames <- c("Y", "C", "BD", "COST")
names(rs2) <- cnames

# check
# sapply(rs, function(x) cellStats(x, sum))
# ybdc$both$optitab[ind %in% pure, Y]  # same, but C optimized out
# sapply(rs2, function(x) cellStats(x, sum))
# plot(pure_r[[3]])

# -----------------------------
# figure out overlaps between different conversion rasters
# -----------------------------
pms2a <- expand.grid(rep(list(0:1), 4))[-1, ] 
pms2b <- pms2a[which(rowSums(pms2a) == 2), ]
names(pms2b) <- cnames
pms2b$pair <- c("ae", "at", "et", "as", "es", "ts")
#pms2b$cl <- c("YC", "YBd", "CBd", "YCt", "CCt", "BdCt")
rownames(pms2b) <- 1:6


# pairwise overlaps between two rasters. 
# if using a raster brick, you have to add a bracket around the which call in order to select from the raster brick correctly (Lyndon's code has the rasters stored as a list)
rs_over <- lapply(1:nrow(pms2b), function(x) {  # apply logic tests
  calc(stack(rs2[which(pms2b[x, ] == 1)]), sum) 
})
names(rs_over) <- pms2b$pair #pms2b$cl
# I get an error, but the result is the same as when using a raster stack and the extra bracket. 

# $convertible is the proportion of each cell that is "unconverted to cropland or urban." This determines how much area each pixel could supply, and therefore how much food  the pixel can create if it's converted to agriculture. See cc_Start chunk "load-basic-gis-files" for inputs. 


# -----------------------------
# Jaccard Index of overlaps
# -----------------------------
rs_over_a <- sapply(1:length(rs_over), function(x) { # x <- 4
  sapply(1:2, function(y) {  # y <- 3
    r <- rs_over[[x]] == y # this is looking first for 1s and then 2s. This is a categorical Jaccard calculation that doesn't work right with the ensemble means
    round(cellStats(r * convertible_r0, sum), 1) # must use convertible_r without PAs so that the extents match
  })
})
pms2b$JS <- round(rs_over_a[2, ] / colSums(rs_over_a) * 100, 2)


# --------------------------------------------------------------------------
# calculate nearest neighbor distance, using spatstat::nncross()
# --------------------------------------------------------------------------

# create an "observation window" (i.e. owin) of analysis in spatstat
zam_owin <- owin(xrange = bbox(zambia)[1, ], yrange = bbox(zambia)[2, ],
                 unitname = "meter")

which1 <- function(x) x == 1  # selector function for r to xy

rsover_nn <- lapply(1:nrow(pms2b), function(x) {  # apply logic tests; x = 2
  
  # select the indices of row x with a value of 1 (which two rasters are overlapping here)
  ind <- which(pms2b[x, 1:4] == 1) 
  
  # select the two rasters of interest, save as a new list with those two rasters
  rl <- rs2[ind]
  
  # convert those rasters to points. 
  rxy <- lapply(rl, function(x) rasterToPoints(x, fun = which1)) # a simple function returning a logical value, to select a subset of the raster values
  
  
  pps <- lapply(rxy, function(x) {
    ppp(x = x[, 1], y = x[, 2], window = zam_owin)
  })
  # reorder to find which has most points, to put that in as X
  reord <- sort(sapply(pps, function(x) x$n), decreasing = TRUE)
  ppnn <- nncross(pps[[names(reord)[1]]], pps[[names(reord)[2]]])
})

pms2b$NND <- round(sapply(rsover_nn, function(x) mean(x$dist))) / 1000


# melt the data.frame
# melt(pms2b, )
#example
#jac_w_clean %>% melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE)

plot(NND ~ pair, data = pms2b)
plot(pms2b$NND)


gg_nn <- ggplot(data = pms2b, aes(x = pair, y = NND, fill = pair)) + 
  theme_classic() + 
  geom_bar(stat = "identity", position = position_dodge(0.6)) + 
  xlab("pairwise comparison") + ylab("Average distance \nto neighbor (km)")
gg_js <- ggplot(data = pms2b, aes(x = pair, y = JS, fill = pair)) + 
  theme_classic() + 
  geom_bar(stat = "identity", position = position_dodge(0.6)) + 
  xlab("pairwise comparison") + ylab("Jaccard Similarity")

gg_nn
gg_js
gg_nn %+% filter(pms2b, vert_all == 1)
gg_nn %+% filter(pms2b, vert_endemism == 1)
gg_nn %+% filter(pms2b, vert_threat == 1)
gg_nn %+% filter(pms2b, vert_small == 1)

# ok.. now, what do i do with the ensemble means? 
# I end up with an average distance for each point to the neighest neighbor. Maybe, I should make a weighted average




facet_r_b
types_r <- lapply(1:nlayers(facet_r_b), function(x) {facet_r_b[[x]]})
# names(types_r) <- names(facet_r_b[[1:4]]) # or
names(types_r) <- names(facet_r_b[[1:4]]) # facet_names[1:4]

types_pairs

types_pairs0 <- expand.grid(rep(list(0:1), 4))[-1, ] 
types_pairs <- types_pairs0[which(rowSums(types_pairs0) == 2), ]
names(types_pairs) <- names(types_r)
types_pairs$pair <- c("ae", "at", "et", "as", "es", "ts")
#pms2b$cl <- c("YC", "YBd", "CBd", "YCt", "CCt", "BdCt")
rownames(types_pairs) <- 1:6

ensembles_nn <- lapply(1:nrow(types_pairs), function(x) {  # apply logic tests; x = 2
  
  # select the indices of row x with a value of 1 (which two rasters are overlapping here)
  ind <- which(types_pairs[x, 1:4] == 1) 
  
  # select the two rasters of interest, save as a new list with those two rasters
  rl <- types_r[ind]
  
  # convert those rasters to points. 
  rxy <- lapply(rl, function(x) rasterToPoints(x, fun = function(x) x > 0)) # selecting a subset of raster values (those larger than 0), using a simple function returning a logical values
  
  pps <- lapply(rxy, function(x) {
    ppp(x = x[, 1], y = x[, 2], window = zam_owin)
  })
  # reorder to find which has most points, to put that in as X
  reord <- sort(sapply(pps, function(x) x$n), decreasing = TRUE)
  ppnn <- nncross(pps[[names(reord)[1]]], pps[[names(reord)[2]]])
  # Note that this function is not symmetric in X and Y. To find the nearest neighbour in X of each point in Y, where Y is a point pattern, use nncross(Y, X).
})

types_pairs$NND <- round(sapply(ensembles_nn, function(x) mean(x$dist))) / 1000

plot(pps$all)
plot(pps$endemism)
```



```{r nn_calc}
# --------------------------------------------------------------------------
# nn_calc
# --------------------------------------------------------------------------

rl <- lapply(1:nlayers(facet_r_bp), function(x) {facet_r_bp[[x]]})
names(rl) <- names(facet_r_bp)

nndat <- jac_w_melt %>%
#  as_tibble() %>% 
  filter(weight == "bp") %>%
  select(comparison, weight, facet_full, pair_full, pair, facet) %>%
  arrange(facet_full) # this sorts correctly, because facet is a factor in the correct order

# create an "observation window" (i.e. owin) of analysis in spatstat
zam_owin <- owin(xrange = bbox(zambia)[1, ], yrange = bbox(zambia)[2, ],
                 unitname = "meter")

tic()
nnl <- lapply(1:nrow(nndat), function(i) {
  # select indices to grab from rl
  ind <- c(
    which(names(rl) == nndat$facet_full[i]), 
    which(names(rl) == nndat$pair_full[i])
    )
  
  # select the two rasters of interest, save as a new list with those two rasters
  rl_ind <- rl[ind]
  
  # convert those rasters to points. 
  rxy <- lapply(rl_ind, function(x) rasterToPoints(x, fun = function(x) x > 0)) # selecting a subset of raster values (those larger than 0), using a simple function returning a logical values
  
  pps <- lapply(rxy, function(x) {
    ppp(x = x[, 1], y = x[, 2], window = zam_owin)
  })
  
  ppnn <- nncross(pps[[names(rl)[ind[1]]]], pps[[names(rl)[ind[2]]]]) %>%
    as_tibble() %>% mutate(surrogate_key = row_number())
  
  # ------------------------------------------------
  # join ppnn to the rxy values
  rxy_tbl <- lapply(rxy, function(x) mutate(as_tibble(x), surrogate_key = row_number()))
  
  ppnn_join <- ppnn %>% 
    # join ppnn to the rxy values
    left_join(rxy_tbl[[1]], by = "surrogate_key") %>% 
    select(-c(x, y)) %>%
    left_join(rxy_tbl[[2]], 
              by = c("which" = "surrogate_key")) %>% 
    select(-c(x, y)) %>%
    
    # with joined table, calculate the average ensemble value
    mutate(
      mean_value = rowMeans(cbind(.[, 4], .[, 5]), na.rm=T),
      adj_dist = dist * mean_value)
})
toc() # 155.906 sec

nnl_sums <- lapply(nnl, function(x) {
  summarise(x, 
          dist_sum = sum(dist), 
          npoints = nrow(x),
          adj_dist_sum = sum(adj_dist),
          mean_value_sum = sum(mean_value))
})
nnl_sums <- do.call("rbind", nnl_sums) 
nnl_sums <- nnl_sums %>%
  mutate(raw_mean_dist = dist_sum/npoints,
         adj_mean_dist = adj_dist_sum/mean_value_sum)

nndat_full <- nndat %>% cbind(nnl_sums)

nndat <- nndat_full %>%
  filter(!facet %in% c("bird_composite", "habitats", "plants"),
         !pair %in% c("bird_composite", "habitats", "plants")) %>%
  mutate(
    comparison = fct_relevel(comparison, c("indices", "taxa", "types", "methods", "resolution", "weights")),
    comparison = fct_recode(comparison, "richness" = "types"))

as_tibble(nndat)

# calculate mean distance for each facet
# facet_stats_order
nndat_facet_stats <- nndat %>%
  group_by(facet_full) %>% 
  summarise(
    count = n(),
    facet = unique(facet),
    pair = unique(pair),
    pair_full = unique(pair_full),
    comparison = unique(comparison),
    weight = unique(weight),
    facet_mean_dist = mean(adj_mean_dist, na.rm = TRUE))

nndat_facet_stats

object_size(nndat, nnl, nnl_sums, nndat_facet_stats)
save(nndat, nnl, nnl_sums, nndat_facet_stats, file = fp(p_mod_output, "nnd_files.RData"))

# --------------------------------------------------------------------------
# plot ---------------------------------------------------------------------
# --------------------------------------------------------------------------

gg_nnd_pairs <- ggplot(nndat, aes(x = facet_full, y = adj_mean_dist / 1000, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Adjusted Average Distance \nto Nearest Neighbor (km)") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")
gg_nnd_pairs

gg_nnd <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + 
  ylab("Mean Distance to Nearest Neighbor (km)") + #fct_relevel(facet, facet_names_distill)
  geom_point(data = nndat_facet_stats,
             mapping = aes(x = facet, y = facet_mean_dist / 1000, color = comparison),
             size = 2) +
  geom_point(data = nndat, 
             mapping = aes(x = facet, y = adj_mean_dist / 1000),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+ theme(legend.title = element_text("Mean Value"))
gg_nnd0
gg_nnd02
gg_nnd


# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_nnd_bp", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    gg_nnd + 
      #ggtitle("Pure biodiversity (100% weight on bd, with average yields)") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()


# nnd pairs
png(paste0(p_plots, "/ms_v3/", "nnd_bp_pairs", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_nnd + theme(legend.position = "bottom"))
dev.off()


```

```{r random_checks}

# does normalizing the facet ensemble means affect the jaccard values? 
# yes, from this test it looks like normalizing the facet ensemble means before running the jaccard similarity causes the Jaccard Similarity to decline

# pre-normalization
test_dt <- as.data.table(facet_r_bp[[c("res1_bp", "res10_bp")]], xy = FALSE, keep.rownames=TRUE)
test_dt <- na.omit(test_dt)
test_dt[, c("res1_bp", "res10_bp"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
test_dt %>% summary()

# normalization
test_dt2 <- as.data.table(normalize(facet_r_bp[[c("res1_bp")]]), xy = FALSE, keep.rownames=TRUE)
test_dt3 <- as.data.table(normalize(facet_r_bp[[c("res10_bp")]]), xy = FALSE, keep.rownames=TRUE)

identical(na.omit(test_dt3), agroEcoTradeoff::standardize(test_dt[, 2]))

test_dt2 <- na.omit(cbind(test_dt2, test_dt3))
test_dt2 %>% summary()
test_dt2[, c("res1_bp", "res10_bp"), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]


filter(facet_stats, weight == "bp") %>% print(n = 21)

jac_w_melt %>% filter(weight == "bp", comparison %in% c("methods", "resolution")) #%>%  select(jac_w) %>%  summary()


# normalize the rasters before running the similarities:
dt_norm_pre <- dt_m_convertible[, 1:2]
dt_norm_pre <- cbind(dt_norm_pre, dt_m_convertible[, grep("_bp$", names(dt_m_convertible), value = TRUE), with = FALSE])
dt_norm <- dt_norm_pre[, lapply(.SD, standardize)]
dt_norm
dt_norm[, x := dt_norm_pre$x]
dt_norm[, y := dt_norm_pre$y]

# now, run the jac_w

norm_jac_w <- matrix(
  nrow = 22,  # facets plus composites
  ncol = 22)
colnames(norm_jac_w) <- facet_names_distill_w_threat[1:22]

norm_jac_w <- data.frame(
  facet = facet_names_distill_w_threat[1:22],
  norm_jac_w
)
norm_jac_w <- norm_jac_w %>% mutate(facet = fct_relevel(facet, 
                                                    facet_names_distill_w_threat[1:22]))
rownames(norm_jac_w) <- facet_names_distill_w_threat[1:22]


# ------------------------------------------------------------------
tic()
for (group in 0) { # just 1 group of 22 (15 facets plus 7 composites)

  # for the first four: types  
  for(i in 1:4){
    for(j in 1:4){
      norm_jac_w[22*group + i, 22*group + 1 + j] <- dt_norm[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: taxonomic groups  
  for(i in 5:8){
    for(j in 5:8){
      norm_jac_w[22*group + i, 22*group + 1 + j] <- dt_norm[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next four: methods
  for(i in 9:12){
    for(j in 9:12){
      norm_jac_w[22*group + i, 22*group + 1 + j] <- dt_norm[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next three: resolutions
  for(i in 13:15){
    for(j in 13:15){
      norm_jac_w[22*group + i, 22*group + 1 + j] <- dt_norm[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
  
  # for the next 7: composites
  for(i in 16:22){
    for(j in 16:22){
      norm_jac_w[22*group + i, 22*group + 1 + j] <- dt_norm[, c(2 + 22*group + i, 2 + 22*group + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
}
toc() # 



# remove self similarities
norm_jac_w[norm_jac_w == 1] <- NA

# ------------------------------------------------------------------
# prep and melt
# ------------------------------------------------------------------
nrow(norm_jac_w)
norm_jac_w_melt <- norm_jac_w %>% 
  mutate(
    comparison = c(
      rep("types", 4), # formerly 4
      rep("taxa", 4),
      rep("methods", 4),
      rep("resolution", 3),
      rep("composites", 7)),
    weight = "norm") %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE) %>% 
  mutate(comparison = fct_relevel(comparison, c("composites", "types", "taxa", "methods", "resolution", "weights")),
         weight = fct_relevel(weight, c("bp",   "b",    "by",   "bc",   "bt",   "byct", "z50",  "all", "bd", "norm"))) %>%
  arrange(facet)

fwrite(norm_jac_w_melt, file = fp(p_mod_output, "norm_jac_w_melt.csv"))


# ------------------------------------------------------------------
# facet_stats_norm
facet_stats_norm <- norm_jac_w_melt %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))



# ------------------------------------------------------------------
# plot the results -------------------------------------------------
# ------------------------------------------------------------------
# condensed plot
SI_fig_jac_w_norm <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_norm,
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = norm_jac_w_melt,
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")


# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_norm", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_norm + 
      labs(title = "Similarities, after normalizing each facet raster (0-1)") + 
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

```

```{r threatened-species-richness}
conv_extras_bp_dt
env_size(ls())
# --------------------------------------------------------------------------
# save new version of the dt, with threatened species richness, just for bp for now
dt_bp_threat <- fread(file = fp(p_mod_output, "dt_bp.csv"))
dt_bp_threat
conv_extras_bp_dt
names(conv_extras_bp_dt) <- c("x", "y", paste0(extra_runs, "_bp"))
names(dt_bp_threat)

names(conv_extras_bp_dt)


# --------------------------------------------------------------------------
# cut out layers I don't use, including reptiles
grep("mam|bird_[^c]|amp", names(dt_bp_threat), value = TRUE, invert = FALSE)

dt_bp_threat
dt_bp_threat[, grep("mam|bird|amp", names(dt_bp_threat)), with = FALSE] %>% length # 5*7*3 # 5 (4 taxa plus combo) * 3 resolutions * 7 weights
length(dt_bp_threat)
dt_bp_threat[, (grep("mam|bird_[^c]|amp", names(dt_bp_threat), value = TRUE, invert = TRUE)) := NULL]



# merge with new extra runs:
dt_bp_threat <- cbind(
  dt_bp_threat, 
  conv_extras_bp_dt[, grep("sum_norm", names(conv_extras_bp_dt[, -c(1:2)]), invert = TRUE, value= TRUE)
        , with = FALSE]
  )

dt_bp_threat_m <- conv_extras_bp_dt[, 1:2]

# --------------------------------------------------------------------------
# re calculate the ensemble means to just include mammals, birds, and amphibians.
# richness type averages

dt_bp_threat_m[, all_bp := rowMeans(dt_bp_threat[, grep("_all.+bp$", names(dt_bp_threat)), with = FALSE])]
dt_bp_threat_m[, endemism_bp := rowMeans(dt_bp_threat[, grep("_endemism.+bp$", names(dt_bp_threat)), with = FALSE])]
dt_bp_threat_m[, threat_bp := rowMeans(dt_bp_threat[, grep("_threat.+bp$", names(dt_bp_threat)), with = FALSE])]
dt_bp_threat_m[, small_bp := rowMeans(dt_bp_threat[, grep("_small.+bp$", names(dt_bp_threat)), with = FALSE])]

# taxa averages
dt_bp_threat_m[, mam_bp := rowMeans(dt_bp_threat[, grep("mam.+bp$", names(dt_bp_threat)), with = FALSE])]
dt_bp_threat_m[, bird_bp := rowMeans(dt_bp_threat[, grep("bird.[^c]+bp$", names(dt_bp_threat)), with = FALSE])]
dt_bp_threat_m[, amp_bp := rowMeans(dt_bp_threat[, grep("amp.+bp$", names(dt_bp_threat)), with = FALSE])]
# dt_bp_threat_m[, rep_bp := rowMeans(dt_bp_threat[, grep("rep.+bp$", names(dt_bp_threat)), with = FALSE])]



# --------------------------------------------------------------------------
# adjust by convertible areas
dt_bp_threat_m_convertible <- dt_bp_threat_m[, lapply(.SD, function(x) {
  il$convertible[valinds, ]$convertible * x})]

dt_bp_threat_m_convertible[, x := dt_bp_threat_m$x]
dt_bp_threat_m_convertible[, y := dt_bp_threat_m$y]

# --------------------------------------------------------------------------
# run loop to calculate the weighted jaccard

jac_w_threat <- matrix(
  nrow = 7,  # facets plus composites
  ncol = 7)
colnames(jac_w_threat) <- gsub("_bp", "", names(dt_bp_threat_m_convertible)[-c(1:2)])

jac_w_threat <- data.frame(
  facet = gsub("_bp", "", names(dt_bp_threat_m_convertible)[-c(1:2)]),
  jac_w_threat
)
jac_w_threat <- jac_w_threat %>% 
  mutate(facet = fct_relevel(facet,
                             gsub("_bp", "", names(dt_bp_threat_m_convertible)[-c(1:2)])))
rownames(jac_w_threat) <- gsub("_bp", "", names(dt_bp_threat_m_convertible)[-c(1:2)])


# ------------------------------------------------------------------
tic()
  # for the first four: types  
for(i in 1:4){
  for(j in 1:4){
      jac_w_threat[i, 1 + j] <- dt_bp_threat_m_convertible[, c(2 + i, 2 + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
}

for(i in 5:7){
  for(j in 5:7){
      jac_w_threat[i, 1 + j] <- dt_bp_threat_m_convertible[, c(2 + i, 2 + j), with = FALSE
                            ][, sum(pmin(.SD[, 1], .SD[, 2]))/sum(pmax(.SD[, 1], .SD[, 2]))]
    }
  }
toc() # 10.755 sec.


# remove self similarities
jac_w_threat[jac_w_threat == 1] <- NA

# ------------------------------------------------------------------
# prep and melt
# ------------------------------------------------------------------
nrow(jac_w_threat)
jac_w_threat_melt <- jac_w_threat %>% 
  mutate(
    comparison = c(
      rep("richness", 4), # formerly 4
      rep("taxa", 3)),
    weight = "bp") %>%
  select(., facet, comparison, weight, everything()) %>% 
  melt(variable.name = "pair", value.name = "jac_w", na.rm = TRUE) %>% 
  mutate(comparison = fct_relevel(comparison, c("taxa", "richness"))) %>%
  arrange(facet)

fwrite(jac_w_threat_melt, file = fp(p_mod_output, "jac_w_threat_melt.csv"))


# ------------------------------------------------------------------
# facet_stats_threat
facet_stats_threat <- jac_w_threat_melt %>%
  group_by(facet) %>% 
  summarise(
    count = n(),
    comparison = unique(comparison),
    weight = unique(weight),
    mean_jac_w = mean(jac_w, na.rm = TRUE),
    se_jac_w = sqrt(var(jac_w, na.rm = TRUE) / sum(!is.na(jac_w))))

fwrite(facet_stats_threat, file = fp(p_mod_output, "facet_stats_threat.csv"))

# --------------------------------------------------------
# --------------------------------------------------------
# condensed plot
SI_fig_jac_w_threat <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = facet_stats_threat,
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = jac_w_threat_melt,
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") +
  scale_colour_discrete("Mean Values")

SI_fig_jac_w_threat + 
  labs(title = "With Threatened Species Richness") + 
  coord_cartesian(ylim=c(0, 1.0))

# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_threat", ".png"), 
    width = 4, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_threat + 
      #labs(title = "Including Threatened Species Richness") + 
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()


# maps:


facet_r_threat <- writeRaster(
  dt_to_raster(dt_bp_threat_m_convertible, CRSobj),
  overwrite=TRUE, fp(p_mod_output,"facet_r_threat.tif"))
plot(facet_r_threat)
facet_r_threat <- brick(fp(p_mod_output,"facet_r_threat.tif"))
names(facet_r_threat) <- gsub("_bp", "", names(dt_bp_threat_m_convertible)[-c(1:2)])


pixels <- 5000000
  
p1 <- gplot(facet_r_threat[[c("mam", "bird", "amp")]], maxpixels = pixels) + 
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white", limits = c(0, 1)) + 
      labs(y = "Taxonomic Groups", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), 
            axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.title = element_blank()) + 
      coord_equal()

p2 <- gplot(facet_r_threat[[c("all", "endemism", "threat", "small")]], maxpixels = pixels) + # or facet_r[[comparison_names$types]] for just the four ensemble means
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white", limits = c(0, 1)) + 
      labs(y = "Richness Types", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.position = "none") + 
      coord_equal()


# start png call here. 
png(paste0(p_plots, "/ms_v5/","SI_fig_facet_r_threat", "_combo.png"),    
    width = 5, height = 6,
    units = "in", res = 300)

plot_grid(
  p1, p2, 
  SI_fig_jac_w_threat + theme(legend.position = "top"), 
  labels = "auto",
  ncol = 1, rel_heights = c(1.3, 1.2, 2.5))

dev.off()



```

```{r norm_order}
# first get mean of all vert richness across four types and 3 weights:
# first collect and merge dt_b, dt_by, and dt_byct, but just the vert and the sum_norm columns
names(dt_bp)
conv_extras_bp_dt %>% names
grep("sum_norm", names(conv_extras_bp_dt), value = TRUE)
grep("vert_[^t]", names(dt_bp), value = TRUE)


dt <- merge(dt_b[, c(1:6, 53:56)], dt_by[, c(1:6, 53:56)], by = c("x","y"))
dt <- merge(dt, dt_byct[, c(1:6, 53:56)], by = c("x","y"))

dt %>% ncol()

dt_norm <- cbind(
  conv_extras_bp_dt[, 1:2],
  conv_extras_bp_dt[, grep("sum_norm", names(conv_extras_bp_dt), value = TRUE), with = FALSE],
  dt_bp[, grep("vert_[^t]", names(dt_bp), value = TRUE), with = FALSE]
  )
names(dt_norm)

grep("sum_norm", names(dt), invert = TRUE, value = TRUE)
grep("sum_norm", names(dt), value = TRUE)

grep("sum_norm", names(dt_norm[, -c(1:2)]), invert = TRUE, value= TRUE)

dt_norm[, grep("sum_norm", names(dt_norm[, -c(1:2)]), invert = TRUE, value= TRUE)
        , with = FALSE]


dt_norm[, norm_first := rowMeans(
  dt_norm[, grep("sum_norm", names(dt_norm[, -c(1:2)]), invert = TRUE, value= TRUE), with = FALSE]  
  )]
dt_norm[, sum_first := rowMeans(
  dt_norm[, grep("sum_norm", names(dt_norm)), with = FALSE])]

dt_norm[, difference := norm_first - sum_first]
names(dt_norm)

norm_r <- dt_to_raster(dt_norm[, .(x, y, norm_first, sum_first, difference)], CRSobj)
plot(norm_r)
#norm_r[norm_r <= 0] <- NA # set all 0s to NA


png(file = fp(p_plots, "/ms_v5/norm_r.png"), 
    width = 6, height = 6, units = "in", res = 300)
plot(norm_r[[1]] - norm_r[[2]], #main = "norm first - sum first", 
     box = FALSE, axes = FALSE)

plot(pas, col = col_pas_all, border = "gray", add=T)
legend("bottomright", legend= c("GMA", "Nat'l Park"), fill=col_pas, cex = 1.1, bty = "n")
plot(msk_shp, add = TRUE)
dev.off()

dt_norm[, .(norm_first, sum_first) # select the two columns you're interested in... (this works with column names in quotes, or as column indices)
   ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))] # then calculate the weighted Jaccard

# 0.789

p1 <- gplot(norm_r[[c("norm_first", "sum_first")]], maxpixels = 5000000) + 
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white", limits = c(0, 1)) + 
      labs(y = "Normalization Order", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.title = element_blank()) + 
      coord_equal()

p2 <- gplot(norm_r[["difference"]], maxpixels = 5000000) + 
      geom_raster(aes(fill = value)) +
      #facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white"#, limits = c(0, 1)
                           ) + 
      labs(y = "Difference", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.title = element_blank()) + 
      coord_equal()

png(paste0(p_plots, "/ms_v5/","SI_norm_order_plots.png"),    
    width = 4, height = 5,
    units = "in", res = 300)
plot_grid(p1, p2, ncol = 1, rel_heights = c(1, 2))
dev.off()

rm(p1, p2)
```



# plots
```{r *primary_plots}
ms_fig_jac_w_bp <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "bp"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "bp"), 
             mapping = aes(x = facet, y = jac_w), #color = "black", show.legend = FALSE,
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + 
  scale_colour_discrete("Mean Values") #+ theme(legend.text = element_text("1", "2", "3", "4", "5"))



ms_fig_jac_w_bp + ggtitle("Pure biodiversity (100% weight on bd, with average yields)")


gg_jac_w_bp_pairs <- ggplot(filter(jac_w_melt, weight == "bp"), 
                            aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")


# save:
png(paste0(p_plots, "/ms_v5/", "ms_fig_jac_w_bp", ".png"), 
    width = 7, height = 4, units = "in", res = 400)
print(
    ms_fig_jac_w_bp + 
      #ggtitle("Pure biodiversity (100% weight on bd, with average yields)") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(#legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()


# combo jac_w & nnd:
png(paste0(p_plots, "/ms_v5/", "ms_fig_combo_jac_w_nnd_bp", ".png"), 
    width = 7, height = 6, units = "in", res = 400)

plot_grid(
  plot_grid(
    ms_fig_jac_w_bp + 
      coord_cartesian(ylim=c(0, 1.0)) +
      theme(strip.background = element_blank(), strip.text.x = element_blank(),
            axis.title.x = element_blank(), axis.text.x = element_blank(), legend.position = "none"),
    gg_nnd + 
      # coord_cartesian(ylim=c(0, 200))
      ylab("Mean Distance to \nNearest Neight (km)") + 
      theme(legend.position = "none"),
    ncol = 1, align = "v", rel_heights = c(1, 1.2), labels = "auto"
    ),
  get_legend(ms_fig_jac_w_bp + theme(legend.position = "right")),
  ncol = 2, rel_widths = c(1, 0.2)
  )

dev.off()
```

```{r *si_jac_w}

# --------------------------------------------------------
# b ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_b <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "b"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "b"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+ theme(legend.title = element_text("Mean Value"))

# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_b", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_b + 
      ggtitle("100% weight on biodiversity, accurate (dynamic) yields") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()



# --------------------------------------------------------
# z50 ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_z50 <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "z50"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "z50"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+ theme(legend.title = element_text("Mean Value"))

# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_z50", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_z50 + 
      labs(title = "Converting 50% of Zambia", 
       subtitle = "100% weight on biodiversity, mean yields") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()


# --------------------------------------------------------
# by ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_by <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "by"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "by"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+ theme(legend.title = element_text("Mean Value"))

# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_by", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_by + 
      labs(title = "Incorporating Yields", 
       subtitle = "50% weight on yield, 50% on biodiversity") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

# --------------------------------------------------------
# bc ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_bc <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "bc"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "bc"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+ theme(legend.title = element_text("Mean Value"))

# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_bc", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_bc + 
      labs(title = "Incorporating Carbon", 
       subtitle = "50% weight on carbon loss, 50% on biodiversity") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

# --------------------------------------------------------
# bt ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_bt <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "bt"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "bt"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+ theme(legend.title = element_text("Mean Value"))

# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_bt", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_bt + 
      labs(title = "Incorporating Travel Cost", 
       subtitle = "50% weight on Travel Cost, 50% on biodiversity") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()



# --------------------------------------------------------
# byct ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_byct <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "byct"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "byct"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+ theme(legend.title = element_text("Mean Value"))

# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_byct", ".png"), 
    width = 6, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_byct + 
      ggtitle("Equal weights on biodiversity, yield, carbon, and travel cost") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

# --------------------------------------------------------
# all ----------------------------------------------------
# --------------------------------------------------------
SI_fig_jac_w_all <- ggplot() +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Jaccard Similarity") +
  geom_point(data = filter(facet_stats, weight == "all"),
             mapping = aes(x = facet, y = mean_jac_w, color = comparison),
             size = 2) +
  geom_point(data = filter(jac_w_melt, weight == "all"), 
             mapping = aes(x = facet, y = jac_w),
             alpha = 0.15) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+ theme(legend.title = element_text("Mean Value"))

# save:
png(paste0(p_plots, "/ms_v5/", "SI_fig_jac_w_all", ".png"), 
    width = 7, height = 4, units = "in", res = 400)
print(
    SI_fig_jac_w_all + 
      ggtitle("Similarity between facets, averaged across all model weights") +
      coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()


```



```{r gg_theme}
# define new theme:
cc_theme3 <- theme(
  #legend.position = "none",
  plot.title = element_blank(),
  plot.subtitle = element_blank(),
  plot.caption = element_blank(),
  axis.title.x = element_blank(),
  #axis.title.y = element_text(size=9),
  axis.text.x = element_text(size=9)
)

cc_theme3_print <- cc_theme3 + theme(axis.text.x = element_text(size=9))

cc_theme3_bottom <- theme(legend.position = "bottom")
cc_theme3_none <- theme(legend.position = "none")

cc_theme3_trim <-  theme(axis.text.x = element_text(angle = 0, vjust = 0, hjust = 0.5))


# ------------------------------------------------------------------------------------------------------------------------
# final the color scheme
gg_jac_w_comp_colors <- scale_color_manual(#name = "Weights",
                     labels = c("all" = "average",
                                "b" = "b",
                                "by" = "by",
                                "byct" = "byct"),
                     values = c("all" = "black",
                                "b" = hue_pal()(3)[2], # "green"
                                "by" = hue_pal()(3)[3], #"blue"
                                "byct" = hue_pal()(3)[1])) #"red"

```


```{r gg_jac_w_all}
# next up: plot the results
names(facet_stats)

gg_jac_w_base <- ggplot(data = facet_stats) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Weighted Jaccard Similarity \n(Mean Within Comparison)") + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  labs(title = "Mean Weighted \nJaccard Index", 
       subtitle = "between each facet and the group",
       caption = "Error bars represent 95% confidence intervals")


# ------------------------------------------------------------------------------------------------------------------------
# this shows all four comparisons, with all four weights - but it's too much for one figure. 
gg_jac_w_all_weights <- gg_jac_w_base +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, 
                           color = weight#, shape = comparison
                           ), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = facet, ymin = mean_jac_w - 1.96*se_jac_w, ymax = mean_jac_w + 1.96*se_jac_w, 
                              color = weight), position = position_dodge(0.6), width = 0.4) +
  cc_theme3 +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+
  #gg_jac_w_comp_colors

gg_jac_w_all_weights
gg_jac_w_all_weights0

# just the average weights
gg_jac_w_all <- gg_jac_w_all_weights %+% filter(facet_stats, weight == "all"#, comparison != "weights"
                                               ) + theme(legend.position = "none") + gg_jac_w_comp_colors

# just composites
gg_jac_w_all_weights %+% filter(facet_stats, comparison == "composites")
gg_jac_w_all_weights %+% filter(facet_stats, weight == "all", comparison == "composites")

facet_stats %>% filter(comparison == "composites")

# all weights averaged together, with weights.

gg_jac_w_all_by_comp <- ggplot(data = filter(facet_stats, weight == "all"#, comparison != "weights"
                                             )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")
gg_jac_w_all_by_comp


# 
gg_jac_w_all_weights %+% filter(facet_stats, weight %in% c("bp", "by", "byct", "all_lite"), comparison != "composites")
# whhy is bp less similar than by for types and taxa, but by is less similar than bp for many of the methods and resolutions?
gg_jac_w_all_weights %+% filter(facet_stats, comparison == "composites")


filter(facet_stats, weight == "bp", comparison %in% c("methods", "resolution"))
gg_jac_w_b_pure_wt # <- gg_jac_w_b_pure
gg_jac_w_b_pure <- ggplot(data = filter(facet_stats, weight == "bp"#, comparison != "composites"
                                        )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")

gg_jac_w_b_pure + ggtitle("Pure biodiversity (100% weight on bd, with average yields)")



gg_jac_w_bd100_by_comp0
gg_jac_w_bd100_by_comp <- ggplot(data = filter(facet_stats, weight == "b"# comparison != "composites"
                                               )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")
gg_jac_w_bd100_by_comp + ggtitle("100% weight on bd, with accurate, variable yields)")
gg_jac_w_bd100_by_comp0

# 50/50 biodiversity and yield:
gg_jac_w_by <- ggplot(data = filter(facet_stats, weight == "by"# comparison != "composites"
                                               )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")
gg_jac_w_by + ggtitle("Weight split equally between bd and yield \n(50% on each, assuming accurate, variable yields)")


gg_jac_w_z50 <- ggplot(data = filter(facet_stats, weight == "z50"#, comparison != "composites"
                                     )) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Mean Weighted \nJaccard Similarity") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = facet, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.4) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x")
gg_jac_w_z50 + ggtitle("Converting 50% of Zambia \n(100% weight on bd, accurate, variable yields)")



# ------------------------------------------------------------------------------------------------------------------------
# just the standard errors as the error bars, not the 95% confidence intervals. 
gg_jac_w_all_just_se <- gg_jac_w_base %+% filter(facet_stats, weight == "all") +
  geom_point(mapping = aes(x = facet, y = mean_jac_w, #color = comparison
                           ), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = facet,
                              ymin = mean_jac_w - se_jac_w,
                              ymax = mean_jac_w + se_jac_w,
                              #color = comparison
                              ),
                position = position_dodge(0.6), width = 0.4) +
  cc_theme3 + cc_theme3_bottom +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x")
gg_jac_w_all_just_se
```

```{r gg_jac_by_comparison}
# just a single value for each decision category:

# all weights
mean_jac_w_by_comparison <- jac_w_melt %>% 
  filter(weight == "all") %>% 
  group_by(comparison, weight) %>% 
  summarise(mean_jac_w = mean(jac_w), 
            se_jac_w = sqrt(var(jac_w) / sum(jac_w)))

gg_mean_jac_w_by_comparison <- ggplot(data = mean_jac_w_by_comparison) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Comparison") + ylab("Mean Weighted \nJaccard Similarity") + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  geom_point(mapping = aes(x = comparison, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = comparison, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.3)



# b pure :
mean_jac_w_b_pure_by_comparison <- jac_w_melt %>% 
  filter(weight == "bp") %>% 
  group_by(comparison, weight) %>% 
  summarise(mean_jac_w = mean(jac_w), 
            se_jac_w = sqrt(var(jac_w) / sum(jac_w)))

gg_mean_jac_w_b_pure_by_comparison <- ggplot(data = mean_jac_w_b_pure_by_comparison) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Comparison") + ylab("Mean Weighted \nJaccard Similarity") + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  geom_point(mapping = aes(x = comparison, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = comparison, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.3)

# b weights only:
mean_jac_w_bd100_by_comparison <- jac_w_melt %>% 
  filter(weight == "b") %>% 
  group_by(comparison, weight) %>% 
  summarise(mean_jac_w = mean(jac_w), 
            se_jac_w = sqrt(var(jac_w) / sum(jac_w)))

gg_mean_jac_w_bd100_by_comparison <- ggplot(data = mean_jac_w_bd100_by_comparison) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Comparison") + ylab("Mean Weighted \nJaccard Similarity") + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  geom_point(mapping = aes(x = comparison, y = mean_jac_w, color = comparison)) +
  geom_errorbar(mapping = aes(x = comparison, color = comparison,
                              ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w), width = 0.3)
```




```{r gg_jac_indiv_comparisons}

# ------------------------------------------------------------------------------------------------------------------------
# Individual comparisons, colored by weight:
gg_jac_w_types <- gg_jac_w_all_weights %+% 
  filter(facet_stats, comparison == "types") + #, weight %in% c("all", "b", "by", "byct")
  facet_grid(labeller = NULL)# + cc_theme3_trim
gg_jac_w_types

# just the taxa comparison, colored by weight:
gg_jac_w_taxa  <- gg_jac_w_all_weights %+% 
  filter(facet_stats, comparison == "taxa") + 
  facet_grid(labeller = NULL) #+ cc_theme3_trim
gg_jac_w_taxa

# just the methods comparison, colored by weight:
gg_jac_w_methods  <- gg_jac_w_all_weights %+% 
  filter(facet_stats, comparison == "methods") + 
  facet_grid(labeller = NULL) + cc_theme3_trim
gg_jac_w_methods

# just the resolution comparison, colored by weight:
gg_jac_w_resolution  <- gg_jac_w_all_weights %+% 
  filter(facet_stats, comparison == "resolution") + 
  facet_grid(labeller = NULL) + cc_theme3_trim
gg_jac_w_resolution

# just the weights comparison, colored by weight:
gg_jac_w_weights  <- gg_jac_w_all_weights %+% 
  filter(facet_stats, comparison == "weights") + 
  facet_grid(labeller = NULL) + cc_theme3_trim
gg_jac_w_weights



# old, types, as a bar chart - I don't like this one
ggplot(filter(facet_stats, comparison == "types"), 
       aes(x = facet, y = mean_jac_w, fill = weight)) +
  theme_classic() + 
  xlab(NULL) + ylab("Mean Weighted Jaccard Index") + 
  geom_bar(position = position_dodge(0.9), stat = "identity") +
  geom_errorbar(mapping = aes(ymin = mean_jac_w - 1.96*se_jac_w, 
                              ymax = mean_jac_w + 1.96*se_jac_w, 
                              color = weight), position = position_dodge(0.9), width = 0.4) +
  cc_theme3 + cc_theme3_trim


```


```{r gg_jac_w_pairs}
# so i'm now trying to produce a plot showing the pairwise similarities, to show the relative similarities between decisions. 

# ------------------------------------------------------------------
# plotting pairwise jaccard weighted values
# ------------------------------------------------------------------
gg_jac_w_pairs <- ggplot(filter(jac_w_melt, weight == "all"), 
                         aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  #ylim(-0.1, 1.2) +
  #coord_cartesian(ylim=c(0, 1.0)) + #cale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  #labs(title = "Pairwise overlap")
  #filter(jac_w_melt, comparison %in% c("types", "taxa")) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_bp_pairs_wt# <- gg_jac_w_bp_pairs
gg_jac_w_bp_pairs
gg_jac_w_bp_pairs <- ggplot(filter(jac_w_melt, weight == "bp"#, !comparison %in% c("resolution", "composites")
                                   ), 
                            aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_b_pairs <- ggplot(filter(jac_w_melt, weight == "b"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_by_pairs <- ggplot(filter(jac_w_melt, weight == "by"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_bc_pairs <- ggplot(filter(jac_w_melt, weight == "bc"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_bt_pairs <- ggplot(filter(jac_w_melt, weight == "bt"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_byct_pairs <- ggplot(filter(jac_w_melt, weight == "byct"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_z50_pairs <- ggplot(filter(jac_w_melt, weight == "z50"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_pairs
gg_jac_w_bp_pairs
gg_jac_w_b_pairs
gg_jac_w_by_pairs
gg_jac_w_bc_pairs
gg_jac_w_bt_pairs
gg_jac_w_byct_pairs
gg_jac_w_z50_pairs


gg_jac_w_pairs # + scale_fill_viridis(discrete = TRUE)

gg_jac_w_pairs %+% filter(jac_w_melt, comparison %in% c("types","taxa")) + cc_theme3_trim
gg_jac_w_pairs %+% filter(jac_w_melt, comparison %in% c("methods","resolution", "weights")) + cc_theme3_trim
gg_jac_w_pairs %+% filter(jac_w_melt, comparison == "types")
gg_jac_w_pairs %+% filter(jac_w_melt, comparison == "types")


jac_w_melt$facet
facet_names

# just pairs of types:
png(paste0(p_plots, "/ms_v5/", "jac_w_pairs_types", ".png"), 
    width = 9, height = 5, 
    units = "in", res = 400)

plot_grid(
  ggplot(filter(jac_w_melt, comparison == "types"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  #ylim(-0.1, 1.2) +
  #coord_cartesian(ylim=c(0, 1.0)) + #cale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  #labs(title = "Pairwise overlap")
  #filter(jac_w_melt, comparison %in% c("types", "taxa")) + 
  facet_grid(cols = vars(weight), scales = "free_x", switch = "x", 
             space = "free_x") + 
  theme(legend.position = "bottom"),
  NULL, ncol = 2, rel_widths = c(1, 0.05))

dev.off()
```

```{r gg_weights_pairs}
jac_w_melt$comparison

gg_jac_w_weights_pairs <- ggplot(filter(jac_w_melt, comparison == "weights"), aes(x = facet, y = jac_w, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Pairwise Weighted \nJaccard Similarity") + 
  #ylim(-0.1, 1.2) +
  #coord_cartesian(ylim=c(0, 1.0)) + #cale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  #labs(title = "Pairwise overlap")
  #filter(jac_w_melt, comparison %in% c("types", "taxa")) + 
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") + theme(legend.position = "bottom")

gg_jac_w_weights_pairs

# this shows that bp and b are very similar, but still only 
jac_w_melt %>% 
  filter(comparison == "weights",
         facet %in% c("bp", "b"),
         pair %in% c("bp", "b"))

```


```{r gg_area_conv}
# ------------------------------------------------------------------
# area converted
# ------------------------------------------------------------------
gg_area_conv <- ggplot(data = facet_stats) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +

  #xlab("Facet") + 
  ylab(expression("Adj. Area Converted (km"^{2}*")")) +
  geom_point(mapping = aes(x = facet, y = area_conv, color = weight), position = position_dodge(0.6)) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") #+ 
  #gg_jac_w_comp_colors

gg_area_conv %+% filter(facet_stats, facet != "z50", weight != "z50")

gg_area_conv0

gg_area_conv %+% filter(facet_stats, weight == "bp") # basically all around 21888


gg_area_conv %+% filter(facet_stats, weight == "bp") + theme(legend.position = "none") + xlab(NULL) + scale_color_manual(values = c("bp" = "black"))

# ------------------------------------------------------------------
# show the jaccard index and the area converted one above each other
# ------------------------------------------------------------------
facet_stats_melt <- facet_stats %>%
  select(-facet_names) %>% 
  melt(id.vars = c("facet", "comparison", "weight"), variable.name = "variable", value.name = "value")

# show the weighted jaccard and the area converted as a facet grid
ggplot(data = filter(facet_stats_melt, weight == "bp", !variable %in% c("count", "se_jac_w", "name", "area_conv_raw"))) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) + 
  #ylim(0, 1.0) +
  #coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  #xlab("Facet") + 
  ylab(expression("Area Converted (km"^{2}*")")) +
  geom_point(mapping = aes(x = facet, y = value), position = position_dodge(0.6)) +
  facet_grid(cols = vars(comparison), rows = vars(variable), scales = "free", switch = "x")
# ------------------------------------------------------------------



# ------------------------------------------------------------------
# new area results, limiting based on the convertible areas
# ------------------------------------------------------------------
new_df

gg_area_conv_new <- ggplot(data = filter(new_df, weight == "b")) + theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) + 
  ylab(expression("Area Converted (km"^{2}*")")) +
  geom_point(mapping = aes(x = facet, y = area_conv, color = convertible_adj), position = position_dodge(0.6)) +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", space = "free_x")

gg_area_conv_new # basically the same pattern, just lower. 

```

```{r gg_composites}
# not really necessary any more


# four panel figure:
# top panel - the overlap of maps
# the seven maps in a row
# then the jaccard and the area converted:


# show the mean jaccard similarity and the area converted for the different composites
names(results_combo)
composites_results <- left_join(
  jaccard_combo %>% 
    filter(bd_input %in% runs[ensembles_list$en5_composites]) %>%
    select(bd_input, mod_spec, mean_jaccard_en5_composites),
  results_combo %>% 
    filter(bd_input %in% runs[ensembles_list$en5_composites]) %>%
    select(bd_input, mod_spec, area_conv))

composites_results <- composites_results %>% select(facet = bd_input, 
                weight = mod_spec, 
                mean_jac_w = mean_jaccard_en5_composites,
                area_conv)

composites_results <- composites_results %>% 
  mutate(weight = base::replace(weight, weight == "eq", "byct")) %>%
  mutate(weight = base::replace(weight, weight == "bd50_y50", "by")) %>%
  mutate(weight = base::replace(weight, weight == "bd100", "b"))

composites_results_all <- composites_results %>% 
  group_by(facet) %>% summarise(mean_jac_w = mean(mean_jac_w), area_conv = mean(area_conv)) %>%
  mutate(weight = "all") %>% select(facet, weight, mean_jac_w, area_conv)

composites_results <- rbind(composites_results, composites_results_all)
composites_results_summary <- composites_results %>% 
  group_by(weight) %>% 
  summarise(mean_jac_w = mean(mean_jac_w))# ,            se_jac_w = sqrt(var(mean_jac_w) / sum(mean_jac_w)))

composites_results_summary <- composites_results_summary %>% mutate(se_jac_w = c(0,0,0,0))
composites_results_summary$se_jac_w[1] <- 
  sqrt(var(composites_results$mean_jac_w[1:7], na.rm = TRUE) / 
         sum(!is.na(composites_results$mean_jac_w[1:7])))

composites_results_summary$se_jac_w[2] <- 
  sqrt(var(composites_results$mean_jac_w[7+1:7], na.rm = TRUE) / 
         sum(!is.na(composites_results$mean_jac_w[7+1:7])))

composites_results_summary$se_jac_w[3] <- 
  sqrt(var(composites_results$mean_jac_w[14+1:7], na.rm = TRUE) / 
         sum(!is.na(composites_results$mean_jac_w[14+1:7])))

composites_results_summary$se_jac_w[4] <- 
  sqrt(var(composites_results$mean_jac_w[21+1:7], na.rm = TRUE) / 
         sum(!is.na(composites_results$mean_jac_w[21+1:7])))

composites_results_summary



composites_results %>% filter(weight == "all")
# don't like that it doesn't have the error bars. 

p_mean_jaccard_en5_composites +
  geom_point(data = filter(composites_results, weight == "all"), mapping = aes(x = facet, y = mean_jac_w), position = position_dodge(0.6))

p_area_converted_en5_composites
row_en5_composites

leg_bot <- get_legend(p_area_converted_en5_composites + 
                        theme(legend.position = "bottom"))

composites_plot_grid <- plot_grid(
  plot_grid(row_en5_composites, labels = c("a")),
  plot_grid(p_mean_jaccard_en5_composites + 
              theme(legend.position = "none"),
          p_area_converted_en5_composites + 
            theme(legend.position = "none",
                  plot.title = element_blank(),
                  plot.subtitle = element_blank(),
                  plot.caption = element_blank()),
          ncol = 2, labels = c("b", "c")),
  leg_bot,
  ncol = 1, rel_heights = c(0.8, 1.2, 0.1))

# save
png(paste0(p_plots, "/ms_v3/", "composites_plot_grid", ".png"), 
    width = 7, height = 5, 
    units = "in", res = 400)
print(composites_plot_grid)
dev.off()


### just the bd results, and the raw maps:

p_mean_jaccard_en5_composites %+% filter(jaccard_combo, mod_spec == "bd100", bd_input %in% runs[ensembles_list[[14]]])


# -----------------------------------------------------------------------------
# composites, comparing the conversion maps and the mean jaccard index. 
png(paste0(p_plots, "/ms_v3/", "composites_bd100_map_jacw_area3", ".png"), 
    width = 10, height = 4, 
    units = "in", res = 400)
print(
  plot_grid(
  # # row 1
  #   gplot(bd_dt_r[[ensembles_list$en5_composites]], maxpixels = 5000000) + 
  #   geom_raster(aes(fill = value)) +
  #   facet_wrap(~ variable, nrow = 1) + 
  #   scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  #   labs(y = "raw biodiversity \nindices", x = NULL) + 
  #   theme(rect = element_blank(), line = element_blank(), 
  #         axis.line = element_blank(), axis.ticks = element_blank(), 
  #         axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  #   coord_equal(),

  # row 2
  gplot(conv_r[[1]][[ensembles_list$en5_composites]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "100% weight on \nbiodiversity", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
          legend.position = "none") + 
    coord_equal(),
  
  # row 3
  plot_grid(
    ggplot(data = filter(mutate(jaccard_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),
           bd_input %in% runs[ensembles_list[[14]]], mod_spec == "bd100")) +
      theme_classic() + xlab(NULL) + ylab("Mean Jaccard Similarity") + 
      theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
      geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en5_composites)) +
      geom_errorbar(mapping = aes(x = bd_input, ymin = mean_jaccard_en5_composites -
                                    1.96*se_jaccard_en5_composites,
                                  ymax = mean_jaccard_en5_composites +
                                    1.96*se_jaccard_en5_composites),
                    width = 0.1) + 
      theme(legend.position = "none"),
    
    # row 4 - area_conv
    ggplot(mutate(adj_comp_area, facet = fct_relevel(facet, runs_w_ref[runs_reorder][1:7]))) +
      theme_classic() + 
      theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
      geom_point(mapping = aes(x = facet, y = adj_area_conv/10000)) +
      ylab(expression("Adj. Area Conv. (10"^{4}*" km"^{2}*")")) + xlab(NULL),
    # p_area_converted_en5_composites %+% 
    # filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),
    #        mod_spec == "bd100", 
    #        bd_input %in% runs[ensembles_list[[14]]]) + 
    # theme(legend.position = "none",
    #       plot.title = element_blank(),
    #       plot.subtitle = element_blank(),
    #       plot.caption = element_blank()) + 
    # scale_color_manual(values = c("bd100" = "black")),
    ncol = 2),
  ncol = 1, rel_heights = c(1, 1))
)

dev.off()


# calculate the adjusted area:
plot(conv_r$bd100$estes)
cellStats(conv_r$bd100$estes, "sum")

plot(conv_r$bd100$estes * convertible_r0)
cellStats(conv_r$bd100$estes * convertible_r0, "sum")
cellStats(conv_r$bd100$laurance * convertible_r0, "sum")
cellStats(conv_r$bd100$damania * convertible_r0, "sum")
cellStats(conv_r$bd100$habitats * convertible_r0, "sum")
cellStats(conv_r$bd100$bird_composite * convertible_r0, "sum")
cellStats(conv_r$bd100$vert_endemism * convertible_r0, "sum")
cellStats(conv_r$bd100$plants * convertible_r0, "sum")
runs[ensembles_list[[14]]]

adj_comp_area <- data.frame(
  facet = runs[ensembles_list[[14]]],
  adj_area_conv = c(
    cellStats(conv_r$bd100$estes * convertible_r0, "sum"), 
    cellStats(conv_r$bd100$laurance * convertible_r0, "sum"), 
    cellStats(conv_r$bd100$damania * convertible_r0, "sum"), 
    cellStats(conv_r$bd100$habitats * convertible_r0, "sum"), 
    cellStats(conv_r$bd100$bird_composite * convertible_r0, "sum"), 
    cellStats(conv_r$bd100$vert_endemism * convertible_r0, "sum"), 
    cellStats(conv_r$bd100$plants * convertible_r0, "sum")
  )
)
plot(data = adj_comp_area, adj_comp_area$adj_area_conv ~ adj_comp_area$facet)

ggplot(mutate(adj_comp_area, facet = fct_relevel(facet, runs_w_ref[runs_reorder][1:7]))) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  geom_point(mapping = aes(x = facet, y = adj_area_conv/10000)) +
  ylab(expression("Adj. Area Conv. (10"^{4}*" km"^{2}*")")) + xlab(NULL)



as_tibble(results_combo)
results_combo %>% 
  filter(bd_input == "estes",
         mod_spec == "bd100") %>%
  .$area_conv


# testing the area:
names(results_combo)
p_area_converted_en5_composites %+% 
  filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),
         mod_spec == "bd100", 
         bd_input %in% runs[ensembles_list[[14]]]) + 
  theme(legend.position = "none",
        plot.title = element_blank(),
        plot.subtitle = element_blank(),
        plot.caption = element_blank()) + 
  scale_color_manual(values = c("bd100" = "black"))
            
            

##
ggplot(data = filter(mutate(jaccard_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),
         bd_input %in% runs[ensembles_list[[14]]], mod_spec == "bd100")) +
  theme_classic() + xlab(NULL) + ylab("Mean Jaccard \nSimilarity") + 
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en5_composites)) +
  geom_errorbar(mapping = aes(x = bd_input, ymin = mean_jaccard_en5_composites -
                                1.96*se_jaccard_en5_composites,
                              ymax = mean_jaccard_en5_composites +
                                1.96*se_jaccard_en5_composites),
                width = 0.1) + 
  theme(legend.position = "none")


##


ggplot(data = filter(
  mutate(jaccard_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),
  bd_input %in% runs[ensembles_list[[14]]], 
  mod_spec == "bd100")
  ) +
  theme_classic() + 
  xlab(NULL) + ylab("Mean Jaccard \nSimilarity") +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en5_composites), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input,
                              ymin = mean_jaccard_en5_composites -
                                1.96*se_jaccard_en5_composites,
                              ymax = mean_jaccard_en5_composites +
                                1.96*se_jaccard_en5_composites),
                width = 0.1, position = position_dodge(0.6)) +
  #ylim(0, 0.25) + 
  theme(legend.position = "none")

```

```{r gg_agreement}
gg_agreement_base <- ggplot(data = facet_stats) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Facet") + ylab("Mean Cell Value")

names(facet_stats)
# ------------------------------------------------------------------------------------------------------------------------
# this shows all four comparisons, with all four weights - but it's too much for one figure. 


# you know, I'm not actually sure what these plots mean:
# the mean cell value maps very nicely onto area converted. 
# the number of cells that at least one model chooses, shows  

# mean cell value
gg_agreement_base +
  geom_point(mapping = aes(x = facet, y = mean, 
                           color = weight#, shape = comparison
                           ), position = position_dodge(0.6)) + cc_theme3 +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") +
  gg_jac_w_comp_colors

# ncells
gg_agreement_base +
  geom_point(mapping = aes(x = facet, y = ncells, 
                           color = weight#, shape = comparison
                           ), position = position_dodge(0.6)) + cc_theme3 +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") +
  ylab("ncells") + 
  gg_jac_w_comp_colors

# mean_non0
gg_agreement_base +
  geom_point(mapping = aes(x = facet, y = mean_non0, 
                           color = weight#, shape = comparison
                           ), position = position_dodge(0.6)) + cc_theme3 +
  facet_grid(cols = vars(comparison), scales = "free_x", switch = "x", 
             space = "free_x") +
  ylab("mean_non0") + 
  gg_jac_w_comp_colors

# just the average weights
gg_agreement_all <-gg_agreement_all_weights %+% filter(facet_stats, weight == "all"#, comparison != "weights"
                                               ) + theme(legend.position = "none")



```


### plot plans
I want to show the following:
- area converted
- mean weighted jaccard index for the individual comparisons, averaged across all the weights
- parwise jaccard indices for all average within each comparison
- just the richness types for the pairwise indices
- the mean weighted jaccard index broken across all three weights, to show the importance of weight

What are my main results?
1. some comparisons matter more than others. gg_jac_w_all
This should be shown just for averaged across all weights, with weight as one of the comparisons at the end. This shows the relative importance of the comparisons - in general, this shows the mean similarity between a facet and others in the same comparison type. 
```{r}
gg_mean_jac_w_by_comparison
gg_jac_w_all_by_comp

gg_jac_w_all # just the averaged weights, for all five comparisons
gg_jac_w_all_weights
```

2. What's most similar within comparisons? gg_jac_w_pairs
This shows the underlying reason why the 95% confidence intervals are so high. 
```{r}
gg_jac_w_pairs # just the pairwise comparisons
gg_jac_w_pairs %+% filter(jac_w_melt, comparison %in% c("types","taxa")) + cc_theme3_trim
gg_jac_w_pairs %+% filter(jac_w_melt, !comparison %in% c("types","taxa")) + cc_theme3_trim
```

3. Weight matters a lot - gg_jac_w_types
Show: 
Should I show the pairwise comparison, and the area converted just for the weights?
```{r}
# plots just showing the comparison, with all and the various weights
gg_jac_w_types # or
gg_jac_w_taxa

# alternatively, pairwise plot:
gg_jac_w_pairs %+% filter(jac_w_melt, comparison == "weights") + cc_theme3_trim + gg_jac_w_comp_colors_fill

gg_area_conv %+% filter(facet_stats, comparison == "weights") + cc_theme3_trim

gg_weight_plot_1 <- plot_grid(
  gg_jac_w_all_weights %+% filter(facet_stats, comparison %in% c("types", "taxa")) + theme(legend.position = "top"),
  #gg_jac_w_taxa + theme(legend.position = "bottom") + coord_cartesian(ylim=c(0, 0.7)),
  gg_jac_w_pairs %+% filter(jac_w_melt, comparison == "weights") + 
    cc_theme3_trim + gg_jac_w_comp_colors_fill + 
    theme(legend.position = "top", 
          #plot.margin = margin(t = 6, r = 6, b = 28, l = 6, unit = "pt")
          ) + 
    ylim(0, 0.6),
  ncol = 2, rel_widths = c(2, 1), align = "h", labels = c("a", "b"))

gg_weight_plot_2 <- plot_grid(
  gg_area_conv %+% filter(facet_stats, weight == "all") + theme(legend.position = "none") + xlab(NULL),
  ncol = 1, labels = c("c"))

# save this one:
plot_grid(gg_weight_plot_1, gg_weight_plot_2, ncol = 1)




gg_area_conv %+% filter(facet_stats, comparison == "weights") + 
            cc_theme3_trim + theme(legend.position = "none") + facet_grid(labeller = NULL)
          



```

4. Area converted - gg_area_conv
There is no real pattern with the area converted, across the different facets. The weight plays a much larger role. Just mention this in the 

```{r}
# main result: that for area converted, the weight plays the largest role. 
gg_area_conv
gg_area_conv %+% filter(facet_stats, weight == "all")
gg_area_conv %+% filter(facet_stats, 
                        #!comparison == "weights",
                        !weight == "all")

gg_area_conv %+% filter(facet_stats, comparison == "weights") + cc_theme3_trim + 
  theme(legend.position = "none") + facet_grid(labeller = NULL)
```

```{r save_plots}

gg_jac_w_all
gg_jac_w_all_weights
gg_jac_w_types
gg_jac_w_taxa
gg_jac_w_pairs
gg_jac_w_bp_pairs

gg_area_conv

gg_jac_w_all_by_comp
gg_jac_w_b_pure + ggtitle("Pure biodiversity (100% weight on bd, with average yields)")
gg_jac_w_bd100_by_comp + ggtitle("100% weight on bd (accurate, variable yields)")
gg_jac_w_z50 + ggtitle("Converting 50% of Zambia (100% weight on bd, accurate, variable yields)")

# ------------------------------------------------------------------
# ------------------------------------------------------------------
# 0. mean jac_w across all decision categories comparison, and for each facet within comparison
# ------------------------------------------------------------------
png(paste0(p_plots, "/ms_v5/", "jac_w_plot_by_comp_all_a_b", ".png"), 
    width = 7.5, height = 3, units = "in", res = 400)
print(
  plot_grid(
    gg_jac_w_all_by_comp + 
      ggtitle("All weights averaged") + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.2, 0.2, 0.2), "cm")),
    gg_mean_jac_w_by_comparison + coord_cartesian(ylim=c(-0.15, 1.05)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.6, 0.35, 0), "cm"), 
            axis.title.y = element_blank()), 
    ncol = 2, rel_widths = c(2.5,1), labels = "auto")
  )
dev.off()

# ----------------------------
# just panel a: all weights averaged
png(paste0(p_plots, "/ms_v5/", "jac_w_plot_by_comp_all", ".png"), 
    width = 6, height = 3, units = "in", res = 400)
print(gg_jac_w_all_by_comp + 
        #ggtitle("All weights averaged") + 
        #coord_cartesian(ylim=c(0, 1.0)) + 
        theme(legend.position = "none", 
              plot.margin = unit(c(0.4, 0.2, 0.2, 0.2), "cm"))
      )
dev.off()


# ----------------------------
# pure biodiversity (bp)
png(paste0(p_plots, "/ms_v5/", "jac_w_plot_by_comp_bp", ".png"), 
    width = 6, height = 3, units = "in", res = 400)
print(
    gg_jac_w_b_pure + 
      #ggtitle("Pure biodiversity (100% weight on bd, with average yields)") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

gg_jac_w_b_pure + ggtitle("Pure biodiversity (100% weight on bd, with average yields)")




# ----------------------------
# just for 100% biodiversity weights (b)
gg_jac_w_bd100_by_comp + ggtitle("100% weight on bd (accurate, variable yields)")

png(paste0(p_plots, "/ms_v5/", "jac_w_plot_by_comp_b", ".png"), 
    width = 6, height = 3, units = "in", res = 400)
print(
    gg_jac_w_bd100_by_comp + 
      #ggtitle("100% Weight on Biodiversity (original, with accurate yields)") + 
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

# ----------------------------
# converting 50% of Zambia (z50)

gg_jac_w_z50 + ggtitle("Converting 50% of Zambia (100% weight on bd, accurate, variable yields)")

png(paste0(p_plots, "/ms_v5/", "jac_w_plot_by_comp_z50", ".png"), 
    width = 6, height = 3, units = "in", res = 400)
print(
    gg_jac_w_z50 + 
      #ggtitle("Converting 50% of Zambia \n(100% weight on bd, accurate, variable yields)") +
      #coord_cartesian(ylim=c(0, 1.0)) + 
      theme(legend.position = "none", 
            plot.margin = unit(c(0.4, 0.5, 0.2, 0.2), "cm"))
  )
dev.off()

# see test figures in the test section directly


# ------------------------------------------------------------------
# ------------------------------------------------------------------
# 1. all, mean weighted jaccard
# ------------------------------------------------------------------
png(paste0(p_plots, "/ms_v5/", "jac_w_plot_all", ".png"), 
    width = 7, height = 3, 
    units = "in", res = 400)
print(gg_jac_w_all)
dev.off()

# ----------------------------
# 2. pairs, for the SI
png(paste0(p_plots, "/ms_v5/", "jac_w_pairs_all", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_jac_w_pairs + theme(legend.position = "bottom"))
dev.off()


# ----------------------------
# 2.5 pairs just bd, for the SI
png(paste0(p_plots, "/ms_v5/", "jac_w_b_pairs", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_jac_w_bd100_pairs + theme(legend.position = "bottom"))
dev.off()

png(paste0(p_plots, "/ms_v5/", "jac_w_bp_pairs", ".png"), 
    width = 8, height = 5, 
    units = "in", res = 400)
print(gg_jac_w_bp_pairs + theme(legend.position = "bottom"))
dev.off()

# ------------------------------------------------------------------
# ------------------------------------------------------------------
# 3. weights plot
# ------------------------------------------------------------------
png(paste0(p_plots, "/ms_v5/", "weights_fig", ".png"), 
    width = 8, height = 6, 
    units = "in", res = 400)
print(
  plot_grid(gg_weight_plot_1, gg_weight_plot_2, ncol = 1)
  )
dev.off()


# ------------------------------------------------------------------
# ------------------------------------------------------------------
# 4. mean weighted jaccard, across all weights
# ------------------------------------------------------------------
gg_jac_w_weights_legend_b <- get_legend(gg_jac_w_weights + theme(legend.position = "bottom", legend.margin = margin(b = 3)))

png(paste0(p_plots, "/ms_v5/", "jac_w_plot_all_w_weights", ".png"), 
    width = 7, height = 4, 
    units = "in", res = 400)
print(
  gg_jac_w_all_weights + theme(legend.position = "bottom") + coord_cartesian(ylim=c(0, 1.05))
  )
dev.off()


# ------------------------------------------------------------------
# ------------------------------------------------------------------
# 5. area converted, with weights:
# ------------------------------------------------------------------
# with weights
png(paste0(p_plots, "/ms_v5/", "area_conv_w_weights", ".png"), 
    width = 7, height = 3, 
    units = "in", res = 400)
print(
  gg_area_conv %+% filter(facet_stats) + theme(legend.position = "right") + xlab(NULL)  
)
dev.off()

# ----------------------------
# area conv, all
png(paste0(p_plots, "/ms_v5/", "area_conv_all", ".png"), 
    width = 7, height = 3, 
    units = "in", res = 400)
print(gg_area_conv %+% filter(facet_stats, weight == "all") + theme(legend.position = "none") + xlab(NULL))
dev.off()

# ----------------------------
# area conv, bd100
png(paste0(p_plots, "/ms_v5/", "area_conv_bd100", ".png"), 
    width = 7, height = 3, 
    units = "in", res = 400)
print(gg_area_conv %+% filter(facet_stats, weight == "b") + theme(legend.position = "none") + xlab(NULL) + scale_color_manual(values = c("b" = "black")))
dev.off()


# ----------------------------
# also included the composites comparison, see gg_composites
  
# --------
gg_jac_w_pairs_leg_b <- get_legend(gg_jac_w_pairs + theme(legend.position = "bottom", legend.margin = margin(b = 3)))


gg_jac_w_all_legend_b <- get_legend(gg_jac_w_all + theme(legend.position = "bottom", legend.margin = margin(b = 3)))

    
```

5. actual maps 


```{r jac_w_tester}
# https://en.wikipedia.org/wiki/Jaccard_index#Weighted_Jaccard_similarity_and_distance
# the weighted jaccard is:
# jw <- sum(min(x, y)) / sum(max(x, y))

# test dt
dt <- data.table(
  a = c(0.5, 0.75, .25, .5, .25,
        0, 1, 0.25, 0.75, 0.75),
  b = c(0, 1, .5, .25, .75,
        0, 0, 0, 0.25, 0.75))

dtx <- data.table(
  a = runif(10000, min=0,max=1),
  b = runif(10000, min=0,max=1),
  c = runif(10000, min=0,max=1),
  d = runif(10000, min=0,max=1)
)


class(dt)

dt
dt[, min := pmin(a, b)]
dt[, max := pmax(a, b)]
dt[, sum(min)] / dt[, sum(max)] # this is the weighted Jaccard Similarity Index. 
dt[, sum(pmin(a, b))/sum(pmax(a, b))] # this works too, all in one step, without the need for additional columns. 

txt <- c("min")

# see here: https://stackoverflow.com/questions/14937165/using-dynamic-column-names-in-data-table/14937323#14937323
dt[, lapply(.SD, sum), .SDcols = 3] # .SDcols accepts both indices or column names as text
dt[, lapply(.SD, sum), .SDcols = "min"] # .SDcols accepts both indices or column names as text
# the above works, but I don't know how to have the function work on x and y (below)

dt[, lapply(.SD, function(x,y) {sum(pmin(x, y))/sum(pmax(x, y))}), .SDcols = c("min", "max")] # .SDcols accepts both indices or column names as text
# ^ the above does not work.


# maybe subset the dt first, to just the two rows I'm interested in...
dt[, 1:2][, sum(pmin(a, b))/sum(pmax(a, b))] # 0.41667

dt[, c("a", "b") # select the two columns you're interested in...
   ][, sum(pmin(dt[,1],dt[,2]))/sum(pmax(dt[,1],dt[,2]))] # then calculate the weighted Jaccard. Nope!


# how do I make these an index?
# assign names to the column before I calculate it?
dtx[, sum(pmin(a, b))/sum(pmax(a, b))]
dtx[, sum(pmin(a, c))/sum(pmax(a, c))]
dtx[, sum(pmin(c,d))/sum(pmax(c,d))]
dtx[, sum(pmin(b,d))/sum(pmax(b,d))]


# testing on a larger data.table
dtx

pair1 <- c("a", "c")
pair2 <- c(1, 3)

dtx[, ..pair # select the two columns you're interested in... (this works with column names in quotes, or as column indices)
   ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))] # then calculate the weighted Jaccard

```

```{r}
# based on Laszlo Gadar's code from here: https://rpubs.com/lgadar/weighted-jaccard

#weighted jaccard similarity matrix setup
dt[, .(x, y, mam, bird, amp, rep)]
sim.jac <- dt[, . (x, y)]
sim.jac[, ]



A <- matrix(c(2,5,2,1,0,0,0,0,1,0,0,0,0,1,3,5,6,0,0,1,0,0,0,2,0,0,1,2,7,2,4,6,2,5,1,0,0,1,0,0,0,1,0,0,3,5,4,0,0,1,0,0,1,0,0,2,0,3,5,7,3,1,4,0,1,0,0,0,0,2,0,0,0,1,3,4,6,0,0,1), byrow=T, nrow=8, ncol=10)
colnames(A) <- letters[1:10]
rownames(A) <- LETTERS[1:8]
print(A)

sim.jac <- matrix(0, nrow=nrow(A), ncol=nrow(A))
rownames(sim.jac) <- rownames(A)
colnames(sim.jac) <- rownames(A)

#weighted jaccard
pairs <- t(combn(1:nrow(A), 2))
A[pairs[1,1], 
  1] # this is the column to iterate through with sapply
A[pairs[1,2], 1]

A

for (i in 1:nrow(pairs)){
  num <- sum(sapply(1:ncol(A), function(x)(min(A[pairs[i,1],x], A[pairs[i,2],x]))))
  den <- sum(sapply(1:ncol(A), function(x)(max(A[pairs[i,1],x], A[pairs[i,2],x]))))
  sim.jac[pairs[i,1],pairs[i,2]] <- num/den
  sim.jac[pairs[i,2],pairs[i,1]] <- num/den  
}
sim.jac[which(is.na(sim.jac))] <- 0
diag(sim.jac) <- 1
```

## raster plots:
main figure
1. maps of averages for each facet

2. averages for each comparison
Same format as the original plot, but the 
bd_input -- all -- b -- by -- byct

 ```{r save_raw_bd_facet_gplots}
# ----------------------------------------
# put the main figure together, for bd100
# ----------------------------------------
names(bd_dt_m_r)
png(paste0(p_plots, "/ms_v5/","raw_bd_facet_gplots_w_threat.png"),    
    width = 8, height = 12,
    units = "in", res = 300)
plot_grid(
  gplot(bd_dt_m_r[[1:4]], maxpixels = 5000000) + # or facet_r[[comparison_names$types]] for just the four ensemble means
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Types of Richness", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal(),
  
  gplot(bd_dt_m_r[[5:8]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Taxonomic Groups", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal(),
  
  gplot(bd_dt_m_r[[9:12]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Methods", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal(),
  
  gplot(bd_dt_m_r[[13:15]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Resolution", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal(),
    
  gplot(bd_dt_m_r[[16:19]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Composites", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal(),
    
  gplot(bd_dt_m_r[[20:22]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Composites", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal(),
  ncol = 1, labels = "auto")
dev.off()
```

```{r save_facet_rasters_png}


# -------------------------------------------------------------------------------
# save plots
png(paste0(p_plots, "/ms_v5/","bd_input_ensemble_av.png"),    
    width = 11, height = 10,
    units = "in", res = 300)
plot(bd_dt_m_r[[c(1:22)]], axes = FALSE, legend = TRUE, box = TRUE, maxnl = 30)
dev.off()

names(bd_dt_m_r)
plot(bd_dt_m_r[[facet_names_distill[1:4]]])


png(paste0(p_plots, "/ms_v5/","facet_r_ensemble_av.png"),    
    width = 11, height = 10,
    units = "in", res = 300)
plot(facet_r, axes = FALSE, maxnl = 30)
dev.off()

png(paste0(p_plots, "/ms_v5/","facet_bp_ensemble_av.png"),    
    width = 11, height = 10,
    units = "in", res = 300)
plot(facet_r_bp, axes = FALSE, box = FALSE, maxpixels = 5000, maxnl = 30, nc = 4, nr = 6)
dev.off()

subset(facet_r_bp, c(1, 2, 4, 3))
names(facet_r_bp)[3] <- " "


png(paste0(p_plots, "/ms_v5/","facet_b_ensemble_av.png"),    
    width = 11, height = 10,
    units = "in", res = 300)
plot(facet_r_b, axes = FALSE, maxnl = 30)
dev.off()


# 
gplot(facet_r_b[[1:4]], maxpixels = 5000000) + # or facet_r[[comparison_names$types]] for just the four ensemble means
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Types of Richness", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

```

```{r}
facet_r_bp %>% names


#save_basic_conv_plots_all <- function(runs, i, tag, fig_width = 12, fig_height = 13) {
  png(paste0(p_plots, "/ms_v5/", "basic_conv_maps_", names(conv_r)[i], tag, ".png"),    
      width = fig_width, height = fig_height, units = "in", res = 300)
  
  par(mfrow=c(6,7), mar=c(1,1,2,1), oma = c(1, 1, 1, 1))
  for (j in paste0(runs, paste0("_", names(conv_r)[i]))) {
    plot(facet_r_bp[[types_names]], axes = FALSE, box = FALSE)

    plot(conv_r[[i]][[j]], 
         main = names(conv_r[[i]][[j]]),
         axes = FALSE, legend = FALSE, box = FALSE)
    
    plot(pas, col = col_pas_all, border = "gray", add=TRUE)
    #legend("bottomright", legend= c("GMA", "Nat'l Park"), fill=col_pas, cex = 1.1, bty = "n")
    plot(msk_shp, add = TRUE)
    
  }
  
  dev.off()
#  }

save_basic_conv_plots_all(i = 1, runs = runs_1, tag = "_1")
```


```{r *ms_figure_raster_bp}
facet_r_bp %>% names
names(facet_r_bp) <- gsub("_bp", "", names(facet_r_bp))
facet_r_bp <- dropLayer(facet_r_bp, 3)

facet_r_z50 %>% names
names(facet_r_z50) <- gsub("_z50", "", names(facet_r_z50))
facet_r_z50 <- dropLayer(facet_r_z50, 3)

facet_r_bp
eval(parse(text = paste0("facet_r_","bp")))[[1:3]]
# ----------------------------------------
# put the main figure together, for bp
# ----------------------------------------
# weight <- "bp"
# weight <- "z50"
weight <- "all"

drop_threat <- TRUE
brick <- eval(parse(text = paste0("facet_r_", weight)))
names(brick) <- gsub(paste0("_", weight), "", names(brick))
if (drop_threat) {brick <- dropLayer(brick, which(names(brick) == "threat"))}

pixels <- 5000000

  
p1 <- gplot(brick[[c("mam", "bird", "amp", "rep")]], maxpixels = pixels) + 
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white", limits = c(0, 1)) + 
      labs(y = "Taxonomic Groups", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), 
            axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.position = "none") + 
      coord_equal()

p2 <- gplot(brick[[c("all", "endemism", "small")]], maxpixels = pixels) + # or facet_r[[comparison_names$types]] for just the four ensemble means
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white", limits = c(0, 1)) + 
      labs(y = "Richness Types", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.position = "none") + 
      coord_equal()
    
p3 <- gplot(brick[[c("average", "geometric", "max", "multi")]], maxpixels = pixels) + 
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white", limits = c(0, 1)) + 
      labs(y = "Methods", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.position = "none") + 
      coord_equal()
    
p4 <- gplot(brick[[c("res1", "res10", "res110")]], maxpixels = pixels) + 
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white", limits = c(0, 1)
                           ) + 
      labs(y = "Resolution", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(), legend.position = "none"
            ) + 
      coord_equal()
    
p5 <- gplot(brick[[c("vert_endemism", #"plants", 
                     "estes", "laurance", #"habitats", "bird_composite", 
                     "damania")]], 
            maxpixels = pixels) + 
      geom_raster(aes(fill = value)) +
      facet_wrap(~ variable, nrow = 1) + 
      scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white", limits = c(0, 1)) + 
      labs(y = "Indices", x = NULL) + 
      theme(rect = element_blank(), line = element_blank(), 
            axis.line = element_blank(), axis.ticks = element_blank(), 
            axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
            legend.title = element_blank()) + 
      coord_equal()
    
    
# p6 <- gplot(brick[[c("plants", "habitats", "bird_composite")]], maxpixels = pixels) + 
#       geom_raster(aes(fill = value)) +
#       facet_wrap(~ variable, nrow = 1) + 
#       scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
#       labs(y = "Composites", x = NULL) + 
#       theme(rect = element_blank(), line = element_blank(), 
#             axis.line = element_blank(), axis.ticks = element_blank(), 
#             axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
#       coord_equal()

# start png call here. 
png(paste0(p_plots, "/ms_v5/","ms_fig_facet_r_", weight, "_wide.png"),    
    width = 8, height = 5,
    units = "in", res = 300)

plot_grid(
  plot_grid(p5, nrow = 1, labels = c("a")),
  plot_grid(p1, NULL, p2, nrow = 1, labels = c("b", "", "c"), rel_widths = c(4, 0.1, 3.1)), 
  plot_grid(p3, NULL, p4, nrow = 1, labels = c("d", "", "e"), rel_widths = c(4, 0.1, 3.1)),
  ncol = 1, rel_heights = c(1.2, 1, 1))

dev.off()

# plot_grid(
#           ncol = 1, #align = "v", axis = "l", 
#           labels = "auto"
#           )

# -----------------------------------------------------------
## go to here.
# -----------------------------------------------------------


# doing it manually
# unused

png(paste0(p_plots, "/ms_v5/","ms_fig_facet_r_bp_manual.png"),    
    width = 8, height = 12,
    units = "in", res = 300)
par(mfrow = c(6, 4))
# types
for (i in c(1, 2, 4)) {
  plot(facet_r_bp[[i]], axes = FALSE, box = FALSE, legend = FALSE, zlim = c(0, 1), 
       main = names(facet_r_bp[[i]]))
}
plot(facet_r_bp[[3]], axes = FALSE, box = FALSE)

# taxa
for (i in 5:8) {
  plot(facet_r_bp[[i]], axes = FALSE, box = FALSE, legend = FALSE, zlim = c(0, 1),
       main = names(facet_r_bp[[i]]))
}

# methods
for (i in 9:12) {
  plot(facet_r_bp[[i]], axes = FALSE, box = FALSE, legend = FALSE, zlim = c(0, 1),
       main = names(facet_r_bp[[i]]))
}

# resolution
for (i in 13:15) {
  plot(facet_r_bp[[i]], axes = FALSE, box = FALSE, legend = FALSE, zlim = c(0, 1),
       main = names(facet_r_bp[[i]]))
}
plot(facet_r_bp[[3]], axes = FALSE, box = FALSE)

# composites
for (i in 16:19) {
  plot(facet_r_bp[[i]], axes = FALSE, box = FALSE, legend = FALSE, zlim = c(0, 1),
       main = names(facet_r_bp[[i]]))
}

for (i in 20:22) {
  plot(facet_r_bp[[i]], axes = FALSE, box = FALSE, legend = FALSE, zlim = c(0, 1),
       main = names(facet_r_bp[[i]]))
}
plot(facet_r_bp[[3]], axes = FALSE, box = FALSE)

dev.off()
```

```{r *print basic conv maps}
# --------------------------------------------------------------------------------------------------------
# this function plots all of the conversion maps for each bd input run, for the different model specifications
# in the current iteration, it amounts to a 7 x 8 grid of 56 plots, including the reference plots.
# --------------------------------------------------------------------------------------------------------
conv_r[[1]][[1]]
names(conv_r)
conv_b_pure_dt[, c("x", "y", runs_1), with = FALSE]


save_basic_conv_plots_all <- function(runs, i, tag, fig_width = 12, fig_height = 13) {
  png(paste0(p_plots, "/ms_v5/", "basic_conv_maps_", names(conv_r)[i], tag, ".png"),    
      width = fig_width, height = fig_height, units = "in", res = 300)
  
  par(mfrow=c(6,7), mar=c(1,1,2,1), oma = c(1, 1, 1, 1))
  for (j in paste0(runs, paste0("_", names(conv_r)[i]))) {
    plot(conv_r[[i]][[j]], 
         main = names(conv_r[[i]][[j]]),
         axes = FALSE, legend = FALSE, box = FALSE)
    
    plot(pas, col = col_pas_all, border = "gray", add=TRUE)
    #legend("bottomright", legend= c("GMA", "Nat'l Park"), fill=col_pas, cex = 1.1, bty = "n")
    plot(msk_shp, add = TRUE)
    
    }
  dev.off()
  }

save_basic_conv_plots_all(i = 1, runs = runs_1, tag = "_1")
save_basic_conv_plots_all(i = 1, runs = runs_10, tag = "_10")
save_basic_conv_plots_all(i = 1, runs = runs_110, tag = "_110")

names(conv_r)
for (i in 1:7) { # seq_along(conv_r)
  save_basic_conv_plots_all(i = i, runs = runs_1, tag = "_1")
  save_basic_conv_plots_all(i = i, runs = runs_10, tag = "_10")
  save_basic_conv_plots_all(i = i, runs = runs_110, tag = "_110")
  #save_basic_conv_plots_all(i)
  }
# 
# save_bd_input_plots <- function(runs = runs_1, tag = "runs_1", fig_width = 12, fig_height = 13) {
#   png(paste0(p_plots, "/ms_v5/", "bd_input_maps_", tag, ".png"),    
#       width = fig_width, height = fig_height, units = "in", res = 300)
#   
#   par(mfrow=c(6,7), mar=c(1,1,2,1), oma = c(1, 1, 1, 1))
#   for (j in runs) {
#     plot(bd_inputs_brick[[j]], 
#          main = names(bd_inputs_brick[[j]]),
#          axes = FALSE, legend = FALSE, box = FALSE)
#     
#     #plot(pas, col = col_pas_all, border = "gray", add=TRUE)
#     #legend("bottomright", legend= c("GMA", "Nat'l Park"), fill=col_pas, cex = 1.1, bty = "n")
#     plot(msk_shp, add = TRUE)
#     
#     }
#   dev.off()
#   }



# --------------------------------------------------------------------------------------------------------
# just the conv maps for the main comparisons:
# --------------------------------------------------------------------------------------------------------
# specifically, I just want:
ensembles_list[indices$main]
runs[ensembles_list[indices$main][[1]]] # 4
runs[ensembles_list[indices$main][[2]]] # 4
runs[ensembles_list[indices$main][[3]]] # 4
runs[ensembles_list[indices$main][[4]]] # 2 additional
runs[ensembles_list[indices$main][[5]]] # 6 additional

# so, it's 20 total. try a 4 column by 5 row figure
conv_r[[1]][[]]
ensembles_list[indices$main]
print_list <- c(
  ensembles_list[indices$main][[1]],
  ensembles_list[indices$main][[2]],
  ensembles_list[indices$main][[3]],
  ensembles_list[indices$main][[4]][-1], # without the first entry, "3"
  ensembles_list[indices$main][[5]][-6]) # without the sixth entry, "2"

length(print_list)
conv_r[[1]][[print_list[5]]]

save_basic_conv_plots_main <- function(i, fig_width = 8, fig_height = 10) {
  png(paste0(p_plots, "/ms_fig_raster/", "basic_conv_maps_", names(conv_r)[i], "_main.png"),    
      width = fig_width, height = fig_height, units = "in", res = 300)
  
  par(mfrow=c(5,4), mar=c(1,1,2,1), oma = c(1, 1, 1, 1))
  for (j in print_list) {
    plot(conv_r[[i]][[j]], 
         main = names(conv_r[[i]][[j]]),
         axes = FALSE, legend = FALSE, box = FALSE)
    }
  dev.off()
  }

for (i in seq_along(conv_r)) {save_basic_conv_plots_main(i)}


plot(conv_10p_bd_dt_ensembles_r, nc = 6, nr = 6)



par(mfrow=c(6,6), mar=c(0, 0, 1, 0), oma = c(1, 1, 1, 1))
for (i in 1:length(runs_w_ref)) plot(conv_10p_bd_dt_ensembles_r[[i]], main = names(conv_10p_bd_dt_ensembles_r[[i]]), axes = FALSE, legend = FALSE, box = FALSE)
```

```{r **print_conv_r_new}
names(conv_r)
which(names(conv_r) == "bp")
which(c("b", "byct") == "bp")

conv_r %>% names
conv_r$bd$all %T>% plot()
runs_1
indices <- 1:4

save_conv_plots_new <- function(i, runs = runs_1, indices = 1:4, tag = "",
                                fig_width = 7, fig_height = 10, pixels = 100000) {
  row_density <- densityplot(conv_r$bd[[runs[indices]]], layout = c(4, 1))
  # row_1 <- histogram(bd_dt_r[[ensembles_list[[2]]]], layout = c(4, 1))

  row_bd_raw <- gplot(conv_r$bd[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Raw BD Inputs", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_bp <- gplot(conv_r$bp[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Pure Biodiversity \n100% weight, mean yields", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_b <- gplot(conv_r$b[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "100% weight on bd \nvariable yields", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_by <- gplot(conv_r$by[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "50% weight on bd,\n50% yield", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_bc <- gplot(conv_r$bc[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "50% weight on bd,\n50% carbon", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_bt <- gplot(conv_r$bt[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "50% weight on bd,\n50% travel cost", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_byct <- gplot(conv_r$byct[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "equal weights", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_z50 <- gplot(conv_r$z50[[runs[indices]]], maxpixels = pixels) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Pure biodiversity \n convert 50%", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  
  png(paste0(p_plots, "/ms_v5/", tag, 
             "_conv_maps.png"),    
      width = fig_width, height = fig_height, 
      units = "in", res = 300)
  # pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
  #            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
  print(
    plot_grid(row_density, row_bd_raw, row_bp, row_b, row_z50, NULL,
              ncol = 1, rel_heights = c(1.5, 1, 1, 1, 1, 0.1))
    )
  dev.off()
  
  png(paste0(p_plots, "/ms_v5/", tag, 
             "_conv_maps2.png"),    
      width = fig_width, height = fig_height, 
      units = "in", res = 300)
  # pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
  #            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
  print(
    plot_grid(row_b, row_by, row_bc, row_bt, row_byct, NULL,
              ncol = 1, rel_heights = c(1, 1, 1, 1, 1, 0.1))
    )
  dev.off()
}

names(ensembles_list)[1]
tic()
# types
save_conv_plots_new(runs = runs_1, indices = 1:4, tag = "types_1")
save_conv_plots_new(runs = runs_10, indices = 1:4, tag = "types_10")
save_conv_plots_new(runs = runs_110, indices = 1:4, tag = "types_110")

# taxa_all
save_conv_plots_new(runs = runs_1, indices = 5:8, tag = "taxa_all_1")
save_conv_plots_new(runs = runs_10, indices = 5:8, tag = "taxa_all_10")
save_conv_plots_new(runs = runs_110, indices = 5:8, tag = "taxa_all_110")

# taxa_endemism
save_conv_plots_new(runs = runs_1, indices = 10:13, tag = "taxa_endemism_1")
save_conv_plots_new(runs = runs_10, indices = 10:13, tag = "taxa_endemism_10")
save_conv_plots_new(runs = runs_110, indices = 10:13, tag = "taxa_endemism_110")

# taxa_threat
save_conv_plots_new(runs = runs_1, indices = 14:17, tag = "taxa_threat_1")
save_conv_plots_new(runs = runs_10, indices = 14:17, tag = "taxa_threat_10")
save_conv_plots_new(runs = runs_110, indices = 14:17, tag = "taxa_threat_110")

# taxa_small
save_conv_plots_new(runs = runs_1, indices = 18:21, tag = "taxa_small_1")
save_conv_plots_new(runs = runs_10, indices = 18:21, tag = "taxa_small_10")
save_conv_plots_new(runs = runs_110, indices = 18:21, tag = "taxa_small_110")

# methods_mb
save_conv_plots_new(runs = runs_1, indices = c(22, 25, 28, 31), tag = "methods_mb_1")
save_conv_plots_new(runs = runs_10, indices = c(22, 25, 28, 31), tag = "methods_mb_10")
save_conv_plots_new(runs = runs_110, indices = c(22, 25, 28, 31), tag = "methods_mb_110")

# methods_vp
save_conv_plots_new(runs = runs_1, indices = 1 + c(22, 25, 28, 31), tag = "methods_vp_1")
save_conv_plots_new(runs = runs_10, indices = 1 + c(22, 25, 28, 31), tag = "methods_vp_10")
save_conv_plots_new(runs = runs_110, indices = 1+ c(22, 25, 28, 31), tag = "methods_vp_110")

# methods_ae
save_conv_plots_new(runs = runs_1, indices = 2 + c(22, 25, 28, 31), tag = "methods_ae_1")
save_conv_plots_new(runs = runs_10, indices = 2+ c(22, 25, 28, 31), tag = "methods_ae_10")
save_conv_plots_new(runs = runs_110, indices = 2 + c(22, 25, 28, 31), tag = "methods_ae_110")

# methods_ae
save_conv_plots_new(runs = runs_1, indices = 2 + c(22, 25, 28, 31), tag = "methods_ae_1")
save_conv_plots_new(runs = runs_10, indices = 2+ c(22, 25, 28, 31), tag = "methods_ae_10")
save_conv_plots_new(runs = runs_110, indices = 2 + c(22, 25, 28, 31), tag = "methods_ae_110")


# composites
save_conv_plots_new(runs = runs_1, indices = c(2, 9, 34:38), tag = "composites_1", 
                    fig_width = 10, fig_height = 9)
save_conv_plots_new(runs = runs_10, indices = c(2, 9, 34:38), tag = "composites_10", 
                    fig_width = 10, fig_height = 9)
save_conv_plots_new(runs = runs_110, indices = c(2, 9, 34:38), tag = "composites_110",
                    fig_width = 10, fig_height = 9)



toc()

tic()
save_conv_plots_new(i = 1, fig_width = 7, fig_height = 9, pixels = 100000) # tester for 1, think I did 7 and 9 earlier. 
toc()

names(ensembles_list)[c(1, 3:9)]
for (i in c(2, 4:9)) save_conv_plots_new(i, fig_width = 7, fig_height = 9) # four comparisons in the ensemble
save_conv_plots_new(3, fig_width = 8, fig_height = 9) # 5 inputs
save_conv_plots_new(14, fig_width = 10, fig_height = 8) # 7 inputs

for (i in c(10:13)) save_conv_plots_new(i, fig_width = 7, fig_height = 11) # 3 inputs # these are fine
for (i in c(15:18)) save_conv_plots_new(i, fig_width = 7, fig_height = 11) # 2 inputs # these are also fine

```

```{r dt_comp}
# ---------------------------------------------------------------------------------------------------------
# just averaged comparisons ---------------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------------------
dt_comp <- dt_m[, 1:2]
names(dt_m)
grep("^all", names(dt_m), value = TRUE)
rowMeans(dt_m[, comparison_names$types, with = FALSE])
names(comparison_names)

dt_comp[, c(names(comparison_names)) := .(
  rowMeans(dt_m[, comparison_names[[1]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[2]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[3]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[4]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[5]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[6]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[7]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[8]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[9]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[10]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[11]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[12]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[13]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[14]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[15]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[16]], with = FALSE]),
  rowMeans(dt_m[, comparison_names[[17]], with = FALSE])
)]

length(comparison_names)

# make raster
dt_comp_r <- dt_to_raster(dt_comp, CRSobj)
plot(dt_comp_r)
names(dt_comp_r)


# add biodiversity layers, after reversing them to show high values as those that have less biodiversity (to match the conversion maps)
dt_comp_r$types_bd <- (1 - bd_dt_m_r$types_bd)
dt_comp_r$taxa_bd <- (1 - bd_dt_m_r$taxa_bd)
dt_comp_r$methods_bd <- (1 - bd_dt_m_r$methods_bd)
dt_comp_r$resolution_bd <- (1 - bd_dt_m_r$resolution_bd)
dt_comp_r$weight_bd <- (1 - bd_dt_m_r$weights_bd)

# add in the weights specific averages
dt_comp_r$weights_b <- facet_r$b
dt_comp_r$weights_by <- facet_r$by
dt_comp_r$weights_byct <- facet_r$byct
```

```{r comp_gplot_weights}
comp_brick_types <- dt_comp_r[[c("types_bd", "types", "types_b", "types_by", "types_byct")]]
names(comp_brick_types) <- c("bd_inputs", "mean", "b", "by", "byct")
comp_gplot_types <- gplot(comp_brick_types,
  #dt_comp_r[[c("types_bd", "types", "types_b", "types_by", "types_byct")]], 
                          maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Types of Richness", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

comp_brick_taxa <- dt_comp_r[[c("taxa_bd", "taxa", "taxa_b", "taxa_by", "taxa_byct")]]
names(comp_brick_taxa) <- c("bd_inputs", "mean", "b", "by", "byct")
comp_gplot_taxa <- gplot(comp_brick_taxa, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Taxonomic Groups", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

comp_brick_methods <- dt_comp_r[[c("methods_bd", "methods", "methods_b", "methods_by", "methods_byct")]]
names(comp_brick_methods) <- c("bd_inputs", "mean", "b", "by", "byct")
comp_gplot_methods <- gplot(comp_brick_methods, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Methods", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

comp_brick_resolution <- dt_comp_r[[c("resolution_bd", "resolution", "resolution_b", "resolution_by", "resolution_byct")]]
names(comp_brick_resolution) <- c("bd_inputs", "mean", "b", "by", "byct")
comp_gplot_resolution <- gplot(comp_brick_resolution, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Resolution", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

comp_brick_weights <- dt_comp_r[[c("resolution_bd", "weights", "weights_b", "weights_by", "weights_byct")]]
names(comp_brick_weights) <- c("bd_inputs", "mean", "b", "by", "byct")
comp_gplot_weights <- gplot(comp_brick_weights, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Weights", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()



# ----------------------------------------
# put the main figure together
# ----------------------------------------


png(paste0(p_plots, "/ms_v3/","comp_gplots_weights.png"),    
    width = 10, height = 10,
    units = "in", res = 300)
plot_grid(comp_gplot_types,
          comp_gplot_taxa,
          comp_gplot_methods,
          comp_gplot_resolution,
          comp_gplot_weights,
          ncol = 1, labels = "auto")
dev.off()


# create rasters

# dt_r <- dt_to_raster(dt[, grep("all|endemism|threat", names(dt), invert = TRUE), with = FALSE], CRSobj)
# plot(dt_r)

```

```{r facet_gplot_all}
brick_types <- facet_r[[comparison_names$types]]
brick_types$comparison_mean <- dt_comp_r$types
brick_taxa <- facet_r[[comparison_names$taxa]]
brick_taxa$comparison_mean <- dt_comp_r$taxa
brick_methods <- facet_r[[comparison_names$methods]]
brick_methods$comparison_mean <- dt_comp_r$methods
brick_resolution <- facet_r[[comparison_names$resolution]]
brick_resolution$comparison_mean <- dt_comp_r$resolution
brick_weights <- facet_r[[comparison_names$weights]]
brick_weights$comparison_mean <- dt_comp_r$weights

# optional: if you want to normalize the bricks to be plotted so that areas of agreement show up 
# brick_types <- log(brick_types)
# brick_taxa <- normalize(brick_taxa)
# brick_methods <- normalize(brick_methods)
# brick_resolution <- normalize(brick_resolution)
# brick_weights <- normalize(brick_weights)



gplot_types <- gplot(brick_types, maxpixels = 5000000) + # or facet_r[[comparison_names$types]] for just the four ensemble means
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Types of Richness", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

gplot_taxa <- gplot(brick_taxa, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Taxonomic Groups", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

gplot_methods <- gplot(brick_methods, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Methods", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

gplot_resolution <- gplot(brick_resolution, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Resolution", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

gplot_weights <- gplot(brick_weights, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Model Weights", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()




# ----------------------------------------
# put the main figure together
# ----------------------------------------
png(paste0(p_plots, "/ms_v3/","facet_gplots.png"),    
    width = 10, height = 10,
    units = "in", res = 300)
plot_grid(gplot_types,
          gplot_taxa,
          gplot_methods,
          gplot_resolution,
          gplot_weights,
          ncol = 1, labels = "auto")
dev.off()
```

```{r facet_gplot_bd100}
dt_bp_r %>% names
# ----------------------------------------
# put the main figure together, for bd100
# ----------------------------------------
png(paste0(p_plots, "/ms_v3/","facet_gplots_bd100.png"),    
    width = 8, height = 8,
    units = "in", res = 300)
plot_grid(
  gplot(facet_r_b[[1:4]], maxpixels = 5000000) + # or facet_r[[comparison_names$types]] for just the four ensemble means
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Types of Richness", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal(),
  
  gplot(facet_r_b[[5:8]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Taxonomic Groups", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal(),
  
  gplot(facet_r_b[[9:12]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Methods", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal(),
  
  gplot(facet_r_b[[13:15]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "Resolution", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal(),
  ncol = 1, labels = "auto")
dev.off()
```


```{r facet_levelplot}
# using levelplot

row_types <- levelplot(facet_r[[comparison_names$types]], 
                       col.regions = terrain.colors(50, rev = TRUE), 
                       #main = "Richness Types",
                       scales = list(draw = FALSE), 
                       layout = c(4,1), # layout = c(columns,  rows)
                       names.attr = c("All species", "Endemism", "Threatened", "Small-ranged"),
                       axis.line = list(col='transparent'),
                       ylab = "Richness Types", xlab = NULL) +
  latticeExtra::layer(sp.polygons(msk_shp, lwd=1))

row_taxa <- levelplot(facet_r[[comparison_names$taxa]], 
                      col.regions = terrain.colors(50, rev = TRUE), 
                      #main = "Vertebrate Taxonomic Groups",
                      scales = list(draw = FALSE), 
                      layout = c(4,1), # layout = c(columns,  rows)
                      names.attr = c("Mammals", "Birds", "Amphibians", "Reptiles"),
                      axis.line = list(col='transparent'),
                      ylab = "Taxonomic Groups", xlab = NULL) +
  latticeExtra::layer(sp.polygons(msk_shp, lwd=1))

row_methods <- levelplot(facet_r[[comparison_names$methods]], 
                         col.regions = terrain.colors(50, rev = TRUE), 
                         #main = "Methods of Combination",
                         scales = list(draw = FALSE), 
                         layout = c(4,1), # layout = c(columns,  rows)
                         names.attr = c("Arithmetic Mean", "Geometric Mean", "Maximum", "Multiplication"),
                         axis.line = list(col='transparent'),
                         ylab = "Methods", xlab = NULL) +
  latticeExtra::layer(sp.polygons(msk_shp, lwd=1))

row_res <- levelplot(facet_r[[comparison_names$resolution]], 
                     col.regions = terrain.colors(50, rev = TRUE), 
                     #main = "Resolution of Analysis",
                     scales = list(draw = FALSE), 
                       layout = c(4,1), # layout = c(columns,  rows)
                       names.attr = c("1-km grid", "10-km grid", "110-km grid"),
                       axis.line = list(col='transparent'),
                       ylab = "Resolutions", xlab = NULL) +
  latticeExtra::layer(sp.polygons(msk_shp, lwd=1))


row_weights <- levelplot(facet_r[[comparison_names$weights]], 
                         col.regions = terrain.colors(50, rev = TRUE), 
                         #main = "agroEcoTradeoff Model Weights",
                         scales = list(draw = FALSE), 
                       layout = c(4,1), # layout = c(columns,  rows)
                       names.attr = c("B", "BY", "BYCT"),
                       axis.line = list(col='transparent'),
                       ylab = "Model Weights", xlab = NULL) +
  latticeExtra::layer(sp.polygons(msk_shp, lwd=1))

png(paste0(p_plots, "/ms_v3/","facet_levelplots.png"),    
    width = 7, height = 10,
    units = "in", res = 300)
plot_grid(row_types,
          row_taxa,
          row_methods,
          row_res,
          row_weights,
          ncol = 1, labels = "auto")
dev.off()
```

```{r plotting playground}
install.packages("ggspatial")
library(ggspatial)
ggplot(data = facet_r$all) + ggraster( aes(col = DEPTH_M))
msk_shp

levelplot(facet_r[[comparison_names$types]], 
          col.regions = terrain.colors(50, rev = TRUE), 
          main = "Types of Species Richness",
          #par.settings=list(axis.line=list(col='transparent')), # suppress axes and legend outline
          scales = list(draw = FALSE), # remove axis labels
          layout = c(4,1), # layout: columns, rows
          names.attr = comparison_names$types,
          axis.line = list(col='transparent'),
          ylab = "Types", xlab = NULL
          ) + # layout = c(columns,  rows)
    latticeExtra::layer(sp.polygons(msk_shp, lwd=1))


ggplot() + geom_spraster_rgb(facet_r$all, interpolate = TRUE) +
  coord_fixed()
dt_m[, c("x", "y", "all"), with = FALSE]

ggplot(dt_m[, c("x", "y", "all", "endemism"), with = FALSE], aes(x, y, fill = all)) + 
  geom_raster() + 
  #facet_wrap(nrow = 1) + 
  coord_fixed() +
  scale_fill_continuous("terrain") + 
  theme_classic()
```

```{r distributions}

densityplot(bd_dt_r[[1:4]], layout = c(4, 1))

hist(bd_dt_r[[1]])
```


## extra
```{r hotspots}
# Not sure how this is going to work
# Setup -------------------------------------------------------------------

# Create 50 x 50 raster with random distribution of values
set.seed(172)
df <- data.frame(expand.grid(x = 1:50, y = 1:50), z = runif(2500, 1, 10))

# Multiply handful of pixels by 3 to create a hot spot
df$z[df$x %in% 10:15 & df$y %in% 10:15] <- 
    (df$z[df$x %in% 10:15 & df$y %in% 10:15]) * 3

# Divide handful of pixels by 3 to create a cold spot
df$z[df$x %in% 40:45 & df$y %in% 40:45] <- 
    (df$z[df$x %in% 40:45 & df$y %in% 40:45]) / 3

# Stats -------------------------------------------------------------------

# Identify nearest 8 neighbours
nr_neigh <- spdep::knearneigh(cbind(dt$x, dt$y), k = 8)


nr_neigh <- spdep::knearneigh(cbind(df$x, df$y), k = 8)
nr_neigh <- spdep::knn2nb(nr_neigh)
# Include self to calculate G* variant of local G statistic
nr_neigh <- spdep::include.self(nr_neigh)

# Get neighbour weights
nb_weights <- spdep::nb2listw(nr_neigh, 
                              style = "W",
                              zero.policy = FALSE)
# Calculate local G statistic
local_g <-
    spdep::localG(x = spdep::spNamedVec("z", df),
                  listw = nb_weights,
                  zero.policy = FALSE,
                  spChk = NULL)

# Add Z-values to dataframe
df <- data.frame(df, Z_val = matrix(local_g))

# Define significance categories, using critical values defined in  Getis and
# Ord (1996 )
get_critical_Z <- function(n){
    if(n >= 1 & n < 10){
        critical_z <- 1.6450
    }else if(n >= 10 & n < 30){
        critical_z <- 2.5683
    }else if(n >= 30 & n < 50){
        critical_z <- 2.9291
    }else if(n >= 50 & n < 100){
        critical_z <- 3.0833
    }else if(n >= 100 & n < 1000){
        critical_z <- 3.2889
    }else if(n > 1000){
        critical_z <- 3.8855
    }else{
        critical_z <- NA
    }
}
critical_Z <- get_critical_Z(nrow(df))

df$G_bin <- ifelse(df$Z_val >= critical_Z, 1,
                   ifelse(df$Z_val <= -critical_Z, -1, 0))


# Plot --------------------------------------------------------------------

# Plot raw data
raster::plot(raster::raster(reshape2::acast(df, y ~ x, value.var = "z")))
# Plot hot and cold spots
raster::plot(raster::raster(reshape2::acast(df, y ~ x, value.var = "G_bin")))



```

# unused:


```{r nnd_tester}

ind <- c(
    which(names(rl) == "max_b"), 
    which(names(rl) == "multi_b")
    )
  
  # select the two rasters of interest, save as a new list with those two rasters
  rl_ind <- rl[ind]
  
  # convert those rasters to points. 
  rxy <- lapply(rl_ind, function(x) rasterToPoints(x, fun = function(x) x > 0)) # selecting a subset of raster values (those larger than 0), using a simple function returning a logical values
  
  pps <- lapply(rxy, function(x) {
    ppp(x = x[, 1], y = x[, 2], window = zam_owin)
  })
  
  ppnn <- nncross(pps[[names(rl)[ind[1]]]], pps[[names(rl)[ind[2]]]]) %>%
    as_tibble() %>% mutate(surrogate_key = row_number())
  
  # ------------------------------------------------
  # join ppnn to the rxy values
  rxy_tbl <- lapply(rxy, function(x) mutate(as_tibble(x), surrogate_key = row_number()))
  
  ppnn_join <- ppnn %>% 
    # join ppnn to the rxy values
    left_join(rxy_tbl[[1]], by = "surrogate_key") %>% 
    select(-c(x, y)) %>%
    left_join(rxy_tbl[[2]], 
              by = c("which" = "surrogate_key")) %>% 
    select(-c(x, y)) %>%
    
    # with joined table, calculate the average ensemble value
    mutate(
      mean_value = rowMeans(cbind(.[, 4], .[, 5]), na.rm=T),
      adj_dist = dist * mean_value)

# ----------------------------------------
# calc summary files
ppnn_sums <- ppnn_join %>%
    summarise(dist_sum = sum(dist),
                       npoints = nrow(.),
                       adj_dist_sum = sum(adj_dist),
                       mean_sum = sum(mean_value))

ppnn_sums$dist_sum / nrow(ppnn_join) # raw average distance (in meters)
ppnn_sums$adj_dist_sum / ppnn_sums$mean_sum # adjusted average distance (in meters)

## checks out!

# ------------------------------------------------
# trying it with all first:
ppnn_join <- ppnn %>% 
  # join ppnn to the rxy values
  left_join(rxy_tbl[[which(names(rxy_tbl) == names(reord0)[1])]], 
            by = "surrogate_key") %>% 
  select(-c(x, y)) %>%
  left_join(rxy_tbl[[which(names(rxy_tbl) == names(reord0)[2])]], 
            by = c("which" = "surrogate_key")) %>% 
  select(-c(x, y)) %>%
  
  # with joined table, calculate the average ensemble value
  mutate(
    mean = rowMeans(cbind(
      .[, which(names(.) == names(reord0)[1])], 
      .[, which(names(.) == names(reord0)[2])]),
      na.rm=T),
    adj_dist = dist * mean)

ppnn0_sums <- summarise(ppnn0_join, 
          dist_sum = sum(dist), 
          adj_dist_sum = sum(adj_dist),
          mean_sum = sum(mean))

ppnn0_sums$dist_sum / nrow(ppnn0_join) # raw average distance (in meters)
ppnn0_sums$adj_dist_sum / ppnn0_sums$mean_sum # adjusted average distance (in meters)


# ------------------------------------------------
# with joined table, calculate the average ensemble value
which(names(ppnn_join) == names(reord)[1])
ppnn_join[, which(names(ppnn_join) == names(reord)[1])]

ppnn_join <- ppnn_join %>% 
  mutate(
    mean = rowMeans(cbind(
      ppnn_join[, which(names(ppnn_join) == names(reord)[1])], 
      ppnn_join[, which(names(ppnn_join) == names(reord)[2])]),
      na.rm=T),
    adj_dist = dist * mean)

ppnn_sums <- summarise(ppnn_join, 
          dist_sum = sum(dist), 
          adj_dist_sum = sum(adj_dist),
          mean_sum = sum(mean))

ppnn_sums$dist_sum / nrow(ppnn_join) # raw average distance (in meters)
ppnn_sums$adj_dist_sum / ppnn_sums$mean_sum # adjusted average distance (in meters)


test_join_sums[1,1]/nrow(test_join) # raw distance
test_join_sums[1,2]/test_join_sums[1,3] # adjusted distance




# -------------------------------------------------------------------
# weighted averaging
head(rxy$endemism) # the value
rxy$endemism[, 3] # just the cell values
sum(rxy$endemism[, 3]) # sum of the cell values


# # ## # # # # # 

test <- as_tibble(ppnn) %>% 
  mutate(surrogate_key = row_number())

head(test)
nrow(test)
test$endemism_b <- rxy$endemism[, 3]
nrow(rxy$endemism)
head(rxy$endemism)

# ------------------------------------------------
# manual join method
test0 <- ppnn %>%
  mutate(endemism = rxy$endemism[, 3])

tic()
test0$all <- 0
for (i in 1:nrow(test0)){
  test0[i, 4] <- rxy$all[test0[i, 2], 3]
}
toc() # 65 seconds
test0 <- test0 %>% rename(all = V4)
head(test0)
# this is really slow. There must be a faster way to do this. Maybe make them into data.tables?

# ------------------------------------------------
# just do a join! using tibbles

head(test)
head(rxy$endemism); head(rxy$all)

endemism_df <- as_tibble(rxy$endemism) %>%
  mutate(surrogate_key = row_number())

all_df <- as_tibble(rxy$all) %>%
  mutate(surrogate_key = row_number())


test_join <- left_join(test, endemism_df, by = "surrogate_key") %>%
  select(-c(x, y))
test_join 

test_join <- left_join(test_join, all_df, by = c("which" = "surrogate_key")) %>% select(-c(x, y))

test0 <- as_tibble(test0)

test0
select(test_join, dist, which, endemism = endemism_b, all = all_b)
identical(test0, select(test_join, dist, which, endemism = endemism_b, all = all_b))


# ------------------------------------------------
# just do a join! using data.tables
test_dt <- as.data.table(ppnn)
test_dt[, surrogate_key := 1:.N]
endemism_dt <- as.data.table(as.data.frame(rxy$endemism))
endemism_dt[, surrogate_key := 1:.N]

all_dt <- as.data.table(as.data.frame(rxy$all))
all_dt[, surrogate_key := 1:.N]

test_dt_join <- merge(test_dt, endemism_dt, by = "surrogate_key")
# also this works
# endemism_dt[test_dt, on = "surrogate_key"]
test_dt_join <- test_dt_join[, !c("x", "y")] # drop columns

test_dt_join2 <- merge(test_dt_join, all_dt, by.x = "which", by.y = "surrogate_key")
test_dt_join2 <- test_dt_join2[, !c("x", "y")] # drop columns
test_dt_join2

setorder(test_dt_join2, surrogate_key)
identical(as.data.table(test_join), test_dt_join2[, .(dist, which, surrogate_key, endemism_b, all_b)])

# multiply distance by ensemble_mean cell value
ppnn$dist[231:240] * rxy$endemism[, 3][231:240]




# ------------------------------------------------
# with joined table, calculate the average ensemble value

test_join <-  test_join %>% 
  mutate(#mean = rowMeans(cbind(endemism_b, all_b), na.rm=T), # all do the same thing
         #mean = (endemism_b + all_b)/2,
         mean = rowMeans(cbind(test_join[,4], test_join[,5]), na.rm=T),
         adj_dist = dist * mean)

test_join_sums <- summarise(test_join, 
          dist_sum = sum(dist), 
          adj_dist_sum = sum(adj_dist),
          mean_sum = sum(mean))

test_join_sums[1,1]/nrow(test_join) # raw distance
test_join_sums[1,2]/test_join_sums[1,3] # adjusted distance




# -------------------------------------------------------------------
# weighted averaging
head(rxy$endemism) # the value
rxy$endemism[, 3] # just the cell values
sum(rxy$endemism[, 3]) # sum of the cell values



```

```{r jac_bd}
# can i calculate the jw for the raw biodiversity maps themselves? I think so. 

pair1 <- c("all", "endemism")
pair2 <- c(3, 4)
dt_m[, ..pair2 # select the two columns you're interested in... (this works with column names in quotes, or as column indices)
   ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))] # then calculate the weighted Jaccard

dt_m[, c(facet_names[1], facet_names[2]), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]

dt_m[, c(3, 4), with = FALSE
     ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]

bd_dt[, c(1:6)]
bd_dt[, c(3,4), with = FALSE]
names(bd_dt)[c(3,4)]
bd_dt[, names(bd_dt)[c(3,4)], with = FALSE
      ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]

# calculate the order of biodiveristy from least to greatest biodiversity value.
# for loop to percentilize the whole dt
tdt <- bd_dt[, c(1:6)]
tdt[, key := 1:.N]
tdt
for (i in c(3:6)) {
  setorderv(tdt, names(tdt)[i])
  tdt[, names(tdt)[i] := (1:.N)/.N]  # create a new column listing the order from smallest to greatest.
  setorder(tdt, key)
}
tdt

bd_dt[, names(bd_dt)[c(3,4)], with = FALSE
      ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
# 0.1628715

tdt[, names(bd_dt)[c(3,4)], with = FALSE
      ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))]
# 0.5697009




library(data.table)

```
```{r add_agreement}
# Not sure what this chunk does. (5/15/2020 - Chris)
dt_m$all
mean(dt_m$all)
dt_m[, all > 0] %>% nrow()

dt_m[all > 0, length(all)]

dt_m["1" > 0, length(all)]
dt_m[c(1) > 0, all:bird, with = FALSE]

test <- "all"
dt_m[..(test) > 0, length(all), with = FALSE]

# mean value of each cell
dt_m[, mean(b)] # 0.04765

# mean value of cells chosen by at least one model
dt_m[b > 0, mean(b)] # 0.1040
dt_m[by > 0, mean(by)] # 0.1040
dt_m[byct > 0, mean(byct)] # 0.1040
dt_m[get(test[1]) > 0, mean(get(test[1]))]
test

# number of cells chosen by at least one model
dt_m[b > 0, length(b)] # 233853

# --------------------------------------------------------
facet_stats %>% mutate(
  mean = vector(length = length(facet_names)),
  ncells = vector(length = length(facet_names)),
  mean_non0 = vector(length = length(facet_names))
)



# calculate vector of mean values of cells chosen by at least one model 
for (i in seq_along(facet_names)) {
  facet_stats[i, "mean"] <- dt_m[, mean(get(facet_names[i]))]
  facet_stats[i, "ncells"] <- dt_m[get(facet_names[i]) > 0, length(get(facet_names[i]))]
  facet_stats[i, "mean_non0"] <- dt_m[get(facet_names[i]) > 0, mean(get(facet_names[i]))]
}

facet_stats


```



# Previous code: prior to May 2020

# Biodiversity impact metrics
Two main types of biodiversity loss:
1. Species*km2 of range converted
- This involves multiplying a data.table of the conversion areas (0s and 1s) with a data.table that lists the raw species richness. 


2. Species range equivalents converted
- This would involve just having the raw weighted endemism richness value, and multiplying this by the conversion maps to identify overlaps, and then summing this. What does this mean?
- Kier et al. 2009's weighted endemism metric: the cumulative proportions of each species range that overlaps with that cell. Kier et al. 2009 calls these range equivalents. And because summing all range equivalents across all map cells yields the total number of species in the analysis, the number "can be interpreted as the specific contribution of an area to global biodiversity. So, that means it might be better to divide this value by the number of species, so that you get the average proportion of range thats contained in the cell, and the contribution to global biodiversity of whatever taxa it concerns. Alternatively, I can just leave this as the number of range equivalents per 1km2. The sum all the range equivalents that are lost across all of the converted cells.

Additional Impact metrics are calculated for individual species.
- Species-specific proportions of range converted. The simplest method I can think of involves using Lyndons function as.data.table.raster() to create a data.table out of each species raster (which has to be rasterized from the polygons). Then, multiply this by the data.table of the conversion map (0s and 1s), which will show where they overlap. If they are both 0s and 1s, then I can sum this to calculate the area of overlap. To figure out the proportion of each species global range and Zambia-specific range, I would then multiply this sum (area of overlap) by 1/range (either global or Zambia-specific). 
- A further metric might be the number of species who lose habitat? 










# Plots:
## ggplots 
```{r results_combo-ggplots}
p_results_combo_base <- ggplot(results_combo) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Biodiversity Input") + ylab("Mean % Unprotected \nBiodiversity Loss") + 
  labs(title = "Average biodiversity loss across inputs in group", 
       subtitle = "as a percent of unprotected biodiversity",
       caption = "Error bars represent 95% confidence intervals") + 
  # scale_color_manual(name = "Model Specifications",
  #                    labels = c("eq" = "Equal Weights",
  #                               "bd50_y50" = "50% on Biodiversity, \n50% Yield",
  #                               "bd100" = "100% on Biodiversity"),
  #                    values = c("eq" = hue_pal()(3)[1], #"red"
  #                               "bd50_y50" = hue_pal()(3)[3], #"blue"
  #                               "bd100" = hue_pal()(3)[2])) # "green"
  scale_color_manual(name = "Weights",
                     labels = c("bd100" = "b",
                                "bd50_y50" = "by",
                                "eq" = "byct"),
                     values = c("all" = "black",
                                "bd100" = hue_pal()(3)[2], # "green"
                                "bd50_y50" = hue_pal()(3)[3], #"blue"
                                "eq" = hue_pal()(3)[1])) #"red"

                                 

# choosing the ggplot default colors. 
library(scales)
show_col(hue_pal()(3))



results_combo
overlap_combo

names(results_combo)
results_combo[, c(1:2, 36:45)] %>% filter(bd_input %in% runs[ensembles_list$en1_types])

```


```{r mean_bd_loss}
# ---------------------------------------------------------
# mean biodiversity loss for each layer
# ---------------------------------------------------------
p_mean_bd_loss <- p_results_combo_base +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, ymin = mean_bd_loss - 1.96*se_bd_loss, ymax = mean_bd_loss + 1.96*se_bd_loss, color = mod_spec), width = 0.4, position = position_dodge(0.6))

p_mean_bd_loss %+% filter(results_combo, bd_input %in% runs[en1_types])


# subsets of the plot
# runs_en1
names(results_combo)
names(ensembles_list)

# now filtered to just the right runs, and the right column of results
# 1
p_mean_bd_loss_en1_types <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en1_types]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en1_types, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en1_types - 1.96*se_bd_loss_en1_types, 
                              ymax = mean_bd_loss_en1_types + 1.96*se_bd_loss_en1_types), 
                width = 0.4, position = position_dodge(0.6))

# 2
p_mean_bd_loss_en1_types_b <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en1_types_b]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en1_types_b, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en1_types_b - 1.96*se_bd_loss_en1_types_b, 
                              ymax = mean_bd_loss_en1_types_b + 1.96*se_bd_loss_en1_types_b), 
                width = 0.4, position = position_dodge(0.6))

# 3
p_mean_bd_loss_en2_taxa_all <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en2_taxa_all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en2_taxa_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en2_taxa_all - 1.96*se_bd_loss_en2_taxa_all, 
                              ymax = mean_bd_loss_en2_taxa_all + 1.96*se_bd_loss_en2_taxa_all), 
                width = 0.4, position = position_dodge(0.6))

# 4
p_mean_bd_loss_en2_taxa_endemism <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en2_taxa_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en2_taxa_endemism, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en2_taxa_endemism - 1.96*se_bd_loss_en2_taxa_endemism, 
                              ymax = mean_bd_loss_en2_taxa_endemism + 1.96*se_bd_loss_en2_taxa_endemism), 
                width = 0.4, position = position_dodge(0.6))

# 5
p_mean_bd_loss_en2_taxa_threat <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en2_taxa_threat]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en2_taxa_threat, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en2_taxa_threat - 1.96*se_bd_loss_en2_taxa_threat, 
                              ymax = mean_bd_loss_en2_taxa_threat + 1.96*se_bd_loss_en2_taxa_threat), 
                width = 0.4, position = position_dodge(0.6))

# 6
p_mean_bd_loss_en2_taxa_small <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en2_taxa_small]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en2_taxa_small, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en2_taxa_small - 1.96*se_bd_loss_en2_taxa_small, 
                              ymax = mean_bd_loss_en2_taxa_small + 1.96*se_bd_loss_en2_taxa_small), 
                width = 0.4, position = position_dodge(0.6))

# 7
p_mean_bd_loss_en3_mb <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en3_mb]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en3_mb, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en3_mb - 1.96*se_bd_loss_en3_mb, 
                              ymax = mean_bd_loss_en3_mb + 1.96*se_bd_loss_en3_mb), 
                width = 0.4, position = position_dodge(0.6))

# 8
p_mean_bd_loss_en3_vp <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en3_vp]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en3_vp, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en3_vp - 1.96*se_bd_loss_en3_vp, 
                              ymax = mean_bd_loss_en3_vp + 1.96*se_bd_loss_en3_vp), 
                width = 0.4, position = position_dodge(0.6))

# 9
p_mean_bd_loss_en3_ae <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en3_ae]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en3_ae, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en3_ae - 1.96*se_bd_loss_en3_ae, 
                              ymax = mean_bd_loss_en3_ae + 1.96*se_bd_loss_en3_ae), 
                width = 0.4, position = position_dodge(0.6))

# 10
p_mean_bd_loss_en4_all <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en4_all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en4_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en4_all - 1.96*se_bd_loss_en4_all, 
                              ymax = mean_bd_loss_en4_all + 1.96*se_bd_loss_en4_all), 
                width = 0.4, position = position_dodge(0.6))

# 11
p_mean_bd_loss_en4_endemism <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en4_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en4_endemism, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en4_endemism - 1.96*se_bd_loss_en4_endemism, 
                              ymax = mean_bd_loss_en4_endemism + 1.96*se_bd_loss_en4_endemism), 
                width = 0.4, position = position_dodge(0.6))

# 12
p_mean_bd_loss_en4_threat <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en4_threat]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en4_threat, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en4_threat - 1.96*se_bd_loss_en4_threat, 
                              ymax = mean_bd_loss_en4_threat + 1.96*se_bd_loss_en4_threat), 
                width = 0.4, position = position_dodge(0.6))

# 13
p_mean_bd_loss_en4_small <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en4_small]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en4_small, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en4_small - 1.96*se_bd_loss_en4_small, 
                              ymax = mean_bd_loss_en4_small + 1.96*se_bd_loss_en4_small), 
                width = 0.4, position = position_dodge(0.6))

# 14
p_mean_bd_loss_en5_composites <- p_results_combo_base %+% 
  filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en5_composites, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en5_composites - 1.96*se_bd_loss_en5_composites, 
                              ymax = mean_bd_loss_en5_composites + 1.96*se_bd_loss_en5_composites), 
                width = 0.4, position = position_dodge(0.6))

# 15
p_mean_bd_loss_en6_norm_all <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en6_norm_all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en6_norm_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en6_norm_all - 1.96*se_bd_loss_en6_norm_all, 
                              ymax = mean_bd_loss_en6_norm_all + 1.96*se_bd_loss_en6_norm_all), 
                width = 0.4, position = position_dodge(0.6))

# 16
p_mean_bd_loss_en6_norm_endemism <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en6_norm_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en6_norm_endemism, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en6_norm_endemism - 1.96*se_bd_loss_en6_norm_endemism, 
                              ymax = mean_bd_loss_en6_norm_endemism + 1.96*se_bd_loss_en6_norm_endemism), 
                width = 0.4, position = position_dodge(0.6))

# 17
p_mean_bd_loss_en6_norm_threat <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en6_norm_threat]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en6_norm_threat, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en6_norm_threat - 1.96*se_bd_loss_en6_norm_threat, 
                              ymax = mean_bd_loss_en6_norm_threat + 1.96*se_bd_loss_en6_norm_threat), 
                width = 0.4, position = position_dodge(0.6))

# 18
p_mean_bd_loss_en6_norm_small <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[en6_norm_small]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_en6_norm_small, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_en6_norm_small - 1.96*se_bd_loss_en6_norm_small, 
                              ymax = mean_bd_loss_en6_norm_small + 1.96*se_bd_loss_en6_norm_small), 
                width = 0.4, position = position_dodge(0.6))

# 19
p_mean_bd_loss_all <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_bd_loss_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, color = mod_spec,
                              ymin = mean_bd_loss_all - 1.96*se_bd_loss_all, 
                              ymax = mean_bd_loss_all + 1.96*se_bd_loss_all), 
                width = 0.4, position = position_dodge(0.6))

p_mean_bd_loss_en1_types
p_mean_bd_loss_en1_types_b
p_mean_bd_loss_en2_taxa_all
p_mean_bd_loss_en2_taxa_endemism
p_mean_bd_loss_en2_taxa_threat
p_mean_bd_loss_en2_taxa_small
p_mean_bd_loss_en3_mb
p_mean_bd_loss_en3_vp
p_mean_bd_loss_en3_ae
p_mean_bd_loss_en4_all
p_mean_bd_loss_en4_endemism
p_mean_bd_loss_en4_threat
p_mean_bd_loss_en4_small
p_mean_bd_loss_en5_composites
p_mean_bd_loss_en6_norm_all
p_mean_bd_loss_en6_norm_endemism
p_mean_bd_loss_en6_norm_threat
p_mean_bd_loss_en6_norm_small
p_mean_bd_loss_all


# 
# -----------------------------------------------------------------------------------------------------
# -----------------------------------------------------------------------------------------------------
# -----------------------------------------------------------------------------------------------------
#
# extra, tying to design code to iterate the creation of these 19 plots - 
p_mean_bd_loss_en1_taxa_all2 <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[2]]]) +
  geom_point(mapping = aes(x = bd_input, 
                           y = eval(parse(text = paste0("mean_bd_loss_", names(ensembles_list)[2]))), 
                           color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = eval(parse(text = paste0("mean_bd_loss_", names(ensembles_list)[2])))
                              - 1.96*eval(parse(text = paste0("se_bd_loss_", names(ensembles_list)[2]))), 
                              ymax = eval(parse(text = paste0("mean_bd_loss_", names(ensembles_list)[2])))
                              + 1.96*eval(parse(text = paste0("se_bd_loss_", names(ensembles_list)[2]))), 
                              color = mod_spec), width = 0.4, position = position_dodge(0.6))

# the for loop doesn't work, but assigning it manually, changing the i each time doesn't seem to work either.
for (i in seq_along(ensembles_list)) {
  assign(paste0("mp_mean_bd_loss_", names(ensembles_list)[i]), 
       p_results_combo_base %+% 
         filter(results_combo, bd_input %in% runs[ensembles_list[[i]]]) +
  geom_point(mapping = aes(x = bd_input, 
                           y = eval(parse(text = paste0("mean_bd_loss_", names(ensembles_list)[1]))), 
                           color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = eval(parse(text = paste0("mean_bd_loss_", names(ensembles_list)[i])))
                              - 1.96*eval(parse(text = paste0("se_bd_loss_", names(ensembles_list)[i]))), 
                              ymax = eval(parse(text = paste0("mean_bd_loss_", names(ensembles_list)[i])))
                              + 1.96*eval(parse(text = paste0("se_bd_loss_", names(ensembles_list)[i]))), 
                              color = mod_spec), width = 0.4, position = position_dodge(0.6))
  )
}

# 
par(mfrow = c(1,2))
eval(parse(text = paste0("p_mean_bd_loss_", names(ensembles_list)[1])))
eval(parse(text = paste0("mp_mean_bd_loss_", names(ensembles_list)[1])))


names(results_combo)
results_combo %>%
  filter(bd_input %in% runs[ensembles_list$en1_types]) %>%
  .[, c(1,2, 3, 69, 75)]
  
names(results_combo)

p_mean_bd_loss_en1_types

ensembles_list[[1]]
eval(parse(text = paste0("mean_bd_loss_", names(ensembles_list)[1])))

ensembles_list
paste0("mean_bd_loss_", names(ensembles_list))



mp_mean_bd_loss_en1_types
p_mean_bd_loss_en1_types2

mp_mean_bd_loss_en1_types_b
p_mean_bd_loss_en1_taxa_all2


mp_mean_bd_loss_en2_taxa_all
mp_mean_bd_loss_en2_taxa_endemism
mp_mean_bd_loss_en2_taxa_threat
mp_mean_bd_loss_en2_taxa_small
mp_mean_bd_loss_en3_mb
mp_mean_bd_loss_en3_vp
mp_mean_bd_loss_en3_ae
mp_mean_bd_loss_en4_all
mp_mean_bd_loss_en4_endemism
mp_mean_bd_loss_en4_threat
mp_mean_bd_loss_en4_small
mp_mean_bd_loss_en5_composites
mp_mean_bd_loss_en6_norm_all
mp_mean_bd_loss_en6_norm_endemism
mp_mean_bd_loss_en6_norm_threat
mp_mean_bd_loss_en6_norm_small
mp_mean_bd_loss_all





```

```{r bd_loss_control}
# ---------------------------------------------------------
# percent biodiversity loss in controlling layer
# ---------------------------------------------------------
names(results_combo)
p_bd_loss_control <- 
  p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs) +
  geom_point(mapping = aes(x = bd_input, y = percent_bd_loss_control, color = mod_spec), position = position_dodge(0.6)) +
  #geom_col(mapping = aes(x = bd_input, y = mean_bd_loss, fill = mod_spec), position = "dodge") + # to add a bar chart
  labs(title = "Biodiversity loss in controlling layer", subtitle = "as a percent of unprotected biodiversity", caption = NULL,
       y = "Percent Unprotected \nBiodiversity Loss") #+ 
  #facet_grid(rows = vars(mod_spec))

# p_bd_loss_control #%+% filter(results_combo, mod_spec == "bd100")

p_bd_loss_control_en1_types <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[1]]])

p_bd_loss_control_en1_types_b <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[2]]])

p_bd_loss_control_en2_taxa_all <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[3]]])

p_bd_loss_control_en2_taxa_endemism <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[4]]])

p_bd_loss_control_en2_taxa_threat <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[5]]])

p_bd_loss_control_en2_taxa_small <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[6]]])

p_bd_loss_control_en3_mb <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[7]]])

p_bd_loss_control_en3_vp <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[8]]])

p_bd_loss_control_en3_ae <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[9]]])

p_bd_loss_control_en4_all <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[10]]])

p_bd_loss_control_en4_endemism <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[11]]])

p_bd_loss_control_en4_threat <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[12]]])

p_bd_loss_control_en4_small <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[13]]])

p_bd_loss_control_en5_composites <- p_bd_loss_control %+% 
  filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])

p_bd_loss_control_en6_norm_all <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[15]]])

p_bd_loss_control_en6_norm_endemism <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[16]]])

p_bd_loss_control_en6_norm_threat <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[17]]])

p_bd_loss_control_en6_norm_small <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[18]]])

p_bd_loss_control_all <- p_bd_loss_control %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list[[19]]])

p_bd_loss_control_en1_types
p_bd_loss_control_en1_types_b
p_bd_loss_control_en2_taxa_all
p_bd_loss_control_en2_taxa_endemism
p_bd_loss_control_en2_taxa_threat
p_bd_loss_control_en2_taxa_small
p_bd_loss_control_en3_mb
p_bd_loss_control_en3_vp
p_bd_loss_control_en3_ae
p_bd_loss_control_en4_all
p_bd_loss_control_en4_endemism
p_bd_loss_control_en4_threat
p_bd_loss_control_en4_small
p_bd_loss_control_en5_composites
p_bd_loss_control_en6_norm_all
p_bd_loss_control_en6_norm_endemism
p_bd_loss_control_en6_norm_threat
p_bd_loss_control_en6_norm_small
p_bd_loss_control_all


```

```{r raw_richness_loss}
# ---------------------------------------------------------------------------------------------------------
# ---------- raw all species richness -----------------------------------------
# ---------------------------------------------------------------------------------------------------------
p_raw_all_richness_loss <- 
  p_results_combo_base %+% 
  filter(results_combo_raw, bd_input %in% runs) +
  geom_point(mapping = aes(x = bd_input, y = vert_all_raw_bd_loss/1000000, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Raw area of all species ranges lost in converted areas", 
       subtitle = NULL, caption = NULL,
       y = expression("Range Area \nConverted (10"^{6}*" km"^{2}*")"))
p_raw_all_richness_loss

p_raw_all_richness_loss_en1_types <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[1]]])
p_raw_all_richness_loss_en1_types_b <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[2]]])
p_raw_all_richness_loss_en2_taxa_all <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[3]]])
p_raw_all_richness_loss_en2_taxa_endemism <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[4]]])
p_raw_all_richness_loss_en2_taxa_threat <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[5]]])
p_raw_all_richness_loss_en2_taxa_small <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[6]]])
p_raw_all_richness_loss_en3_mb <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[7]]])
p_raw_all_richness_loss_en3_vp <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[8]]])
p_raw_all_richness_loss_en3_ae <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[9]]])
p_raw_all_richness_loss_en4_all <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[10]]])
p_raw_all_richness_loss_en4_endemism <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[11]]])
p_raw_all_richness_loss_en4_threat <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[12]]])
p_raw_all_richness_loss_en4_small <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[13]]])
p_raw_all_richness_loss_en5_composites <- p_raw_all_richness_loss  %+% 
  filter(mutate(results_combo_raw, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])
p_raw_all_richness_loss_en6_norm_all <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[15]]])
p_raw_all_richness_loss_en6_norm_endemism <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[16]]])
p_raw_all_richness_loss_en6_norm_threat <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[17]]])
p_raw_all_richness_loss_en6_norm_small <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[18]]])
p_raw_all_richness_loss_all <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[19]]])

# ---------------------------------------------------------------------------------------------------------
# ---------- raw endemism richness -----------------------------------------
# ---------------------------------------------------------------------------------------------------------
p_raw_endemism_richness_loss <- 
  p_results_combo_base %+% 
  filter(results_combo_raw, bd_input %in% runs) +
  geom_point(mapping = aes(x = bd_input, y = vert_endemism_raw_bd_loss, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Global range equivalents lost in converted areas", 
       subtitle = "(Summed proportions of global range lost)", caption = NULL,
       y = "Range equivalents \nconverted")

p_raw_endemism_richness_loss_en1_types <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[1]]])
p_raw_endemism_richness_loss_en1_types_b <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[2]]])
p_raw_endemism_richness_loss_en2_taxa_all <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[3]]])
p_raw_endemism_richness_loss_en2_taxa_endemism <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[4]]])
p_raw_endemism_richness_loss_en2_taxa_threat <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[5]]])
p_raw_endemism_richness_loss_en2_taxa_small <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[6]]])
p_raw_endemism_richness_loss_en3_mb <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[7]]])
p_raw_endemism_richness_loss_en3_vp <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[8]]])
p_raw_endemism_richness_loss_en3_ae <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[9]]])
p_raw_endemism_richness_loss_en4_all <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[10]]])
p_raw_endemism_richness_loss_en4_endemism <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[11]]])
p_raw_endemism_richness_loss_en4_threat <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[12]]])
p_raw_endemism_richness_loss_en4_small <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[13]]])
p_raw_endemism_richness_loss_en5_composites <- p_raw_endemism_richness_loss  %+% 
  filter(mutate(results_combo_raw, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])
p_raw_endemism_richness_loss_en6_norm_all <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[15]]])
p_raw_endemism_richness_loss_en6_norm_endemism <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[16]]])
p_raw_endemism_richness_loss_en6_norm_threat <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[17]]])
p_raw_endemism_richness_loss_en6_norm_small <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[18]]])
p_raw_endemism_richness_loss_all <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[19]]])


# ---------------------------------------------------------------------------------------------------------
# ---------- raw threatened richness -----------------------------------------
# ---------------------------------------------------------------------------------------------------------
p_raw_threat_richness_loss <- 
  p_results_combo_base %+% 
  filter(results_combo_raw, bd_input %in% runs) +
  geom_point(mapping = aes(x = bd_input, y = vert_threat_raw_bd_loss/1000, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Raw area of threatened species ranges lost in converted areas", 
       subtitle = NULL, caption = NULL,
       y = expression("Range Area \nConverted (10"^{3}*" km"^{2}*")"))

p_raw_threat_richness_loss_en1_types <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[1]]])
p_raw_threat_richness_loss_en1_types_b <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[2]]])
p_raw_threat_richness_loss_en2_taxa_all <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[3]]])
p_raw_threat_richness_loss_en2_taxa_endemism <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[4]]])
p_raw_threat_richness_loss_en2_taxa_threat <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[5]]])
p_raw_threat_richness_loss_en2_taxa_small <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[6]]])
p_raw_threat_richness_loss_en3_mb <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[7]]])
p_raw_threat_richness_loss_en3_vp <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[8]]])
p_raw_threat_richness_loss_en3_ae <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[9]]])
p_raw_threat_richness_loss_en4_all <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[10]]])
p_raw_threat_richness_loss_en4_endemism <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[11]]])
p_raw_threat_richness_loss_en4_threat <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[12]]])
p_raw_threat_richness_loss_en4_small <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[13]]])
p_raw_threat_richness_loss_en5_composites <- p_raw_threat_richness_loss %+% 
  filter(mutate(results_combo_raw, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])
p_raw_threat_richness_loss_en6_norm_all <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[15]]])
p_raw_threat_richness_loss_en6_norm_endemism <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[16]]])
p_raw_threat_richness_loss_en6_norm_threat <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[17]]])
p_raw_threat_richness_loss_en6_norm_small <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[18]]])
p_raw_threat_richness_loss_all <- p_raw_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[19]]])



# ---------------------------------------------------------------------------------------------------------
# ---------- raw small-ranged richness -----------------------------------------
# ---------------------------------------------------------------------------------------------------------
p_raw_small_richness_loss <- 
  p_results_combo_base %+% 
  filter(results_combo_raw, bd_input %in% runs) +
  geom_point(mapping = aes(x = bd_input, y = vert_small_raw_bd_loss/1000, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Raw area of globally small-ranged species ranges \nlost in converted areas", 
       subtitle = NULL, caption = NULL,
       y = expression("Range Area \nConverted (10"^{3}*" km"^{2}*")"))

p_raw_small_richness_loss_en1_types <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[1]]])
p_raw_small_richness_loss_en1_types_b <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[2]]])
p_raw_small_richness_loss_en2_taxa_all <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[3]]])
p_raw_small_richness_loss_en2_taxa_endemism <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[4]]])
p_raw_small_richness_loss_en2_taxa_threat <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[5]]])
p_raw_small_richness_loss_en2_taxa_small <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[6]]])
p_raw_small_richness_loss_en3_mb <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[7]]])
p_raw_small_richness_loss_en3_vp <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[8]]])
p_raw_small_richness_loss_en3_ae <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[9]]])
p_raw_small_richness_loss_en4_all <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[10]]])
p_raw_small_richness_loss_en4_endemism <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[11]]])
p_raw_small_richness_loss_en4_threat <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[12]]])
p_raw_small_richness_loss_en4_small <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[13]]])
p_raw_small_richness_loss_en5_composites <- p_raw_small_richness_loss %+% 
  filter(mutate(results_combo_raw, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])
p_raw_small_richness_loss_en6_norm_all <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[15]]])
p_raw_small_richness_loss_en6_norm_endemism <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[16]]])
p_raw_small_richness_loss_en6_norm_threat <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[17]]])
p_raw_small_richness_loss_en6_norm_small <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[18]]])
p_raw_small_richness_loss_all <- p_raw_small_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[19]]])



# ---------------------------------------------------------------------------------------------------------
# ---------- raw threat-weighted richness loss -----------------------------------------
# ---------------------------------------------------------------------------------------------------------
p_raw_threat_weighted_richness_loss <- 
  p_results_combo_base %+% 
  filter(results_combo_raw, bd_input %in% runs) +
  geom_point(mapping = aes(x = bd_input, y = vert_threat_weighted_raw_bd_loss, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Raw threat-weighted species richness lost in converted areas", 
       subtitle = "(threatened species equivalents)", caption = NULL,
       y = expression("Sum of threat-weighted \nrichness converted"))

p_raw_threat_weighted_richness_loss_en1_types <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[1]]])
p_raw_threat_weighted_richness_loss_en1_types_b <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[2]]])
p_raw_threat_weighted_richness_loss_en2_taxa_all <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[3]]])
p_raw_threat_weighted_richness_loss_en2_taxa_endemism <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[4]]])
p_raw_threat_weighted_richness_loss_en2_taxa_threat <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[5]]])
p_raw_threat_weighted_richness_loss_en2_taxa_small <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[6]]])
p_raw_threat_weighted_richness_loss_en3_mb <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[7]]])
p_raw_threat_weighted_richness_loss_en3_vp <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[8]]])
p_raw_threat_weighted_richness_loss_en3_ae <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[9]]])
p_raw_threat_weighted_richness_loss_en4_all <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[10]]])
p_raw_threat_weighted_richness_loss_en4_endemism <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[11]]])
p_raw_threat_weighted_richness_loss_en4_threat <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[12]]])
p_raw_threat_weighted_richness_loss_en4_small <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[13]]])
p_raw_threat_weighted_richness_loss_en5_composites <- p_raw_threat_weighted_richness_loss  %+% 
  filter(mutate(results_combo_raw, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])
p_raw_threat_weighted_richness_loss_en6_norm_all <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[15]]])
p_raw_threat_weighted_richness_loss_en6_norm_endemism <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[16]]])
p_raw_threat_weighted_richness_loss_en6_norm_threat <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[17]]])
p_raw_threat_weighted_richness_loss_en6_norm_small <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[18]]])
p_raw_threat_weighted_richness_loss_all <- p_raw_threat_weighted_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[19]]])



# ---------------------------------------------------------------------------------------------------------
# ---------- raw small-ranged and threatened species richness -----------------------------------------
# ---------------------------------------------------------------------------------------------------------
p_raw_small_threat_richness_loss <- 
  p_results_combo_base %+% 
  filter(results_combo_raw, bd_input %in% runs) +
  geom_point(mapping = aes(x = bd_input, y = vert_small_threat_raw_bd_loss/1000, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Raw area of globally small-ranged or threatened species \nranges lost in converted areas", 
       subtitle = NULL, caption = NULL,
       y = expression("Range Area \nConverted (10"^{3}*" km"^{2}*")"))

p_raw_small_threat_richness_loss_en1_types <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[1]]])
p_raw_small_threat_richness_loss_en1_types_b <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[2]]])
p_raw_small_threat_richness_loss_en2_taxa_all <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[3]]])
p_raw_small_threat_richness_loss_en2_taxa_endemism <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[4]]])
p_raw_small_threat_richness_loss_en2_taxa_threat <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[5]]])
p_raw_small_threat_richness_loss_en2_taxa_small <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[6]]])
p_raw_small_threat_richness_loss_en3_mb <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[7]]])
p_raw_small_threat_richness_loss_en3_vp <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[8]]])
p_raw_small_threat_richness_loss_en3_ae <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[9]]])
p_raw_small_threat_richness_loss_en4_all <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[10]]])
p_raw_small_threat_richness_loss_en4_endemism <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[11]]])
p_raw_small_threat_richness_loss_en4_threat <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[12]]])
p_raw_small_threat_richness_loss_en4_small <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[13]]])
p_raw_small_threat_richness_loss_en5_composites <- p_raw_small_threat_richness_loss  %+% 
  filter(mutate(results_combo_raw, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])
p_raw_small_threat_richness_loss_en6_norm_all <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[15]]])
p_raw_small_threat_richness_loss_en6_norm_endemism <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[16]]])
p_raw_small_threat_richness_loss_en6_norm_threat <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[17]]])
p_raw_small_threat_richness_loss_en6_norm_small <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[18]]])
p_raw_small_threat_richness_loss_all <- p_raw_small_threat_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[19]]])



# ---------------------------------------------------------------------------------------------------------
# ---------- raw Zambian small-ranged richness -----------------------------------------
# ---------------------------------------------------------------------------------------------------------
p_raw_small_zam_richness_loss <- 
  p_results_combo_base %+% 
  filter(results_combo_raw, bd_input %in% runs) +
  geom_point(mapping = aes(x = bd_input, y = vert_small_zam_raw_bd_loss/1000000, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Raw area of Zambian small-ranged species ranges \nlost in converted areas", 
       subtitle = NULL, caption = NULL,
       y = expression("Range Area \nConverted (10"^{6}*" km"^{2}*")"))

p_raw_small_zam_richness_loss_en1_types <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[1]]])
p_raw_small_zam_richness_loss_en1_types_b <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[2]]])
p_raw_small_zam_richness_loss_en2_taxa_all <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[3]]])
p_raw_small_zam_richness_loss_en2_taxa_endemism <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[4]]])
p_raw_small_zam_richness_loss_en2_taxa_threat <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[5]]])
p_raw_small_zam_richness_loss_en2_taxa_small <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[6]]])
p_raw_small_zam_richness_loss_en3_mb <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[7]]])
p_raw_small_zam_richness_loss_en3_vp <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[8]]])
p_raw_small_zam_richness_loss_en3_ae <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[9]]])
p_raw_small_zam_richness_loss_en4_all <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[10]]])
p_raw_small_zam_richness_loss_en4_endemism <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[11]]])
p_raw_small_zam_richness_loss_en4_threat <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[12]]])
p_raw_small_zam_richness_loss_en4_small <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[13]]])
p_raw_small_zam_richness_loss_en5_composites <- p_raw_small_zam_richness_loss %+% 
  filter(mutate(results_combo_raw, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])
p_raw_small_zam_richness_loss_en6_norm_all <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[15]]])
p_raw_small_zam_richness_loss_en6_norm_endemism <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[16]]])
p_raw_small_zam_richness_loss_en6_norm_threat <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[17]]])
p_raw_small_zam_richness_loss_en6_norm_small <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[18]]])
p_raw_small_zam_richness_loss_all <- p_raw_small_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[19]]])



# ---------------------------------------------------------------------------------------------------------
# ---------- raw endemism_zam richness -----------------------------------------
# ---------------------------------------------------------------------------------------------------------
p_raw_endemism_zam_richness_loss <- 
  p_results_combo_base %+% 
  filter(results_combo_raw, bd_input %in% runs) +
  geom_point(mapping = aes(x = bd_input, y = vert_endemism_zam_raw_bd_loss, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Zambian range equivalents lost in converted areas", 
       subtitle = "(Summed proportions of Zambian range lost)", caption = NULL,
       y = "Zambian range \nequivalents converted")

p_raw_endemism_zam_richness_loss_en1_types <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[1]]])
p_raw_endemism_zam_richness_loss_en1_types_b <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[2]]])
p_raw_endemism_zam_richness_loss_en2_taxa_all <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[3]]])
p_raw_endemism_zam_richness_loss_en2_taxa_endemism <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[4]]])
p_raw_endemism_zam_richness_loss_en2_taxa_threat <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[5]]])
p_raw_endemism_zam_richness_loss_en2_taxa_small <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[6]]])
p_raw_endemism_zam_richness_loss_en3_mb <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[7]]])
p_raw_endemism_zam_richness_loss_en3_vp <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[8]]])
p_raw_endemism_zam_richness_loss_en3_ae <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[9]]])
p_raw_endemism_zam_richness_loss_en4_all <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[10]]])
p_raw_endemism_zam_richness_loss_en4_endemism <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[11]]])
p_raw_endemism_zam_richness_loss_en4_threat <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[12]]])
p_raw_endemism_zam_richness_loss_en4_small <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[13]]])
p_raw_endemism_zam_richness_loss_en5_composites <- p_raw_endemism_zam_richness_loss %+% 
  filter(mutate(results_combo_raw, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])
p_raw_endemism_zam_richness_loss_en6_norm_all <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[15]]])
p_raw_endemism_zam_richness_loss_en6_norm_endemism <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[16]]])
p_raw_endemism_zam_richness_loss_en6_norm_threat <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[17]]])
p_raw_endemism_zam_richness_loss_en6_norm_small <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[18]]])
p_raw_endemism_zam_richness_loss_all <- p_raw_endemism_zam_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[19]]])
```



```{r var_from_control}
results_combo$var_from_control
match("var_from_control", names(results_combo)) 

head(results_combo)[, c(1:2, 70:78)]
# ---------------------------------------------------------
# variance from control
# ---------------------------------------------------------
p_var_from_control <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs) + 
  geom_point(mapping = aes(x = bd_input, y = var_from_control, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Variance in Biodiversity Loss", 
       subtitle = "For all biodiversity inputs \nrelative to loss in controlling layer", caption = NULL) +
  ylab("Variance in \nUnprotected Biodiversity Loss")

# print(p_var_from_control)
paste0("p_var_from_control_", names(ensembles_list))

p_var_from_control_en1_types <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[1]]])
p_var_from_control_en1_types_b <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[2]]])
p_var_from_control_en2_taxa_all <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[3]]])
p_var_from_control_en2_taxa_endemism <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[4]]])
p_var_from_control_en2_taxa_threat <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[5]]])
p_var_from_control_en2_taxa_small <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[6]]])
p_var_from_control_en3_mb <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[7]]])
p_var_from_control_en3_vp <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[8]]])
p_var_from_control_en3_ae <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[9]]])
p_var_from_control_en4_all <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[10]]])
p_var_from_control_en4_endemism <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[11]]])
p_var_from_control_en4_threat <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[12]]])
p_var_from_control_en4_small <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[13]]])
p_var_from_control_en5_composites <- p_var_from_control  %+% 
  filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])
p_var_from_control_en6_norm_all <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[15]]])
p_var_from_control_en6_norm_endemism <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[16]]])
p_var_from_control_en6_norm_threat <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[17]]])
p_var_from_control_en6_norm_small <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[18]]])
p_var_from_control_all <- p_var_from_control %+% filter(results_combo, bd_input %in% runs[ensembles_list[[19]]])


p_var_from_control_en1_types
p_var_from_control_en1_types_b
p_var_from_control_en2_taxa_all
p_var_from_control_en2_taxa_endemism
p_var_from_control_en2_taxa_threat
p_var_from_control_en2_taxa_small
p_var_from_control_en3_mb
p_var_from_control_en3_vp
p_var_from_control_en3_ae
p_var_from_control_en4_all
p_var_from_control_en4_endemism
p_var_from_control_en4_threat
p_var_from_control_en4_small
p_var_from_control_en5_composites
p_var_from_control_en6_norm_all
p_var_from_control_en6_norm_endemism
p_var_from_control_en6_norm_threat
p_var_from_control_en6_norm_small
p_var_from_control_all







```

```{r coeff_var}
# ---------------------------------------------------------
# coefficient of variation
# ---------------------------------------------------------
p_cv_bd_loss_base <- p_results_combo_base %+% 
  labs(title = "Variation in biodiversity loss", subtitle = "As coefficient of variation (sd/mean)", caption = NULL) + 
  ylab("Coefficient of Variation of \nUnprotected Biodiversity Loss")

p_cv_bd_loss <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs) + 
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss, color = mod_spec), position = position_dodge(0.6))

# names(results_combo)

# subsets
p_cv_bd_loss_en1_types <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en1_types]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en1_types, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en1_types_b <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en1_types_b]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en1_types_b, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en2_taxa_all <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en2_taxa_all]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en2_taxa_all, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en2_taxa_endemism <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en2_taxa_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en2_taxa_endemism, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en2_taxa_threat <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en2_taxa_threat]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en2_taxa_threat, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en2_taxa_small <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en2_taxa_small]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en2_taxa_small, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en3_mb <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en3_mb]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en3_mb, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en3_vp <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en3_vp]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en3_vp, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en3_ae <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en3_ae]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en3_ae, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en4_all <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en4_all]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en4_all, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en4_endemism <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en4_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en4_endemism, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en4_threat <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en4_threat]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en4_threat, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en4_small <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en4_small]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en4_small, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en5_composites <- p_cv_bd_loss_base %+% 
  filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en5_composites, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en6_norm_all <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en6_norm_all]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en6_norm_all, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en6_norm_endemism <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en6_norm_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en6_norm_endemism, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en6_norm_threat <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en6_norm_threat]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en6_norm_threat, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en6_norm_small <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$en6_norm_small]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_en6_norm_small, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_all <- p_cv_bd_loss_base %+% 
  filter(results_combo, bd_input %in% runs[ensembles_list$all]) +
  geom_point(mapping = aes(x = bd_input, y = cv_bd_loss_all, color = mod_spec), position = position_dodge(0.6))

p_cv_bd_loss_en1_types
p_cv_bd_loss_en1_types_b
p_cv_bd_loss_en2_taxa_all
p_cv_bd_loss_en2_taxa_endemism
p_cv_bd_loss_en2_taxa_threat
p_cv_bd_loss_en2_taxa_small
p_cv_bd_loss_en3_mb
p_cv_bd_loss_en3_vp
p_cv_bd_loss_en3_ae
p_cv_bd_loss_en4_all
p_cv_bd_loss_en4_endemism
p_cv_bd_loss_en4_threat
p_cv_bd_loss_en4_small
p_cv_bd_loss_en5_composites
p_cv_bd_loss_en6_norm_all
p_cv_bd_loss_en6_norm_endemism
p_cv_bd_loss_en6_norm_threat
p_cv_bd_loss_en6_norm_small
p_cv_bd_loss_all

# p_cv_bd_loss_en1 + facet_grid(cols = vars(mod_spec))#, scales = "free")
# p_cv_bd_loss_en1 + facet_wrap(vars(mod_spec), nrow = 2, ncol = 2)#, scales = "free")
# p_cv_bd_loss_en1 


```


```{r sd_se}
# ---------------------------------------------------------
# standard deviation
# ---------------------------------------------------------
p_bd_loss_sd <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs) + 
  geom_point(mapping = aes(x = bd_input, y = sd_bd_loss, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Variation in biodiversity loss in conversion areas selected by tradeoff model", 
       subtitle = NULL, caption = NULL) +
  ylab("Standard Deviation of Biodiversity Loss")
# p_bd_loss_sd

# ---------------------------------------------------------
# standard error
# ---------------------------------------------------------
p_bd_loss_se <- p_results_combo_base %+% 
  filter(results_combo, bd_input %in% runs) + 
  geom_point(mapping = aes(x = bd_input, y = se_bd_loss, color = mod_spec), position = position_dodge(0.6)) +
  labs(title = "Variation in biodiversity loss in conversion areas selected by tradeoff model", 
       subtitle = NULL, caption = NULL) +
  ylab("Standard Error of Biodiversity Loss")

```

```{r area_conv_ggplot}
# ---------------------------------------------------------
# area converted
# ---------------------------------------------------------
p_area_converted <- p_results_combo_base + 
  geom_point(mapping = aes(x = bd_input, y = area_conv/10000, color = mod_spec), position = position_dodge(0.6)) +
  # labs(title = "Area converted by tradeoff model", 
  #      subtitle = "for each controlling biodiversity input layer", caption = NULL) +
  ylab(
    expression("Area Converted (10"^{4}*" km"^{2}*")")
       ) + xlab(NULL)

# p_area_converted

p_area_converted_en1_types <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[1]]])
p_area_converted_en1_types_b <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[2]]])
p_area_converted_en2_taxa_all <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[3]]])
p_area_converted_en2_taxa_endemism <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[4]]])
p_area_converted_en2_taxa_threat <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[5]]])
p_area_converted_en2_taxa_small <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[6]]])
p_area_converted_en3_mb <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[7]]])
p_area_converted_en3_vp <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[8]]])
p_area_converted_en3_ae <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[9]]])
p_area_converted_en4_all <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[10]]])
p_area_converted_en4_endemism <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[11]]])
p_area_converted_en4_threat <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[12]]])
p_area_converted_en4_small <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[13]]])
p_area_converted_en5_composites <- p_area_converted %+% 
  filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]])
p_area_converted_en6_norm_all <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[15]]])
p_area_converted_en6_norm_endemism <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[16]]])
p_area_converted_en6_norm_threat <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[17]]])
p_area_converted_en6_norm_small <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[18]]])
p_area_converted_all <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[19]]])


p_area_converted_en1_types
p_area_converted_en1_types_b
p_area_converted_en2_taxa_all
p_area_converted_en2_taxa_endemism
p_area_converted_en2_taxa_threat
p_area_converted_en2_taxa_small
p_area_converted_en3_mb
p_area_converted_en3_vp
p_area_converted_en3_ae
p_area_converted_en4_all
p_area_converted_en4_endemism
p_area_converted_en4_threat
p_area_converted_en4_small
p_area_converted_en5_composites
p_area_converted_en6_norm_all
p_area_converted_en6_norm_endemism
p_area_converted_en6_norm_threat
p_area_converted_en6_norm_small
p_area_converted_all

```

```{r overlap_ggplots}
# ---------------------------------------------------------
# mean overlap
# ---------------------------------------------------------
head(overlap_combo)

p_overlap_combo_base <- ggplot(data = overlap_combo) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Biodiversity Input") + ylab("Mean Percent Overlap \nBetween Converted Areas") + 
  #ylim(-0.1, 1.2) +
  coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  labs(title = "Average overlap", 
       subtitle = "between each biodiversity input and the group",
       caption = "Error bars represent 95% confidence intervals") + 
  # scale_color_manual(name = "Model Specifications",
  #                    labels = c("eq" = "Equal Weights",
  #                               "bd50_y50" = "50% on Biodiversity, \n50% Yield",
  #                               "bd100" = "100% on Biodiversity"),
  #                    values = c("eq" = hue_pal()(3)[1], #"red"
  #                               "bd50_y50" = hue_pal()(3)[3], #"blue"
  #                               "bd100" = hue_pal()(3)[2])) # "green"
  scale_color_manual(name = "Weights",
                     labels = c("bd100" = "b",
                                "bd50_y50" = "by",
                                "eq" = "byct"),
                     values = c("all" = "black",
                                "bd100" = hue_pal()(3)[2], # "green"
                                "bd50_y50" = hue_pal()(3)[3], #"blue"
                                "eq" = hue_pal()(3)[1])) #"red"

  
filter(overlap_combo, bd_input %in% runs[ensembles_list$en1_types])

p_overlap_combo_mean <- 
  p_overlap_combo_base +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, ymin = mean_overlap - 1.96*se_overlap, ymax = mean_overlap + 1.96*se_overlap, color = mod_spec), width = 0.4, position = position_dodge(0.6))


p_mean_overlap_en1_types <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en1_types]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en1_types, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en1_types - 1.96*se_overlap_en1_types, 
                              ymax = mean_overlap_en1_types + 1.96*se_overlap_en1_types, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en1_types_b <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en1_types_b]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en1_types_b, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en1_types_b - 1.96*se_overlap_en1_types_b, 
                              ymax = mean_overlap_en1_types_b + 1.96*se_overlap_en1_types_b, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en2_taxa_all <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en2_taxa_all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en2_taxa_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en2_taxa_all - 1.96*se_overlap_en2_taxa_all, 
                              ymax = mean_overlap_en2_taxa_all + 1.96*se_overlap_en2_taxa_all, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en2_taxa_endemism <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en2_taxa_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en2_taxa_endemism, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en2_taxa_endemism - 1.96*se_overlap_en2_taxa_endemism, 
                              ymax = mean_overlap_en2_taxa_endemism + 1.96*se_overlap_en2_taxa_endemism, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en2_taxa_threat <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en2_taxa_threat]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en2_taxa_threat, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en2_taxa_threat - 1.96*se_overlap_en2_taxa_threat, 
                              ymax = mean_overlap_en2_taxa_threat + 1.96*se_overlap_en2_taxa_threat, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en2_taxa_small <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en2_taxa_small]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en2_taxa_small, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en2_taxa_small - 1.96*se_overlap_en2_taxa_small, 
                              ymax = mean_overlap_en2_taxa_small + 1.96*se_overlap_en2_taxa_small, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en3_mb <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en3_mb]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en3_mb, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en3_mb - 1.96*se_overlap_en3_mb, 
                              ymax = mean_overlap_en3_mb + 1.96*se_overlap_en3_mb, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en3_vp <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en3_vp]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en3_vp, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en3_vp - 1.96*se_overlap_en3_vp, 
                              ymax = mean_overlap_en3_vp + 1.96*se_overlap_en3_vp, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en3_ae <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en3_ae]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en3_ae, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en3_ae - 1.96*se_overlap_en3_ae, 
                              ymax = mean_overlap_en3_ae + 1.96*se_overlap_en3_ae, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en4_all <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en4_all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en4_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en4_all - 1.96*se_overlap_en4_all, 
                              ymax = mean_overlap_en4_all + 1.96*se_overlap_en4_all, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en4_endemism <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en4_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en4_endemism, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en4_endemism - 1.96*se_overlap_en4_endemism, 
                              ymax = mean_overlap_en4_endemism + 1.96*se_overlap_en4_endemism, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en4_threat <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en4_threat]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en4_threat, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en4_threat - 1.96*se_overlap_en4_threat, 
                              ymax = mean_overlap_en4_threat + 1.96*se_overlap_en4_threat, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en4_small <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en4_small]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en4_small, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en4_small - 1.96*se_overlap_en4_small, 
                              ymax = mean_overlap_en4_small + 1.96*se_overlap_en4_small, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en5_composites <- p_overlap_combo_base  %+% 
  filter(mutate(overlap_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en5_composites, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en5_composites - 1.96*se_overlap_en5_composites, 
                              ymax = mean_overlap_en5_composites + 1.96*se_overlap_en5_composites, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en6_norm_all <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en6_norm_all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en6_norm_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en6_norm_all - 1.96*se_overlap_en6_norm_all, 
                              ymax = mean_overlap_en6_norm_all + 1.96*se_overlap_en6_norm_all, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en6_norm_endemism <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en6_norm_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en6_norm_endemism, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en6_norm_endemism - 1.96*se_overlap_en6_norm_endemism, 
                              ymax = mean_overlap_en6_norm_endemism + 1.96*se_overlap_en6_norm_endemism, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en6_norm_threat <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en6_norm_threat]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en6_norm_threat, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en6_norm_threat - 1.96*se_overlap_en6_norm_threat, 
                              ymax = mean_overlap_en6_norm_threat + 1.96*se_overlap_en6_norm_threat, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_en6_norm_small <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en6_norm_small]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en6_norm_small, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en6_norm_small - 1.96*se_overlap_en6_norm_small, 
                              ymax = mean_overlap_en6_norm_small + 1.96*se_overlap_en6_norm_small, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_overlap_all <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_all - 1.96*se_overlap_all, 
                              ymax = mean_overlap_all + 1.96*se_overlap_all, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))


match("mean_overlap_en1_types", names(overlap_combo))
overlap_combo[1:4, c(1:10, 64, 65)]
mean(c(NA, 0.5609057, 0.5199669, 0.5817741), na.rm = TRUE)
mean(c(0.8732523    ,     0.4988029  ,    0.5460377     ,    0.6109190))

p_overlap_combo_mean

p_mean_overlap_en1_types
p_mean_overlap_en1_types_b
p_mean_overlap_en2_taxa_all
p_mean_overlap_en2_taxa_endemism
p_mean_overlap_en2_taxa_threat
p_mean_overlap_en2_taxa_small
p_mean_overlap_en3_mb
p_mean_overlap_en3_vp
p_mean_overlap_en3_ae
p_mean_overlap_en4_all
p_mean_overlap_en4_endemism
p_mean_overlap_en4_threat
p_mean_overlap_en4_small
p_mean_overlap_en5_composites
p_mean_overlap_en6_norm_all
p_mean_overlap_en6_norm_endemism
p_mean_overlap_en6_norm_threat
p_mean_overlap_en6_norm_small
p_mean_overlap_all
# 

# 
# p_mean_overlap_plot_grid <- 
#   cowplot::plot_grid(p_mean_overlap_en1 + labs(title = NULL, subtitle = NULL, caption = NULL), 
#                      p_mean_overlap_en2 + labs(title = NULL, subtitle = NULL, caption = NULL), 
#                      p_mean_overlap_en3 + labs(title = NULL, subtitle = NULL, caption = NULL), 
#                      p_mean_overlap_en4 + labs(title = NULL, subtitle = NULL, caption = NULL), 
#                      labels = c('en1', 'en2', 'en3', 'en4'), label_size = 12)
# 
# p_mean_overlap_plot_grid




```

```{r jaccard_ggplots}
# ---------------------------------------------------------
# mean jaccard
# ---------------------------------------------------------
head(jaccard_combo)

p_jaccard_combo_base <- ggplot(data = jaccard_combo) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab(NULL) + ylab("Mean Jaccard Similarity") + 
  #ylim(0, 1.0) +
  coord_cartesian(ylim=c(0, 1.0)) + #scale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  # labs(title = "Mean Jaccard Similarity", 
  #      subtitle = "between each biodiversity input and the group",
  #      caption = "Error bars represent 95% confidence intervals") + 
  # scale_color_manual(name = "Model Specifications",
  #                    labels = c("eq" = "Equal Weights",
  #                               "bd50_y50" = "50% on Biodiversity, \n50% Yield",
  #                               "bd100" = "100% on Biodiversity"),
  #                    values = c("eq" = hue_pal()(3)[1], #"red"
  #                               "bd50_y50" = hue_pal()(3)[3], #"blue"
  #                               "bd100" = hue_pal()(3)[2])) # "green"
  scale_color_manual(name = "Weights",
                     labels = c("bd100" = "b",
                                "bd50_y50" = "by",
                                "eq" = "byct"),
                     values = c("all" = "black",
                                "bd100" = hue_pal()(3)[2], # "green"
                                "bd50_y50" = hue_pal()(3)[3], #"blue"
                                "eq" = hue_pal()(3)[1])) #"red"


filter(jaccard_combo, bd_input %in% runs[ensembles_list$en1_types])

p_jaccard_combo_mean <- 
  p_jaccard_combo_base +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, ymin = mean_jaccard - 1.96*se_jaccard, ymax = mean_jaccard + 1.96*se_jaccard, color = mod_spec), width = 0.4, position = position_dodge(0.6))


p_mean_jaccard_en1_types <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en1_types]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en1_types, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en1_types - 1.96*se_jaccard_en1_types, 
                              ymax = mean_jaccard_en1_types + 1.96*se_jaccard_en1_types, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en1_types_b <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en1_types_b]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en1_types_b, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en1_types_b - 1.96*se_jaccard_en1_types_b, 
                              ymax = mean_jaccard_en1_types_b + 1.96*se_jaccard_en1_types_b, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en2_taxa_all <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en2_taxa_all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en2_taxa_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en2_taxa_all - 1.96*se_jaccard_en2_taxa_all, 
                              ymax = mean_jaccard_en2_taxa_all + 1.96*se_jaccard_en2_taxa_all, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en2_taxa_endemism <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en2_taxa_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en2_taxa_endemism, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en2_taxa_endemism - 1.96*se_jaccard_en2_taxa_endemism, 
                              ymax = mean_jaccard_en2_taxa_endemism + 1.96*se_jaccard_en2_taxa_endemism, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en2_taxa_threat <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en2_taxa_threat]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en2_taxa_threat, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en2_taxa_threat - 1.96*se_jaccard_en2_taxa_threat, 
                              ymax = mean_jaccard_en2_taxa_threat + 1.96*se_jaccard_en2_taxa_threat, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en2_taxa_small <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en2_taxa_small]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en2_taxa_small, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en2_taxa_small - 1.96*se_jaccard_en2_taxa_small, 
                              ymax = mean_jaccard_en2_taxa_small + 1.96*se_jaccard_en2_taxa_small, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en3_mb <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en3_mb]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en3_mb, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en3_mb - 1.96*se_jaccard_en3_mb, 
                              ymax = mean_jaccard_en3_mb + 1.96*se_jaccard_en3_mb, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en3_vp <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en3_vp]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en3_vp, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en3_vp - 1.96*se_jaccard_en3_vp, 
                              ymax = mean_jaccard_en3_vp + 1.96*se_jaccard_en3_vp, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en3_ae <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en3_ae]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en3_ae, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en3_ae - 1.96*se_jaccard_en3_ae, 
                              ymax = mean_jaccard_en3_ae + 1.96*se_jaccard_en3_ae, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en4_all <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en4_all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en4_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en4_all - 1.96*se_jaccard_en4_all, 
                              ymax = mean_jaccard_en4_all + 1.96*se_jaccard_en4_all, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en4_endemism <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en4_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en4_endemism, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en4_endemism - 1.96*se_jaccard_en4_endemism, 
                              ymax = mean_jaccard_en4_endemism + 1.96*se_jaccard_en4_endemism, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en4_threat <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en4_threat]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en4_threat, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en4_threat - 1.96*se_jaccard_en4_threat, 
                              ymax = mean_jaccard_en4_threat + 1.96*se_jaccard_en4_threat, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en4_small <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en4_small]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en4_small, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en4_small - 1.96*se_jaccard_en4_small, 
                              ymax = mean_jaccard_en4_small + 1.96*se_jaccard_en4_small, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en5_composites <- p_jaccard_combo_base  %+% 
  filter(mutate(jaccard_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), 
         bd_input %in% runs[ensembles_list[[14]]]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en5_composites, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en5_composites - 1.96*se_jaccard_en5_composites, 
                              ymax = mean_jaccard_en5_composites + 1.96*se_jaccard_en5_composites, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en6_norm_all <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en6_norm_all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en6_norm_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en6_norm_all - 1.96*se_jaccard_en6_norm_all, 
                              ymax = mean_jaccard_en6_norm_all + 1.96*se_jaccard_en6_norm_all, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en6_norm_endemism <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en6_norm_endemism]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en6_norm_endemism, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en6_norm_endemism - 1.96*se_jaccard_en6_norm_endemism, 
                              ymax = mean_jaccard_en6_norm_endemism + 1.96*se_jaccard_en6_norm_endemism, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en6_norm_threat <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en6_norm_threat]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en6_norm_threat, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en6_norm_threat - 1.96*se_jaccard_en6_norm_threat, 
                              ymax = mean_jaccard_en6_norm_threat + 1.96*se_jaccard_en6_norm_threat, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_en6_norm_small <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$en6_norm_small]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_en6_norm_small, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_en6_norm_small - 1.96*se_jaccard_en6_norm_small, 
                              ymax = mean_jaccard_en6_norm_small + 1.96*se_jaccard_en6_norm_small, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))

p_mean_jaccard_all <- p_jaccard_combo_base %+% 
  filter(jaccard_combo, bd_input %in% runs[ensembles_list$all]) +
  geom_point(mapping = aes(x = bd_input, y = mean_jaccard_all, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_jaccard_all - 1.96*se_jaccard_all, 
                              ymax = mean_jaccard_all + 1.96*se_jaccard_all, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))


which("mean_jaccard_en1_types" == names(jaccard_combo))
match("mean_jaccard_en1_types", names(jaccard_combo))
jaccard_combo[1:4, c(1:10, 64, 65)]
mean(c(NA, 0.3616612  , 0.3322567 , 0.3801228), na.rm = TRUE)

p_jaccard_combo_mean

p_mean_jaccard_en1_types
p_mean_jaccard_en1_types_b
p_mean_jaccard_en2_taxa_all
p_mean_jaccard_en2_taxa_endemism
p_mean_jaccard_en2_taxa_threat
p_mean_jaccard_en2_taxa_small
p_mean_jaccard_en3_mb
p_mean_jaccard_en3_vp
p_mean_jaccard_en3_ae
p_mean_jaccard_en4_all
p_mean_jaccard_en4_endemism
p_mean_jaccard_en4_threat
p_mean_jaccard_en4_small
p_mean_jaccard_en5_composites
p_mean_jaccard_en6_norm_all
p_mean_jaccard_en6_norm_endemism
p_mean_jaccard_en6_norm_threat
p_mean_jaccard_en6_norm_small
p_mean_jaccard_all
```




## MS Figures
### results
```{r}
# six original results elements, plus eight raw richness results
p_area_converted_en1_types
p_bd_loss_control_en1_types
p_mean_overlap_en1_types

p_area_converted_en5_composites
p_bd_loss_control_en5_composites
p_mean_overlap_en5_composites

p_mean_bd_loss_en1_types
p_cv_bd_loss_en1_types
p_var_from_control_en1_types


# four main raw richness results:
p_raw_all_richness_loss_en1_types
p_raw_endemism_richness_loss_en1_types
p_raw_threat_richness_loss_en1_types
p_raw_small_richness_loss_en1_types

# extra four raw richness losses
p_raw_threat_weighted_richness_loss_en1_types
p_raw_small_threat_richness_loss_en1_types
p_raw_small_zam_richness_loss_en1_types
p_raw_endemism_zam_richness_loss_en1_types


# all layers:
p_area_converted_all
p_bd_loss_control_all
p_mean_overlap_all

p_mean_bd_loss_all
p_cv_bd_loss_all
p_var_from_control_all


# four main raw richness results:
p_raw_all_richness_loss_en1_types
p_raw_endemism_richness_loss_en1_types
p_raw_threat_richness_loss_en1_types
p_raw_small_richness_loss_en1_types

```

```{r *plot_themes}
theme <- theme(legend.position="none", 
               plot.margin = unit(c(0.7, 0.6, 0.2, 0), "cm"),
               plot.title = element_blank(),
               plot.subtitle = element_blank(),
               plot.caption = element_blank(),
               axis.title.x = element_blank(),
               #axis.title.x = element_text(size=9),
               axis.title.y = element_text(size=9),
               axis.text.x = element_text(size=7)
               )

theme_no_y <- theme + theme(axis.title.y = element_blank(), 
                            #axis.ticks.y = element_blank(),
                            axis.text.y = element_blank())
# theme_no_y <- theme + theme(axis.title.y = element_blank())

theme_raw_main <- theme(legend.position="none", 
               plot.margin = unit(c(0.7, 0.6, 0.2, 0), "cm"),
               plot.title = element_blank(),
               plot.subtitle = element_blank(),
               plot.caption = element_blank(),
               axis.title.x = element_blank(),
               #axis.title.x = element_text(size=9),
               axis.title.y = element_text(size=9),
               axis.text.x = element_text(size=8)
               )

my_theme <- theme(legend.position="none", 
                  plot.margin = unit(c(0.5, 1, 0.5, 0.5), "cm"), 
                  plot.title = element_text(size=11),
                  plot.subtitle = element_text(size=9),
                  axis.title.x = element_text(size=9),
                  axis.title.y = element_text(size=9)
                  )

my_theme_no_titles <- theme(legend.position="none", plot.margin = unit(c(0.5, 1, 0.5, 0.5), "cm"),
                  plot.title = element_blank(),
                  plot.subtitle = element_blank(),
                  plot.caption = element_blank(),
                  axis.title.x = element_blank(),
                  #axis.title.x = element_text(size=9),
                  axis.title.y = element_text(size=9)
                  )





result_type <- list(
  "area" = "p_area_converted_",
  "bd_loss_control" = "p_bd_loss_control_",
  "overlap" = "p_mean_overlap_",
  "jaccard" = "p_mean_jaccard_",
  
  "mean_bd_loss" = "p_mean_bd_loss_",
  "cv" = "p_cv_bd_loss_",
  "var" = "p_var_from_control_",
  
  "raw_all" = "p_raw_all_richness_loss_",
  "raw_endemism" = "p_raw_endemism_richness_loss_",
  "raw_threat" = "p_raw_threat_richness_loss_",
  "raw_small" = "p_raw_small_richness_loss_"
)

names(ensembles_list)[c(1, 5, 7, 12, 14)] # main
names(ensembles_list)[c(1:6)] # extras, types+taxa
names(ensembles_list)[c(7:9)] # extras, methods
names(ensembles_list)[c(10:13)] # extras, resolution
names(ensembles_list)[c(15:18)] # extras, normalization
# run the codes for 

indices <- list(
  "main" = c(1, 5, 7, 12, 14),
  "types_taxa" = c(1:6),
  "taxa" = c(3:6),
  "methods" = c(7:9),
  "resolution" = c(10:13),
  "normalization" = c(15, 16, 17, 18)
)

ensembles_list[indices$main]
ensembles_list[indices$types_taxa]
ensembles_list[indices$methods]
ensembles_list[indices$resolution]
ensembles_list[indices$normalization]
```


```{r save_results_plots}
p_bd_loss_control_en1_types + my_theme_no_titles
# function to print results plots



save_results_plots <- function(i, theme = my_theme, png_width, png_height, label = "") {
  
  results_plot_grid <- plot_grid(
    eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[i]))) + theme,
    eval(parse(text = paste0("p_bd_loss_control_", names(ensembles_list)[i]))) + theme,
    eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[i]))) + theme, 
    eval(parse(text = paste0("p_mean_bd_loss_", names(ensembles_list)[i]))) + theme, 
    eval(parse(text = paste0("p_cv_bd_loss_", names(ensembles_list)[i]))) + theme,
    eval(parse(text = paste0("p_var_from_control_", names(ensembles_list)[i]))) + theme,
    labels = "auto")
  
  results_legend_b <- get_legend(
    eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[i]))) + 
      theme(legend.position = "bottom"))
  
  png(paste0(p_plots, "/doc_figures/", names(ensembles_list)[i], "_results", label, ".png"), width = png_width, height = png_height, units = "in", res = 300)
  #pdf(paste0(p_plots, "/doc_figures/", names(ensembles_list)[i], "_results", label, ".pdf"), width = 12, height = 9) # "en1"
  print(plot_grid(results_plot_grid, results_legend_b, 
                  ncol = 1, rel_heights = c(1, .1)))
  dev.off()
}

# these were originally for 
# 1.	en1
# 2.	en1_types **
# 3.	en1_taxa_threat **
# 4.	en1_taxa_all **
# 5.	en2
# 6.	en2_mb ** 
# 7.	en2_vp **
# 8.	en3
# 9.	en3_all **
# 10.	en3_threat ** 
# 11.	en3_small **
# 12.	en3_small_threat ** 
# 13.	en4 **
# 14.	en_norm **
# 15.	en_l_norm
# 16.	all

names(ensembles_list)
ensembles_list[c(2:4, 6:7, 9:15)]
for (i in c(2:4, 6:7, 9:15)) {save_results_plots(i, png_width = 12, png_height = 9, 
                                                 theme = my_theme)}

for (i in c(2:4, 6:7, 9:15)) {save_results_plots(i, png_width = 12, png_height = 9,
                                               theme = my_theme_no_titles, 
                                               label = "_combo")}


```

```{r *minimal+SI_results_plots}
save_results_plots_minimal <- function(i, theme = my_theme, png_width, png_height, label = "",
                                       main_text = FALSE, SI = FALSE, raw_main = FALSE, raw_extra = FALSE) {
  # build plots
  results_plot_grid_main <- plot_grid(
      eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[i]))) + theme, 
      eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[i]))) + theme,
      eval(parse(text = paste0("p_raw_all_richness_loss_", names(ensembles_list)[i]))) + theme, 
      eval(parse(text = paste0("p_raw_endemism_richness_loss_", names(ensembles_list)[i]))) + theme, 
      align = "h", 
      nrow = 1, labels = c("a", "b", "c", "d", "e")
  )
  
  raw_richness_results_plot_grid_main <- plot_grid(
      eval(parse(text = paste0("p_raw_all_richness_loss_", names(ensembles_list)[i]))) + theme + 
        theme(plot.margin = unit(c(0.7, 0.6, 0.2, 0.5), "cm")), 
      eval(parse(text = paste0("p_raw_endemism_richness_loss_", names(ensembles_list)[i]))) + theme, 
      eval(parse(text = paste0("p_raw_threat_richness_loss_", names(ensembles_list)[i]))) + theme,
      eval(parse(text = paste0("p_raw_small_richness_loss_", names(ensembles_list)[i]))) + theme,
      align = "h", 
      nrow = 1, labels = c("a", "b", "c", "d")
  )

  raw_richness_results_plot_grid_extra <- plot_grid(
      eval(parse(text = paste0("p_raw_threat_weighted_richness_loss_", names(ensembles_list)[i]))) + theme +
        theme(plot.margin = unit(c(0.7, 0.6, 0.2, 0.5), "cm")), 
      eval(parse(text = paste0("p_raw_small_threat_richness_loss_", names(ensembles_list)[i]))) + theme, 
      eval(parse(text = paste0("p_raw_small_zam_richness_loss_", names(ensembles_list)[i]))) + theme,
      eval(parse(text = paste0("p_raw_endemism_zam_richness_loss_", names(ensembles_list)[i]))) + theme,
      align = "h", 
      nrow = 1, labels = c("a", "b", "c", "d")
  )
  
  results_plot_grid_SI <- plot_grid(
    eval(parse(text = paste0("p_bd_loss_control_", names(ensembles_list)[i]))) + theme +
      theme(plot.margin = unit(c(0.7, 0.6, 0.2, 0.5), "cm")), 
    eval(parse(text = paste0("p_mean_bd_loss_", names(ensembles_list)[i]))) + theme, 
    eval(parse(text = paste0("p_cv_bd_loss_", names(ensembles_list)[i]))) + theme,
    eval(parse(text = paste0("p_var_from_control_", names(ensembles_list)[i]))) + theme,
    align = "h", 
    nrow = 1, labels = c("a", "b", "c", "d")
  )
  
  results_legend_b <- get_legend(
    eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[i]))) + 
      theme(legend.position = "bottom", legend.margin = margin(b = 3)))
  
  png(paste0(p_plots, "/ms_fig_scatter_by_en/", names(ensembles_list)[i], "_results", label, ".png"), 
      width = png_width, height = png_height, units = "in", res = 300)
  # print the plot I want to use, depending on main_text argument
  
  if (main_text) {
    print(plot_grid(results_plot_grid_main, results_legend_b, 
                    ncol = 1, rel_heights = c(1, .1)))
  } 
  
  if (SI) {
    print(plot_grid(results_plot_grid_SI, results_legend_b, 
                    ncol = 1, rel_heights = c(1, .1)))
  }
  
  if (raw_main) {
    print(plot_grid(raw_richness_results_plot_grid_main, results_legend_b, 
                    ncol = 1, rel_heights = c(1, .1)))
  }  
  
  if (raw_extra) {
    print(plot_grid(raw_richness_results_plot_grid_extra, results_legend_b, 
                    ncol = 1, rel_heights = c(1, .1)))
  }
  
  dev.off()
}

ensembles_list[c(2:4, 6:7, 9:15)]
names(ensembles_list)[14]

# run the for loop

for (i in 1:18) { # i in 1:18
  # save_results_plots_minimal(i, label = "_main_v2", png_width = 9, png_height = 2.75,
  #                            theme = theme, main_text = TRUE)
  # 
  # save_results_plots_minimal(i, label = "_raw_main", png_width = 9, png_height = 2.75,
  #                            theme = theme, raw_main = TRUE)
  # 
  save_results_plots_minimal(i, label = "_raw_extra", png_width = 9, png_height = 2.75,
                             theme = theme, raw_extra = TRUE)

  # save_results_plots_minimal(i, label = "_SI",  png_width = 9, png_height = 2.75,
  #                            theme = theme, SI = TRUE)
}



names(ensembles_list)
# individual ensembles, for testing:
# 5
save_results_plots_minimal(1, label = "_main", png_width = 15, png_height = 3.5, 
                             theme = my_theme_no_titles, main_text = TRUE)

save_results_plots_minimal(14, label = "_main", png_width = 9, png_height = 2.75, 
                             theme = theme, main_text = TRUE)
  
# 4
save_results_plots_minimal(1, label = "_raw_main", png_width = 12, png_height = 3.5, 
                           theme = my_theme_no_titles, raw_main = TRUE)

# 4
save_results_plots_minimal(1, label = "_raw_extra", png_width = 13, png_height = 4, 
                           theme = my_theme_no_titles, raw_extra = TRUE)

# 3
save_results_plots_minimal(1, label = "_SI", png_width = 10, png_height = 3, 
                           theme = my_theme_no_titles, SI = TRUE)


# composites i = 14
ensembles_list[14]













#
#
#
# unused:

# without titles
for (i in 1:18) {
  save_results_plots_minimal(i, label = "_main", png_width = 10, png_height = 4, 
                             theme = my_theme_no_titles,
                             main_text = TRUE)
}

for (i in 1:18) {
  save_results_plots_minimal(i, label = "_main_3", png_width = 10, png_height = 4, 
                             theme = my_theme_no_titles,
                             main_text = TRUE)
}

for (i in 1:18) {
  save_results_plots_minimal(i, label = "_SI", png_width = 10, png_height = 4, 
                             theme = my_theme_no_titles,
                             main_text = FALSE)
}

# with titles
for (i in c(2:4, 6:7, 9:15)) {
  save_results_plots_minimal(i, label = "_main_w_titles", png_width = 10, png_height = 5, 
                             theme = my_theme,
                             main_text = TRUE)
}

for (i in c(2:4, 6:7, 9:15)) {
  save_results_plots_minimal(i, label = "_SI_w_titles", png_width = 10, png_height = 5, 
                             theme = my_theme,
                             main_text = FALSE)
}


# ------------------------------------------------------------------
#### without 10p_bd
# ------------------------------------------------------------------
for (i in c(2:4, 6:7, 9:15)) {
  save_results_plots_minimal(i, label = "_main_no10p", png_width = 10, png_height = 4, 
                             theme = my_theme_no_titles,
                             main_text = TRUE)
}

for (i in c(2:4, 6:7, 9:15)) {
  save_results_plots_minimal(i, label = "_SI_no10p", png_width = 10, png_height = 4, 
                             theme = my_theme_no_titles,
                             main_text = FALSE)
}


```

```{r *save_plots_by_result}
save_plots_by_result <- function(indices, result_type, label, 
                                 png_width, png_height, theme, indices = indices){
  
  theme_no_y <- theme + theme(axis.title.y = element_blank())

if (length(indices) == 3) {
results_plot_grid <- plot_grid(
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[1]]))) + theme,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[2]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[3]]))) + theme_no_y,

    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )
}

if (length(indices) == 4) {
results_plot_grid <- plot_grid(
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[1]]))) + theme,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[2]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[3]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[4]]))) + theme_no_y,

    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )
}

if (length(indices) == 5) {
results_plot_grid <- plot_grid(
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[1]]))) + theme,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[2]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[3]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[4]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[5]]))) + theme_no_y,

    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )
}

if (length(indices) == 6) {
results_plot_grid <- plot_grid(
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[1]]))) + theme,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[2]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[3]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[4]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[5]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[6]]))) + theme_no_y,

    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )
}

if (length(indices) == 7) {
results_plot_grid <- plot_grid(
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[1]]))) + theme,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[2]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[3]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[4]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[5]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[6]]))) + theme_no_y,
    eval(parse(text = paste0(result_type, names(ensembles_list)[indices[7]]))) + theme_no_y,

    nrow = 1, labels = c("a", "b", "c", "d", "e", "f", "g")
    )
}

results_legend_bottom <- get_legend(
  eval(parse(text = paste0(result_type, names(ensembles_list)[indices[1]]))) + 
    theme(legend.position = "bottom"))

png(paste0(p_plots, "/ms_fig_scatter_by_result/", label, ".png"), 
    width = png_width, height = png_height, units = "in", res = 300)
print(plot_grid(results_plot_grid, results_legend_bottom, ncol = 1, rel_heights = c(1, .1)))
dev.off()

}




for (i in seq_along(result_type)) {
  save_plots_by_result(indices = c(1, 5, 7, 12, 14), result_type = result_type[[i]], 
                     label = paste0(names(result_type)[i], "_results_main"),
                     png_width = 9, png_height = 2.75, theme = theme)#}
  
  save_plots_by_result(indices = c(1:6), result_type = result_type[[i]], 
                     label = paste0(names(result_type)[i], "_results_types+taxa"),
                     png_width = 15, png_height = 4, theme = theme)
  save_plots_by_result(indices = c(7:9), result_type = result_type[[i]], 
                     label = paste0(names(result_type)[i], "_results_methods"),
                     png_width = 15, png_height = 4)
  save_plots_by_result(indices = c(10:13), result_type = result_type[[i]], 
                     label = paste0(names(result_type)[i], "_results_resolution"),
                     png_width = 15, png_height = 4)
  save_plots_by_result(indices = c(15:18), result_type = result_type[[i]], 
                     label = paste0(names(result_type)[i], "_results_normalization"),
                     png_width = 15, png_height = 4)
}

# just overlap
save_plots_by_result(indices = c(1, 5, 7, 12, 14), result_type = result_type[[3]], 
                     label = paste0(names(result_type)[3], "_results_main_large"),
                     png_width = 8, png_height = 2)

# 



```

```{r *scatter_by_result_main}

# single overlap figure:
# maybe consider updating the theme x axis text to 7 from 8.
results_plot_grid_overlap <- plot_grid(
    eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[1]))) + theme + 
      theme(plot.margin = unit(c(0.7, 0.5, 0.2, 0.1), "cm")),
    
    eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[5]))) + theme_no_y +
      theme(plot.margin = unit(c(0.7, 0.5, 0.4, 0), "cm")),
    
    eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[7]))) + theme_no_y +
      theme(plot.margin = unit(c(0.7, 0.4, 0.3, 0), "cm")),
    
    eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[12]))) + theme_no_y +
      theme(plot.margin = unit(c(0.7, 0.9, 0.2, 0), "cm")),
    
    eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[14]))) + theme_no_y +
      theme(plot.margin = unit(c(0.7, 0.6, 0.2, 0), "cm")),
    
    align = "h", 
    rel_widths = c(1.2, 1, 1, .9, 1.2),
    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )

results_plot_grid_jaccard <- plot_grid(
    eval(parse(text = paste0("p_mean_jaccard_", names(ensembles_list)[1]))) + theme + 
      theme(plot.margin = unit(c(0.7, 0.5, 0.2, 0.1), "cm")),
    
    eval(parse(text = paste0("p_mean_jaccard_", names(ensembles_list)[5]))) + theme_no_y +
      theme(plot.margin = unit(c(0.7, 0.5, 0.4, 0), "cm")),
    
    eval(parse(text = paste0("p_mean_jaccard_", names(ensembles_list)[7]))) + theme_no_y +
      theme(plot.margin = unit(c(0.7, 0.4, 0.3, 0), "cm")),
    
    eval(parse(text = paste0("p_mean_jaccard_", names(ensembles_list)[12]))) + theme_no_y +
      theme(plot.margin = unit(c(0.7, 0.9, 0.2, 0), "cm")),
    
    eval(parse(text = paste0("p_mean_jaccard_", names(ensembles_list)[14]))) + theme_no_y +
      theme(plot.margin = unit(c(0.7, 0.6, 0.2, 0), "cm")),
    
    align = "h", 
    rel_widths = c(1.2, 1, 1, .9, 1.2),
    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )

# jaccard
png(paste0(p_plots, "/ms_fig_scatter_by_result/", "jaccard_results_main_large", ".png"), 
    width = 9, height = 2.5, 
    units = "in", res = 400)
print(plot_grid(results_plot_grid_jaccard, results_legend_bottom, 
                ncol = 1, rel_heights = c(1, .1)))
dev.off()


results_plot_grid_area_conv <- plot_grid(
    eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[1]))) + theme +
      ylim(20000, 50000) + theme(plot.margin = unit(c(0.7, 0.5, 0.2, 0.1), "cm")),
    
    eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[5]))) + theme_no_y +
      ylim(20000, 50000) + theme(plot.margin = unit(c(0.7, 0.5, 0.4, 0), "cm")),
    
    eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[7]))) + theme_no_y +
      ylim(20000, 50000) + theme(plot.margin = unit(c(0.7, 0.4, 0.3, 0), "cm")),
    
    eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[12]))) + theme_no_y +
      ylim(20000, 50000) + theme(plot.margin = unit(c(0.7, 0.9, 0.2, 0), "cm")),
    
    eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[14]))) + theme_no_y +
      ylim(20000, 50000) + theme(plot.margin = unit(c(0.7, 0.6, 0.2, 0), "cm")),
    
    align = "h", 
    rel_widths = c(1.2, 1, 1, .9, 1.2),
    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )

results_plot_grid_bd_loss_control <- plot_grid(
    eval(parse(text = paste0("p_bd_loss_control_", names(ensembles_list)[1]))) + theme +
      ylim(0, 0.071) + theme(plot.margin = unit(c(0.7, 0.5, 0.2, 0.1), "cm")),
    
    eval(parse(text = paste0("p_bd_loss_control_", names(ensembles_list)[5]))) + theme_no_y +
      ylim(0, 0.071) + theme(plot.margin = unit(c(0.7, 0.5, 0.4, 0), "cm")),
    
    eval(parse(text = paste0("p_bd_loss_control_", names(ensembles_list)[7]))) + theme_no_y +
      ylim(0, 0.071) + theme(plot.margin = unit(c(0.7, 0.4, 0.3, 0), "cm")),
    
    eval(parse(text = paste0("p_bd_loss_control_", names(ensembles_list)[12]))) + theme_no_y +
      ylim(0, 0.071) + theme(plot.margin = unit(c(0.7, 0.9, 0.2, 0), "cm")),
    
    eval(parse(text = paste0("p_bd_loss_control_", names(ensembles_list)[14]))) + theme_no_y +
      ylim(0, 0.071) + theme(plot.margin = unit(c(0.7, 0.6, 0.2, 0), "cm")),
    
    align = "h", 
    rel_widths = c(1.2, 1, 1, .9, 1.2),
    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )

results_plot_grid_raw_all <- plot_grid(
    eval(parse(text = paste0("p_raw_all_richness_loss_", names(ensembles_list)[1]))) + theme +
      ylim(11, 30) + theme(plot.margin = unit(c(0.7, 0.5, 0.2, 0.3), "cm")),
    
    eval(parse(text = paste0("p_raw_all_richness_loss_", names(ensembles_list)[5]))) + theme_no_y +
      ylim(11, 30) + theme(plot.margin = unit(c(0.7, 0.5, 0.4, 0), "cm")),
    
    eval(parse(text = paste0("p_raw_all_richness_loss_", names(ensembles_list)[7]))) + theme_no_y +
      ylim(11, 30) + theme(plot.margin = unit(c(0.7, 0.4, 0.3, 0), "cm")),
    
    eval(parse(text = paste0("p_raw_all_richness_loss_", names(ensembles_list)[12]))) + theme_no_y +
      ylim(11, 30) + theme(plot.margin = unit(c(0.7, 0.9, 0.2, 0), "cm")),
    
    eval(parse(text = paste0("p_raw_all_richness_loss_", names(ensembles_list)[14]))) + theme_no_y +
      ylim(11, 30) + theme(plot.margin = unit(c(0.7, 0.6, 0.2, 0), "cm")),
    
    align = "h", 
    rel_widths = c(1.2, 1, 1, .9, 1.2),
    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )

results_plot_grid_raw_endemism <- plot_grid(
    eval(parse(text = paste0("p_raw_endemism_richness_loss_", names(ensembles_list)[1]))) + theme +
      ylim(3, 9.3) + theme(plot.margin = unit(c(0.7, 0.5, 0.2, 0.1), "cm")),
    
    eval(parse(text = paste0("p_raw_endemism_richness_loss_", names(ensembles_list)[5]))) + theme_no_y +
      ylim(3, 9.3) + theme(plot.margin = unit(c(0.7, 0.5, 0.4, 0), "cm")),
    
    eval(parse(text = paste0("p_raw_endemism_richness_loss_", names(ensembles_list)[7]))) + theme_no_y +
      ylim(3, 9.3) + theme(plot.margin = unit(c(0.7, 0.4, 0.3, 0), "cm")),
    
    eval(parse(text = paste0("p_raw_endemism_richness_loss_", names(ensembles_list)[12]))) + theme_no_y +
      ylim(3, 9.3) + theme(plot.margin = unit(c(0.7, 0.9, 0.2, 0), "cm")),
    
    eval(parse(text = paste0("p_raw_endemism_richness_loss_", names(ensembles_list)[14]))) + theme_no_y +
      ylim(3, 9.3) + theme(plot.margin = unit(c(0.7, 0.6, 0.2, 0), "cm")),
    
    align = "h",
    rel_widths = c(1.2, 1, 1, .9, 1.2),
    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )

results_legend_bottom <- get_legend(
  eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[1]))) + 
    theme(legend.position = "bottom", legend.margin = margin(b = 3)))

# overlap
png(paste0(p_plots, "/ms_fig_scatter_by_result/", "overlap_results_main_large", ".png"), 
    width = 8, height = 2.5, 
    units = "in", res = 400)
print(plot_grid(results_plot_grid_overlap, results_legend_bottom, 
                ncol = 1, rel_heights = c(1, .1)))
dev.off()

# jaccard
png(paste0(p_plots, "/ms_fig_scatter_by_result/", "jaccard_results_main_large", ".png"), 
    width = 8, height = 2.5, 
    units = "in", res = 400)
print(plot_grid(results_plot_grid_jaccard, results_legend_bottom, 
                ncol = 1, rel_heights = c(1, .1)))
dev.off()

# area_conv
png(paste0(p_plots, "/ms_fig_scatter_by_result/", "area_conv_results_main_large", ".png"), 
    width = 8, height = 2.5, 
    units = "in", res = 400)
print(plot_grid(results_plot_grid_area_conv, results_legend_bottom,
                ncol = 1, rel_heights = c(1, .1)))
dev.off()

# percent_bd_loss
png(paste0(p_plots, "/ms_fig_scatter_by_result/", "bd_loss_control_results_main_large", ".png"), 
    width = 8, height = 2.5, 
    units = "in", res = 400)
print(plot_grid(results_plot_grid_bd_loss_control, results_legend_bottom, 
                ncol = 1, rel_heights = c(1, .1)))
dev.off()

# raw bd loss
png(paste0(p_plots, "/ms_fig_scatter_by_result/", "raw_all_results_main_large", ".png"), 
    width = 8, height = 2.5, 
    units = "in", res = 400)
print(plot_grid(results_plot_grid_raw_all, results_legend_bottom, 
                ncol = 1, rel_heights = c(1, .1)))
dev.off()

# raw endemism loss
png(paste0(p_plots, "/ms_fig_scatter_by_result/", "raw_endemism_results_main_large", ".png"), 
    width = 8, height = 2.5, 
    units = "in", res = 400)
print(plot_grid(results_plot_grid_raw_endemism, results_legend_bottom, 
                ncol = 1, rel_heights = c(1, .1)))
dev.off()


```

```{r indiv_overlaps}
theme_ind <- theme(legend.position="none", 
               plot.margin = unit(c(0.7, 0.7, 0.7, 0.7), "cm"),
               plot.title = element_blank(),
               plot.subtitle = element_blank(),
               plot.caption = element_blank(),
               axis.title.x = element_blank(),
               #axis.title.x = element_text(size=9),
               axis.title.y = element_text(size=9),
               axis.text.x = element_text(size=7)
               )
# --------------------------------------------------------------------------------------------------
# overlaps -----------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------

# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/ )
ov_melt <- overlap_combo %>% 
  filter(bd_input %in% runs[c(ensembles_list$en1_types)]#, mod_spec == "bd100"
         ) %>% 
  select(bd_input, mod_spec, runs[ensembles_list$en1_types]) %>%
  melt(variable.name = "pair", value.name = "overlap") %>%
  na.omit()

gg_ind_overlap <- ggplot(ov_melt, aes(x = bd_input, y = overlap, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Biodiversity Input") + ylab("Pairwise Percent Overlap \nBetween Converted Areas") #+ 
  #ylim(-0.1, 1.2) +
  #coord_cartesian(ylim=c(0, 1.0)) + #cale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  #labs(title = "Pairwise overlap")

gg_ind_overlap %+% filter(ov_melt, mod_spec == "bd100")
gg_ind_overlap %+% filter(ov_melt, mod_spec == "bd50_y50")
gg_ind_overlap %+% filter(ov_melt, mod_spec == "eq")

# --------------------------------------------------------------------------------------------------
# jaccard -----------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------
j_melt <- jaccard_combo %>% 
  filter(bd_input %in% runs[c(ensembles_list$en1_types)]#, mod_spec == "bd100"
         ) %>% 
  select(bd_input, mod_spec, runs[ensembles_list$en1_types]) %>%
  melt(variable.name = "pair", value.name = "jaccard") %>%
  na.omit()

gg_ind_jaccard <- ggplot(j_melt, aes(x = bd_input, y = jaccard, fill = pair)) +
  geom_bar(position = "dodge", stat = "identity") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0)) +
  xlab("Biodiversity Input") + ylab("Jaccard Index \n(Pairwise)") + 
  ylim(0, 0.7)
  #coord_cartesian(ylim=c(0, 1.0)) + #cale_y_continuous(breaks=seq(0, 0.25, 0.5, 0.75, 1.0)) +
  #labs(title = "Pairwise jaccard")

gg_ind_jaccard %+% filter(j_melt, mod_spec == "bd100")
gg_ind_jaccard %+% filter(j_melt, mod_spec == "bd50_y50")
gg_ind_jaccard %+% filter(j_melt, mod_spec == "eq")

gg_ind_jaccard_grid <- plot_grid(
    gg_ind_jaccard %+% filter(j_melt, mod_spec == "bd100") + theme_ind, 
    gg_ind_jaccard %+% filter(j_melt, mod_spec == "bd50_y50") + theme_ind, 
    gg_ind_jaccard %+% filter(j_melt, mod_spec == "eq") + theme_ind,
    align = "h",
    rel_widths = c(1.2, 1, 1, .9, 1.2),
    nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
    )

gg_ind_legend_bottom <- get_legend(
  gg_ind_jaccard + theme(legend.position = "bottom", legend.margin = margin(b = 3)))

plot_grid(
  gg_ind_jaccard_grid,
  gg_ind_legend_bottom,
  ncol = 1, rel_heights = c(1, .1)
)
```


```{r mega_results_fig}
# goal: set up a figure with the five comparison groups on the x axis, and the main result types on the y axis, to facilitate comparisons
# results types:
result_type$area
  # "area" = "p_area_converted_",
  # "overlap" = "p_mean_overlap_",
  # "bd_loss_control" = "p_bd_loss_control_",
  # "raw_all" = "p_raw_all_richness_loss_",
  # "raw_endemism" = "p_raw_endemism_richness_loss_",

# comparisons:
names(ensembles_list)[c(1, 5, 7, 12, 14)] # main
ensembles_list[[1]]
ensembles_list[[5]]
ensembles_list[[7]]
ensembles_list[[12]]
ensembles_list[[14]]

main_runs <- c(ensembles_list[[1]], 
               ensembles_list[[5]], 
               ensembles_list[[7]], 
               ensembles_list[[12]], 
               ensembles_list[[14]])

runs[main_runs]

# area
p_area_converted_en1_types <- p_area_converted %+% filter(results_combo, bd_input %in% runs[ensembles_list[[1]]])
p_area_converted_en1_types + coord_cartesian(ylim=c(20000, 50000))


# bd loss in control
levels(results_combo$bd_input)
runs_w_ref[runs_reorder]

main_bd_loss_control <- p_bd_loss_control %+% 
  filter(
    mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),
    bd_input %in% runs[main_runs])


# raw all
p_raw_all_richness_loss_en2_taxa_all
p_raw_all_richness_loss_en1_types <- p_raw_all_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[1]]])

# raw endemism
p_raw_endemism_richness_loss_en1_types <- p_raw_endemism_richness_loss %+% 
  filter(results_combo_raw, bd_input %in% runs[ensembles_list[[1]]])

# overlap

## create new column in overlap_combo with just the right numbers

p_mean_overlap_en1_types <- p_overlap_combo_base %+% 
  filter(overlap_combo, bd_input %in% runs[ensembles_list$en1_types]) +
  geom_point(mapping = aes(x = bd_input, y = mean_overlap_en1_types, color = mod_spec), position = position_dodge(0.6)) +
  geom_errorbar(mapping = aes(x = bd_input, 
                              ymin = mean_overlap_en1_types - 1.96*se_overlap_en1_types, 
                              ymax = mean_overlap_en1_types + 1.96*se_overlap_en1_types, 
                              color = mod_spec),
                width = 0.4, position = position_dodge(0.6))



# -------------------------------------------------------------------------
# save mega plot
# -------------------------------------------------------------------------

save_mega_plot <- function(index, is_main = TRUE,
                           area_y_lim = c(20000, 50000), 
                           bd_loss_control_y_lim = c(0,0.08), 
                           raw_all_y_lim = c(10,30), 
                           raw_endemism_y_lim = c(2,10),
                           label, label_main_SI, width, height) {
    
  theme_w_x <- theme(legend.position="none", plot.margin = unit(c(0.4, 0.5, 0, 0.5), "cm"),
                         plot.title = element_blank(),
                         plot.subtitle = element_blank(),
                         plot.caption = element_blank(),
                         axis.title.x = element_blank(),
                         axis.title.y = element_text(size=9),
                         axis.text.x = element_text(size=8)

                         )
  theme <- theme_w_x #+ theme(axis.text.x = element_blank())
  theme_no_y <- theme + theme(axis.title.y = element_blank(), plot.margin = unit(c(0.4, 0.5, 0, 0.5), "cm"))
  theme_w_x_no_y <- theme_w_x + theme(axis.title.y = element_blank(), plot.margin = unit(c(0.4, 0.5, 0.1, 0.5), "cm"))
  
  # create rows:
  area_results <- plot_grid(
      eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[indices[[index]][1]]))) + ylim(area_y_lim) + theme,
      eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[indices[[index]][2]]))) + ylim(area_y_lim) + theme_no_y,
      eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[indices[[index]][3]]))) + ylim(area_y_lim) + theme_no_y,
      # eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[indices[[index]][4]]))) + ylim(area_y_lim) + theme_no_y,
      # eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[indices[[index]][5]]))) + ylim(area_y_lim) + theme_no_y,
      # eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[indices[[index]][6]]))) + ylim(area_y_lim) + theme_no_y,
      align = "h", 
      nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
      #labels = c("types", "taxa", "methods", "resolutions", "composites"), label_x = 0.25, label_size = 11
      )
  
  overlap_results <- plot_grid(
      eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[indices[[index]][1]]))) + theme,
      eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[indices[[index]][2]]))) + theme_no_y,
      eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[indices[[index]][3]]))) + theme_no_y,
      # eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[indices[[index]][4]]))) + theme_no_y,
      # eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[indices[[index]][5]]))) + theme_no_y,
      # eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[indices[[index]][6]]))) + theme_no_y,
      align = "h", 
      nrow = 1 #, labels = c("a", "b", "c", "d", "e", "f")
      )
  
  raw_all_results <- plot_grid(
      eval(parse(text = paste0("p_raw_all_richness_loss_", 
                               names(ensembles_list)[indices[[index]][1]]))) + ylim(raw_all_y_lim) + theme,
      eval(parse(text = paste0("p_raw_all_richness_loss_", 
                               names(ensembles_list)[indices[[index]][2]]))) + ylim(raw_all_y_lim) + theme_no_y,
      eval(parse(text = paste0("p_raw_all_richness_loss_", 
                               names(ensembles_list)[indices[[index]][3]]))) + ylim(raw_all_y_lim) + theme_no_y,
      # eval(parse(text = paste0("p_raw_all_richness_loss_",
      #                          names(ensembles_list)[indices[[index]][4]]))) + ylim(raw_all_y_lim) + theme_no_y,
      # eval(parse(text = paste0("p_raw_all_richness_loss_",
      #                          names(ensembles_list)[indices[[index]][5]]))) + ylim(raw_all_y_lim) + theme_no_y,
      # eval(parse(text = paste0("p_raw_all_richness_loss_",
      #                          names(ensembles_list)[indices[[index]][6]]))) + ylim(raw_all_y_lim) + theme_no_y,
      align = "h", 
      nrow = 1 #, labels = c("a", "b", "c", "d", "e", "f")
      )
  
  raw_endemism_results <- plot_grid(
      eval(parse(text = paste0("p_raw_endemism_richness_loss_", 
                               names(ensembles_list)[indices[[index]][1]]))) + ylim(raw_endemism_y_lim) + theme_w_x,
      eval(parse(text = paste0("p_raw_endemism_richness_loss_", 
                               names(ensembles_list)[indices[[index]][2]]))) + ylim(raw_endemism_y_lim) + theme_w_x_no_y,
      eval(parse(text = paste0("p_raw_endemism_richness_loss_", 
                               names(ensembles_list)[indices[[index]][3]]))) + ylim(raw_endemism_y_lim) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_raw_endemism_richness_loss_",
      #                          names(ensembles_list)[indices[[index]][4]]))) + ylim(raw_endemism_y_lim) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_raw_endemism_richness_loss_",
      #                          names(ensembles_list)[indices[[index]][5]]))) + ylim(raw_endemism_y_lim) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_raw_endemism_richness_loss_",
      #                          names(ensembles_list)[indices[[index]][6]]))) + ylim(raw_endemism_y_lim) + theme_w_x_no_y,
      align = "h", 
      nrow = 1 #, labels = c("a", "b", "c", "d", "e", "f")
      )
  
  # SI rows
  bd_loss_control_results <- plot_grid(
      eval(parse(text = paste0("p_bd_loss_control_", 
                               names(ensembles_list)[indices[[index]][1]]))) + ylim(bd_loss_control_y_lim) + theme,
      eval(parse(text = paste0("p_bd_loss_control_", 
                               names(ensembles_list)[indices[[index]][2]]))) + ylim(bd_loss_control_y_lim) + theme_no_y,
      eval(parse(text = paste0("p_bd_loss_control_", 
                               names(ensembles_list)[indices[[index]][3]]))) + ylim(bd_loss_control_y_lim) + theme_no_y,
      # eval(parse(text = paste0("p_bd_loss_control_",
      #                          names(ensembles_list)[indices[[index]][4]]))) + ylim(bd_loss_control_y_lim) + theme_no_y,
      # eval(parse(text = paste0("p_bd_loss_control_",
      #                          names(ensembles_list)[indices[[index]][5]]))) + ylim(bd_loss_control_y_lim) + theme_no_y,
      # eval(parse(text = paste0("p_bd_loss_control_",
      #                          names(ensembles_list)[indices[[index]][6]]))) + ylim(bd_loss_control_y_lim) + theme_no_y,
      nrow = 1, labels = c("a", "b", "c", "d", "e", "f")
      )
  
  mean_bd_loss_results <- plot_grid(
      eval(parse(text = paste0("p_mean_bd_loss_", 
                               names(ensembles_list)[indices[[index]][1]]))) + theme_w_x,
      eval(parse(text = paste0("p_mean_bd_loss_", 
                               names(ensembles_list)[indices[[index]][2]]))) + theme_w_x_no_y,
      eval(parse(text = paste0("p_mean_bd_loss_", 
                               names(ensembles_list)[indices[[index]][3]]))) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_mean_bd_loss_",
      #                          names(ensembles_list)[indices[[index]][4]]))) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_mean_bd_loss_",
      #                          names(ensembles_list)[indices[[index]][5]]))) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_mean_bd_loss_",
      #                          names(ensembles_list)[indices[[index]][6]]))) + theme_w_x_no_y,
      nrow = 1 #, labels = c("a", "b", "c", "d", "e", "f")
      )
  
  cv_bd_loss_results <- plot_grid(
      eval(parse(text = paste0("p_cv_bd_loss_", 
                               names(ensembles_list)[indices[[index]][1]]))) + theme_w_x,
      eval(parse(text = paste0("p_cv_bd_loss_", 
                               names(ensembles_list)[indices[[index]][2]]))) + theme_w_x_no_y,
      eval(parse(text = paste0("p_cv_bd_loss_", 
                               names(ensembles_list)[indices[[index]][3]]))) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_cv_bd_loss_",
      #                          names(ensembles_list)[indices[[index]][4]]))) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_cv_bd_loss_",
      #                          names(ensembles_list)[indices[[index]][5]]))) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_cv_bd_loss_",
      #                          names(ensembles_list)[indices[[index]][6]]))) + theme_w_x_no_y,
      nrow = 1 #, labels = c("a", "b", "c", "d", "e", "f")
      )
  
  var_from_control_results <- plot_grid(
      eval(parse(text = paste0("p_var_from_control_", 
                               names(ensembles_list)[indices[[index]][1]]))) + theme_w_x,
      eval(parse(text = paste0("p_var_from_control_", 
                               names(ensembles_list)[indices[[index]][2]]))) + theme_w_x_no_y,
      eval(parse(text = paste0("p_var_from_control_", 
                               names(ensembles_list)[indices[[index]][3]]))) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_var_from_control_",
      #                          names(ensembles_list)[indices[[index]][4]]))) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_var_from_control_",
      #                          names(ensembles_list)[indices[[index]][5]]))) + theme_w_x_no_y,
      # eval(parse(text = paste0("p_var_from_control_",
      #                          names(ensembles_list)[indices[[index]][6]]))) + theme_w_x_no_y,
      nrow = 1 #, labels = c("a", "b", "c", "d", "e", "f")
      )
  
  results_legend_bottom <- get_legend(p_area_converted + theme(legend.position = "bottom", legend.margin = margin(b = 3)))
  
  
  # go through and change indices[[1]] to go through the different comparisons, to make individual mega plots, 
  png(paste0(p_plots, "/ms_fig_scatter_by_result/", "mega_plot_", label, label_main_SI, ".png"),
      width = width, height = height, units = "in", res = 300) 
  
  if(is_main) {
    print(
    plot_grid(
      area_results,
      overlap_results,
      raw_all_results,
      raw_endemism_results,
      
      results_legend_bottom, 
      ncol = 1, rel_heights = c(1, 1, 1, 1, .2)))
  } else {
    print(
    plot_grid(
      bd_loss_control_results,
      mean_bd_loss_results,
      cv_bd_loss_results,
      var_from_control_results,
      
      results_legend_bottom, 
      ncol = 1, rel_heights = c(1, 1, 1, 1, .2)))
  }
  
  dev.off() 
  # SI
  
}

indices

# make sure to go through and comment out the evals to match the number of columns. 
save_mega_plot(1, label = "primary", label_main_SI = "_main", is_main = TRUE, width = 12, height = 10) # five columns
save_mega_plot(1, label = "primary", label_main_SI = "_SI", is_main = FALSE, width = 12, height = 10) # five columns

save_mega_plot(2, label = "types_taxa", label_main_SI = "_main", is_main = TRUE, width = 15, height = 10) # six columns
save_mega_plot(2, label = "types_taxa", label_main_SI = "_SI", is_main = FALSE, width = 15, height = 10) # six columns

save_mega_plot(4, label = "methods", label_main_SI = "_main", is_main = TRUE, width = 6, height = 8) # three columns
save_mega_plot(4, label = "methods", label_main_SI = "_SI", is_main = FALSE, width = 6, height = 8) # three columns


save_mega_plot(3, label = "taxa", label_main_SI = "_main", is_main = TRUE, width = 8, height = 8) # four columns
save_mega_plot(3, label = "taxa", label_main_SI = "_SI", is_main = FALSE, width = 8, height = 8) # four columns

save_mega_plot(5, label = "resolution", label_main_SI = "_main", is_main = TRUE, width = 8, height = 8) # four columns
save_mega_plot(5, label = "resolution", label_main_SI = "_SI", is_main = FALSE, width = 8, height = 8) # four columns

save_mega_plot(6, label = "norm", label_main_SI = "_main", is_main = TRUE, width = 8, height = 8) # four columns
save_mega_plot(6, label = "norm", label_main_SI = "_SI", is_main = FALSE, width = 8, height = 8) # four columns

 
```


```{r plots_w_o_10p}
names(ensembles_list)
head(results_combo)

levels(results_combo$mod_spec)[1:3]

p_area_converted_en1_types
p_area_converted_en1_types %+% 
  filter(results_combo, mod_spec %in% c("eq", "bd100", "bd50_y50"), bd_input %in% runs[en1_types])

p_area_converted_en1_types %+% 
  filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), bd_input %in% runs[en1])

p_bd_loss_control_en1_types
p_mean_overlap_en1_types

```

```{r main_stats_df}
# drawing from 
results_combo
results_combo_raw
overlap_combo

names(results_combo)
names(results_combo)[c(1:2,57:58, 65, 68, 75:93)]

stats_df <- 
  results_combo %>%
  select(bd_input, mod_spec, 
         vert_all_raw_bd_loss_percent = vert_all_raw_bd_loss, 
         vert_endemism_raw_bd_loss_percent = vert_endemism_raw_bd_loss, 
         area_conv, percent_bd_loss_control, 
         mean_bd_loss_en1_types:mean_bd_loss_all)

names(results_combo_raw)
stats_df <- 
  results_combo_raw %>%
  select(bd_input, mod_spec, vert_all_raw_bd_loss:vert_endemism_raw_bd_loss) %>%
  left_join(stats_df, .)

names(overlap_combo)
stats_df <- 
  overlap_combo %>%
  select(bd_input, mod_spec, mean_overlap_en1_types:mean_overlap_all) %>%
  left_join(stats_df, .)

# now, you have a table of the main results we want to work with.
write_csv(stats_df, path = fp(p_mod_output, "stats_df.csv"))
```

```{r sd_and_confidence-intervals}
# see all the way at the bottom for the good stuff....


# confidence intervals are caluclated as 
# mean plus or minus the z score (z*) multiplied by the standard error (sigma / sqrt(n)). The variance is sigma^2, or sum((x - mean)^2)/(n-1)

# so the 

x <- c(12.70, 13.21, 13.15, 13.90) # # range area converted
x <- c(23433, 23198, 22088, 25607)


sd(x)
var(x)
mean(x)

mean(x) + 1.645*sd(x)/(sqrt(length(x)))
mean(x) - 1.645*sd(x)/(sqrt(length(x)))

# width of confidence interval
x <- stats_df %>% filter(bd_input %in% runs[ensembles_list[[1]]], mod_spec == "bd100") %>% .[,5] 

names(stats_df)
sd_df <- sd_df_temp[, 1:2]
backup_df <- sd_df_temp

df <- stats_df

  for (stat in names(df)[-c(1:2)]) {
    index <- which(names(df) == stat)
    sd_df_temp <- data.frame()

    for(i in seq_along(ensembles_list)){
      
      bd100 <- filter(df, bd_input %in% runs[ensembles_list[[i]]], mod_spec == "bd100") %>% .[,index]
      bd50_y50 <- filter(df, bd_input %in% runs[ensembles_list[[i]]], mod_spec == "bd50_y50") %>% .[,index]
      eq <- filter(df, bd_input %in% runs[ensembles_list[[i]]], mod_spec == "eq") %>% .[,index]
      
      new_df <- data.frame(
        ensemble = names(ensembles_list[i]),
        mod_spec = c("bd100", "bd50_y50", "eq"),
        sd = c(sd(bd100), sd(bd50_y50), sd(eq))
        )
      
      sd_df_temp <- rbind(sd_df_temp, new_df)
    }

    names(sd_df_temp)[which(names(sd_df_temp) == "sd")] <- paste0("sd_", stat)
    
    sd_df <- left_join(sd_df, sd_df_temp)
    }

# basic function

cc_compute_sd <- function(df = stats_df, z_score = 1.645, stat, ensemble_index) {
index <- which(names(df) == stat)

      bd100 <- filter(df, bd_input %in% runs[ensembles_list[[ensemble_index]]], mod_spec == "bd100") %>% .[,index]
      bd50_y50 <- filter(df, bd_input %in% runs[ensembles_list[[ensemble_index]]], mod_spec == "bd50_y50") %>% .[,index]
      eq <- filter(df, bd_input %in% runs[ensembles_list[[ensemble_index]]], mod_spec == "eq") %>% .[,index]
     
  print("sd for bd100 is:")
  print(sd(bd100)) 
  print("sd for bd50_y50 is:")
  print(sd(bd50_y50))  
  print("sd for eq is:")
  print(sd(eq))
  
  # print("CI window for bd100 is")
  # print(z_score*sd(bd100)/(sqrt(length(bd100)))*2)
  # 
  # print("CI window for bd50_y50 is")
  # print(z_score*sd(bd50_y50)/(sqrt(length(bd50_y50)))*2)
  # 
  # print("CI window for eq is")
  # print(z_score*sd(eq)/(sqrt(length(eq)))*2)
}

cc_compute_sd(ensemble_index = 1, stat = "area_conv")
cc_compute_sd(ensemble_index = 1, stat = "vert_all_raw_bd_loss")
cc_compute_sd(ensemble_index = 1, stat = "vert_endemism_raw_bd_loss")
cc_compute_sd(ensemble_index = 1, stat = "mean_overlap_en1_types")

cc_compute_sd(ensemble_index = 1, stat = "mean_bd_loss_en1_types")

# -------------------------------------------------------------------------------------
# good stuff -------------------------------------------------------------------------------------
# -------------------------------------------------------------------------------------
names(sd_df)
sd_df %>% filter(ensemble == names(ensembles_list[5])#, mod_spec == "bd100"
                 ) %>% as_tibble()


# basic stats - easy! -------------------------------------------------------------------------------------
names(stats_df)
cc_ensemble_mean_sd <- function(index, weights){
  x <- filter(stats_df, 
       bd_input %in% runs[ensembles_list[[index]]], 
       mod_spec == weights) %>% 
  select(bd_input, mod_spec, area_conv, 
         vert_all_raw_bd_loss, 
         vert_endemism_raw_bd_loss,
         percent_bd_loss_control,
         eval(paste0("mean_overlap_", names(ensembles_list[index])))) #%>% 
 # mean()
  
  x[length(ensembles_list[[index]])+1,] <- c(NA, NA,
    apply(x[c(1:length(ensembles_list[[index]])), -c(1:2)], 2, FUN = mean))
  
  x[length(ensembles_list[[index]])+2,] <- c(NA, NA,
    apply(x[c(1:length(ensembles_list[[index]])), -c(1:2)], 2, FUN = sd))

x %>% as_tibble()
}

names(ensembles_list)

index <- 1
ensembles_list[index]; runs[ensembles_list[[index]]]
cc_ensemble_mean_sd(index = index, weights = "bd100")
cc_ensemble_mean_sd(index = index, weights = "bd50_y50")
cc_ensemble_mean_sd(index = index, weights = "eq")

cc_ensemble_mean_sd(index = 10, weights = "bd100")
cc_ensemble_mean_sd(index = 11, weights = "bd100")
cc_ensemble_mean_sd(index = 12, weights = "bd100")
cc_ensemble_mean_sd(index = 13, weights = "bd100")


names(ensembles_list)[c(1, 5, 7, 12, 14)] # main
for(i in c(1, 5, 7, 12, 14)) {
  print(cc_ensemble_mean_sd(index = i, weights = "bd100"))
  print(cc_ensemble_mean_sd(index = i, weights = "bd50_y50"))
  print(cc_ensemble_mean_sd(index = i, weights = "eq"))
}


runs
apply(x[, -c(1:2)], 2, FUN = mean); apply(x[, -c(1:2)], 2, FUN = sd)

mean(x);sd(x)

```

```{r *extracting_numbers}
sd(c(19924442, 22689926, 22130496, 22501059))
names(results_combo)

names(stats_df)

# variables of interest are:
stats_df$area_conv
stats_df$vert_all_raw_bd_loss
stats_df$vert_endemism_raw_bd_loss
stats_df$percent_bd_loss_control
stats_df$mean_bd_loss_en1_types
stats_df$mean_overlap_en1_types

# framework for filtering these results --------------------------------------------------------------------
stats_df %>% 
  filter(bd_input %in% runs[ensembles_list$en1_types], 
         mod_spec == "bd100") %>%
  select(bd_input, mod_spec, area_conv, vert_all_raw_bd_loss, vert_endemism_raw_bd_loss, 
         percent_bd_loss_control, mean_bd_loss_en1_types, mean_overlap_en1_types)

# overlap
names(overlap_combo)
overlap_combo %>% 
  filter(bd_input %in% runs[ensembles_list$en1_types], 
         mod_spec == "bd100") %>% 
  select(bd_input, runs[ensembles_list$en1_types]) #%>% .[1,] %>% as.numeric() %>% mean(na.rm = T)



# percent changes:
filter(stats_df, bd_input == "vert_all", mod_spec == "bd100") %>% select(area_conv)

which(names(stats_df) == "area_conv")
names(stats_df)[5]
cc_percent_change <- function(df = stats_df, 
                              bd_input_name, mod_spec_x = "bd100", mod_spec_y, stat = "area_conv"
                              ) {
  index <- which(names(df) == stat)
  x <- filter(df, bd_input == bd_input_name, mod_spec == mod_spec_x) %>% .[,index]
  y <- filter(df, bd_input == bd_input_name, mod_spec == mod_spec_y) %>% .[,index]
  print((y-x)/x)
}

# area_conv
results_combo %>% filter(bd_input == "reference_y") %>% .$area_conv


# show the four percent changes relative to bd100. The fifth value is the mean.
stat <- "area_conv"
mod_spec_y <- "eq"
runs_of_interest <- runs[ensembles_list$en1_types]
mean(c(
  cc_percent_change(bd_input_name = runs_of_interest[1], mod_spec_y = mod_spec_y, stat = stat),
  cc_percent_change(bd_input_name = runs_of_interest[2], mod_spec_y = mod_spec_y, stat = stat),
  cc_percent_change(bd_input_name = runs_of_interest[3], mod_spec_y = mod_spec_y, stat = stat),
  cc_percent_change(bd_input_name = runs_of_interest[4], mod_spec_y = mod_spec_y, stat = stat)
  ))

stats_df %>% filter(bd_input %in% runs_of_interest) %>% select(bd_input, mod_spec, vert_all_raw_bd_loss)

mean(c(0.4437332, 0.6214329, 0.6617168, 0.469481))
############

cc_percent_change(bd_input_name = "vert_all", mod_spec_y = "bd50_y50", statistic = "area_conv")
cc_percent_change(bd_input_name = "vert_all", mod_spec_y = "eq", statistic = "area_conv")


cc_percent_change(
  filter(stats_df, bd_input == "vert_all", mod_spec == "bd100") %>% select(area_conv), 
  filter(stats_df, bd_input == "vert_all", mod_spec == "eq") %>% select(area_conv))

cc_percent_change(
  filter(stats_df, bd_input == "vert_all", mod_spec == "bd100") %>% select(area_conv), 
  filter(stats_df, bd_input == "vert_all", mod_spec == "bd50_y50") %>% select(area_conv))

  # select(bd_input, mod_spec, area_conv, vert_all_raw_bd_loss, vert_endemism_raw_bd_loss, 
  #       percent_bd_loss_control, mean_bd_loss_en1_types, mean_overlap_en1_types)


names(results_combo)[58] # mean_bd_loss_en4
names(results_combo)[65] # area_conv
which(names(results_combo) == "vert_all_raw_bd_loss")

names(results_combo)[68] # percent_bd_loss_control
names(overlap_combo)[55] # mean_overlap_en4
names(results_combo)[89] # cv_bd_loss_e4
names(results_combo)[45] # var_from_control

names(overlap_combo)[59] # mean_overlap
names(overlap_combo)[64] # mean_overlap_en1_types


names(results_combo)[65] # area_conv
names(results_combo)[68] # percent_bd_loss_control
names(results_combo)[69] # mean_bd_loss

names(results_combo_raw)[61] # vert_all_raw_bd_loss
names(results_combo_raw)[62] # vert_endemism_raw_bd_loss

runs
results_combo %>% names()

results_combo %>% 
  filter(bd_input %in% runs[ensembles_list[[1]]]) %>% 
  # .$mean_overlap %>% 
  # .$bd_input
  .[, c(1:2, 57, 58, 65, 68:69)]

filter(results_combo, bd_input %in% runs[1], mod_spec == "bd100") %>% .$area_conv

results_combo_raw %>% 
  filter(#mod_spec == "bd50_y50", 
         bd_input %in% runs[ensembles_list[[1]]]) %>% 
  .[, c(1:2, 61, 62)]

names(overlap_combo)
overlap_combo %>% filter(bd_input %in% runs[ensembles_list[[1]]]) %>% .[, c(1:2, 59, 64)]



# summary statistics:
# these should only be for some of the 54 runs
runs[]

# area
results_combo %>% filter(bd_input %in% runs) %>% .$area_conv %>% summary()
results_combo %>% filter(mod_spec == "bd100", bd_input %in% runs) %>% .$area_conv %>% summary()
results_combo %>% filter(mod_spec == "bd50_y50", bd_input %in% runs) %>% .$area_conv %>% summary()
results_combo %>% filter(mod_spec == "eq", bd_input %in% runs) %>% .$area_conv %>% summary()

# vert_all_raw_bd_loss
results_combo_raw %>% filter(bd_input %in% runs) %>% .$vert_all_raw_bd_loss %>% summary()
results_combo_raw %>% filter(mod_spec == "bd100", bd_input %in% runs) %>% .$vert_all_raw_bd_loss %>% summary()
results_combo_raw %>% filter(mod_spec == "bd50_y50", bd_input %in% runs) %>% .$vert_all_raw_bd_loss %>% summary()
results_combo_raw %>% filter(mod_spec == "eq", bd_input %in% runs) %>% .$vert_all_raw_bd_loss %>% summary()

# vert_endemism_raw_bd_loss
results_combo_raw %>% filter(bd_input %in% runs) %>% .$vert_endemism_raw_bd_loss %>% summary()
results_combo_raw %>% filter(mod_spec == "bd100", bd_input %in% runs) %>% .$vert_endemism_raw_bd_loss %>% summary()
results_combo_raw %>% filter(mod_spec == "bd50_y50", bd_input %in% runs) %>% .$vert_endemism_raw_bd_loss %>% summary()
results_combo_raw %>% filter(mod_spec == "eq", bd_input %in% runs) %>% .$vert_endemism_raw_bd_loss %>% summary()

# mean_bd_loss
results_combo %>% filter(bd_input %in% runs) %>% .$mean_bd_loss %>% summary()
results_combo %>% filter(mod_spec == "bd100", bd_input %in% runs) %>% .$mean_bd_loss %>% summary()
results_combo %>% filter(mod_spec == "bd50_y50", bd_input %in% runs) %>% .$mean_bd_loss %>% summary()
results_combo %>% filter(mod_spec == "eq", bd_input %in% runs) %>% .$mean_bd_loss %>% summary()

# mean_overlap
overlap_combo$mean_overlap
overlap_combo %>% filter(bd_input %in% runs) %>% .$mean_overlap %>% summary()
overlap_combo %>% filter(mod_spec == "bd100", bd_input %in% runs) %>% .$mean_overlap %>% summary()
overlap_combo %>% filter(mod_spec == "bd50_y50", bd_input %in% runs) %>% .$mean_overlap %>% summary()
overlap_combo %>% filter(mod_spec == "eq", bd_input %in% runs) %>% .$mean_overlap %>% summary()


overlap_combo %>% filter(mod_spec == "bd50_y50", bd_input %in% runs) %>% .$mean_overlap %>% summary()


min(results_combo_raw$vert_endemism_raw_bd_loss) / sum(bd_dt$vert_endemism_raw) * 100



summary(results_combo[, 1:46] %>% filter(mod_spec == "bd100")) # 510328 km2 
summary(results_combo[, 2 + seq_along(runs)])
results_combo[, c(1:2, 36, 39)] %>% filter(mod_spec != "eq") %>% arrange(bd_input, mod_spec) %>% mutate(percent100 = percent_bd_loss_control*100)

results_combo[, c(1:2, 57, 58, 65, 68:69)] %>% 
  filter(bd_input %in% runs[ensembles_list$en2_taxa_threat],  
         mod_spec == "bd100")

results_combo[, c(1:2, 36, 39:40, 45, 48)] %>% 
  filter(bd_input %in% runs[ensembles_list$en4_threat]) %>% arrange(mod_spec)

overlap_combo %>% filter(mod_spec == "bd50_y50") %>% .$mean_overlap %>% summary()

summary(overlap_combo$mean_overlap)
overlap_combo[, c(1:2, 52)] %>% filter(bd_input %in% runs[ensembles_list$en3_threat]) %>%
  arrange(mod_spec)

summary(overlap_combo[, c(1:2, 38:45)] %>% filter(mod_spec == "bd100"))
ensembles_list$en1_types



overlap_combo %>% filter(bd_input %in% runs[ensembles_list$en1_types],
                         mod_spec == "eq") %>%
  .[, c(1:2,44)] %>% summary() 

overlap_combo %>% filter(bd_input %in% runs[ensembles_list$en1_taxa_threat],
                         mod_spec == "bd100") %>%
  .[, c(1:2,45)] %>% summary() 

overlap_combo %>% filter(bd_input %in% runs[ensembles_list$en1_taxa_all],
                         mod_spec == "bd100") %>%
  .[, c(1:2,46)] %>% summary() 

overlap_combo %>% filter(bd_input %in% runs[ensembles_list$en2_mb],
                         mod_spec == "bd100") %>%
  .[, c(1:2,48)] %>% summary() 
overlap_combo %>% filter(bd_input %in% runs[ensembles_list$en2_vp],
                         mod_spec == "bd100") %>%
  .[, c(1:2,49)] %>% summary() 

overlap_combo %>% filter(bd_input %in% runs[ensembles_list$en3_all],
                         mod_spec == "bd100") %>%
  .[, c(1:2,51)] %>% summary()
overlap_combo %>% filter(bd_input %in% runs[ensembles_list$en3_threat],
                         mod_spec == "bd100") %>%
  .[, c(1:2,52)] %>% summary()
overlap_combo %>% filter(bd_input %in% runs[ensembles_list$en3_small],
                         mod_spec == "bd100") %>%
  .[, c(1:2,53)] %>% summary()
overlap_combo %>% filter(bd_input %in% runs[ensembles_list$en3_small_threat],
                         mod_spec == "bd100") %>%
  .[, c(1:2,54)] %>% summary()

overlap_combo %>% filter(bd_input %in% runs[ensembles_list$en4],
                         mod_spec == "bd100") %>%
  .[, c(1:2,55)] %>% summary()

summary(overlap_combo[ensembles_list$en1_types, c(1:2,44)]) # mean_overlap_en1_types

```

```{r carbon loss}
# upshot is that I don't think these conversion metrics are correct.
reference_y_toff$impacts
plot(reference_y)
reference_y_carbon <- reference_y * carbon_input
plot(reference_y_carbon)
cellStats(reference_y_carbon, stat = "sum")

tradeoff_mod
impact

carbon_input # this is the above ground biomas pus 0.25 the belowground biomass.
# presumably if you multiplied this by the conversion areas, and then summed this, it would match the impacts, right? Let's see:

test <- conv_r$eq$vert_all * carbon_input
plot(test)

cellStats(conv_r$eq$vert_all, stat = "sum")
cellStats(test, stat = "sum")
plot(carbon_input)

results_combo$area_conv

conv_r$eq$vert_all %T>% plot()



```


### Raster plots
```{r ensemble_rasters_plots}
# ---------------------------------------
# ensemble plots, base plot
# ---------------------------------------
pdf(file = fp(p_plots,"conv_eq_ensembles_plots.pdf"), width = 9, height = 9)
par(mfrow=c(2,2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(conv_eq_dt_ensembles_r, 1:4)
dev.off()

pdf(file = fp(p_plots,"conv_bd50_y50_ensembles_plots.pdf"), width = 9, height = 9)
par(mfrow=c(2,2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(conv_bd50_y50_dt_ensembles_r, 1:4)
dev.off()

pdf(file = fp(p_plots,"conv_bd100_ensembles_plots.pdf"), width = 9, height = 9)
par(mfrow=c(2,2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(conv_bd100_dt_ensembles_r, 1:4)
dev.off()

pdf(file = fp(p_plots,"conv_10p_bd_ensembles_plots.pdf"), width = 9, height = 9)
par(mfrow=c(2,2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(conv_10p_bd_dt_ensembles_r, 1:4)
dev.off()


pdf(file = fp(p_plots,"conv_all_ensembles_plots.pdf"), width = 12, height = 4)
par(mfrow=c(1,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(conv_eq_dt_ensembles_r[[5]], main = "equal weights")
plot(conv_bd100_dt_ensembles_r[[5]], main = "100% weight on bd")
plot(conv_10p_bd_dt_ensembles_r[[5]], main = "Lowest 10% bd scores")
dev.off()


pdf(file = fp(p_plots,"conv_all_en1_plots.pdf"), width = 12, height = 4)
par(mfrow=c(1,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(conv_eq_dt_ensembles_r[[1]], main = "equal weights")
plot(conv_bd100_dt_ensembles_r[[1]], main = "100% weight on bd")
plot(conv_10p_bd_dt_ensembles_r[[1]], main = "Lowest 10% bd scores")
dev.off()

pdf(file = fp(p_plots,"conv_all_en2_plots.pdf"), width = 12, height = 4)
par(mfrow=c(1,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(conv_eq_dt_ensembles_r[[2]], main = "equal weights")
plot(conv_bd100_dt_ensembles_r[[2]], main = "100% weight on bd")
plot(conv_10p_bd_dt_ensembles_r[[2]], main = "Lowest 10% bd scores")
dev.off()

pdf(file = fp(p_plots,"conv_all_en3_plots.pdf"), width = 12, height = 4)
par(mfrow=c(1,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(conv_eq_dt_ensembles_r[[3]], main = "equal weights")
plot(conv_bd100_dt_ensembles_r[[3]], main = "100% weight on bd")
plot(conv_10p_bd_dt_ensembles_r[[3]], main = "Lowest 10% bd scores")
dev.off()

pdf(file = fp(p_plots,"conv_all_en4_plots.pdf"), width = 12, height = 4)
par(mfrow=c(1,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(conv_eq_dt_ensembles_r[[4]], main = "equal weights")
plot(conv_bd100_dt_ensembles_r[[4]], main = "100% weight on bd")
plot(conv_10p_bd_dt_ensembles_r[[4]], main = "Lowest 10% bd scores")
dev.off()


# ---------------------------------------------------------
# ggplot
# ---------------------------------------------------------
plot(conv_eq_dt_ensembles_r, legend = FALSE)
names(conv_eq_dt_ensembles_r)

gplot(conv_eq_dt_ensembles_r$en1)

ggplot(data = conv_eq_dt_ensembles, aes(x = x, y = y)) +
         geom_raster(aes(fill = m1_vert_all)) +
         theme_bw() +
         coord_equal()

conv_eq_dt_ensembles_r
names(conv_eq_dt_ensembles_r)


theme_set(theme_bw())
gplot(conv_eq_dt_ensembles_r, maxpixels=5000) + 
  geom_tile(aes(fill = value)) +
  facet_wrap(~ variable) +
  scale_fill_gradient(low = 'white', high = 'blue') +
  theme_bw() +
  coord_equal()

rasterVis::histogram(conv_r$eq[[1:2]])

## 
gplot(bd_dt_r[[1]], maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  coord_equal() + 
  ggplot() + geom_sf(data = msk_sf)

ggplot() + 
  geom_sf(data = msk_sf)

ggplot(data = bd_dt, aes(x = x, y = y)) +
         geom_raster(aes(fill = m1_vert_all_bd)) +
         theme_bw() +
         coord_equal()
```

```{r ensemble-overlap-rasters}
# for normalization
lengths <- c()
for (i in 1:length(ensembles_list)) {
  lengths <- c(lengths, length(ensembles_list[[i]]))
}
length(lengths)

conv_eq_dt_ensembles_r/lengths
plot(conv_eq_dt_ensembles_r/lengths)

# -----------------------------------------
conv_eq_dt_ensembles_r/lengths

conv_eq_dt_ensembles_r/c()
plot(conv_eq_dt_ensembles_r)
plot(conv_eq_dt_ensembles_r/lengths)

length(lengths)
ensembles_list
conv_eq_dt_ensembles_r[[en_r]]
nlayers(conv_eq_dt_ensembles_r[[en_r]])
length(lengths)

# ---------------------------------------------------------
# normalized ensembles, rasterVis::levelplot()
# ---------------------------------------------------------
levelplot(conv_eq_dt_ensembles_r[[en_r]]/lengths, 
          col.regions = terrain.colors(50, rev = TRUE))

names(conv_eq_dt_ensembles_r[[en_r]])[c(2:3, 6, 10, 13, 15)]
(conv_eq_dt_ensembles_r[[en_r]])[["en_norm"]]

levelplot((conv_eq_dt_ensembles_r[[en_r]]/lengths)[[c(2:3, 6, 10, 13, 15)]], 
          col.regions = terrain.colors(50, rev = TRUE), main = "eq")

levelplot((conv_bd50_y50_dt_ensembles_r[[en_r]]/lengths)[[c(2:3, 6, 10, 13, 15)]], 
          col.regions = terrain.colors(50, rev = TRUE), main = "bd50_y50")

levelplot((conv_bd100_dt_ensembles_r[[en_r]]/lengths)[[c(2:3, 6, 10, 13, 15)]], 
          col.regions = terrain.colors(50, rev = TRUE), main = "bd100")

levelplot((conv_10p_bd_dt_ensembles_r[[en_r]]/lengths)[[c(2:3, 6, 10, 13, 15)]], 
          col.regions = terrain.colors(50, rev = TRUE), main = "10p_bd")


names(ensembles_list)
# ---------------------------------------------------------
# producing and printing a pdf for each ensemble: this is the main piece here
# ---------------------------------------------------------
length(ensembles_list)
save_ensemble_brick_plots <- function(i) {
  tmp_brick <- brick(
  # conv_r$eq$en1/length(en1)
    conv_r[[1]][[names(ensembles_list)[i]]]/length(ensembles_list[[i]]), # conv_r[[1:4]] are conv_r$eq, etc.
    conv_r[[2]][[names(ensembles_list)[i]]]/length(ensembles_list[[i]]),
    conv_r[[3]][[names(ensembles_list)[i]]]/length(ensembles_list[[i]]),
    conv_r[[4]][[names(ensembles_list)[i]]]/length(ensembles_list[[i]])
    )
  names(tmp_brick) <- names(conv_r)
  
  #pdf(paste0(p_plots, "/", names(ensembles_list)[i], "_brick_plot.pdf")) # "en1"
  png(paste0(p_plots, "/doc_figures/", names(ensembles_list)[i], "_brick_plot.png"), 
      width = 7, height = 7, units = "in", res = 300)
  print(levelplot(tmp_brick, 
                  col.regions = terrain.colors(50, rev = TRUE), 
                  main = paste0("Degree of model agreement (areas of overlap: ", names(ensembles_list)[i], ")"))
        )
  dev.off()
}

#for (i in seq_along(ensembles_list)) {save_ensemble_brick_plots(i)}
for (i in c(2:4, 6:7, 9:15)) {save_ensemble_brick_plots(i)}

# -----
en1_brick <- brick(conv_r$eq$en1/length(en1),
                   conv_r$bd50_y50$en1/length(en1),
                   conv_r$bd100$en1/length(en1),
                   conv_r$`10p_bd`$en1/length(en1))
names(en1_brick) <- c("eq", "bd50_y50", "bd100", "10p_bd")
pdf(fp(p_plots, "en1_brick_plot.pdf"))
print(levelplot(en1_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en1"))
dev.off()
# -----

en_norm_brick <- brick(conv_eq_dt_ensembles_r$en_norm/length(en_norm),
                   conv_bd50_y50_dt_ensembles_r$en_norm/length(en_norm),
                   conv_bd100_dt_ensembles_r$en_norm/length(en_norm),
                   conv_10p_bd_dt_ensembles_r$en_norm/length(en_norm))
names(en_norm_brick) <- c("eq", "bd50_y50", "bd100", "10p_bd")

en_l_norm_brick <- brick(conv_eq_dt_ensembles_r$en_l_norm/length(en_l_norm),
                   conv_bd50_y50_dt_ensembles_r$en_l_norm/length(en_l_norm),
                   conv_bd100_dt_ensembles_r$en_l_norm/length(en_l_norm),
                   conv_10p_bd_dt_ensembles_r$en_l_norm/length(en_l_norm))
names(en_l_norm_brick) <- c("eq", "bd50_y50", "bd100", "10p_bd")

all_runs_brick <- brick(conv_eq_dt_ensembles_r$all/length(runs),
                   conv_bd50_y50_dt_ensembles_r$all/length(runs),
                   conv_bd100_dt_ensembles_r$all/length(runs),
                   conv_10p_bd_dt_ensembles_r$all/length(runs))
names(all_runs_brick) <- c("eq", "bd50_y50", "bd100", "10p_bd")

en1_brick
en1_types_brick
en1_taxa_threat_brick
en1_taxa_all_brick
en2_brick
en2_mb_brick
en2_vp_brick
en3_brick
en3_all_brick
en3_threat_brick
en3_small_brick
en3_small_threat_brick
en4_brick
en_norm_brick
en_l_norm_brick
all_runs_brick

conv_bd100_dt_ensembles_r
levelplot(en1_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en1")
levelplot(en1_types_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en1")
levelplot(en1_taxa_threat_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en1")
levelplot(en1_taxa_all_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en1")
levelplot(en2_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en2")
levelplot(en2_mb_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en2_mb")
levelplot(en2_vp_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en2_vp")
levelplot(en3_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en3")
levelplot(en3_all_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en3_all")
levelplot(en3_threat_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en3_threat")
levelplot(en3_small_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en3_small")
levelplot(en3_small_threat_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en3_small_threat")
levelplot(en4_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en4")
levelplot(en_norm_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en1")
levelplot(en_l_norm_brick, col.regions = terrain.colors(50, rev = TRUE), main = "en1")
levelplot(all_runs_brick, col.regions = terrain.colors(50, rev = TRUE), main = "all runs")

```

Update these maps to remove the 10p_bd maps, and include an overlap map between the three weights for the same input.
```{r *print_conv_rasters_per_en}
# basic levelplot
levelplot(bd_dt_r[[ensembles_list[[2]]]], layout = c(4,1),
          col.regions = terrain.colors(50, rev = TRUE))

dev.off()
# need to produce plots showing the individual conversion maps for each ensemble, across the four model specs to see how they change. A 4x4 or 3x4 matrix, depending on the number of 
ensembles_list[c(2:4, 6:7, 9:15)]
ensembles_list[c(2:4, 6, 13:14)]

save_conv_plots <- function(i, fig_width = 7, fig_height = 10) {
  row_density <- densityplot(bd_dt_r[[ensembles_list[[i]]]], layout = c(4, 1))
  # row_1 <- histogram(bd_dt_r[[ensembles_list[[2]]]], layout = c(4, 1))

  row_bd <- gplot(bd_dt_r[[ensembles_list[[i]]]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "bd input layers", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_bd100 <- gplot(conv_r[[1]][[ensembles_list[[i]]]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "100% weight on bd \nvariable yields", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_bd50_y50 <- gplot(conv_r[[2]][[ensembles_list[[i]]]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "50% weight on bd,\n50% yield", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  row_eq <- gplot(conv_r[[3]][[ensembles_list[[i]]]], maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "equal weights", x = NULL ) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
  
  # # 10p_bd, formerly row_6
  # row_10p_bd <- gplot(conv_r[[4]][[ensembles_list[[i]]]], maxpixels = 5000000) + 
  #   geom_raster(aes(fill = value)) +
  #   facet_wrap(~ variable, nrow = 1) + 
  #   scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  #   labs(y = "Lowest 10% bd scores \nconstant yield", x = NULL ) + 
  #   theme(rect = element_blank(), line = element_blank(), 
  #         axis.line = element_blank(), axis.ticks = element_blank(), 
  #         axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  #   coord_equal()
  
  png(paste0(p_plots, "/ms_fig_raster/", names(ensembles_list)[i], 
             "_conv_maps.png"),    
      width = fig_width, height = fig_height, 
      units = "in", res = 300)
  # pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
  #            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
  print(
    plot_grid(row_density, row_bd, row_bd100, row_bd50_y50, row_eq, NULL,
              ncol = 1, rel_heights = c(1.5, 1, 1, 1, 1, 0.1))
    )
  dev.off()
}


ensembles_list[indices$main]
ensembles_list[indices$types_taxa]
ensembles_list[indices$methods]
ensembles_list[indices$resolution]
ensembles_list[indices$normalization]

ensembles_list[c(1, 5, 7, 12, 14)]

for (i in seq_along(ensembles_list)) {
  print(length(ensembles_list[[i]]))
  print(names(ensembles_list[i]))
  }

#for (i in 1:18) {save_conv_plots(i, fig_width = 7, fig_height = 11)}

runs[ensembles_list[[14]]]

save_conv_plots(1, fig_width = 7, fig_height = 9) # tester for 1, think I did 7 and 9 earlier. 

for (i in c(1, 2, 4:9)) save_conv_plots(i, fig_width = 7, fig_height = 9) # four comparisons in the ensemble
save_conv_plots(3, fig_width = 8, fig_height = 9) # 5 inputs
save_conv_plots(14, fig_width = 10, fig_height = 8) # 7 inputs

for (i in c(10:13)) save_conv_plots(i, fig_width = 7, fig_height = 11) # 3 inputs # these are fine
for (i in c(15:18)) save_conv_plots(i, fig_width = 7, fig_height = 11) # 2 inputs # these are also fine




save_conv_plots()
names(ensembles_list)[c(14,15)]
ensembles_list[c(2:4, 6:7, 9:15)]
ensembles_list[c(6:7, 9:12)]

ensembles_list[2]
conv_r[[4]][[c(2:5)]]

names(conv_r)

conv_r$bd100$m7_amp_threat %T>% 
  plot()
```




```{r *new_main_fig_ensemble_overlap}
plot(conv_r$bd100$en1_types)
names(conv_r)

dev.off()

par(mfrow = c(2, 2))
plot(bd_dt_r$en1_types, main = "en1_types", zlim = c(0,4))
bd_dt_r$m1_vert_all
plot((bd_dt_r$m1_vert_all + bd_dt_r$m2_vert_threat + bd_dt_r$m3_vert_small + bd_dt_r$m4_vert_small_threat), 
     main = "manual addition", zlim = c(0,4))
plot(4 - bd_dt_r$en1_types, main = "inverted (4 - en1_types)", zlim = c(0,4))
bd_dt_r
conv_r

dev.off()
plot(bd_dt_r$en1_types, breaks = "quantile")


# --------------------------------------
# this code should go through each ensemble and create a new brick for each ensemble, with four pieces: the bd_input overlap (inverted), bd100, bd50_y50, and eq. This is to make it easier to plot, using gplots with facet
# --------------------------------------
ensemble_fig_brick <- vector("list", length = 19)
names(ensemble_fig_brick) <- names(ensembles_list)

seq_along(ensembles_list)
for (i in seq_along(ensembles_list)) {
  ensemble_fig_brick[[i]] <- brick(
    (length(ensembles_list[[i]]) - bd_dt_r[[length(runs_w_raw) + i]]), # NOTE: this code inverts the bd layer, so that high values correspond to low biodiversity, i.e. which are prioritized for conversion (rather than high biodiversity). This is the length of the ensemble (i.e. the number of layers being overlaid, which is the max value) minus the ensemble overlap of those bd input layers. 
    # conv_r$`10p_bd`[[length(runs_w_ref) + i]], 
    conv_r$bd100[[length(runs_w_ref) + i]], 
    conv_r$bd50_y50[[length(runs_w_ref) + i]], 
    conv_r$eq[[length(runs_w_ref) + i]])
  names(ensemble_fig_brick[[i]]) <- c("bd_input", #"10p_bd", 
                                      "b", "by", "byct")
}

# ensemble_fig_brick <- writeRaster(ensemble_fig_brick, overwrite=TRUE, fp(p_mod_output,"ensemble_fig_brick.tif"))
# ensemble_fig_brick <- brick(fp(p_mod_output,"ensemble_fig_brick.tif"))
# names(ensemble_fig_brick) <- ensemble_names
save(ensemble_fig_brick, file = fp(p_mod_output, "ensemble_fig_brick.RData"))
object_size(ensemble_fig_brick)
rm(ensemble_fig_brick)

# load it back in: -------------------------------------------------------
load(file = fp(p_mod_output, "ensemble_fig_brick.RData"), verbose = TRUE)


plot(ensemble_fig_brick$en1_types)

conv_r$bd100[[length(runs_w_ref) + 5]]
names(ensembles_list)[5]
names(conv_r$bd100)
length(runs_w_ref)
names(bd_dt_r)
plot(bd_dt_r[[length(runs_w_raw) + 1]])
plot(length(ensembles_list[[1]]) - bd_dt_r[[length(runs_w_raw) + 1]])
length(runs_w_ref)

ensemble_fig_brick$en1_types
names(ensemble_fig_brick)
names(ensembles_list)[indices$main]
# --------------------------------------------------------------------------------------------
# make rows for figures
# --------------------------------------------------------------------------------------------
print(paste0("row_", names(ensembles_list)))

row_en1_types <- gplot(ensemble_fig_brick$en1_types, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Types of Richness", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en1_types_b <- gplot(ensemble_fig_brick$en1_types_b, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Types of Richness \n(extra)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en2_taxa_all <- gplot(ensemble_fig_brick$en2_taxa_all, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Taxa \n(all sp. richness)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en2_taxa_endemism <- gplot(ensemble_fig_brick$en2_taxa_endemism, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Taxa \n(endemism richness)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en2_taxa_threat <- gplot(ensemble_fig_brick$en2_taxa_threat, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Taxa (threat. sp.)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en2_taxa_small <- gplot(ensemble_fig_brick$en2_taxa_small, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Taxa \n(small-ranged \nsp. richness)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en3_mb <- gplot(ensemble_fig_brick$en3_mb, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Methods \n(mammals & birds)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en3_vp <- gplot(ensemble_fig_brick$en3_vp, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Methods \n(vert. & plants)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en3_ae <- gplot(ensemble_fig_brick$en3_ae, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Methods \n(all sp. richness \n& endemism)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en4_all <- gplot(ensemble_fig_brick$en4_all, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Resolution \n(all vert.)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en4_endemism <- gplot(ensemble_fig_brick$en4_endemism, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Resolution \n(endemism)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en4_threat <- gplot(ensemble_fig_brick$en4_threat, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Resolution \n(threat. vert.)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en4_small <- gplot(ensemble_fig_brick$en4_small, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Resolution \n(small-ranged vert.)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en5_composites <- gplot(ensemble_fig_brick$en5_composites, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Composites", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en6_norm_all <- gplot(ensemble_fig_brick$en6_norm_all, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Normalization \n Order \n (all sp.)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en6_norm_endemism <- gplot(ensemble_fig_brick$en6_norm_endemism, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Normalization \n Order \n (endemism)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en6_norm_threat <- gplot(ensemble_fig_brick$en6_norm_threat, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Normalization \n Order \n (threat. sp.)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_en6_norm_small <- gplot(ensemble_fig_brick$en6_norm_small, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "Normalization \n Order \n (small-ranged sp.)", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()

row_all <- gplot(ensemble_fig_brick$all, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = "All inputs", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()



# ----------------------------------------
# put the main figure together
# ----------------------------------------
paste0("rows_", names(ensembles_list)[indices$main])

png(paste0(p_plots, "/ms_fig_raster/","main_ensemble.png"),    
    width = 8.2, height = 10,
    units = "in", res = 300)
# pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
#            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
print(
  plot_grid(row_en1_types, 
            row_en2_taxa_threat, 
            row_en3_mb, 
            row_en4_threat, 
            row_en5_composites,
            ncol = 1, rel_heights = c(1, 1, 1, 1, 1), labels = "auto")
  )
dev.off()


# ----------------------------------------
# put the SI figures together
# ----------------------------------------
names(ensembles_list)[indices$types_taxa]
names(ensembles_list)[indices$methods]
names(ensembles_list)[indices$resolution]
names(ensembles_list)[indices$normalization] # plus all

# types
png(paste0(p_plots, "/ms_fig_raster/","main_ensemble_SI_extra_types.png"),    
      width = 8.2, height = 4, 
      units = "in", res = 300)
# pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
#            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
print(
  plot_grid(row_en1_types, 
            row_en1_types_b,
            ncol = 1, rel_heights = c(1, 1))
  )
dev.off()
# taxa

png(paste0(p_plots, "/ms_fig_raster/","main_ensemble_SI_taxa.png"),    
      width = 8.2, height = 8, 
      units = "in", res = 300)
# pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
#            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
print(
  plot_grid(row_en2_taxa_all, 
            row_en2_taxa_endemism, 
            row_en2_taxa_threat, 
            row_en2_taxa_small,
            ncol = 1, rel_heights = c(1, 1, 1, 1))
  )
dev.off()

# methods
png(paste0(p_plots, "/ms_fig_raster/","main_ensemble_SI_methods.png"),    
      width = 8.2, height = 6, 
      units = "in", res = 300)
# pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
#            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
print(
  plot_grid(row_en3_mb, 
            row_en3_vp, 
            row_en3_ae, 
            ncol = 1, rel_heights = c(1, 1, 1))
  )
dev.off()

# resolution
png(paste0(p_plots, "/ms_fig_raster/","main_ensemble_SI_res.png"),    
      width = 8.2, height = 8, 
      units = "in", res = 300)
# pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
#            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
print(
  plot_grid(row_en4_all, 
            row_en4_endemism, 
            row_en4_threat, 
            row_en4_small,
            ncol = 1, rel_heights = c(1, 1, 1, 1))
  )
dev.off()

# normalization + all
png(paste0(p_plots, "/ms_fig_raster/","main_ensemble_SI_norm+all.png"),    
      width = 8.2, height = 10, 
      units = "in", res = 300)
# pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
#            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
print(
  plot_grid(row_en6_norm_all, 
            row_en6_norm_endemism, 
            row_en6_norm_threat, 
            row_en6_norm_small, 
            row_all,
            ncol = 1, rel_heights = c(1, 1, 1, 1, 1))
  )
dev.off()











# --------------------------------------------------------------------------------------------------------
# unused below here
# --------------------------------------------------------------------------------------------------------
# testing the first time around
# --------------------------------------------------------------------------------------------------------
new_brick <- vector("list", length = 5)
new_brick$en1_types <- brick(
  (4 - bd_dt_r$en1_types), # NOTE: need to invert this layer, so that high values correspond to more likely to convert (rather than high biodiversity) 
  conv_r$bd100$en1_types, conv_r$bd50_y50$en1_types, conv_r$eq$en1_types)


names(new_brick$en1_types) <- c("bd", "bd100", "bd50_y50", "eq")

plot(bd_dt_r$en1_types)
plot(cellStats(bd_dt_r$en1_types, max) - bd_dt_r$en1_types, zlim = c(0,4), main = "subtracted from max")
plot(invert(normalize(new_brick$en1_types$bd))*4)
plot(4 - bd_dt_r$en1_types, zlim = c(0,4), main = "subtracted from 4")

row_1 <- gplot(new_brick$en1_types, maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "en1_types", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()
row_1
# it has a problem in that the first raster is too washed out. Even after I flipped it around. 

# plot with different z scale
plot(new_brick$en1_types)
hist(new_brick$en1_types)
new_brick$en1_types$bd

plot(new_brick$en1_types$bd, zlim = c(0.5, 2)) # manually change the limits
plot(log(new_brick$en1_types)) # plot the log of the raster

# manually change vlaues (least desirable, but using facets, I don't know a way to allow the z scale to change independently (or manually))
test <- bd_dt_r$en1_types # create test raster to change values
summary(test)
ncell(test[test > 2])
ncell(test)

values(test[test > 2])
test[test < 0.5] <- NA
test[test > 2] <- NA
plot(test)
plot(normalize(test))
plot(invert(normalize(test))*4)
plot(conv_r$`10p_bd`$en1_types)
plot(cellStats(bd_dt_r$en1_types, max)-bd_dt_r$en1_types, zlim = c(0,4))


# adding the newly changed value raster to a new brick
new_brick$en1_types_alt <- brick(
  invert(normalize(test))*4,  # normalized, then multiplied by 4 to match the scale of the other rasters in the brick
  conv_r$bd100$en1_types, 
  conv_r$bd50_y50$en1_types,
  conv_r$eq$en1_types)
names(new_brick$en1_types_alt) <- c("bd", "bd100", "bd50_y50", "eq")


gplot(new_brick$en1_types_alt, maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
    labs(y = "en1_types", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()




##########################################
# just plotting the one raster
##########################################
gplot(new_brick$en1_types$bd, maxpixels = 5000000) + 
    geom_raster(aes(fill = value)) +
    #facet_wrap(~ variable, nrow = 1) + 
    scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white", 
                         limits = c(0.5, 2)) + 
    labs(y = "en1_types", x = NULL) + 
    theme(rect = element_blank(), line = element_blank(), 
          axis.line = element_blank(), axis.ticks = element_blank(), 
          axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
    coord_equal()



par(mfrow = c(1,4))
plot(bd_dt_r$en1_types)
plot(conv_r$bd100$en1_types)
plot(conv_r$bd50_y50$en1_types)
plot(conv_r$eq$en1_types)

```



```{r print_yield_maps}
yield_input_dt
yield_dt
# yield_dt <- toff_eq$reference_y$inputs$p_yield
yield_dt <- fread(file = fp(p_mod_output, "yield_dt.csv"))
yield_dt_r <- dt_to_raster(yield_dt, CRSobj)


# add x and y columns.
bd_dt
yield_dt[, x := bd_dt[, .(x)]]
yield_dt[, y := bd_dt[, .(y)]]

row_maize <- ggplot() +
         geom_raster(data = yield_dt, aes(x = x, y = y, fill = maize)) +
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = NULL, x = NULL, fill = "tons/ha", title = "Maize") + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
        plot.title = element_text(hjust = 0.5)) + 
  coord_equal() + 
  geom_sf(data = pas_sf, aes(alpha = type), lwd = 0.1)

row_soy <- ggplot() +
         geom_raster(data = yield_dt, aes(x = x, y = y, fill = soy)) +
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") + 
  labs(y = NULL, x = NULL, fill = "tons/ha", title = "Soy") + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank(),
        plot.title = element_text(hjust = 0.5)) + 
  coord_equal() + 
  geom_sf(data = pas_sf, aes(alpha = type), lwd = 0.1)

# put the figure together
png(paste0(p_plots, "/doc_figures/","yield_maps.png"),    
      width = 10, height = 5, 
      units = "in", res = 300)
# pdf(paste0(p_plots, "/", names(ensembles_list)[i], 
#            "_conv_maps.pdf"),    width = fig_width,    height = fig_height) # "en1"
print(
  plot_grid(row_maize, row_soy,
            ncol = 2, rel_heights = c(1, 1))
  )
dev.off()


# unused below here....
## base plot()

png(file = fp(p_plots,"yield_plots.png"), width = 7, height = 3.2, units = "in", res = 300)
par(mfrow = c(1,2), mar=c(0, 2, 2, 1) + 0.1, oma = c(1, 1, 1, 1))

plot(yield_dt_r$maize, 
     box = F, axes = F,
     main = "maize")
plot(pas_sf$geometry, col = gray(0.5), border = gray(0.5), add = T)

# or, just plot it classified.
col_pas <- c("light gray","dark gray")
col_pas_all <- col_pas[pas$type] # this sets up the colors based on a particular attribute, in this case, "type" . See levels(pas$type) to view the order in which the colors will be assigned to the values. 


plot(yield_dt_r$maize, box = F, axes = F, main = "maize")
plot(pas, col = col_pas_all, border = NA, add=T)
plot(msk_shp, add = T)
legend("bottomright", legend=levels(pas$type), fill = col_pas)

plot(yield_dt_r$soy, box = F, axes = F, main = "soy")
plot(pas, col = col_pas_all, border = NA, add=T)
plot(msk_shp, add = T)
legend("bottomright", legend=levels(pas$type), fill = col_pas)

dev.off()
```



```{r *individual_conv_rasters}
# to plot individual conversion rasters, use the following:
conv_eq_dt_r
conv_bd50_y50_dt_r
conv_bd100_dt_r
conv_10p_bd_dt_r
# or, conv_r, or 
conv_eq_dt_ensembles_r


# ---------------------------------------------------------
# 100% weight on biodiversity
# ---------------------------------------------------------
levelplot(conv_bd100_dt_r[[en1]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en1")
levelplot(conv_r$bd100[[en1_types]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en1_types")
levelplot(conv_bd100_dt_r[[en1_taxa_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en1_taxa_threat")
levelplot(conv_bd100_dt_r[[en1_taxa_all]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en1_taxa_all")
levelplot(conv_bd100_dt_r[[en2]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: ensemble 2, methods", index.cond=list(c(1, 3, 5, 2, 4, 6)))
levelplot(conv_bd100_dt_r[[en2_mb]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: ensemble 2, combining mammals and birds", layout = c(3, 1))
levelplot(conv_bd100_dt_r[[en2_vp]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: ensemble 2, combining verts and plants", layout = c(3, 1))
levelplot(conv_bd100_dt_r[[en3]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: ensemble 3, resolution", layout = c(4, 3))
levelplot(conv_bd100_dt_r[[en3_all]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en3_all")
levelplot(conv_bd100_dt_r[[en3_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en3_threat")
levelplot(conv_bd100_dt_r[[en3_small]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en3_small")
levelplot(conv_bd100_dt_r[[en3_small_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en3_small_threat")
levelplot(conv_bd100_dt_r[[en4]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en4")
levelplot(conv_bd100_dt_r[[en_norm]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en_norm")
levelplot(conv_bd100_dt_r[[en_l_norm]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd: en_l_norm")

names(conv_bd100_dt_r[[en3]])

# ---------------------------------------------------------
# converting 10% of land, constant yield
# ---------------------------------------------------------
levelplot(conv_10p_bd_dt_r[[en1]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: ensemble1")
# ---------------------------------------------------------
# Convt. 10% land, lowest bd
# ---------------------------------------------------------
levelplot(conv_10p_bd_dt_r[[en1]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en1")
levelplot(conv_10p_bd_dt_r[[en1_types]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en1_types")
levelplot(conv_10p_bd_dt_r[[en1_taxa_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en1_taxa_threat")
levelplot(conv_10p_bd_dt_r[[en1_taxa_all]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en1_taxa_all")
levelplot(conv_10p_bd_dt_r[[en2]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: ensemble 2, methods", index.cond=list(c(1, 3, 5, 2, 4, 6)))
levelplot(conv_10p_bd_dt_r[[en2_mb]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: ensemble 2, combining mammals and birds", layout = c(3, 1))
levelplot(conv_10p_bd_dt_r[[en2_vp]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: ensemble 2, combining verts and plants", layout = c(3, 1))
levelplot(conv_10p_bd_dt_r[[en3]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: ensemble 3, resolution", layout = c(4, 3))
levelplot(conv_10p_bd_dt_r[[en3_all]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en3_all")
levelplot(conv_10p_bd_dt_r[[en3_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en3_threat")
levelplot(conv_10p_bd_dt_r[[en3_small]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en3_small")
levelplot(conv_10p_bd_dt_r[[en3_small_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en3_small_threat")
levelplot(conv_10p_bd_dt_r[[en4]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en4")
levelplot(conv_10p_bd_dt_r[[en_norm]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en_norm")
levelplot(conv_10p_bd_dt_r[[en_l_norm]], col.regions = terrain.colors(50, rev = TRUE), main = "Convt. 10% land, lowest bd: en_l_norm")

# ---------------------------------------------------------
# 50% weight on bd, 50% on yield
# ---------------------------------------------------------
levelplot(conv_bd50_y50_dt_r[[en1]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en1")
levelplot(conv_bd50_y50_dt_r[[en1_types]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en1_types")
levelplot(conv_bd50_y50_dt_r[[en1_taxa_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en1_taxa_threat")
levelplot(conv_bd50_y50_dt_r[[en1_taxa_all]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en1_taxa_all")
levelplot(conv_bd50_y50_dt_r[[en2]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: ensemble 2, methods", index.cond=list(c(1, 3, 5, 2, 4, 6)))
levelplot(conv_bd50_y50_dt_r[[en2_mb]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: ensemble 2, combining mammals and birds", layout = c(3, 1))
levelplot(conv_bd50_y50_dt_r[[en2_vp]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: ensemble 2, combining verts and plants", layout = c(3, 1))
levelplot(conv_bd50_y50_dt_r[[en3]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: ensemble 3, resolution", layout = c(4, 3))
levelplot(conv_bd50_y50_dt_r[[en3_all]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en3_all")
levelplot(conv_bd50_y50_dt_r[[en3_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en3_threat")
levelplot(conv_bd50_y50_dt_r[[en3_small]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en3_small")
levelplot(conv_bd50_y50_dt_r[[en3_small_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en3_small_threat")
levelplot(conv_bd50_y50_dt_r[[en4]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en4")
levelplot(conv_bd50_y50_dt_r[[en_norm]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en_norm")
levelplot(conv_bd50_y50_dt_r[[en_l_norm]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield: en_l_norm")

# ---------------------------------------------------------
# Equal weights on all four constraints
# ---------------------------------------------------------
levelplot(conv_eq_dt_r[[en1]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en1")
levelplot(conv_eq_dt_r[[en1_types]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en1_types")
levelplot(conv_eq_dt_r[[en1_taxa_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en1_taxa_threat")
levelplot(conv_eq_dt_r[[en1_taxa_all]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en1_taxa_all")
levelplot(conv_eq_dt_r[[en2]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: ensemble 2, methods", index.cond=list(c(1, 3, 5, 2, 4, 6)))
levelplot(conv_eq_dt_r[[en2_mb]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: ensemble 2, combining mammals and birds", layout = c(3, 1))
levelplot(conv_eq_dt_r[[en2_vp]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: ensemble 2, combining verts and plants", layout = c(3, 1))
levelplot(conv_eq_dt_r[[en3]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: ensemble 3, resolution", layout = c(4, 3))
levelplot(conv_eq_dt_r[[en3_all]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en3_all")
levelplot(conv_eq_dt_r[[en3_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en3_threat")
levelplot(conv_eq_dt_r[[en3_small]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en3_small")
levelplot(conv_eq_dt_r[[en3_small_threat]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en3_small_threat")
levelplot(conv_eq_dt_r[[en4]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en4")
levelplot(conv_eq_dt_r[[en_norm]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en_norm")
levelplot(conv_eq_dt_r[[en_l_norm]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights on all four constraints: en_l_norm")





# ---------------------------------------------------------
# overlap between two rasters
# ---------------------------------------------------------
test_r <- conv_bd100_dt_r + 2*conv_10p_bd_dt_r # so that 1 means, just bd100, 2 means just 10p, and 3 means both
names(test_r) <- runs_w_ref

dev.off()
plot(test_r$m1_vert_all, col = col_overlap, legend = FALSE)
legend("topleft", inset = 0, #c(0.05,0.05), # inset changes where the legend is placed. cex changes the text size.
       legend = c(
         "bd100 (100% Weight on BD, \ndynamic yields)",
         "10p_bd (convt. 10% land, \nconstant yield)",
         "Both model specifications"), pch = 15, col = c(col_overlap[2:4]), 
       bty = "n", pt.cex = 1, cex = 0.9, ncol=1)


par(mfrow = c(2,2))
plot((conv_eq_dt_ensembles_r/lengths)$en1, main = "eq")
plot((conv_bd100_dt_ensembles_r/lengths)$en1, main = )
plot((conv_bd50_y50_dt_ensembles_r/lengths)$en1)
plot((conv_10p_bd_dt_ensembles_r/lengths)$en1)
dev.off()
```


### methods panel
```{r *methods_panel}
# set up:
mp_height <- 300
mp_width <- 300
mp_units <- "px"
mp_res <- 300

col_pas <- c("gray88","gray78")
col_pas_all <- col_pas[pas$type] # this sets up the colors based on a particular attribute, in this case, "type" . See levels(pas$type) to view the order in which the colors will be assigned to the values. 
dev.off()



# ------------------------------------------------------------------------------------
# base Zambia
# ------------------------------------------------------------------------------------
png(file = fp(p_plots,"methods_panel/zambia_pas_legend.png"), 
    width = 200, height = 200, units = "px")
par(bg=NA, mar=c(0, 0, 0, 0), oma=c(0, 0, 0, 0))
plot(msk_shp, border = NA, col = "white")
plot(pas, col = col_pas_all, border = "gray", add=T)
#legend("bottomright", legend= c("Game Mgmt. Area", "National Park"), fill=col_pas, cex = 1.5, bty = "n")
plot(msk_shp, add = TRUE)
dev.off()

# ------------------------------------------------------------------------------------
# Africa
# ------------------------------------------------------------------------------------
png(file = fp(p_plots,"methods_panel/africa.png"), 
    width = 300, height = 300, units = "px")
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
africa %>% st_union() %>% st_geometry() %>% st_transform(crs = aaeac) %T>% plot()
plot(msk_shp, border = "black", add = TRUE)
dev.off()

# ------------------------------------------------------------------------------------
# agroEcoTradeoff model inputs
# ------------------------------------------------------------------------------------
load(file = fp(p_mod_inputs, "yct_constraint_inputs.Rdata"), verbose = TRUE)
estes_bd_input_dt
yield_input_dt
carbon_input_dt
travel_input_dt
msk_csv
estes_bd_input %T>% plot()
yield_input %T>% plot()
carbon_input %T>% plot()
travel_input %T>% plot()
msk_no_pas
yield_input_no_pas %T>% plot()
carbon_input_no_pas %T>% plot()
travel_input_no_pas %T>% plot()

yield_dt <- fread(file = fp(p_mod_output, "yield_dt.csv"))
yield_dt_r <- dt_to_raster(yield_dt, CRSobj)
yield_dt[, x := bd_dt[, .(x)]]
yield_dt[, y := bd_dt[, .(y)]]


save_thumbnails <- function(raster, raster_names, label = "",
                            mp_width = 300, mp_height = 300, mp_units = "px", 
                            no_pas, pas_col = col_pas_all, pas_border = NA){
  
  if (no_pas){no_pas_label = "_no_pas"} else {no_pas_label = ""}
  
  png(file = paste0(p_plots,"/ms_v5/methods_panel_v5/", raster_names, no_pas_label, label, ".png"), 
    width = mp_width, height = mp_height, units = mp_units)
  
  par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
  plot(msk_shp, border = NA)
  plot(raster, box = F, axes = F, legend = FALSE, add = TRUE)
  if (no_pas) {
    plot(pas, col = pas_col, border = pas_border, add=T)
  }
  plot(msk_shp, add = T)
  dev.off()
}

#
bd_dt[, 3:6]
bd_scores_vert_all_conv_bd100_dt <- bd_dt[, 3:6]
bd_scores_vert_all_conv_bd100_dt[,1] <- bd_scores_vert_all_conv_bd100_dt[, 1] * conv_bd100_dt[, 3]
bd_scores_vert_all_conv_bd100_dt[,2] <- bd_scores_vert_all_conv_bd100_dt[, 2] * conv_bd100_dt[, 3]
bd_scores_vert_all_conv_bd100_dt[,3] <- bd_scores_vert_all_conv_bd100_dt[, 3] * conv_bd100_dt[, 3]
bd_scores_vert_all_conv_bd100_dt[,4] <- bd_scores_vert_all_conv_bd100_dt[, 4] * conv_bd100_dt[, 3]


bd_scores_vert_all_conv_bd100 <- data.table(
  x = bd_conv_bd100_dt$x,
  y = bd_conv_bd100_dt$y,
  vert_all_bd100 = bd_conv_bd100_dt$vert_all_conv_bd100,
  # vert_all_bd50 = bd_conv_bd50_y50_dt$vert_all_conv_bd50_y50,
  # vert_all_eq = bd_conv_eq_dt$vert_all_conv_eq,
  
  vert_all = bd_scores_vert_all_conv_bd100_dt[,1],
  vert_endemism = bd_scores_vert_all_conv_bd100_dt[,2],
  vert_threat = bd_scores_vert_all_conv_bd100_dt[,3],
  vert_small = bd_scores_vert_all_conv_bd100_dt[,4]
)
bd_scores_in_conv_r <- dt_to_raster(bd_scores_vert_all_conv_bd100, CRSobj)
plot(bd_scores_in_conv_r)

# make list to run through the model
panel_rasters <- list(
  "yield_input_maize" = yield_input$maize,
  "carbon_input" = carbon_input,
  "travel_input" = travel_input,
  
  "vert_all" = vert_all,
  "vert_endemism" = vert_endemism,
  "vert_threat" = vert_threat,
  "vert_small" = vert_small,
  
  
  "vert_all_conv_bd100" = conv_r$bd100$vert_all,
  "vert_all_conv_bd50_y50" = conv_r$bd50_y50$vert_all,
  "vert_all_conv_eq" = conv_r$eq$vert_all,
  
  "vert_endemism_conv_bd100" = conv_r$bd100$vert_endemism,
  "vert_threat_conv_bd100" = conv_r$bd100$vert_threat,
  "vert_small_conv_bd100" = conv_r$bd100$vert_small,

  
  "vert_all_bd_conv_bd100" = bd_scores_in_conv_r$vert_all_bd100,
  
  "vert_endemism_bd_vert_all_conv_bd100" = bd_scores_in_conv_r$vert_endemism.vert_endemism,
  "vert_threat_bd_vert_all_conv_bd100" = bd_scores_in_conv_r$vert_threat.vert_threat,
  "vert_small_bd_vert_all_conv_bd100" = bd_scores_in_conv_r$vert_small.vert_small,
  
  "vert_all_raw" = vert_r$all_richness$sum,
  "vert_endemism_raw" = vert_r$endemism_richness$sum
)

for (i in seq_along(panel_rasters)) {
  save_thumbnails(raster = panel_rasters[[i]], raster_names = names(panel_rasters)[i], 
                  no_pas = FALSE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )
}


panel_r_bd <- list(
  "bird_all" = bd_inputs_brick$bird_all,
  "bird_all_10" = bd_inputs_brick$bird_all_10,
  "bird_all_110" = bd_inputs_brick$bird_all_110,
  "bird_endemism" = bd_inputs_brick$bird_endemism,
  "bird_endemism_10" = bd_inputs_brick$bird_endemism_10,
  "bird_endemism_110" = bd_inputs_brick$bird_endemism_110,
  "bird_small" = bd_inputs_brick$bird_small,
  "bird_small_10" = bd_inputs_brick$bird_small_10,
  "bird_small_110" = bd_inputs_brick$bird_small_110
)
panel_r_conv <- list(
  "conv_bird_all" = conv_r$bp$bird_all,
  "conv_bird_all_10" = conv_r$bp$bird_all_10,
  "conv_bird_all_110" = conv_r$bp$bird_all_110,
  "conv_bird_endemism" = conv_r$bp$bird_endemism,
  "conv_bird_endemism_10" = conv_r$bp$bird_endemism_10,
  "conv_bird_endemism_110" = conv_r$bp$bird_endemism_110,
  "conv_bird_small" = conv_r$bp$bird_small,
  "conv_bird_small_10" = conv_r$bp$bird_small_10,
  "conv_bird_small_110" = conv_r$bp$bird_small_110
)
panel_r_ensemble <- list(
  "mam" = conv_r$facet_r_bp$mam_bp,
  "bird" = conv_r$facet_r_bp$bird_bp,
  "amp" = conv_r$facet_r_bp$amp_bp,
  "rep" = conv_r$facet_r_bp$rep_bp
)

for (i in seq_along(panel_r_bd)) {
  save_thumbnails(raster = panel_r_bd[[i]], raster_names = names(panel_r_bd)[i], 
                  no_pas = FALSE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )
}
for (i in seq_along(panel_r_conv)) {
  save_thumbnails(raster = panel_r_conv[[i]], raster_names = names(panel_r_conv)[i], 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )
}
for (i in seq_along(panel_r_ensemble)) {
  save_thumbnails(raster = panel_r_ensemble[[i]], raster_names = names(panel_r_ensemble)[i], 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )
}


# ---------------------------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------
# ---------------------------------------------------------------------------------------------



# yield
png(file = fp(p_plots,"methods_panel/yield_input_maize2.png"), 
    width = 450, height = 300, units = "px")
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(yield_input$maize, box = F, axes = F, legend = TRUE, add = TRUE)
plot(msk_shp, add = T)
dev.off()


# carbon
png(file = fp(p_plots,"methods_panel/carbon_input.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(carbon_input, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
dev.off()

# travel cost
png(file = fp(p_plots,"methods_panel/travel_cost_input.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(travel_input, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
dev.off()


# -------------------------------------
# with no PAs
# yield
png(file = fp(p_plots,"methods_panel/yield_input_maize_no_pas.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(yield_input_no_pas$maize, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()

# carbon
png(file = fp(p_plots,"methods_panel/carbon_inputs_no_pas.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(carbon_input, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()

# travel cost
png(file = fp(p_plots,"methods_panel/travel_cost_input_no_pas.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(travel_input, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()


# ------------------------------------------------------------------------------------
# example bd input
# ------------------------------------------------------------------------------------
png(file = fp(p_plots,"methods_panel/vert_all.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(vert_all, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
dev.off()

png(file = fp(p_plots,"methods_panel/vert_all_no_pas.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(bd_dt_r$vert_all, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()


# ------------------------------------------------------------------------------------
# example conv map
# ------------------------------------------------------------------------------------
png(file = fp(p_plots,"methods_panel/vert_all_conv_bd100.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(conv_r$bd100$vert_all, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()

png(file = fp(p_plots,"methods_panel/vert_all_conv_bd50.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(conv_r$bd50_y50$vert_all, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()

png(file = fp(p_plots,"methods_panel/vert_all_conv_eq.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(conv_r$eq$vert_all, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()

# ------------------------------------------------------------------------------------
# bd scores in conv
# ------------------------------------------------------------------------------------
bd_scores_in_conv <- data.table(
  x = bd_conv_bd100_dt$x,
  y = bd_conv_bd100_dt$y,
  bd100 = bd_conv_bd100_dt$vert_all_conv_bd100,
  bd50 = bd_conv_bd50_y50_dt$vert_all_conv_bd50_y50,
  eq = bd_conv_eq_dt$vert_all_conv_eq
)
bd_scores_in_conv_r <- dt_to_raster(bd_scores_in_conv, CRSobj)
plot(bd_scores_in_conv_r)

png(file = fp(p_plots,"methods_panel/vert_all_bd_in_conv_bd100.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(bd_scores_in_conv_r$bd100, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()

png(file = fp(p_plots,"methods_panel/vert_all_bd_in_conv_bd50.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))

plot(msk_shp, border = NA)
plot(bd_scores_in_conv_r$bd50, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()

png(file = fp(p_plots,"methods_panel/vert_all_bd_in_conv_eq.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))

plot(msk_shp, border = NA)
plot(bd_scores_in_conv_r$eq, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()


# ------------------------------------------------------------------------------------
# example raw bd all
# ------------------------------------------------------------------------------------
png(file = fp(p_plots,"methods_panel/vert_all_raw.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(vert_r$all_richness$sum, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()

png(file = fp(p_plots,"methods_panel/vert_all_raw_no_pas.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(bd_dt_r$vert_all_raw, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()

# ------------------------------------------------------------------------------------
# example raw endemism richness
# ------------------------------------------------------------------------------------
png(file = fp(p_plots,"methods_panel/vert_endemism_raw.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(vert_r$endemism_richness$sum, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()

png(file = fp(p_plots,"methods_panel/vert_endemism_raw_no_pas.png"), 
    width = mp_width, height = mp_height, units = mp_units)
par(bg=NA, mar=c(0,0,0,0), oma=c(0,0,0,0))
plot(msk_shp, border = NA)
plot(bd_dt_r$vert_endemism_raw, box = F, axes = F, legend = FALSE, add = TRUE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, border = NA, add=T)
dev.off()


```

```{r convprob_r}
# b
vert_all_convprob_r_b <- toff_bd100$vert_all %>%
    list(Y = .$inputs$y_std,
         C = .$inputs$carbon_p,
         BD = .$inputs$cons_p,
         COST = .$inputs$cost_p) %>%
    constraints(inlist = ., cbetas = cbetas_bd100, silent = FALSE) %>%
    cbind(toff_bd100$vert_all$conv[, .(x, y)], .) %>%
    dt_to_raster(., CRSobj)

vert_all_convprob_r_b %T>% plot()

rm(toff_bd100)


# by
vert_all_convprob_r_by <- toff_bd50_y50$vert_all %>%
    list(Y = .$inputs$y_std,
         C = .$inputs$carbon_p,
         BD = .$inputs$cons_p,
         COST = .$inputs$cost_p) %>%
    constraints(inlist = ., cbetas = cbetas_bd50_y50, silent = FALSE) %>%
    cbind(toff_bd50_y50$vert_all$conv[, .(x, y)], .) %>%
    dt_to_raster(., CRSobj)

vert_all_convprob_r_by %T>% plot()

rm(toff_bd50_y50)

# byct
vert_all_convprob_r_byct <- toff_eq$vert_all %>%
    list(Y = .$inputs$y_std,
         C = .$inputs$carbon_p,
         BD = .$inputs$cons_p,
         COST = .$inputs$cost_p) %>%
    constraints(inlist = ., cbetas = cbetas, silent = FALSE) %>%
    cbind(toff_eq$vert_all$conv[, .(x, y)], .) %>%
    dt_to_raster(., CRSobj)

vert_all_convprob_r_byct %T>% plot()

object_size(toff_eq)
rm(toff_eq)

## conversion probabilities raster:
m4_vert_all_toff_bd100_outputs
plot(m4_vert_all_toff_bd100_outputs$convprob_r$maize)
plot(m4_vert_all_toff_bd100_outputs$bd_input) # vert_all
plot(m4_vert_all_toff_bd100_outputs$convprob_r)

m4_vert_all_toff_bd100_outputs$convprob_r$maize

save_thumbnails(raster = vert_all_convprob_r_b$maize,
                raster_names = "vert_all_convprob_r_b", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )
save_thumbnails(raster = vert_all_convprob_r_by$maize,
                raster_names = "vert_all_convprob_r_by", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )
save_thumbnails(raster = vert_all_convprob_r_byct$maize,
                raster_names = "vert_all_convprob_r_byct", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )



```

```{r facet_averages}
dt_m$all

facet_r$all %T>% plot()
facet_r$bird %T>% plot()
facet_r$res110 %T>% plot()

save_thumbnails(raster = facet_r$all,
                raster_names = "facet_r_all", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$mam,
                raster_names = "facet_r_mam", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$bird,
                raster_names = "facet_r_bird", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$amp,
                raster_names = "facet_r_amp", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$rep,
                raster_names = "facet_r_rep", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$res110,
                raster_names = "facet_r_res110", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$b,
                raster_names = "facet_r_b", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$by,
                raster_names = "facet_r_by", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

save_thumbnails(raster = facet_r$byct,
                raster_names = "facet_r_byct", 
                  no_pas = TRUE, label = "",
                  mp_width = 300, mp_height = 300, mp_units = "px"
                  )

dev.off()
raster::plot(facet_r$all, legend = FALSE)
rangeBuilder::addRasterLegend(facet_r$all, location = 'right', side = 3, nTicks = 0)#, mixmax = c(0,2))
addRasterLegend(s1, location = "bottom", direction = "horizontal", side=1,
                nTicks = 0, ramp=col_main)

#, 
	shortFrac = 0.02, longFrac = 0.3, axisOffset = 0, border = TRUE, 
	ramp = "terrain", isInteger = 'auto', ncolors = 64, breaks = NULL, 
	minmax = NULL, locs = NULL, cex.axis = 0.8, labelDist = 0.7, digits = 2, ...)

```


## old
```{r en1-plots}
p_area_converted_en1 %+% 
  filter(
    mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),
         bd_input %in% runs[en1],
         mod_spec == "bd100")

p_bd_loss_control_en1
p_mean_bd_loss_en1
p_mean_overlap_en1

p_cv_bd_loss_en1
p_var_from_control_en1

plot_grid(p_area_converted_en1, 
          p_bd_loss_control_en1, 
          p_mean_bd_loss_en1, 
          p_mean_overlap_en1, 
          p_cv_bd_loss_en1, 
          p_var_from_control_en1)


# with the shared legend on the bottom
plot_grid_en1 <- 
  plot_grid(p_area_converted_en1 + my_theme, 
          p_bd_loss_control_en1 + my_theme, 
          p_mean_bd_loss_en1 + my_theme, 
          p_mean_overlap_en1 + my_theme, 
          p_cv_bd_loss_en1 + my_theme, 
          p_var_from_control_en1 + my_theme)
legend_b <- get_legend(p_area_converted_en1 + theme(legend.position = "bottom"))
plot_grid(plot_grid_en1, legend_b, ncol = 1, rel_heights = c(1, .1))


results_combo$mod_spec
# just bd100 and 50/50
plot_grid_en1_subset <- plot_grid(p_area_converted_en1 %+% 
            filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme, 
          p_bd_loss_control_en1 %+% 
            filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme,
          p_mean_bd_loss_en1 %+% 
            filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme,
          p_mean_overlap_en1 %+% 
            filter(mutate(overlap_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme,
          p_cv_bd_loss_en1 %+% 
            filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme,
          p_var_from_control_en1 %+% 
            filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme)

plot_grid(plot_grid_en1_subset, legend_b, ncol = 1, rel_heights = c(1, .1))


cowplot::plot_grid(p_area_converted_en1 + labs(title = NULL, subtitle = NULL, caption = NULL), 
                     en2_var_from_cont + labs(title = NULL, subtitle = NULL, caption = NULL), 
                     en3_var_from_cont + labs(title = NULL, subtitle = NULL, caption = NULL), 
                     en4_var_from_cont + labs(title = NULL, subtitle = NULL, caption = NULL), 
                     labels = c('en1', 'en2', 'en3', 'en4'), label_size = 12)

var_from_control_plot_grid
```
```{r en1_types_plots}
p_area_converted_en1_types + theme(plot.margin = unit(c(1,1,1,1), "cm"))
p_bd_loss_control_en1_types + labs(title = NULL, subtitle = NULL)
p_mean_bd_loss_en1_types
p_mean_overlap_en1_types
p_cv_bd_loss_en1_types
p_var_from_control_en1_types


p_mean_bd_loss_en1_types + facet_grid(rows = vars(mod_spec))

p_area_converted_en1 %+% 
  filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),
         bd_input %in% runs[en1],
         mod_spec == "bd100")

# with the shared legend on the bottom

p_area_converted_en1_types + my_theme

plot_grid_en1_types <- 
  plot_grid(p_area_converted_en1_types + my_theme, 
          p_bd_loss_control_en1_types + my_theme, 
          p_mean_bd_loss_en1_types + my_theme, 
          p_mean_overlap_en1_types + my_theme, 
          p_cv_bd_loss_en1_types + my_theme, 
          p_var_from_control_en1_types + my_theme,
          scale = 1)

en1_types_legend_b <- get_legend(p_area_converted_en1_types + theme(legend.position = "bottom"))

png(paste0(p_plots, "/doc_figures/", names(ensembles_list)[2], 
             "_results.png"), 
    width = 12, height = 9, units = "in", res = 300) # "en1"
plot_grid(plot_grid_en1_types, en1_types_legend_b, ncol = 1, rel_heights = c(1, .1))
dev.off()

results_combo$mod_spec
# just bd100 and 50/50
plot_grid_en1_types_subset <- plot_grid(p_area_converted_en1_types %+% 
            filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1_types],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme, 
          p_bd_loss_control_en1_types %+% 
            filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1_types],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme,
          p_mean_bd_loss_en1_types %+% 
            filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1_types],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme,
          p_mean_overlap_en1_types %+% 
            filter(mutate(overlap_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1_types],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme,
          p_cv_bd_loss_en1_types %+% 
            filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1_types],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme,
          p_var_from_control_en1_types %+% 
            filter(mutate(results_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])),   
                   bd_input %in% runs[en1_types],                        
                   mod_spec %in% c("bd100","bd50_y50")) + 
            my_theme)

plot_grid(plot_grid_en1_types_subset, legend_b, ncol = 1, rel_heights = c(1, .1))


# overlap:
p_mean_overlap_en1_types

names(overlap_combo)
overlap_combo %>%
  select(bd_input, mod_spec, 
         runs[en1_types], 
         grep("en1_types", names(overlap_combo), value = TRUE) # select only columns with en1_types
         ) %>%
  filter(bd_input %in% runs[en1_types], mod_spec == "eq") %>%
  select(mean_overlap_en1_types) %>%
  sum()/4

overlap_combo %>%
  select(bd_input, mod_spec, runs[en1_types], mean_overlap_en1_types) %>%
  filter(bd_input %in% runs[en1_types], mod_spec == "eq")

tester <- overlap_combo %>%
  select(bd_input, mod_spec, 
         runs[en1_types]) %>%
  filter(bd_input %in% runs[en1_types], mod_spec == "eq")

(sum(tester$m1_vert_all) + sum(tester$m2_vert_threat) + sum(tester$m3_vert_small) + sum(tester$m4_vert_small_threat) - 4) / 12
mean(as.numeric(tester[1, c(4:6)]))

names(overlap_combo)


grep("en1_types", names(overlap_combo), value = TRUE)

overlap_combo %>%
  select(bd_input, mod_spec, runs[en1_types]) %>%
  head()
```


```{r en1_taxa_threat_plots}
p_area_converted_en1_taxa_threat
p_bd_loss_control_en1_taxa_threat
p_mean_bd_loss_en1_taxa_threat
p_mean_overlap_en1_taxa_threat
p_cv_bd_loss_en1_taxa_threat
p_var_from_control_en1_taxa_threat


p_mean_bd_loss_en1_taxa_threat + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en1_taxa_threat, 
          p_bd_loss_control_en1_taxa_threat, 
          p_mean_bd_loss_en1_taxa_threat, 
          p_mean_overlap_en1_taxa_threat, 
          p_cv_bd_loss_en1_taxa_threat, 
          p_var_from_control_en1_taxa_threat)


# with the shared legend on the bottom
plot_grid_en1_taxa_threat <- 
  plot_grid(p_area_converted_en1_taxa_threat + my_theme, 
          p_bd_loss_control_en1_taxa_threat + my_theme, 
          p_mean_bd_loss_en1_taxa_threat + my_theme, 
          p_mean_overlap_en1_taxa_threat + my_theme, 
          p_cv_bd_loss_en1_taxa_threat + my_theme, 
          p_var_from_control_en1_taxa_threat + my_theme)
en1_taxa_threat_legend_b <- get_legend(p_area_converted_en1_taxa_threat + theme(legend.position = "bottom"))
plot_grid(plot_grid_en1_taxa_threat, en1_taxa_threat_legend_b, ncol = 1, rel_heights = c(1, .1))
```

```{r en1_taxa_all_plots}
# ---------------------------------------
# en1_taxa_all plots
# ---------------------------------------
p_area_converted_en1_taxa_all
p_bd_loss_control_en1_taxa_all
p_mean_bd_loss_en1_taxa_all
p_mean_overlap_en1_taxa_all
p_cv_bd_loss_en1_taxa_all
p_var_from_control_en1_taxa_all


p_mean_bd_loss_en1_taxa_all + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en1_taxa_all, 
          p_bd_loss_control_en1_taxa_all, 
          p_mean_bd_loss_en1_taxa_all, 
          p_mean_overlap_en1_taxa_all, 
          p_cv_bd_loss_en1_taxa_all, 
          p_var_from_control_en1_taxa_all)


# with the shared legend on the bottom
plot_grid_en1_taxa_all <- 
  plot_grid(p_area_converted_en1_taxa_all + my_theme, 
          p_bd_loss_control_en1_taxa_all + my_theme, 
          p_mean_bd_loss_en1_taxa_all + my_theme, 
          p_mean_overlap_en1_taxa_all + my_theme, 
          p_cv_bd_loss_en1_taxa_all + my_theme, 
          p_var_from_control_en1_taxa_all + my_theme)
en1_taxa_all_legend_b <- get_legend(p_area_converted_en1_taxa_all + theme(legend.position = "bottom"))
plot_grid(plot_grid_en1_taxa_all, en1_taxa_all_legend_b, ncol = 1, rel_heights = c(1, .1))
```

```{r en2_methods_plots}
p_bd_loss_control_en2
p_bd_loss_control_en2_mb
p_bd_loss_control_en2_vp

p_var_from_control_en2
p_var_from_control_en2_mb
p_var_from_control_en2_vp

p_mean_bd_loss_en2
p_mean_bd_loss_en2_mb
p_mean_bd_loss_en2_vp

p_area_converted_en2
p_area_converted_en2_mb
p_area_converted_en2_vp

p_mean_overlap_en2
p_mean_overlap_en2_mb
p_mean_overlap_en2_vp

# ---------------------------------------
# en2 plots
# ---------------------------------------
p_area_converted_en2
p_bd_loss_control_en2
p_mean_bd_loss_en2
p_mean_overlap_en2
p_cv_bd_loss_en2
p_var_from_control_en2


p_mean_bd_loss_en2 + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en2, 
          p_bd_loss_control_en2, 
          p_mean_bd_loss_en2, 
          p_mean_overlap_en2, 
          p_cv_bd_loss_en2, 
          p_var_from_control_en2)


# with the shared legend on the bottom
plot_grid_en2 <- 
  plot_grid(p_area_converted_en2 + my_theme, 
          p_bd_loss_control_en2 + my_theme, 
          p_mean_bd_loss_en2 + my_theme, 
          p_mean_overlap_en2 + my_theme, 
          p_cv_bd_loss_en2 + my_theme, 
          p_var_from_control_en2 + my_theme)
en2_legend_b <- get_legend(p_area_converted_en2 + theme(legend.position = "bottom"))
plot_grid(plot_grid_en2, en2_legend_b, ncol = 1, rel_heights = c(1, .1))

# ---------------------------------------
# en2_mb plots
# ---------------------------------------
p_area_converted_en2_mb
p_bd_loss_control_en2_mb
p_mean_bd_loss_en2_mb
p_mean_overlap_en2_mb
p_cv_bd_loss_en2_mb
p_var_from_control_en2_mb


p_mean_bd_loss_en2_mb + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en2_mb, 
          p_bd_loss_control_en2_mb, 
          p_mean_bd_loss_en2_mb, 
          p_mean_overlap_en2_mb, 
          p_cv_bd_loss_en2_mb, 
          p_var_from_control_en2_mb)


# with the shared legend on the bottom
plot_grid_en2_mb <- 
  plot_grid(p_area_converted_en2_mb + my_theme, 
          p_bd_loss_control_en2_mb + my_theme, 
          p_mean_bd_loss_en2_mb + my_theme, 
          p_mean_overlap_en2_mb + my_theme, 
          p_cv_bd_loss_en2_mb + my_theme, 
          p_var_from_control_en2_mb + my_theme)
en2_mb_legend_b <- get_legend(p_area_converted_en2_mb + theme(legend.position = "bottom"))
plot_grid(plot_grid_en2_mb, en2_mb_legend_b, ncol = 1, rel_heights = c(1, .1))

# ---------------------------------------
# en2_vp plots
# ---------------------------------------
p_area_converted_en2_vp
p_bd_loss_control_en2_vp
p_mean_bd_loss_en2_vp
p_mean_overlap_en2_vp
p_cv_bd_loss_en2_vp
p_var_from_control_en2_vp


p_mean_bd_loss_en2_vp + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en2_vp, 
          p_bd_loss_control_en2_vp, 
          p_mean_bd_loss_en2_vp, 
          p_mean_overlap_en2_vp, 
          p_cv_bd_loss_en2_vp, 
          p_var_from_control_en2_vp)


# with the shared legend on the bottom
plot_grid_en2_vp <- 
  plot_grid(p_area_converted_en2_vp + my_theme, 
          p_bd_loss_control_en2_vp + my_theme, 
          p_mean_bd_loss_en2_vp + my_theme, 
          p_mean_overlap_en2_vp + my_theme, 
          p_cv_bd_loss_en2_vp + my_theme, 
          p_var_from_control_en2_vp + my_theme)
en2_vp_legend_b <- get_legend(p_area_converted_en2_vp + theme(legend.position = "bottom"))
plot_grid(plot_grid_en2_vp, en2_vp_legend_b, ncol = 1, rel_heights = c(1, .1))

```

```{r en3_resolution_plots}

p_mean_bd_loss_en3
p_mean_bd_loss_en3_all
p_mean_bd_loss_en3_threat
p_mean_bd_loss_en3_small
p_mean_bd_loss_en3_small_threat


p_bd_loss_control_en3
p_bd_loss_control_en3_all
p_bd_loss_control_en3_threat
p_bd_loss_control_en3_small
p_bd_loss_control_en3_small_threat


p_var_from_control_en3
p_var_from_control_en3_all
p_var_from_control_en3_threat
p_var_from_control_en3_small
p_var_from_control_en3_small_threat


p_area_converted_en3
p_area_converted_en3_all
p_area_converted_en3_threat
p_area_converted_en3_small
p_area_converted_en3_small_threat


p_mean_overlap_en3
p_mean_overlap_en3_all
p_mean_overlap_en3_threat
p_mean_overlap_en3_small
p_mean_overlap_en3_small_threat

names(ensembles_list)
###############
# ---------------------------------------
# en3 plots
# ---------------------------------------
p_area_converted_en3
p_bd_loss_control_en3
p_mean_bd_loss_en3
p_mean_overlap_en3
p_cv_bd_loss_en3
p_var_from_control_en3


p_mean_bd_loss_en3 + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en3, 
          p_bd_loss_control_en3, 
          p_mean_bd_loss_en3, 
          p_mean_overlap_en3, 
          p_cv_bd_loss_en3, 
          p_var_from_control_en3)


# with the shared legend on the bottom
plot_grid_en3 <- 
  plot_grid(p_area_converted_en3 + my_theme, 
          p_bd_loss_control_en3 + my_theme, 
          p_mean_bd_loss_en3 + my_theme, 
          p_mean_overlap_en3 + my_theme, 
          p_cv_bd_loss_en3 + my_theme, 
          p_var_from_control_en3 + my_theme)
en3_legend_b <- get_legend(p_area_converted_en3 + theme(legend.position = "bottom"))
plot_grid(plot_grid_en3, en3_legend_b, ncol = 1, rel_heights = c(1, .1))

# ---------------------------------------
# en3_all plots
# ---------------------------------------
p_area_converted_en3_all
p_bd_loss_control_en3_all
p_mean_bd_loss_en3_all
p_mean_overlap_en3_all
p_cv_bd_loss_en3_all
p_var_from_control_en3_all


p_mean_bd_loss_en3_all + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en3_all, 
          p_bd_loss_control_en3_all, 
          p_mean_bd_loss_en3_all, 
          p_mean_overlap_en3_all, 
          p_cv_bd_loss_en3_all, 
          p_var_from_control_en3_all)


# with the shared legend on the bottom
plot_grid_en3_all <- 
  plot_grid(p_area_converted_en3_all + my_theme, 
          p_bd_loss_control_en3_all + my_theme, 
          p_mean_bd_loss_en3_all + my_theme, 
          p_mean_overlap_en3_all + my_theme, 
          p_cv_bd_loss_en3_all + my_theme, 
          p_var_from_control_en3_all + my_theme)
en3_all_legend_b <- get_legend(p_area_converted_en3_all + theme(legend.position = "bottom"))
plot_grid(plot_grid_en3_all, en3_all_legend_b, ncol = 1, rel_heights = c(1, .1))

# ---------------------------------------
# en3_threat plots
# ---------------------------------------
p_area_converted_en3_threat
p_bd_loss_control_en3_threat
p_mean_bd_loss_en3_threat
p_mean_overlap_en3_threat
p_cv_bd_loss_en3_threat
p_var_from_control_en3_threat


p_mean_bd_loss_en3_threat + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en3_threat, 
          p_bd_loss_control_en3_threat, 
          p_mean_bd_loss_en3_threat, 
          p_mean_overlap_en3_threat, 
          p_cv_bd_loss_en3_threat, 
          p_var_from_control_en3_threat)


# with the shared legend on the bottom
plot_grid_en3_threat <- 
  plot_grid(p_area_converted_en3_threat + my_theme, 
          p_bd_loss_control_en3_threat + my_theme, 
          p_mean_bd_loss_en3_threat + my_theme, 
          p_mean_overlap_en3_threat + my_theme, 
          p_cv_bd_loss_en3_threat + my_theme, 
          p_var_from_control_en3_threat + my_theme)
en3_threat_legend_b <- get_legend(p_area_converted_en3_threat + theme(legend.position = "bottom"))
plot_grid(plot_grid_en3_threat, en3_threat_legend_b, ncol = 1, rel_heights = c(1, .1))

# ---------------------------------------
# en3_small plots
# ---------------------------------------
p_area_converted_en3_small
p_bd_loss_control_en3_small
p_mean_bd_loss_en3_small
p_mean_overlap_en3_small
p_cv_bd_loss_en3_small
p_var_from_control_en3_small


p_mean_bd_loss_en3_small + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en3_small, 
          p_bd_loss_control_en3_small, 
          p_mean_bd_loss_en3_small, 
          p_mean_overlap_en3_small, 
          p_cv_bd_loss_en3_small, 
          p_var_from_control_en3_small)


# with the shared legend on the bottom
plot_grid_en3_small <- 
  plot_grid(p_area_converted_en3_small + my_theme, 
          p_bd_loss_control_en3_small + my_theme, 
          p_mean_bd_loss_en3_small + my_theme, 
          p_mean_overlap_en3_small + my_theme, 
          p_cv_bd_loss_en3_small + my_theme, 
          p_var_from_control_en3_small + my_theme)
en3_small_legend_b <- get_legend(p_area_converted_en3_small + theme(legend.position = "bottom"))
plot_grid(plot_grid_en3_small, en3_small_legend_b, ncol = 1, rel_heights = c(1, .1))

# ---------------------------------------
# en3_small_threat plots
# ---------------------------------------
p_area_converted_en3_small_threat
p_bd_loss_control_en3_small_threat
p_mean_bd_loss_en3_small_threat
p_mean_overlap_en3_small_threat
p_cv_bd_loss_en3_small_threat
p_var_from_control_en3_small_threat


p_mean_bd_loss_en3_small_threat + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en3_small_threat, 
          p_bd_loss_control_en3_small_threat, 
          p_mean_bd_loss_en3_small_threat, 
          p_mean_overlap_en3_small_threat, 
          p_cv_bd_loss_en3_small_threat, 
          p_var_from_control_en3_small_threat)


# with the shared legend on the bottom
plot_grid_en3_small_threat <- 
  plot_grid(p_area_converted_en3_small_threat + my_theme, 
          p_bd_loss_control_en3_small_threat + my_theme, 
          p_mean_bd_loss_en3_small_threat + my_theme, 
          p_mean_overlap_en3_small_threat + my_theme, 
          p_cv_bd_loss_en3_small_threat + my_theme, 
          p_var_from_control_en3_small_threat + my_theme)
en3_small_threat_legend_b <- get_legend(p_area_converted_en3_small_threat + theme(legend.position = "bottom"))
plot_grid(plot_grid_en3_small_threat, en3_small_threat_legend_b, ncol = 1, rel_heights = c(1, .1))

```

```{r en4_recipes}
p_bd_loss_control_en4

p_var_from_control_en4

p_mean_bd_loss_en4

p_area_converted_en4

p_mean_overlap_en4

# ---------------------------------------
# en4 plots
# ---------------------------------------
p_area_converted_en4
p_bd_loss_control_en4
p_mean_bd_loss_en4
p_mean_overlap_en4
p_cv_bd_loss_en4
p_var_from_control_en4


p_mean_bd_loss_en4 + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en4, 
          p_bd_loss_control_en4, 
          p_mean_bd_loss_en4, 
          p_mean_overlap_en4, 
          p_cv_bd_loss_en4, 
          p_var_from_control_en4)


# with the shared legend on the bottom
plot_grid_en4 <- 
  plot_grid(p_area_converted_en4 + my_theme, 
          p_bd_loss_control_en4 + my_theme, 
          p_mean_bd_loss_en4 + my_theme, 
          p_mean_overlap_en4 + my_theme, 
          p_cv_bd_loss_en4 + my_theme, 
          p_var_from_control_en4 + my_theme)
en4_legend_b <- get_legend(p_area_converted_en4 + theme(legend.position = "bottom"))
plot_grid(plot_grid_en4, en4_legend_b, ncol = 1, rel_heights = c(1, .1))



```

```{r *en_norm_plots}
# idea, combine results plots and the overlap plots.
results_plot_grid <- plot_grid(
      eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[i]))) + theme, 
      eval(parse(text = paste0("p_bd_loss_control_", names(ensembles_list)[i]))) + theme, 
      eval(parse(text = paste0("p_mean_overlap_", names(ensembles_list)[i]))) + theme,
      nrow = 1, labels = c("a", "b", "c")
  )

results_legend_b <- get_legend(
  eval(parse(text = paste0("p_area_converted_", names(ensembles_list)[i]))) + 
    theme(legend.position = "bottom"))
  
# see the code chunk: "*new_main_fig_ensemble_overlap"
row_norm <- gplot(ensemble_fig_brick$en_norm, maxpixels = 5000000) + 
  geom_raster(aes(fill = value)) +
  facet_wrap(~ variable, nrow = 1) + 
  scale_fill_gradientn(colors = terrain.colors(50, rev = TRUE), na.value = "white") +
  labs(y = "Normalization \nOrder", x = NULL) + 
  theme(rect = element_blank(), line = element_blank(), 
        axis.line = element_blank(), axis.ticks = element_blank(), 
        axis.ticks.length = unit(0, "pt"), axis.text = element_blank()) + 
  coord_equal()
  
row_norm_maps <- plot_grid( 
  row_norm, nrow = 1, labels = c("d")
  )
  
  png(paste0(p_plots, "/doc_figures/", "en_norm", "_results", ".png"), 
      width = 10, height = 4, units = "in", res = 300)
  # print the plot I want to use, depending on main_text argument
  
  print(
    plot_grid(
      results_plot_grid_main, 
      results_legend_b, 
      row_norm,
      ncol = 1, rel_heights = c(1, .1, 1)))
  
  dev.off()



# ---------------------------------------
# en_norm plots
# ---------------------------------------
p_area_converted_en_norm
p_bd_loss_control_en_norm
p_mean_bd_loss_en_norm
p_mean_overlap_en_norm
p_cv_bd_loss_en_norm
p_var_from_control_en_norm


p_mean_bd_loss_en_norm + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en_norm, 
          p_bd_loss_control_en_norm, 
          p_mean_bd_loss_en_norm, 
          p_mean_overlap_en_norm, 
          p_cv_bd_loss_en_norm, 
          p_var_from_control_en_norm)


# with the shared legend on the bottom
plot_grid_en_norm <- 
  plot_grid(p_area_converted_en_norm + my_theme, 
          p_bd_loss_control_en_norm + my_theme, 
          p_mean_bd_loss_en_norm + my_theme, 
          p_mean_overlap_en_norm + my_theme, 
          p_cv_bd_loss_en_norm + my_theme, 
          p_var_from_control_en_norm + my_theme)
en_norm_legend_b <- get_legend(p_area_converted_en_norm + theme(legend.position = "bottom"))
plot_grid(plot_grid_en_norm, en_norm_legend_b, ncol = 1, rel_heights = c(1, .1))

# ---------------------------------------
# en_l_norm plots
# ---------------------------------------
p_area_converted_en_l_norm
p_bd_loss_control_en_l_norm
p_mean_bd_loss_en_l_norm
p_mean_overlap_en_l_norm
p_cv_bd_loss_en_l_norm
p_var_from_control_en_l_norm


p_mean_bd_loss_en_l_norm + facet_grid(rows = vars(mod_spec))


plot_grid(p_area_converted_en_l_norm, 
          p_bd_loss_control_en_l_norm, 
          p_mean_bd_loss_en_l_norm, 
          p_mean_overlap_en_l_norm, 
          p_cv_bd_loss_en_l_norm, 
          p_var_from_control_en_l_norm)


# with the shared legend on the bottom
plot_grid_en_l_norm <- 
  plot_grid(p_area_converted_en_l_norm + my_theme, 
          p_bd_loss_control_en_l_norm + my_theme, 
          p_mean_bd_loss_en_l_norm + my_theme, 
          p_mean_overlap_en_l_norm + my_theme, 
          p_cv_bd_loss_en_l_norm + my_theme, 
          p_var_from_control_en_l_norm + my_theme)
en_l_norm_legend_b <- get_legend(p_area_converted_en_l_norm + theme(legend.position = "bottom"))
plot_grid(plot_grid_en_l_norm, en_l_norm_legend_b, ncol = 1, rel_heights = c(1, .1))

```


```{r normalization_plots}
p_bd_loss_control %+% filter(results_combo, bd_input %in% runs[c(29, 33)]) # m20_laurance, m24_laurance_not_norm

# does the order in which you normalize things matter? # m2_vert_threat, m23_vert_threat_sum_norm
p_bd_loss_control %+% filter(results_combo, bd_input %in% runs[c(2, 32)]) 
p_var_from_control %+% filter(results_combo, bd_input %in% runs[c(2, 32)]) 
p_mean_bd_loss %+% filter(results_combo, bd_input %in% runs[c(2, 32)])
p_area_converted %+% filter(results_combo, bd_input %in% runs[c(2, 32)])
p_overlap_combo_mean %+% filter(overlap_combo, bd_input %in% runs[c(2, 32)])

levelplot(conv_bd100_dt_r[[c(2, 32)]], col.regions = terrain.colors(50, rev = TRUE), main = "100% weight on bd, variable yields")
levelplot(conv_bd50_y50_dt_r[[c(2, 32)]], col.regions = terrain.colors(50, rev = TRUE), main = "50% weight on bd, 50% on yield")
levelplot(conv_10p_bd_dt_r[[c(2, 32)]], col.regions = terrain.colors(50, rev = TRUE), main = "Converting 10% of land, equal yields")
levelplot(conv_eq_dt_r[[c(2, 32)]], col.regions = terrain.colors(50, rev = TRUE), main = "Equal weights")

# overlap
filter(overlap_combo, bd_input %in% runs[c(2,32)])[, c(1:2, 4, 34)] %>% 
  melt(id.vars = c("bd_input", "mod_spec"), variable.name = "overlap_with") %>% 
  filter(value != 1)

ggplot(data = 
         filter(overlap_combo, bd_input %in% runs[c(2,32)])[, c(1:2, 4, 34)] %>% 
         melt(id.vars = c("bd_input", "mod_spec"), variable.name = "overlap_with") %>% 
         filter(value != 1)) +
  geom_point(mapping = aes(x = bd_input, y = value, color = mod_spec), position = position_dodge(0.6)) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 310, vjust = 1, hjust = 0)) +
  xlab("Biodiversity Input") + ylab("Percent Overlap") + 
  labs(title = "Percent Overlap", subtitle = "comparing normalization order",
       caption = NULL) + 
  scale_color_manual(name = "Model Specifications",
                     labels = c("eq" = "Equal Weights",
                                "bd50_y50" = "50% on Biodiversity, \n50% Yield",
                                "bd100" = "100% on Biodiversity",
                                "10p_bd" = "Converting lowest \n10% bd scores"),
                     values = c("eq" = hue_pal()(4)[4], #"purple",
                                "bd50_y50" = hue_pal()(4)[3], #"blue",
                                "bd100" = hue_pal()(4)[2], # "green",
                                "10p_bd" = hue_pal()(4)[1])) # "red" 


names(overlap_combo)

plot(conv_eq_dt_r[[runs[c(2, 32)]]])
raster::plot()

s1
s2
raster::calc(s1, s2, sum)

conv_eq_dt_r[[runs[c(29, 33)]]]

norm_runs_brick <- brick(conv_eq_dt_r$all/length(runs),
                   conv_bd50_y50_dt_ensembles_r$all/length(runs),
                   conv_bd100_dt_ensembles_r$all/length(runs),
                   conv_10p_bd_dt_ensembles_r$all/length(runs))

names(norm_runs_brick) <- c("eq", "bd50_y50", "bd100", "10p_bd")

filter(mutate(overlap_combo, bd_input = fct_relevel(bd_input, runs_w_ref[runs_reorder])), bd_input %in% runs[en1]) +


```


```{r plot}

boxplot(results_eq_norm[, 2:7], notch = TRUE, xlab = "model run", ylab = "bd loss")
boxplot(results_eq_norm[, 10:18], notch = TRUE)

# plotting the averages
p_mean <- ggplot() +
  geom_errorbar(data = results_eq_norm, mapping = aes(x = mod_run, ymin = mean_bd_loss - 1.96*se_bd_loss, ymax = mean_bd_loss + 1.96*se_bd_loss), color = "gray", width = 0.4) + 
  geom_point(data = results_eq_norm, mapping = aes(x = mod_run, y = mean_bd_loss, color = "eq")) +
  geom_errorbar(data = results_bd50_y50_norm, mapping = aes(x = mod_run, ymin = mean_bd_loss - 1.96*se_bd_loss, ymax = mean_bd_loss + 1.96*se_bd_loss), color = "gray", width = 0.4) + 
  geom_point(data = results_bd50_y50_norm, mapping = aes(x = mod_run, y = mean_bd_loss, color = "bd50_y50")) +
  geom_errorbar(data = results_bd100_norm, mapping = aes(x = mod_run, ymin = mean_bd_loss - 1.96*se_bd_loss, ymax = mean_bd_loss + 1.96*se_bd_loss), color = "gray", width = 0.4) + 
  geom_point(data = results_bd100_norm, mapping = aes(x = mod_run, y = mean_bd_loss, color = "bd100")) +
  geom_errorbar(data = results_10p_bd_norm, mapping = aes(x = mod_run, ymin = mean_bd_loss - 1.96*se_bd_loss, ymax = mean_bd_loss + 1.96*se_bd_loss), color = "gray", width = 0.4) + 
  geom_point(data = results_10p_bd_norm, mapping = aes(x = mod_run, y = mean_bd_loss, color = "10p_bd")) +
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 310, vjust = 1, hjust = 0)) +
  xlab("Model Run") + ylab("Mean % Unprotected Biodiversity Loss") + 
  ggtitle("Average Biodiversity Loss for each model run \n(as a percent of unprotected biodiversity)") + 
  scale_color_manual(name = "variance type",
                     labels = c("eq" = "Equal Weights",
                                "bd50_y50" = "50% on Biodiversity, 50% Yield",
                                "bd100" = "100% on Biodiversity",
                                "10p_bd" = "Converting lowest 10% bd scores"),
                     values = c("eq" = "black",
                                "bd50_y50" = "green",
                                "bd100" = "red",
                                "10p_bd" = "blue")
                     )
p_mean



names(results_eq_norm)
p2 <- ggplot(results_eq_norm) +
  geom_point(aes(x = mod_run, y = var_from_control, color = "plot1" # color effectively functions as a label for this set of points...i then need to set the color for this set of points below in scale_color_manual(),.
                 )) +
  #geom_errorbar(aes(x = mod_run, ymin = mean_bd_loss - 1.96*se_bd_loss, ymax = mean_bd_loss + 1.96*se_bd_loss), color = "red") + 
  theme_classic() + 
  theme(axis.text.x = element_text(angle = 310, vjust = 1, hjust = 0)) +
  xlab("Model Run") + ylab("Mean % Unprotected Biodiversity Loss") + 
  geom_point(aes(x = mod_run, y = var_bd_loss, color = "plot2"
                 )) + 
  theme(legend.position = c(0.95, 0.95), legend.justification = c("right", "top")) + 
  scale_color_manual(name = "variance type",
                     labels = c("plot1" = "Variance from controlling layer",
                                "plot2" = "Variance label"),
                     values = c("plot1" = "blue",
                                "plot2" = "red"))
p2



plot(results_eq_norm$var_from_control, col = "red")
points(results_eq_norm$var_bd_loss, col = "blue")



ggplot(results_eq_norm, aes(x = mod_run, y = mean_bd_loss)) +
  geom_col(color = "white") +
  geom_errorbar(aes(x = mod_run, ymin = mean_bd_loss - 1.96*se_bd_loss, ymax = mean_bd_loss + 1.96*se_bd_loss), color = "red") + theme_classic() + 
  theme(axis.text.x = element_text(angle = 310, vjust = 1, hjust = 0)) +
  xlab("Model Run") + ylab("Mean % Unprotected Biodiversity Loss")
p

barplot(test$mean_bd_loss)



plot(test$sum_bd_loss)
plot(test$mean_bd_loss)
plot(test$var_bd_loss)
plot(test$sd_bd_loss)
plot(test$m1_vert_all_bd_loss)

boxplot(results_eq_norm[, 2:7], notch = TRUE)


test <- apply(results_eq_norm[, -1], MARGIN = 1, FUN = sum)
rowSums(results_eq_norm[, -1])
rowMeans(results_eq_norm[, -1])
test$mean_bd_loss
transpose()

mean(results_eq_norm$m12_rep_all_bd_loss)
mean(as.numeric(results_eq_norm[1, -1]))
mean(as.numeric(results_eq_norm[1, -1]))
rowSums(test)
plot(test)
```


# Matrices and Heatmaps
Do a heatmap matrix with color-blind friendly

conversion results on the x axis, conv-bd-scores/unprotected bd score on the y-axis
```{r heatmap1_eq-bd_conv_norm}
# this is the matrix to be plotted, which includes the biodiversity lost in converted areas, as a proportion of all of the unprotected biodiversity in the bd-input raster. 
results_eq$bd_conv_norm # this is just the diagonal
head(results_eq_norm)

as.matrix(results_eq)

names(results_eq)



# colnames(results_eq_norm) <- c("mod_run", runs) # if I want to remove the bd_loss from the columns

# ---------------------------------------------------------
# headmap production steps
# ---------------------------------------------------------
# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/ )
melt_results_eq_norm <- melt(results_eq_norm, variable.name = "bd_input", value.name = "bd_conv_eq_norm")

melt_results_eq_norm <- melt_results_eq_norm %>%
  mutate(percent_bd_loss = bd_conv_eq_norm * 100, # add a percent column by multiplying by 100
         rounded_percent = round(percent_bd_loss, digits = 2) # rounded percents, for labelling. 
         )

melt_eq_og <- melt_results_eq_norm

head(melt_results_eq_norm)
tail(melt_results_eq_norm)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 
melt_results_eq_norm$mod_run <- factor(melt_results_eq_norm$mod_run, 
                                       levels = levels(melt_eq_og$mod_run)[runs_reorder])
melt_results_eq_norm$bd_input <- factor(melt_results_eq_norm$bd_input, 
                                        levels = levels(melt_eq_og$bd_input)[runs_reorder]) 
head(melt_results_eq_norm)
levels(melt_results_eq_norm$mod_run)
levels(melt_results_eq_norm$bd_input)

# change back the order of the factors:
melt_results_eq_norm$mod_run <- factor(melt_results_eq_norm$mod_run, 
                                       levels = levels(melt_eq_og$mod_run))
melt_results_eq_norm$bd_input <- factor(melt_results_eq_norm$bd_input, 
                                        levels = levels(melt_eq_og$bd_input))


# ---------------------------------------------------------
# Build base plot
# ---------------------------------------------------------
bd_loss_heatmap_eq <- 
  ggplot(data = melt_results_eq_norm) + 
  geom_tile(mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  #scale_fill_gradient(low = "blue", high = "red")
  scale_fill_viridis(option = "D", # viridis option
                     limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  labs(title = "Percent Biodiversity Loss in Converted Areas", subtitle = "All model runs, equal weights", fill = "Percent of \nUnprotected \nBiodiversity \nConverted") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_eq)

head(melt_results_eq_norm)

# make it interactive.
library(plotly)
ggplotly(bd_loss_heatmap_eq)



# note, to change the scale, just add:  scale_fill_viridis(limits = NULL)

# ---------------------------------------------------------
# ensemble 1 - biodiversity facets
# ---------------------------------------------------------
bd_loss_heatmap_eq_en1 <- bd_loss_heatmap_eq %+% filter(melt_results_eq_norm, mod_run %in% mod_conv_eq_names[en1], bd_input %in% bd_loss_names[en1]) +
  labs(subtitle = "En 1 Biodiversity facets, equal weights")

# ---------------------------------------------------------
# ensemble 2 - methods
# ---------------------------------------------------------
bd_loss_heatmap_eq_en2 <- bd_loss_heatmap_eq %+% filter(melt_results_eq_norm, mod_run %in% mod_conv_eq_names[en2], bd_input %in% bd_loss_names[en2]) +
  labs(subtitle = "En 2 Methods, equal weights") + scale_fill_viridis(limits = NULL)

# ---------------------------------------------------------
# ensemble 3 - resolution
# ---------------------------------------------------------
bd_loss_heatmap_eq_en3 <- bd_loss_heatmap_eq %+% filter(melt_results_eq_norm, mod_run %in% mod_conv_eq_names[en3], bd_input %in% bd_loss_names[en3]) +
  labs(subtitle = "En 3 Resolution, equal weights") + scale_fill_viridis(limits = NULL)

# ---------------------------------------------------------
# ensemble 4 - recipes
# ---------------------------------------------------------
bd_loss_heatmap_eq_en4 <- bd_loss_heatmap_eq %+% filter(melt_results_eq_norm, mod_run %in% mod_conv_eq_names[en4], bd_input %in% bd_loss_names[en4]) +
  labs(subtitle = "En 4 Recipes, equal weights") + scale_fill_viridis(limits = NULL)



print(bd_loss_heatmap_eq)
print(bd_loss_heatmap_eq_en1)
print(bd_loss_heatmap_eq_en2)
print(bd_loss_heatmap_eq_en3)
print(bd_loss_heatmap_eq_en4)


```

```{r heatmap2_eq-bd_conv_variance}

# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_results_eq_norm_var <- melt(results_eq_norm_var, variable.name = "bd_input", value.name = "bd_conv_eq_norm_var")

melt_results_eq_norm_var <- melt_results_eq_norm_var %>%
  mutate(percent_bd_loss_var = bd_conv_eq_norm_var * 100, # add a percent column by multiplying by 100
         rounded_percent = round(percent_bd_loss_var, digits = 2) # rounded percents, for labelling. 
         )

melt_eq_var_og <- melt_results_eq_norm_var

head(melt_results_eq_norm_var)
tail(melt_results_eq_norm_var)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 
melt_results_eq_norm_var$mod_run <- factor(melt_results_eq_norm_var$mod_run, 
                                       levels = levels(melt_eq_var_og$mod_run)[runs_reorder])
melt_results_eq_norm_var$bd_input <- factor(melt_results_eq_norm_var$bd_input, 
                                        levels = levels(melt_eq_var_og$bd_input)[runs_reorder]) 
head(melt_results_eq_norm_var)
levels(melt_results_eq_norm_var$mod_run)
levels(melt_results_eq_norm_var$bd_input)

# change back the order of the factors:
melt_results_eq_norm_var$mod_run <- factor(melt_results_eq_norm_var$mod_run, 
                                       levels = levels(melt_eq_var_og$mod_run))
melt_results_eq_norm_var$bd_input <- factor(melt_results_eq_norm_var$bd_input, 
                                        levels = levels(melt_eq_var_og$bd_input))

bd_conv_norm_var_df[c(5, 6, 8, 9), c(1, 6, 7, 9, 10)]
results_eq_norm_var[1:4, 1:5]
names(bd_conv_norm_var_df)

# ---------------------------------------------------------
# Build base plot
# ---------------------------------------------------------
min(melt_results_eq_norm_var$percent_bd_loss_var)
max(melt_results_eq_norm_var$percent_bd_loss_var)

bd_loss_var_heatmap_eq <- 
  ggplot(data = melt_results_eq_norm_var) + 
  geom_tile(mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  labs(title = "Percent biodiversity loss in converted areas \nrelative to loss in controlling layer",
       subtitle = "All model runs, equal weights",
       fill = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_eq)
print(bd_loss_var_heatmap_eq_no_amp_rep)
print(bd_loss_heatmap_eq)


bd_loss_var_heatmap_eq %+% filter(melt_results_eq_norm_var, mod_run %in% mod_conv_eq_names[c(1:6, 9:33)], bd_input %in% bd_loss_names[c(1:6, 9:33)]) +
  labs(subtitle = "All layers but amphibians and reptiles, equal weights")

bd_loss_var_heatmap_eq_en1 <- bd_loss_var_heatmap_eq %+% filter(melt_results_eq_norm_var, mod_run %in% mod_conv_eq_names[en1], bd_input %in% bd_loss_names[en1]) +
  labs(subtitle = "Ensemble 1 (Facets of Biodiversity), equal weights")

bd_loss_var_heatmap_eq_en2 <- bd_loss_var_heatmap_eq %+% filter(melt_results_eq_norm_var, mod_run %in% mod_conv_eq_names[en2], bd_input %in% bd_loss_names[en2]) +
  labs(subtitle = "Ensemble 2 (Methods), equal weights")

bd_loss_var_heatmap_eq_en3 <- bd_loss_var_heatmap_eq %+% filter(melt_results_eq_norm_var, mod_run %in% mod_conv_eq_names[en3], bd_input %in% bd_loss_names[en3]) +
  labs(subtitle = "Ensemble 3 (Resolution), equal weights")

bd_loss_var_heatmap_eq_en4 <- bd_loss_var_heatmap_eq %+% filter(melt_results_eq_norm_var, mod_run %in% mod_conv_eq_names[en4], bd_input %in% bd_loss_names[en4]) +
  labs(subtitle = "Ensemble 4 (Recipes), equal weights")




print(bd_loss_var_heatmap_eq)
print(bd_loss_var_heatmap_eq_en1)
print(bd_loss_var_heatmap_eq_en2)
print(bd_loss_var_heatmap_eq_en3)
print(bd_loss_var_heatmap_eq_en4)

```

```{r heatmap3_eq-overlaps}
# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_overlap_eq <- melt(overlap_eq, variable.name = "bd_input", value.name = "overlap")
melt_overlap_eq <- melt_overlap_eq %>%
  mutate(percent_overlap = overlap * 100, # add a percent column by multiplying by 100
         overlap_round = round(percent_overlap, digits = 2) # rounded percents, for labelling. 
         )

melt_overlap_eq_og <- melt_overlap_eq

head(melt_overlap_eq)
tail(melt_overlap_eq)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 
melt_overlap_eq$mod_run <- factor(melt_overlap_eq$mod_run, 
                                       levels = levels(melt_overlap_eq_og$mod_run)[runs_reorder])
melt_overlap_eq$bd_input <- factor(melt_overlap_eq$bd_input, 
                                        levels = levels(melt_overlap_eq_og$bd_input)[runs_reorder]) 
head(melt_overlap_eq)
levels(melt_overlap_eq$mod_run)
levels(melt_overlap_eq$bd_input)

# change back the order of the factors:
melt_overlap_eq$mod_run <- factor(melt_overlap_eq$mod_run, 
                                       levels = levels(melt_overlap_eq_og$mod_run))
melt_overlap_eq$bd_input <- factor(melt_overlap_eq$bd_input, 
                                        levels = levels(melt_overlap_eq_og$bd_input))


# ---------------------------------------------------------
# Build base plot
# ---------------------------------------------------------
min(melt_overlap_eq$percent_overlap)
max(melt_overlap_eq$percent_overlap)
head(melt_overlap_eq)

overlap_heatmap_eq <- 
  ggplot(data = melt_overlap_eq) +  
  geom_tile(mapping = aes(mod_run, bd_input, fill = percent_overlap), color = "white") +
  scale_fill_viridis(option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  labs(title = "Percent Overlap between Model Runs",
       subtitle = "All layers, equal weights",
       fill = "Percent \nOverlap") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_eq)

overlap_heatmap_eq %+% filter(melt_overlap_eq, mod_run %in% mod_conv_eq_names[en1_types], 
                              bd_input %in% mod_conv_eq_names[en1_types]) +
  labs(subtitle = "en1_types, equal weights") + 
  geom_text(aes(mod_run, bd_input, label = overlap_round), color = "black") # to add rounded values as labels

overlap_heatmap_eq %+% filter(melt_overlap_eq, mod_run %in% mod_conv_eq_names[c(1:6, 9:33)], bd_input %in% mod_conv_eq_names[c(1:6, 9:33)]) +
  labs(subtitle = "All layers but amphibians and reptiles, equal weights")

overlap_heatmap_eq_en1 <- overlap_heatmap_eq %+% filter(melt_overlap_eq, mod_run %in% mod_conv_eq_names[en1], bd_input %in% mod_conv_eq_names[en1]) +
  labs(subtitle = "Ensemble 1 (Facets of Biodiversity), equal weights")

overlap_heatmap_eq_en2 <- overlap_heatmap_eq %+% filter(melt_overlap_eq, mod_run %in% mod_conv_eq_names[en2], bd_input %in% mod_conv_eq_names[en2]) +
  labs(subtitle = "Ensemble 2 (Methods), equal weights")

overlap_heatmap_eq_en3 <- overlap_heatmap_eq %+% filter(melt_overlap_eq, mod_run %in% mod_conv_eq_names[en3], bd_input %in% mod_conv_eq_names[en3]) +
  labs(subtitle = "Ensemble 3 (Resolution), equal weights")

overlap_heatmap_eq_en4 <- overlap_heatmap_eq %+% filter(melt_overlap_eq, mod_run %in% mod_conv_eq_names[en4], bd_input %in% mod_conv_eq_names[en4]) +
  labs(subtitle = "Ensemble 4 (Recipes), equal weights")



print(overlap_heatmap_eq)
print(overlap_heatmap_eq_en1)
print(overlap_heatmap_eq_en2)
print(overlap_heatmap_eq_en3)
print(overlap_heatmap_eq_en4)


```

```{r heatmap4_eq-jaccard}
# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_jaccard_eq <- melt(jaccard_eq, variable.name = "bd_input", value.name = "jaccard")

melt_jaccard_eq <- melt_jaccard_eq %>%
  mutate(jaccard_round = round(jaccard, digits = 2) # rounded percents, for labelling. 
         )

melt_jaccard_eq_og <- melt_jaccard_eq

head(melt_jaccard_eq)
tail(melt_jaccard_eq)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 
melt_jaccard_eq$mod_run <- factor(melt_jaccard_eq$mod_run, 
                                       levels = levels(melt_jaccard_eq_og$mod_run)[runs_reorder])
melt_jaccard_eq$bd_input <- factor(melt_jaccard_eq$bd_input, 
                                        levels = levels(melt_jaccard_eq_og$bd_input)[runs_reorder]) 
head(melt_jaccard_eq)
levels(melt_jaccard_eq$mod_run)
levels(melt_jaccard_eq$bd_input)

# change back the order of the factors:
melt_jaccard_eq$mod_run <- factor(melt_jaccard_eq$mod_run, 
                                       levels = levels(melt_jaccard_eq_og$mod_run))
melt_jaccard_eq$bd_input <- factor(melt_jaccard_eq$bd_input, 
                                        levels = levels(melt_jaccard_eq_og$bd_input))


# ---------------------------------------------------------
# Build base plot
# ---------------------------------------------------------
min(melt_jaccard_eq$jaccard)
max(melt_jaccard_eq$jaccard)
head(melt_jaccard_eq)

jaccard_heatmap_eq <- 
  ggplot(data = melt_jaccard_eq) + 
  geom_tile(mapping = aes(mod_run, bd_input, fill = jaccard), color = "white") +
  scale_fill_viridis(option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  labs(title = "Jaccard Similarity between conversion results", subtitle = "All Layers, equal weights", fill = "Jaccard \nIndex") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_eq)

jaccard_heatmap_eq %+% filter(melt_jaccard_eq, mod_run %in% mod_conv_eq_names[c(1:6, 9:33)], bd_input %in% mod_conv_eq_names[c(1:6, 9:33)]) +
  labs(subtitle = "All layers but amphibians and reptiles, equal weights")

jaccard_heatmap_eq_en1 <- jaccard_heatmap_eq %+% filter(melt_jaccard_eq, mod_run %in% mod_conv_eq_names[en1], bd_input %in% mod_conv_eq_names[en1]) +
  labs(subtitle = "Ensemble 1 (Facets of Biodiversity), equal weights")

jaccard_heatmap_eq_en2 <- jaccard_heatmap_eq %+% filter(melt_jaccard_eq, mod_run %in% mod_conv_eq_names[en2], bd_input %in% mod_conv_eq_names[en2]) +
  labs(subtitle = "Ensemble 2 (Methods), equal weights")

jaccard_heatmap_eq_en3 <- jaccard_heatmap_eq %+% filter(melt_jaccard_eq, mod_run %in% mod_conv_eq_names[en3], bd_input %in% mod_conv_eq_names[en3]) +
  labs(subtitle = "Ensemble 3 (Resolution), equal weights")

jaccard_heatmap_eq_en4 <- jaccard_heatmap_eq %+% filter(melt_jaccard_eq, mod_run %in% mod_conv_eq_names[en4], bd_input %in% mod_conv_eq_names[en4]) +
  labs(subtitle = "Ensemble 4 (Recipes), equal weights")


print(jaccard_heatmap_eq)
print(jaccard_heatmap_eq_en1)
print(jaccard_heatmap_eq_en2)
print(jaccard_heatmap_eq_en3)
print(jaccard_heatmap_eq_en4)


```

```{r heatmap1_bd100-bd_conv_norm}
# this is the matrix to be plotted, which includes the biodiversity lost in converted areas, as a proportion of all of the unprotected biodiversity in the bd-input raster. 
results_bd100$bd_conv_norm # this is just the diagonal
head(results_bd100_norm)

as.matrix(results_bd100)

names(results_bd100)



# colnames(results_bd100_norm) <- c("mod_run", runs) # if I want to remove the bd_loss from the columns

# ---------------------------------------------------------
# headmap production steps
# ---------------------------------------------------------
# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_results_bd100_norm <- melt(results_bd100_norm, variable.name = "bd_input", value.name = "bd_conv_bd100_norm")

melt_results_bd100_norm <- melt_results_bd100_norm %>%
  mutate(percent_bd_loss = bd_conv_bd100_norm * 100, # add a percent column by multiplying by 100
         rounded_percent = round(percent_bd_loss, digits = 2) # rounded percents, for labelling. 
         )

melt_bd100_og <- melt_results_bd100_norm

head(melt_results_bd100_norm)
tail(melt_results_bd100_norm)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 


melt_results_bd100_norm$mod_run <- factor(melt_results_bd100_norm$mod_run, 
                                       levels = levels(melt_bd100_og$mod_run)[runs_reorder])
melt_results_bd100_norm$bd_input <- factor(melt_results_bd100_norm$bd_input, 
                                        levels = levels(melt_bd100_og$bd_input)[runs_reorder]) 
head(melt_results_bd100_norm)
levels(melt_results_bd100_norm$mod_run)
levels(melt_results_bd100_norm$bd_input)

# change back the order of the factors:
melt_results_bd100_norm$mod_run <- factor(melt_results_bd100_norm$mod_run, 
                                       levels = levels(melt_bd100_og$mod_run))
melt_results_bd100_norm$bd_input <- factor(melt_results_bd100_norm$bd_input, 
                                        levels = levels(melt_bd100_og$bd_input))


# plot --------------------------------------------
bd_loss_heatmap_bd100 <- 
  ggplot() + 
  geom_tile(data = melt_results_bd100_norm,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  #scale_fill_gradient(low = "blue", high = "red")
  scale_fill_viridis(name = "Percent of \nUnprotected \nBiodiversity \nConverted", 
                     option = "D", # viridis option
                     limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Biodiversity Loss in Converted Areas  \n All model runs, 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_bd100)

head(melt_results_bd100_norm)

# make it interactive.
library(plotly)
ggplotly(bd_loss_heatmap_bd100)


# ---------------------------------------------------------
# ensemble 1 - biodiversity facets
# ---------------------------------------------------------
bd_loss_heatmap_bd100_en1 <- 
  ggplot() + 
  geom_tile(data = melt_results_bd100_norm %>%
              filter(mod_run %in% mod_conv_bd100_names[1:13],
                     bd_input %in% bd_loss_names[1:13])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  scale_fill_viridis(name = "Percent of \nUnprotected \nBiodiversity \nConverted", 
                     option = "D", # viridis option
                     limits = c(0, 15), # set scale limits
                     discrete = FALSE) +  #scale_fill_gradient(low = "blue", high = "red") # other optio
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Biodiversity Loss in Converted Areas  \n En 1 Biodiversity facets, 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_bd100_en1)

# ---------------------------------------------------------
# ensemble 2 - methods
# ---------------------------------------------------------
bd_loss_heatmap_bd100_en2 <- 
  ggplot() + 
  geom_tile(data = melt_results_bd100_norm %>%
              filter(mod_run %in% mod_conv_bd100_names[15:20],
                     bd_input %in% bd_loss_names[15:20])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  scale_fill_viridis(name = "Percent of \nUnprotected \nBiodiversity \nConverted", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +  #scale_fill_gradient(low = "blue", high = "red") # other optio
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Biodiversity Loss in Converted Areas  \n En 2 Methods, 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_bd100_en2)

# ---------------------------------------------------------
# ensemble 3 - resolution
# ---------------------------------------------------------
mod_conv_bd100_names[c(1, 21, 25, 2, 22, 26, 3, 23, 27, 4, 24, 28)]

bd_loss_heatmap_bd100_en3 <- 
  ggplot() + 
  geom_tile(data = melt_results_bd100_norm %>%
              filter(mod_run %in% mod_conv_bd100_names[c(1:4, 21:28)], #c(1:4, 21:28)
                     bd_input %in% bd_loss_names[c(1:4, 21:28)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  scale_fill_viridis(name = "Percent of \nUnprotected \nBiodiversity \nConverted", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +  #scale_fill_gradient(low = "blue", high = "red") # other optio
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size=12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Biodiversity Loss in Converted Areas  \n En 3 Resolution, 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_bd100_en3)

# ---------------------------------------------------------
# ensemble 4 - recipes
# ---------------------------------------------------------
bd_loss_heatmap_bd100_en4 <- 
  ggplot() + 
  geom_tile(data = melt_results_bd100_norm %>%
              filter(mod_run %in% mod_conv_bd100_names[c(14, 29:31)],
                     bd_input %in% bd_loss_names[c(14, 29:31)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  scale_fill_viridis(name = "Percent of \nUnprotected \nBiodiversity \nConverted", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +  #scale_fill_gradient(low = "blue", high = "red") # other optio
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Biodiversity Loss in Converted Areas  \n En 4 Recipes, 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_bd100_en4)

print(bd_loss_heatmap_bd100)
print(bd_loss_heatmap_bd100_en1)
print(bd_loss_heatmap_bd100_en2)
print(bd_loss_heatmap_bd100_en3)
print(bd_loss_heatmap_bd100_en4)

```

```{r heatmap2_bd100-bd_conv_variance}

# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_results_bd100_norm_var <- melt(results_bd100_norm_var, variable.name = "bd_input", value.name = "bd_conv_bd100_norm_var")

melt_results_bd100_norm_var <- melt_results_bd100_norm_var %>%
  mutate(percent_bd_loss_var = bd_conv_bd100_norm_var * 100, # add a percent column by multiplying by 100
         rounded_percent = round(percent_bd_loss_var, digits = 2) # rounded percents, for labelling. 
         )

melt_bd100_var_og <- melt_results_bd100_norm_var

head(melt_results_bd100_norm_var)
tail(melt_results_bd100_norm_var)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 


melt_results_bd100_norm_var$mod_run <- factor(melt_results_bd100_norm_var$mod_run, 
                                       levels = levels(melt_bd100_var_og$mod_run)[runs_reorder])
melt_results_bd100_norm_var$bd_input <- factor(melt_results_bd100_norm_var$bd_input, 
                                        levels = levels(melt_bd100_var_og$bd_input)[runs_reorder]) 
head(melt_results_bd100_norm_var)
levels(melt_results_bd100_norm_var$mod_run)
levels(melt_results_bd100_norm_var$bd_input)

# change back the order of the factors:
melt_results_bd100_norm_var$mod_run <- factor(melt_results_bd100_norm_var$mod_run, 
                                       levels = levels(melt_bd100_var_og$mod_run))
melt_results_bd100_norm_var$bd_input <- factor(melt_results_bd100_norm_var$bd_input, 
                                        levels = levels(melt_bd100_var_og$bd_input))

bd_conv_norm_var_df[c(5, 6, 8, 9), c(1, 6, 7, 9, 10)]
results_bd100_norm_var[1:4, 1:5]
names(bd_conv_norm_var_df)

# plot --------------------------------------------
min(melt_results_bd100_norm_var$percent_bd_loss_var)
max(melt_results_bd100_norm_var$percent_bd_loss_var)

bd_loss_var_heatmap_bd100_no_amp_rep <- 
  ggplot() + 
  geom_tile(data = melt_results_bd100_norm_var %>%
              filter(mod_run %in% mod_conv_bd100_names[c(1:6, 9:33)],
                     bd_input %in% bd_loss_names[c(1:6, 9:33)])
,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), 
            color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red",
                       name = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Relative Percent Biodiversity Loss in Converted Areas \nRelative to loss in controlling layer (All model runs) \n100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_bd100)
print(bd_loss_var_heatmap_bd100_no_amp_rep)
print(bd_loss_heatmap_bd100)


# ---------------------------------------------------------
# ensemble 1 - biodiversity facets
# ---------------------------------------------------------
bd_loss_var_heatmap_bd100_en1 <- 
  ggplot() + 
  geom_tile(data = melt_results_bd100_norm_var %>%
              filter(mod_run %in% mod_conv_bd100_names[1:13],
                     bd_input %in% bd_loss_names[1:13])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), 
            color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       name = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Relative Percent Biodiversity Loss in Converted Areas \nRelative to loss in controlling layer \nEnsemble 1 (Biodiversity Facets) \n100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_bd100_en1)

# ---------------------------------------------------------
# ensemble 2 - methods
# ---------------------------------------------------------
bd_loss_var_heatmap_bd100_en2 <- 
  ggplot() + 
  geom_tile(data = melt_results_bd100_norm_var %>%
              filter(mod_run %in% mod_conv_bd100_names[15:20],
                     bd_input %in% bd_loss_names[15:20])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), 
            color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       name = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Relative Percent Biodiversity Loss in Converted Areas \nRelative to loss in controlling layer \nEnsemble 2 (Methods) \n100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_bd100_en2)

# ---------------------------------------------------------
# ensemble 3 - resolution
# ---------------------------------------------------------
mod_conv_bd100_names[c(1, 21, 25, 2, 22, 26, 3, 23, 27, 4, 24, 28)]

bd_loss_var_heatmap_bd100_en3 <- 
  ggplot() + 
  geom_tile(data = melt_results_bd100_norm_var %>%
              filter(mod_run %in% mod_conv_bd100_names[c(1:4, 21:28)], #c(1:4, 21:28)
                     bd_input %in% bd_loss_names[c(1:4, 21:28)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), 
            color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       name = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Relative Percent Biodiversity Loss in Converted Areas \nRelative to loss in controlling layer \nEnsemble 3 (Resolution) \n100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_bd100_en3)

# ---------------------------------------------------------
# ensemble 4 - recipes
# ---------------------------------------------------------
bd_loss_var_heatmap_bd100_en4 <- 
  ggplot() + 
  geom_tile(data = melt_results_bd100_norm_var %>%
              filter(mod_run %in% mod_conv_bd100_names[c(14, 29:31)],
                     bd_input %in% bd_loss_names[c(14, 29:31)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), 
            color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       name = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Relative Percent Biodiversity Loss in Converted Areas \nRelative to loss in controlling layer \nEnsemble 4 (Recipes) \n100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_bd100_en4)

print(bd_loss_var_heatmap_bd100)
print(bd_loss_var_heatmap_bd100_en1)
print(bd_loss_var_heatmap_bd100_en2)
print(bd_loss_var_heatmap_bd100_en3)
print(bd_loss_var_heatmap_bd100_en4)

```

```{r heatmap3_bd100-overlaps}
# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_overlap_bd100 <- melt(overlap_bd100, variable.name = "bd_input", value.name = "overlap")
melt_overlap_bd100 <- melt_overlap_bd100 %>%
  mutate(percent_overlap = overlap * 100, # add a percent column by multiplying by 100
         overlap_round = round(percent_overlap, digits = 2) # rounded percents, for labelling. 
         )

melt_overlap_bd100_og <- melt_overlap_bd100

head(melt_overlap_bd100)
tail(melt_overlap_bd100)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 


melt_overlap_bd100$mod_run <- factor(melt_overlap_bd100$mod_run, 
                                       levels = levels(melt_overlap_bd100_og$mod_run)[runs_reorder])
melt_overlap_bd100$bd_input <- factor(melt_overlap_bd100$bd_input, 
                                        levels = levels(melt_overlap_bd100_og$bd_input)[runs_reorder]) 
head(melt_overlap_bd100)
levels(melt_overlap_bd100$mod_run)
levels(melt_overlap_bd100$bd_input)

# change back the order of the factors:
melt_overlap_bd100$mod_run <- factor(melt_overlap_bd100$mod_run, 
                                       levels = levels(melt_overlap_bd100_og$mod_run))
melt_overlap_bd100$bd_input <- factor(melt_overlap_bd100$bd_input, 
                                        levels = levels(melt_overlap_bd100_og$bd_input))


# plot --------------------------------------------
min(melt_overlap_bd100$percent_overlap)
max(melt_overlap_bd100$percent_overlap)
head(melt_overlap_bd100)

overlap_heatmap_bd100 <- 
  ggplot() + 
  geom_tile(data = melt_overlap_bd100 #%>%
              # filter(mod_run %in% mod_conv_bd100_names[c(1:6, 9:33)],
              #        bd_input %in% bd_loss_names[c(1:6, 9:33)])
            ,
            mapping = aes(mod_run, bd_input, fill = percent_overlap), 
            color = "white") +
  scale_fill_viridis(name = "Percent \nOverlap", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Overlap between Model Runs \nAll Layers, 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_bd100)

# ---------------------------------------------------------
# ensemble 1 - biodiversity facets
# ---------------------------------------------------------
overlap_heatmap_bd100_en1 <- 
  ggplot() + 
  geom_tile(data = melt_overlap_bd100 %>%
              filter(mod_run %in% mod_conv_bd100_names[1:13],
                     bd_input %in% mod_conv_bd100_names[1:13])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_overlap), 
            color = "white") +
  scale_fill_viridis(name = "Percent \nOverlap", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Overlap between Model Runs \nEnsemble 1 (Biodiversity Facets), 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_bd100_en1)

# ---------------------------------------------------------
# ensemble 2 - methods
# ---------------------------------------------------------
overlap_heatmap_bd100_en2 <- 
  ggplot() + 
  geom_tile(data = melt_overlap_bd100 %>%
              filter(mod_run %in% mod_conv_bd100_names[15:20],
                     bd_input %in% mod_conv_bd100_names[15:20])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_overlap), 
            color = "white") +
  scale_fill_viridis(name = "Percent \nOverlap", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Overlap between Model Runs \nEnsemble 2 (Methods), 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_bd100_en2)

# ---------------------------------------------------------
# ensemble 3 - resolution
# ---------------------------------------------------------
mod_conv_bd100_names[c(1, 21, 25, 2, 22, 26, 3, 23, 27, 4, 24, 28)]

overlap_heatmap_bd100_en3 <- 
  ggplot() + 
  geom_tile(data = melt_overlap_bd100 %>%
              filter(mod_run %in% mod_conv_bd100_names[c(1:4, 21:28)], #c(1:4, 21:28)
                     bd_input %in% mod_conv_bd100_names[c(1:4, 21:28)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_overlap), 
            color = "white") +
  scale_fill_viridis(name = "Percent \nOverlap", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Overlap between Model Runs \nEnsemble 3 (Resolution), 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_bd100_en3)

# ---------------------------------------------------------
# ensemble 4 - recipes
# ---------------------------------------------------------
overlap_heatmap_bd100_en4 <- 
  ggplot() + 
  geom_tile(data = melt_overlap_bd100 %>%
              filter(mod_run %in% mod_conv_bd100_names[c(14, 29:31)],
                     bd_input %in% mod_conv_bd100_names[c(14, 29:31)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_overlap), 
            color = "white") +
  scale_fill_viridis(name = "Percent \nOverlap", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Overlap between Model Runs \nEnsemble 4 (Recipes), 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_bd100_en4)

print(overlap_heatmap_bd100)
print(overlap_heatmap_bd100_en1)
print(overlap_heatmap_bd100_en2)
print(overlap_heatmap_bd100_en3)
print(overlap_heatmap_bd100_en4)


```

```{r heatmap4_bd100-jaccard}
# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_jaccard_bd100 <- melt(jaccard_bd100, variable.name = "bd_input", value.name = "jaccard")

melt_jaccard_bd100 <- melt_jaccard_bd100 %>%
  mutate(jaccard_round = round(jaccard, digits = 2) # rounded percents, for labelling. 
         )

melt_jaccard_bd100_og <- melt_jaccard_bd100

head(melt_jaccard_bd100)
tail(melt_jaccard_bd100)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 


melt_jaccard_bd100$mod_run <- factor(melt_jaccard_bd100$mod_run, 
                                       levels = levels(melt_jaccard_bd100_og$mod_run)[runs_reorder])
melt_jaccard_bd100$bd_input <- factor(melt_jaccard_bd100$bd_input, 
                                        levels = levels(melt_jaccard_bd100_og$bd_input)[runs_reorder]) 
head(melt_jaccard_bd100)
levels(melt_jaccard_bd100$mod_run)
levels(melt_jaccard_bd100$bd_input)

# change back the order of the factors:
melt_jaccard_bd100$mod_run <- factor(melt_jaccard_bd100$mod_run, 
                                       levels = levels(melt_jaccard_bd100_og$mod_run))
melt_jaccard_bd100$bd_input <- factor(melt_jaccard_bd100$bd_input, 
                                        levels = levels(melt_jaccard_bd100_og$bd_input))


# plot --------------------------------------------
min(melt_jaccard_bd100$jaccard)
max(melt_jaccard_bd100$jaccard)
head(melt_jaccard_bd100)

jaccard_heatmap_bd100 <- 
  ggplot() + 
  geom_tile(data = melt_jaccard_bd100 #%>%
              # filter(mod_run %in% mod_conv_bd100_names[c(1:6, 9:33)],
              #        bd_input %in% bd_loss_names[c(1:6, 9:33)])
            ,
            mapping = aes(mod_run, bd_input, fill = jaccard), 
            color = "white") +
  scale_fill_viridis(name = "Jaccard \nIndex", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Jaccard Similarity between conversion results \nAll Layers, 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_bd100)
print(overlap_heatmap_bd100)

# ---------------------------------------------------------
# ensemble 1 - biodiversity facets
# ---------------------------------------------------------
jaccard_heatmap_bd100_en1 <- 
  ggplot() + 
  geom_tile(data = melt_jaccard_bd100 %>%
              filter(mod_run %in% mod_conv_bd100_names[1:13],
                     bd_input %in% mod_conv_bd100_names[1:13])
              ,
            mapping = aes(mod_run, bd_input, fill = jaccard), 
            color = "white") +
  scale_fill_viridis(name = "Jaccard \nIndex", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Jaccard Similarity between conversion results \nEnsemble 1 (Biodiversity Facets), 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_bd100_en1)

# ---------------------------------------------------------
# ensemble 2 - methods
# ---------------------------------------------------------
jaccard_heatmap_bd100_en2 <- 
  ggplot() + 
  geom_tile(data = melt_jaccard_bd100 %>%
              filter(mod_run %in% mod_conv_bd100_names[15:20],
                     bd_input %in% mod_conv_bd100_names[15:20])
              ,
            mapping = aes(mod_run, bd_input, fill = jaccard), 
            color = "white") +
  scale_fill_viridis(name = "Jaccard \nIndex", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Jaccard Similarity between conversion results \nEnsemble 2 (Methods), 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_bd100_en2)

# ---------------------------------------------------------
# ensemble 3 - resolution
# ---------------------------------------------------------
mod_conv_bd100_names[c(1, 21, 25, 2, 22, 26, 3, 23, 27, 4, 24, 28)]

jaccard_heatmap_bd100_en3 <- 
  ggplot() + 
  geom_tile(data = melt_jaccard_bd100 %>%
              filter(mod_run %in% mod_conv_bd100_names[c(1:4, 21:28)], #c(1:4, 21:28)
                     bd_input %in% mod_conv_bd100_names[c(1:4, 21:28)])
              ,
            mapping = aes(mod_run, bd_input, fill = jaccard), 
            color = "white") +
  scale_fill_viridis(name = "Jaccard \nIndex", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Jaccard Similarity between conversion results \nEnsemble 3 (Resolution), 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_bd100_en3)

# ---------------------------------------------------------
# ensemble 4 - recipes
# ---------------------------------------------------------
jaccard_heatmap_bd100_en4 <- 
  ggplot() + 
  geom_tile(data = melt_jaccard_bd100 %>%
              filter(mod_run %in% mod_conv_bd100_names[c(14, 29:31)],
                     bd_input %in% mod_conv_bd100_names[c(14, 29:31)])
              ,
            mapping = aes(mod_run, bd_input, fill = jaccard), 
            color = "white") +
  scale_fill_viridis(name = "Jaccard \nIndex", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Jaccard Similarity between conversion results \nEnsemble 4 (Recipes), 100% weight on biodiversity") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_bd100_en4)

```


Note: all of these heatmaps need to be updated since the 10p layers were updated. 
```{r heatmap1_10p_bd-bd_conv_norm}
# this is the matrix to be plotted, which includes the biodiversity lost in converted areas, as a proportion of all of the unprotected biodiversity in the bd-input raster. 
results_10p_bd$bd_conv_norm # this is just the diagonal
head(results_10p_bd_norm)

as.matrix(results_10p_bd)

names(results_10p_bd)



# colnames(results_10p_bd_norm) <- c("mod_run", runs) # if I want to remove the bd_loss from the columns

# ---------------------------------------------------------
# headmap production steps
# ---------------------------------------------------------
# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_results_10p_bd_norm <- melt(results_10p_bd_norm, variable.name = "bd_input", value.name = "bd_conv_10p_bd_norm")

melt_results_10p_bd_norm <- melt_results_10p_bd_norm %>%
  mutate(percent_bd_loss = bd_conv_10p_bd_norm * 100, # add a percent column by multiplying by 100
         rounded_percent = round(percent_bd_loss, digits = 2) # rounded percents, for labelling. 
         )

melt_10p_bd_og <- melt_results_10p_bd_norm

head(melt_results_10p_bd_norm)
tail(melt_results_10p_bd_norm)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 

melt_results_10p_bd_norm$mod_run <- factor(melt_results_10p_bd_norm$mod_run, 
                                       levels = levels(melt_10p_bd_og$mod_run)[runs_reorder])
melt_results_10p_bd_norm$bd_input <- factor(melt_results_10p_bd_norm$bd_input, 
                                        levels = levels(melt_10p_bd_og$bd_input)[runs_reorder]) 
head(melt_results_10p_bd_norm)
levels(melt_results_10p_bd_norm$mod_run)
levels(melt_results_10p_bd_norm$bd_input)

# # change back the order of the factors:
# melt_results_10p_bd_norm$mod_run <- factor(melt_results_10p_bd_norm$mod_run, 
#                                        levels = levels(melt_10p_bd_og$mod_run))
# melt_results_10p_bd_norm$bd_input <- factor(melt_results_10p_bd_norm$bd_input, 
#                                         levels = levels(melt_10p_bd_og$bd_input))


# plot --------------------------------------------
bd_loss_heatmap_10p_bd <- 
  ggplot() + 
  geom_tile(data = melt_results_10p_bd_norm,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  #scale_fill_gradient(low = "blue", high = "red")
  scale_fill_viridis(name = "Percent of \nUnprotected \nBiodiversity \nConverted", 
                     option = "D", # viridis option
                     limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Biodiversity Loss in Converted Areas  \n All model runs \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_10p_bd)

head(melt_results_10p_bd_norm)

# make it interactive.
library(plotly)
ggplotly(bd_loss_heatmap_10p_bd)


# ---------------------------------------------------------
# ensemble 1 - biodiversity facets
# ---------------------------------------------------------
bd_loss_heatmap_10p_bd_en1 <- 
  ggplot() + 
  geom_tile(data = melt_results_10p_bd_norm %>%
              filter(mod_run %in% mod_conv_10p_bd_names[1:13],
                     bd_input %in% bd_loss_names[1:13])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  scale_fill_viridis(name = "Percent of \nUnprotected \nBiodiversity \nConverted", 
                     option = "D", # viridis option
                     limits = c(0, 15), # set scale limits
                     discrete = FALSE) +  #scale_fill_gradient(low = "blue", high = "red") # other optio
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Biodiversity Loss in Converted Areas  \n En 1 Biodiversity facets \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_10p_bd_en1)

# ---------------------------------------------------------
# ensemble 2 - methods
# ---------------------------------------------------------
bd_loss_heatmap_10p_bd_en2 <- 
  ggplot() + 
  geom_tile(data = melt_results_10p_bd_norm %>%
              filter(mod_run %in% mod_conv_10p_bd_names[15:20],
                     bd_input %in% bd_loss_names[15:20])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  scale_fill_viridis(name = "Percent of \nUnprotected \nBiodiversity \nConverted", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +  #scale_fill_gradient(low = "blue", high = "red") # other optio
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Biodiversity Loss in Converted Areas  \n En 2 Methods \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_10p_bd_en2)

# ---------------------------------------------------------
# ensemble 3 - resolution
# ---------------------------------------------------------
mod_conv_10p_bd_names[c(1, 21, 25, 2, 22, 26, 3, 23, 27, 4, 24, 28)]

bd_loss_heatmap_10p_bd_en3 <- 
  ggplot() + 
  geom_tile(data = melt_results_10p_bd_norm %>%
              filter(mod_run %in% mod_conv_10p_bd_names[c(1:4, 21:28)], #c(1:4, 21:28)
                     bd_input %in% bd_loss_names[c(1:4, 21:28)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  scale_fill_viridis(name = "Percent of \nUnprotected \nBiodiversity \nConverted", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +  #scale_fill_gradient(low = "blue", high = "red") # other optio
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size=12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Biodiversity Loss in Converted Areas  \n En 3 Resolution \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_10p_bd_en3)

# ---------------------------------------------------------
# ensemble 4 - recipes
# ---------------------------------------------------------
bd_loss_heatmap_10p_bd_en4 <- 
  ggplot() + 
  geom_tile(data = melt_results_10p_bd_norm %>%
              filter(mod_run %in% mod_conv_10p_bd_names[c(14, 29:31)],
                     bd_input %in% bd_loss_names[c(14, 29:31)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss), 
            color = "white") +
  scale_fill_viridis(name = "Percent of \nUnprotected \nBiodiversity \nConverted", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +  #scale_fill_gradient(low = "blue", high = "red") # other optio
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Biodiversity Loss in Converted Areas  \n En 4 Recipes \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(bd_loss_heatmap_10p_bd_en4)

print(bd_loss_heatmap_10p_bd)
print(bd_loss_heatmap_10p_bd_en1)
print(bd_loss_heatmap_10p_bd_en2)
print(bd_loss_heatmap_10p_bd_en3)
print(bd_loss_heatmap_10p_bd_en4)

```

```{r heatmap2_10p_bd-bd_conv_variance}

# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_results_10p_bd_norm_var <- melt(results_10p_bd_norm_var, variable.name = "bd_input", value.name = "bd_conv_10p_bd_norm_var")

melt_results_10p_bd_norm_var <- melt_results_10p_bd_norm_var %>%
  mutate(percent_bd_loss_var = bd_conv_10p_bd_norm_var * 100, # add a percent column by multiplying by 100
         rounded_percent = round(percent_bd_loss_var, digits = 2) # rounded percents, for labelling. 
         )

melt_10p_bd_var_og <- melt_results_10p_bd_norm_var

head(melt_results_10p_bd_norm_var)
tail(melt_results_10p_bd_norm_var)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 


melt_results_10p_bd_norm_var$mod_run <- factor(melt_results_10p_bd_norm_var$mod_run, 
                                       levels = levels(melt_10p_bd_var_og$mod_run)[runs_reorder])
melt_results_10p_bd_norm_var$bd_input <- factor(melt_results_10p_bd_norm_var$bd_input, 
                                        levels = levels(melt_10p_bd_var_og$bd_input)[runs_reorder]) 
head(melt_results_10p_bd_norm_var)
levels(melt_results_10p_bd_norm_var$mod_run)
levels(melt_results_10p_bd_norm_var$bd_input)

# # change back the order of the factors:
# melt_results_10p_bd_norm_var$mod_run <- factor(melt_results_10p_bd_norm_var$mod_run, 
#                                        levels = levels(melt_10p_bd_var_og$mod_run))
# melt_results_10p_bd_norm_var$bd_input <- factor(melt_results_10p_bd_norm_var$bd_input, 
#                                         levels = levels(melt_10p_bd_var_og$bd_input))

bd_conv_norm_var_df[c(5, 6, 8, 9), c(1, 6, 7, 9, 10)]
results_10p_bd_norm_var[1:4, 1:5]
names(bd_conv_norm_var_df)

# plot --------------------------------------------
min(melt_results_10p_bd_norm_var$percent_bd_loss_var)
max(melt_results_10p_bd_norm_var$percent_bd_loss_var)

bd_loss_var_heatmap_10p_bd_no_amp_rep <- 
  ggplot() + 
  geom_tile(data = melt_results_10p_bd_norm_var %>%
              filter(mod_run %in% mod_conv_10p_bd_names[c(1:6, 9:33)],
                     bd_input %in% bd_loss_names[c(1:6, 9:33)])
,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), 
            color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red",
                       name = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Relative Percent Biodiversity Loss in Converted Areas \nRelative to loss in controlling layer (All model runs) \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_10p_bd)
print(bd_loss_var_heatmap_10p_bd_no_amp_rep)
print(bd_loss_heatmap_10p_bd)


# ---------------------------------------------------------
# ensemble 1 - biodiversity facets
# ---------------------------------------------------------
bd_loss_var_heatmap_10p_bd_en1 <- 
  ggplot() + 
  geom_tile(data = melt_results_10p_bd_norm_var %>%
              filter(mod_run %in% mod_conv_10p_bd_names[1:13],
                     bd_input %in% bd_loss_names[1:13])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), 
            color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       name = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Relative Percent Biodiversity Loss in Converted Areas \nRelative to loss in controlling layer \nEnsemble 1 (Biodiversity Facets) \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_10p_bd_en1)

# ---------------------------------------------------------
# ensemble 2 - methods
# ---------------------------------------------------------
bd_loss_var_heatmap_10p_bd_en2 <- 
  ggplot() + 
  geom_tile(data = melt_results_10p_bd_norm_var %>%
              filter(mod_run %in% mod_conv_10p_bd_names[15:20],
                     bd_input %in% bd_loss_names[15:20])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), 
            color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       name = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Relative Percent Biodiversity Loss in Converted Areas \nRelative to loss in controlling layer \nEnsemble 2 (Methods) \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_10p_bd_en2)

# ---------------------------------------------------------
# ensemble 3 - resolution
# ---------------------------------------------------------
mod_conv_10p_bd_names[c(1, 21, 25, 2, 22, 26, 3, 23, 27, 4, 24, 28)]

bd_loss_var_heatmap_10p_bd_en3 <- 
  ggplot() + 
  geom_tile(data = melt_results_10p_bd_norm_var %>%
              filter(mod_run %in% mod_conv_10p_bd_names[c(1:4, 21:28)], #c(1:4, 21:28)
                     bd_input %in% bd_loss_names[c(1:4, 21:28)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), 
            color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       name = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Relative Percent Biodiversity Loss in Converted Areas \nRelative to loss in controlling layer \nEnsemble 3 (Resolution) \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_10p_bd_en3)

# ---------------------------------------------------------
# ensemble 4 - recipes
# ---------------------------------------------------------
bd_loss_var_heatmap_10p_bd_en4 <- 
  ggplot() + 
  geom_tile(data = melt_results_10p_bd_norm_var %>%
              filter(mod_run %in% mod_conv_10p_bd_names[c(14, 29:31)],
                     bd_input %in% bd_loss_names[c(14, 29:31)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_bd_loss_var), 
            color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", 
                       name = "Variance in \nunprotected biodiversity \nconverted relative to \ncontrolling layer \n(percentage points)") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Relative Percent Biodiversity Loss in Converted Areas \nRelative to loss in controlling layer \nEnsemble 4 (Recipes) \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(bd_loss_var_heatmap_10p_bd_en4)


print(bd_loss_var_heatmap_10p_bd)
print(bd_loss_var_heatmap_10p_bd_en1)
print(bd_loss_var_heatmap_10p_bd_en2)
print(bd_loss_var_heatmap_10p_bd_en3)
print(bd_loss_var_heatmap_10p_bd_en4)


```

```{r heatmap3_10p_bd-overlaps}
# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_overlap_10p_bd <- melt(overlap_10p_bd, variable.name = "bd_input", value.name = "overlap")
melt_overlap_10p_bd <- melt_overlap_10p_bd %>%
  mutate(percent_overlap = overlap * 100, # add a percent column by multiplying by 100
         overlap_round = round(percent_overlap, digits = 2) # rounded percents, for labelling. 
         )

melt_overlap_10p_bd_og <- melt_overlap_10p_bd

head(melt_overlap_10p_bd)
tail(melt_overlap_10p_bd)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 


melt_overlap_10p_bd$mod_run <- factor(melt_overlap_10p_bd$mod_run, 
                                       levels = levels(melt_overlap_10p_bd_og$mod_run)[runs_reorder])
melt_overlap_10p_bd$bd_input <- factor(melt_overlap_10p_bd$bd_input, 
                                        levels = levels(melt_overlap_10p_bd_og$bd_input)[runs_reorder]) 
head(melt_overlap_10p_bd)
levels(melt_overlap_10p_bd$mod_run)
levels(melt_overlap_10p_bd$bd_input)

# # change back the order of the factors:
# melt_overlap_10p_bd$mod_run <- factor(melt_overlap_10p_bd$mod_run, 
#                                        levels = levels(melt_overlap_10p_bd_og$mod_run))
# melt_overlap_10p_bd$bd_input <- factor(melt_overlap_10p_bd$bd_input, 
#                                         levels = levels(melt_overlap_10p_bd_og$bd_input))


# plot --------------------------------------------
min(melt_overlap_10p_bd$percent_overlap)
max(melt_overlap_10p_bd$percent_overlap)
head(melt_overlap_10p_bd)

overlap_heatmap_10p_bd <- 
  ggplot() + 
  geom_tile(data = melt_overlap_10p_bd #%>%
              # filter(mod_run %in% mod_conv_10p_bd_names[c(1:6, 9:33)],
              #        bd_input %in% bd_loss_names[c(1:6, 9:33)])
            ,
            mapping = aes(mod_run, bd_input, fill = percent_overlap), 
            color = "white") +
  scale_fill_viridis(name = "Percent \nOverlap", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Overlap between Model Runs \nAll Layers \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_10p_bd)

# ---------------------------------------------------------
# ensemble 1 - biodiversity facets
# ---------------------------------------------------------
overlap_heatmap_10p_bd_en1 <- 
  ggplot() + 
  geom_tile(data = melt_overlap_10p_bd %>%
              filter(mod_run %in% mod_conv_10p_bd_names[1:13],
                     bd_input %in% mod_conv_10p_bd_names[1:13])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_overlap), 
            color = "white") +
  scale_fill_viridis(name = "Percent \nOverlap", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Overlap between Model Runs \nEnsemble 1 (Biodiversity Facets) \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_10p_bd_en1)

# ---------------------------------------------------------
# ensemble 2 - methods
# ---------------------------------------------------------
overlap_heatmap_10p_bd_en2 <- 
  ggplot() + 
  geom_tile(data = melt_overlap_10p_bd %>%
              filter(mod_run %in% mod_conv_10p_bd_names[15:20],
                     bd_input %in% mod_conv_10p_bd_names[15:20])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_overlap), 
            color = "white") +
  scale_fill_viridis(name = "Percent \nOverlap", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Overlap between Model Runs \nEnsemble 2 (Methods) \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_10p_bd_en2)

# ---------------------------------------------------------
# ensemble 3 - resolution
# ---------------------------------------------------------
mod_conv_10p_bd_names[c(1, 21, 25, 2, 22, 26, 3, 23, 27, 4, 24, 28)]

overlap_heatmap_10p_bd_en3 <- 
  ggplot() + 
  geom_tile(data = melt_overlap_10p_bd %>%
              filter(mod_run %in% mod_conv_10p_bd_names[c(1:4, 21:28)], #c(1:4, 21:28)
                     bd_input %in% mod_conv_10p_bd_names[c(1:4, 21:28)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_overlap), 
            color = "white") +
  scale_fill_viridis(name = "Percent \nOverlap", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Overlap between Model Runs \nEnsemble 3 (Resolution) \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_10p_bd_en3)

# ---------------------------------------------------------
# ensemble 4 - recipes
# ---------------------------------------------------------
overlap_heatmap_10p_bd_en4 <- 
  ggplot() + 
  geom_tile(data = melt_overlap_10p_bd %>%
              filter(mod_run %in% mod_conv_10p_bd_names[c(14, 29:31)],
                     bd_input %in% mod_conv_10p_bd_names[c(14, 29:31)])
              ,
            mapping = aes(mod_run, bd_input, fill = percent_overlap), 
            color = "white") +
  scale_fill_viridis(name = "Percent \nOverlap", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Percent Overlap between Model Runs \nEnsemble 4 (Recipes) \nLowest 10% bd") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(overlap_heatmap_10p_bd_en4)

print(overlap_heatmap_10p_bd)
print(overlap_heatmap_10p_bd_en1)
print(overlap_heatmap_10p_bd_en2)
print(overlap_heatmap_10p_bd_en3)
print(overlap_heatmap_10p_bd_en4)

```

```{r heatmap4_10p_bd-jaccard}
# 1. melt data.frame from wide format to long format (see here: https://seananderson.ca/2013/10/19/reshape/)
melt_jaccard_10p_bd <- melt(jaccard_10p_bd, variable.name = "bd_input", value.name = "jaccard")

melt_jaccard_10p_bd <- melt_jaccard_10p_bd %>%
  mutate(jaccard_round = round(jaccard, digits = 2) # rounded percents, for labelling. 
         )

melt_jaccard_10p_bd_og <- melt_jaccard_10p_bd

head(melt_jaccard_10p_bd)
tail(melt_jaccard_10p_bd)

# reordering the levels so that the comparisons are more intuitive: simply reordering the order of models doesn't work 


melt_jaccard_10p_bd$mod_run <- factor(melt_jaccard_10p_bd$mod_run, 
                                       levels = levels(melt_jaccard_10p_bd_og$mod_run)[runs_reorder])
melt_jaccard_10p_bd$bd_input <- factor(melt_jaccard_10p_bd$bd_input, 
                                        levels = levels(melt_jaccard_10p_bd_og$bd_input)[runs_reorder]) 
head(melt_jaccard_10p_bd)
levels(melt_jaccard_10p_bd$mod_run)
levels(melt_jaccard_10p_bd$bd_input)

# # change back the order of the factors:
# melt_jaccard_10p_bd$mod_run <- factor(melt_jaccard_10p_bd$mod_run, 
#                                        levels = levels(melt_jaccard_10p_bd_og$mod_run))
# melt_jaccard_10p_bd$bd_input <- factor(melt_jaccard_10p_bd$bd_input, 
#                                         levels = levels(melt_jaccard_10p_bd_og$bd_input))


# plot --------------------------------------------
min(melt_jaccard_10p_bd$jaccard)
max(melt_jaccard_10p_bd$jaccard)
head(melt_jaccard_10p_bd)

jaccard_heatmap_10p_bd <- 
  ggplot() + 
  geom_tile(data = melt_jaccard_10p_bd #%>%
              # filter(mod_run %in% mod_conv_10p_bd_names[c(1:6, 9:33)],
              #        bd_input %in% bd_loss_names[c(1:6, 9:33)])
            ,
            mapping = aes(mod_run, bd_input, fill = jaccard), 
            color = "white") +
  scale_fill_viridis(name = "Jaccard \nIndex", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Jaccard Similarity between conversion results \nAll Layers") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_10p_bd)
print(overlap_heatmap_10p_bd)

# ---------------------------------------------------------
# ensemble 1 - biodiversity facets
# ---------------------------------------------------------
jaccard_heatmap_10p_bd_en1 <- 
  ggplot() + 
  geom_tile(data = melt_jaccard_10p_bd %>%
              filter(mod_run %in% mod_conv_10p_bd_names[1:13],
                     bd_input %in% mod_conv_10p_bd_names[1:13])
              ,
            mapping = aes(mod_run, bd_input, fill = jaccard), 
            color = "white") +
  scale_fill_viridis(name = "Jaccard \nIndex", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Jaccard Similarity between conversion results \nEnsemble 1 (Biodiversity Facets)") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_10p_bd_en1)

# ---------------------------------------------------------
# ensemble 2 - methods
# ---------------------------------------------------------
jaccard_heatmap_10p_bd_en2 <- 
  ggplot() + 
  geom_tile(data = melt_jaccard_10p_bd %>%
              filter(mod_run %in% mod_conv_10p_bd_names[15:20],
                     bd_input %in% mod_conv_10p_bd_names[15:20])
              ,
            mapping = aes(mod_run, bd_input, fill = jaccard), 
            color = "white") +
  scale_fill_viridis(name = "Jaccard \nIndex", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Jaccard Similarity between conversion results \nEnsemble 2 (Methods)") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_10p_bd_en2)

# ---------------------------------------------------------
# ensemble 3 - resolution
# ---------------------------------------------------------
mod_conv_10p_bd_names[c(1, 21, 25, 2, 22, 26, 3, 23, 27, 4, 24, 28)]

jaccard_heatmap_10p_bd_en3 <- 
  ggplot() + 
  geom_tile(data = melt_jaccard_10p_bd %>%
              filter(mod_run %in% mod_conv_10p_bd_names[c(1:4, 21:28)], #c(1:4, 21:28)
                     bd_input %in% mod_conv_10p_bd_names[c(1:4, 21:28)])
              ,
            mapping = aes(mod_run, bd_input, fill = jaccard), 
            color = "white") +
  scale_fill_viridis(name = "Jaccard \nIndex", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Jaccard Similarity between conversion results \nEnsemble 3 (Resolution)") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_10p_bd_en3)

# ---------------------------------------------------------
# ensemble 4 - recipes
# ---------------------------------------------------------
jaccard_heatmap_10p_bd_en4 <- 
  ggplot() + 
  geom_tile(data = melt_jaccard_10p_bd %>%
              filter(mod_run %in% mod_conv_10p_bd_names[c(14, 29:31)],
                     bd_input %in% mod_conv_10p_bd_names[c(14, 29:31)])
              ,
            mapping = aes(mod_run, bd_input, fill = jaccard), 
            color = "white") +
  scale_fill_viridis(name = "Jaccard \nIndex", 
                     option = "D", # viridis option
                     #limits = c(0, 15), # set scale limits
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size = 12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Jaccard Similarity between conversion results \nEnsemble 4 (Recipes)") +
  xlab("Model Run") + ylab("Biodiversity Layer")

print(jaccard_heatmap_10p_bd_en4)


print(jaccard_heatmap_10p_bd)
print(jaccard_heatmap_10p_bd_en1)
print(jaccard_heatmap_10p_bd_en2)
print(jaccard_heatmap_10p_bd_en3)
print(jaccard_heatmap_10p_bd_en4)

```

```{r area_converted}
levels(area_conv$bd_input)

par(oma = c(8, 2, 2, 2))
plot(area_conv[, 2], ylim = c(20000,52000), ylab = "area converted (km2)", xlab = "", pch = 16, main = "Area Converted in each Model", xaxt = "n", )
axis(side = 1, at = 1:35, las = 2, labels = c(runs_w_ref))
points(area_conv$area_bd100, col = "red", pch = 16)
points(area_conv$area_10p_bd, col = "blue", pch = 16)
legend("top", legend = c("Equal Weights (25%)" ,"100% Weight on bd", "Lowest 10% bd converted"), fill = c("black", "red", "blue"))

plot(results_eq[, "area_conv"])

names(area_conv)

barplot(rbind(area_conv$area_eq, area_conv$area_bd100), 
        names.arg = runs_w_ref, #las = 2, #horiz = TRUE, 
        beside = TRUE,
        main = "% of Total Biodiversity Score Converted")
```

```{r area_heatmap}

# construct area_conv data.frame
area_conv <- data.frame(
  bd_input = runs_w_ref,
  area_eq = results_eq[, "area_conv"],
  area_bd100 = results_bd100[, "area_conv"], 
  area_10p_bd = results_10p_bd[, "area_conv"]
)

area_conv$bd_input <- factor(area_conv$bd_input, levels = runs_w_ref) # set levels, in the correct order
levels(area_conv$bd_input)

melt_area_conv <- melt(area_conv, variable.name = "model_spec", value.name = "area_conv")
head(melt_area_conv)
levels(melt_area_conv$bd_input)
melt_area_conv$bd_input <- factor(melt_area_conv$bd_input, levels = runs_w_ref) # set levels, in the correct order


area_conv_heatmap <- 
  ggplot() + 
  geom_tile(data = melt_area_conv %>% 
              filter(model_spec %in% c("area_eq", "area_bd100"),
                     bd_input %in% runs_w_ref[1:13]
                     ),
            mapping = aes(model_spec, bd_input, fill = area_conv), 
            color = "white") +
  #scale_fill_gradient(low = "blue", high = "red")
  scale_fill_viridis(name = "Area \nConverted", 
                     option = "D", # viridis option
                     discrete = FALSE) +
  theme_minimal() +
  theme(plot.title = element_text(size = 20, face = "bold"), axis.text.x = element_text(angle = 320, vjust = 1, hjust = 0), axis.text=element_text(size=12), axis.title=element_text(size=14,face="bold")) +
  ggtitle("Total Area Converted by biodiversity input layer \n shown using equal weights (eq), 100% weight on biodviersity (100bd), and \nsimply converting the cells in the lowest 10% of biodviersity values") +
  xlab("Model Specifications") + ylab("Biodiversity Layer") #+ geom_text(aes(mod_run, bd_input, label = round_bd_conv_norm), color = "black") # to add rounded values as labels

print(area_conv_heatmap)

ggplotly(area_conv_heatmap)

```

```{r base-r-heatmap}
# base R heatmap()
# Notes: transposing flips the axes
# scale = "row" normalizes across each row, meaning, it does the same thing as manually normalizing results_eq. Admittedly, I don't know what actually happens in the normalization process. I doubt they are dividing by the same number as the bd loss in the controlling bd-input, but somehow, the plot looks the same. 
heatmap(t(as.matrix(results_eq[, c(6 + seq_along(runs))])), Colv = NULL, Rowv = NA, 
        scale = "row",
        col =  viridis(100),
        xlab = "model run", margins = c(15,5), main = "For Tong (interpret with caution!)"
        )

# probably should use this one, I'm not sure why, but the two dendrograms do not match. Careful about interpretation! Should be based on the Euclidean distance, but not yet sure how/why.
heatmap(t(as.matrix(results_eq_norm[, -1])), Colv = NULL, Rowv = NULL, 
        col =  viridis(256),
        xlab = "model run", margins = c(15,5), main = "For Tong (interpret with caution!)"
        )

print(bd_conv_eq_heatmap)
# using ggplot2
head(results_eq_norm[, 1:5])
```

# old plots


```{r area_conv}
barplot(results_eq$area_conv)

# total area of the Zambia mask (no lakes, etc.), number of cells in:
cp.dt # 742,821 km2. 
# total unprotected area in Zambia, number of cells in: 
m1_estes_toff$inputs$mask[, .(x, y)] # 510,328 km2

summary(results_eq$area_conv)
#  Min.    1st Qu.   Median    Mean    3rd Qu.   Max. 
#  21697   34595     35706     35917   38031     44358

44358/510328
summary((results_eq$area_conv/510328)*100) # area converted as a percent of total unprotected area: basically, it ranges from 4.3% to 8.7% of area converted. 
# Min.    1st Qu.  Median   Mean    3rd Qu.   Max. 
# 4.252%   6.779%    6.997%    7.038%   7.452%     8.692%

510328*0.10

```

```{r 10th-percentile}
# develop data.table for bottom 10% of cells
quantile(m1_estes, 0.10) # the 10th percentile


# fill 0s with 1s, the value of the closest adjancent ecoregion, and then mask by msk
test_r <- m1_estes
plot(test_r)
quantile(test_r, 0.10)
plot(test_r >= quantile(test_r, 0.10))

test_r[test_r >= quantile(m1_estes, 0.10)] <- 0 # set anything at or above the 10th percentile to 0
test_r[test_r > 0] <- 1 # set all the cells still above 0 (i.e. those below the 10th percentile) to 1
plot(test_r)
cellStats(test_r, stat = "sum")


ecoregions_zambia_r <- raster::mask(ecoregions_zambia_r, msk)
```


```{r distributions}

names(bd_inputs_no_pas_brick)
dev.off()
plot(conv_eq_dt_r$reference_y_conv_eq)
plot(conv_eq_dt_r$reference_yct_conv_eq)

dev.off()
hist(bd_inputs_no_pas_brick, 1:12, maxpixels = 1400000) # facets
hist(bd_inputs_no_pas_brick, c(13, 15:20), maxpixels = 1400000) # methods
hist(bd_inputs_no_pas_brick, 21:28, maxpixels = 1400000) # resolution
hist(bd_inputs_no_pas_brick, c(14, 29:31), maxpixels = 1400000) # recipes

ncell(bd_inputs_no_pas_brick$m1_vert_all)

hist(bd_inputs_brick$m1_estes, maxpixels = 1400000)
hist(bd_inputs_brick$m2_laurance, maxpixels = 1400000)
hist(bd_inputs_brick$m3_habitats, maxpixels = 1400000)
hist(bd_inputs_brick$m4_vert_all, maxpixels = 1400000)
hist(bd_inputs_brick$m5_vert_threat, maxpixels = 1400000)
hist(bd_inputs_brick$m6_vert_small, maxpixels = 1400000)
hist(bd_inputs_brick$m7_vert_small_threat, maxpixels = 1400000)
hist(bd_inputs_brick$m8_plants, maxpixels = 1400000)
hist(bd_inputs_brick$m1_estes, maxpixels = 1400000)
hist(bd_inputs_brick$m1_estes, maxpixels = 1400000)
hist(bd_inputs_brick$m1_estes, maxpixels = 1400000)
hist(bd_inputs_brick$m1_estes, maxpixels = 1400000)

```

```{r new_plots}

pdf(file = fp(p_plots,"en1_input_rasters"), width = 16, height = 9)
par(mfrow=c(3,4), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(bd_inputs_no_pas_brick[[1:12]], box = F, axes = F, main = runs[1:12])
plot(msk_shp, add = T)
dev.off()


```


```{r ensemble1_rasters}
plot(ensemble1, box = F, axes = F, main = "Average of Ensemble 1")
plot(msk_shp, add = T)

ensemble1

hist(bd_inputs_brick$m1_estes)


names(conv_eq_brick[[c(1, 2, 4:6, 8:13)]])

names(conv_eq_brick[[sub_ensemble1]])
names(conv_eq_brick[[sub_ensemble2_mb]])
names(conv_eq_brick[[sub_ensemble2_vp]])
names(conv_eq_brick[[sub_ensemble5.5_norm_order]])
names(conv_eq_brick[[sub_ensemble3_all_species]])
names(conv_eq_brick[[sub_ensemble3_threat_species]])
names(conv_eq_brick[[sub_ensemble3_small_species]])
names(conv_eq_brick[[sub_ensemble3_small_threat_species]])

### 
bd_inputs_brick[[sub_ensemble1]]
plot(ensemble1_conv)
plot(ensemble1_bd_input)


```


```{r ensemble1-plots_bd-input}
pdf(file = fp(p_plots,"ensemble1_bd_input_plots.pdf"), width = 9, height = 6)
par(mfrow=c(3,4), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(bd_inputs_brick$m1_estes, box = F, axes = F, main = "m1_estes"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m2_laurance, box = F, axes = F, main = "m2_laurance"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m3_habitats, box = F, axes = F, main = "m3_habitats"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m4_vert_all, box = F, axes = F, main = "m4_vert_all"); plot(msk_shp, add=TRUE)

plot(bd_inputs_brick$m5_vert_threat, box = F, axes = F, main = "m5_vert_threat"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m6_vert_small, box = F, axes = F, main = "m6_vert_small"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m7_vert_small_threat, box = F, axes = F, main = "m7_vert_small_threat"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m8_plants, box = F, axes = F, main = "m8_plants"); plot(msk_shp, add=TRUE)

plot(bd_inputs_brick$m9_mam_threat, box = F, axes = F, main = "m9_mam_threat"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m10_bird_threat, box = F, axes = F, main = "m10_bird_threat"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m11_bird_sp_hab, box = F, axes = F, main = "m11_bird_sp_hab"); plot(msk_shp, add=TRUE)
plot(ensemble1_bd_input, box = F, axes = F, main = "ensemble1 average bd input"); plot(msk_shp, add=TRUE)

dev.off()
```

```{r ensemble1-plots_conv}
pdf(file = fp(p_plots,"ensemble1_conv_plots.pdf"), width = 9, height = 6)
par(mfrow=c(3,4), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(conv_eq_brick$m1_estes, box = F, axes = F, main = "m1_estes"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m2_laurance, box = F, axes = F, main = "m2_laurance"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m3_habitats, box = F, axes = F, main = "m3_habitats"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m4_vert_all, box = F, axes = F, main = "m4_vert_all"); plot(msk_shp, add=TRUE)

plot(conv_eq_brick$m5_vert_threat, box = F, axes = F, main = "m5_vert_threat"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m6_vert_small, box = F, axes = F, main = "m6_vert_small"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m7_vert_small_threat, box = F, axes = F, main = "m7_vert_small_threat"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m8_plants, box = F, axes = F, main = "m8_plants"); plot(msk_shp, add=TRUE)

plot(conv_eq_brick$m9_mam_threat, box = F, axes = F, main = "m9_mam_threat"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m10_bird_threat, box = F, axes = F, main = "m10_bird_threat"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m11_bird_sp_hab, box = F, axes = F, main = "m11_bird_sp_hab"); plot(msk_shp, add=TRUE)
plot(ensemble1_conv, box = F, axes = F, main = "ensemble1 average bd input"); plot(msk_shp, add=TRUE)

dev.off()
```

```{r en1}
sub_ensemble1
sub_ensemble1_other
ensemble1_conv
ensemble1_bd_input
names(conv_eq_brick[[sub_ensemble1]])

# bd input and conversion plots
pdf(file = fp(p_plots,"ensemble1_bd_input_conv_plots.pdf"), width = 9, height = 4)
par(mfrow=c(1, 2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(ensemble1_bd_input, box = F, axes = F, main = "Average Bd Input"); plot(msk_shp, add=TRUE)
plot(ensemble1_conv, box = F, axes = F, main = "Average Conversion Areas"); plot(msk_shp, add=TRUE)
dev.off()


# non-richness plots of bd inputs and conversion rasters --------------------
sub_ensemble1_other <- sub_ensemble1[c(1:3,8:11)]
runs[sub_ensemble1_other]

pdf(file = fp(p_plots,"ensemble1_other_facets_plots1.pdf"), width = 9, height = 4)
par(mfrow=c(2,4), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(bd_inputs_brick$m1_estes, box = F, axes = F, main = "m1_estes"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m2_laurance, box = F, axes = F, main = "m2_laurance"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m3_habitats, box = F, axes = F, main = "m3_habitats"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m8_plants, box = F, axes = F, main = "m8_plants"); plot(msk_shp, add=TRUE)

plot(conv_eq_brick$m1_estes, box = F, axes = F, main = "m1_estes"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m2_laurance, box = F, axes = F, main = "m2_laurance"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m3_habitats, box = F, axes = F, main = "m3_habitats"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m8_plants, box = F, axes = F, main = "m8_plants"); plot(msk_shp, add=TRUE)
dev.off()

pdf(file = fp(p_plots,"ensemble1_other_facets_plots2.pdf"), width = 9, height = 4)
par(mfrow=c(2,4), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(bd_inputs_brick$m9_mam_threat, box = F, axes = F, main = "m9_mam_threat"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m10_bird_threat, box = F, axes = F, main = "m10_bird_threat"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m11_bird_sp_hab, box = F, axes = F, main = "m11_bird_sp_hab"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$reference_yct, box = F, axes = F, main = "reference_yct"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$reference_y, box = F, axes = F, main = "reference_y"); plot(msk_shp, add=TRUE)

plot(conv_eq_brick$m9_mam_threat, box = F, axes = F, main = "m9_mam_threat"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m10_bird_threat, box = F, axes = F, main = "m10_bird_threat"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m11_bird_sp_hab, box = F, axes = F, main = "m11_bird_sp_hab"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$reference_yct, box = F, axes = F, main = "reference_yct"); plot(msk_shp, add=TRUE)
dev.off()


# reference scenarios bd input and conversion plots
pdf(file = fp(p_plots,"reference_conv_plots.pdf"), width = 9, height = 4)
par(mfrow=c(1, 2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(reference_yct, box = F, axes = F, main = "Reference Scenario: equally weighting \n Yield, Carbon, and Transport Cost"); plot(msk_shp, add=TRUE)
plot(reference_y, box = F, axes = F, main = "Reference Scenario: 100% on Yield"); plot(msk_shp, add=TRUE)
dev.off()


# summary statistics -------- i.e. area converted
runs[sub_ensemble1_other]
results_eq[c(sub_ensemble1_other, 28), ]
xlab_names_en1_other <- c("estes", "laurance", "habitats", "plants", "mam_threat", "bird_threat", "bird_sp_hab")

pdf(file = fp(p_plots,"ensemble1_other_total_area+bd_converted.pdf"), width = 12, height = 9)
par(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

# total area converted
barplot(results_eq[c(sub_ensemble1_other, 28), ]$area_conv, 
        main = "Area converted (km2)", 
        names.arg = c(xlab_names_en1_other,"ref_yct"),
        las = 2,
        ylab = "area converted (km2)")

barplot(results_eq[sub_ensemble1_other, ]$bd_conv/
          results_eq[sub_ensemble1_other, ]$unprotected_bd, 
        names.arg = xlab_names_en1_other,
        las = 2,
        main = "% of Total Biodiversity Score Converted")

# -----
results_eq["reference_yct", ]


barplot(as.numeric(results_eq["reference_yct", c("m1_estes_bd_loss", "m2_laurance_bd_loss" , "m3_habitats_bd_loss", "m8_plants_bd_loss", "m9_mam_threat_bd_loss", "m10_bird_threat_bd_loss", "m11_bird_sp_hab_bd_loss")]), 
        col = "red",
        main = "Biodiversity Score Converted", 
        names.arg = xlab_names_en1_other,
        las = 2,
        ylab = "Biodiversity Score converted")

barplot(results_eq[sub_ensemble1_other, ]$bd_conv, add = T, axes = F)

barplot(results_eq[sub_ensemble1_other, ]$bd100_conv, add = T, axes = F,
        col = "green")

legend("topleft", legend = c("Equal Weights (25%)" ,"Best Case (100%)", "Worst Case (0%)"), fill = c("gray", "green", "red"))

plot(estes_bd_input)
names(results_eq)
barplot(results_eq$m1_estes_bd_loss)
barplot(as.numeric(results_eq[1, 5:31]))

max(results_eq$m1_estes_bd_loss)

view(results_eq)

# -----
barplot(results_eq[sub_ensemble1_other, ]$bd_conv/results_eq[sub_ensemble1_other, ]$area_conv,
        main = "Biodiversity Score Converted \n as a Percent of Total Area Converted",
        names.arg = xlab_names_en1_other,
        las = 2,
        ylab = "Percent of Total")

dev.off()


```

```{r en1_sub_species-richness}
en1_richness_facets_conv <- calc(conv_eq_brick[[sub_richness]], fun = mean)
en1_richness_facets_bd_input <- calc(bd_inputs_brick[[sub_richness]], fun = mean)


# plots of bd inputs and conversion rasters --------------------
pdf(file = fp(p_plots,"ensemble1_richness_facets_plots.pdf"), width = 9, height = 4)
par(mfrow=c(2,4), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(bd_inputs_brick$m4_vert_all, box = F, axes = F, main = "m4_vert_all"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m5_vert_threat, box = F, axes = F, main = "m5_vert_threat"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m6_vert_small, box = F, axes = F, main = "m6_vert_small"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m7_vert_small_threat, box = F, axes = F, main = "m7_vert_small_threat"); plot(msk_shp, add=TRUE)

plot(conv_eq_brick$m4_vert_all, box = F, axes = F, main = "m4_vert_all"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m5_vert_threat, box = F, axes = F, main = "m5_vert_threat"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m6_vert_small, box = F, axes = F, main = "m6_vert_small"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m7_vert_small_threat, box = F, axes = F, main = "m7_vert_small_threat"); plot(msk_shp, add=TRUE)
dev.off()

# bd input and conversion plots
pdf(file = fp(p_plots,"ensemble1_richness_bd_input_conv_plots.pdf"), width = 9, height = 4)
par(mfrow=c(1, 2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(en1_richness_facets_bd_input, box = F, axes = F, main = "Average Bd Input"); plot(msk_shp, add=TRUE)
plot(en1_richness_facets_conv, box = F, axes = F, main = "Average Conversion Areas"); plot(msk_shp, add=TRUE)
dev.off()

# raster stats -------------
conv_stats_vert_richness_all <- cc_raster_stats(conv_eq_brick[[sub_richness]][[1]], conv_eq_brick[[sub_richness]])
conv_stats_vert_richness_threat <- cc_raster_stats(conv_eq_brick[[sub_richness]][[2]], conv_eq_brick[[sub_richness]])
conv_stats_vert_richness_small <- cc_raster_stats(conv_eq_brick[[sub_richness]][[3]], conv_eq_brick[[sub_richness]])
conv_stats_vert_richness_small_threat <- cc_raster_stats(conv_eq_brick[[sub_richness]][[4]], conv_eq_brick[[sub_richness]])

names(conv_stats_vert_richness_all$overlap_r1) <- c("all", "threatened", "small", "s or t")
names(conv_stats_vert_richness_all$jaccard) <- c("all", "threatened", "small", "s or t")
names(conv_stats_vert_richness_all$overlap_r1) <- c("all", "threatened", "small", "s or t")

names(conv_stats_vert_richness_threat$overlap_r1) <- c("all", "threatened", "small", "s or t")
names(conv_stats_vert_richness_threat$jaccard) <- c("all", "threatened", "small", "s or t")
names(conv_stats_vert_richness_threat$overlap_r1) <- c("all", "threatened", "small", "s or t")

names(conv_stats_vert_richness_small$overlap_r1) <- c("all", "threatened", "small", "s or t")
names(conv_stats_vert_richness_small$jaccard) <- c("all", "threatened", "small", "s or t")
names(conv_stats_vert_richness_small$overlap_r1) <- c("all", "threatened", "small", "s or t")

names(conv_stats_vert_richness_small_threat$overlap_r1) <- c("all", "threatened", "small", "s or t")
names(conv_stats_vert_richness_small_threat$jaccard) <- c("all", "threatened", "small", "s or t")
names(conv_stats_vert_richness_small_threat$overlap_r1) <- c("all", "threatened", "small", "s or t")

# overlap and jaccard plots
pdf(file = fp(p_plots,"ensemble1_richness_facets_overlap_jaccard.pdf"), width = 9, height = 5)
par(mfrow=c(2,4), mar=c(1,4,4,1), oma=c(4, 1, 1, 1), cex.main=1) # setting the plot parameters. 

barplot(conv_stats_vert_richness_all$overlap_r1[-1], main = "Percent Overlap: Vert All")
barplot(conv_stats_vert_richness_threat$overlap_r1[-2], main = "Percent Overlap: Vert Threat")
barplot(conv_stats_vert_richness_small$overlap_r1[-3], main = "Percent Overlap: Vert Small")
barplot(conv_stats_vert_richness_small_threat$overlap_r1[-4], main = "Percent Overlap: Vert Small or Threat")

barplot(conv_stats_vert_richness_all$jaccard[-1], main = "Jaccard Similarity: Vert All")
barplot(conv_stats_vert_richness_threat$jaccard[-2], main = "Jaccard Similarity: Vert Threat")
barplot(conv_stats_vert_richness_small$jaccard[-3], main = "Jaccard Similarity: Vert Small")
barplot(conv_stats_vert_richness_small_threat$jaccard[-4], main = "Jaccard Similarity: Vert Small or Threat")
dev.off()

# summary statistics -------- i.e. area converted
results_eq[c(sub_richness, 28), ]

pdf(file = fp(p_plots,"ensemble1_richness_facets_total_area+bd_converted.pdf"), width = 7, height = 6)
par(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

# total area converted
barplot(results_eq[c(sub_richness, 28), ]$area_conv, 
        main = "Area converted (km2)", 
        names.arg = c("all", "threat", "small", "s or t", "ref_yct"),
        xlab = "model run", ylab = "area converted (km2)")

barplot(results_eq[sub_richness, ]$bd_conv/
          results_eq[sub_richness, ]$unprotected_bd, 
        names.arg = c("all", "threat", "small", "s or t"),
        main = "% of Total Biodiversity Score Converted")

# -----
barplot(as.numeric(results_eq["reference_yct", c("m4_vert_all_bd_loss", "m5_vert_threat_bd_loss", "m6_vert_small_bd_loss", "m7_vert_small_threat_bd_loss")]), 
        col = "red",
        main = "Biodiversity Score Converted", 
        names.arg = c("all", "threat", "small", "s or t"),
        xlab = "model run", ylab = "Biodiversity Score converted")

barplot(results_eq[sub_richness, ]$bd_conv, add = T, axes = F)


barplot(results_eq[sub_richness, ]$bd100_conv, add = T, axes = F,
        col = "green")
legend("topright", legend = c("Equal Weights (25%)" ,"Best Case (100%)", "Worst Case (0%)"), fill = c("gray", "green", "red"))


# -----
barplot(results_eq[sub_richness, ]$bd_conv/results_eq[sub_richness, ]$area_conv,
        main = "Biodiversity Score Converted \n as a Percent of Total Area Converted",
        names.arg = c("all", "threat", "small", "s or t"),
        xlab = "model run", ylab = "Percent of Total")

dev.off()


```

```{r en2_methods}
sub_ensemble2_mb
sub_ensemble2_vp
ensemble2_mb_conv
ensemble2_mb_bd_input
ensemble2_vp_conv
ensemble2_vp_bd_input

# plots of bd inputs and conversion rasters --------------------
pdf(file = fp(p_plots,"ensemble2_methods_mb_plots.pdf"), width = 7, height = 4)
par(mfrow=c(2,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(bd_inputs_brick$m12_average_mb, box = F, axes = F, main = "m12_average_mb"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m13_max_mb, box = F, axes = F, main = "m13_max_mb"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m14_multi_mb, box = F, axes = F, main = "m14_multi_mb"); plot(msk_shp, add=TRUE)

plot(conv_eq_brick$m12_average_mb, box = F, axes = F, main = "m12_average_mb"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m13_max_mb, box = F, axes = F, main = "m13_max_mb"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m14_multi_mb, box = F, axes = F, main = "m14_multi_mb"); plot(msk_shp, add=TRUE)

dev.off()

pdf(file = fp(p_plots,"ensemble2_methods_vp_plots.pdf"), width = 7, height = 4)
par(mfrow=c(2,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(bd_inputs_brick$m12_average_vp, box = F, axes = F, main = "m12_average_vp"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m13_max_vp, box = F, axes = F, main = "m13_max_vp"); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick$m14_multi_vp, box = F, axes = F, main = "m14_multi_vp"); plot(msk_shp, add=TRUE)

plot(conv_eq_brick$m12_average_vp, box = F, axes = F, main = "m12_average_vp"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m13_max_vp, box = F, axes = F, main = "m13_max_vp"); plot(msk_shp, add=TRUE)
plot(conv_eq_brick$m14_multi_vp, box = F, axes = F, main = "m14_multi_vp"); plot(msk_shp, add=TRUE)

dev.off()

# bd input and conversion plots
pdf(file = fp(p_plots,"ensemble2_methods_mb_bd_input_conv_plots.pdf"), width = 9, height = 4)
par(mfrow=c(1, 2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(ensemble2_mb_bd_input, box = F, axes = F, main = "Average Bd Input \n combining mammals and birds"); plot(msk_shp, add=TRUE)
plot(ensemble2_mb_conv, box = F, axes = F, main = "Average Conversion Areas \n combining mammals and birds"); plot(msk_shp, add=TRUE)
dev.off()

pdf(file = fp(p_plots,"ensemble2_methods_vp_bd_input_conv_plots.pdf"), width = 9, height = 4)
par(mfrow=c(1, 2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(ensemble2_vp_bd_input, box = F, axes = F, main = "Average Bd Input \n combining verts and plants"); plot(msk_shp, add=TRUE)
plot(ensemble2_vp_conv, box = F, axes = F, main = "Average Conversion Areas \n combining verts and plants"); plot(msk_shp, add=TRUE)
dev.off()

# raster stats -------------
conv_stats_methods_mb_average <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble2_mb]][[1]], conv_eq_brick[[sub_ensemble2_mb]])
conv_stats_methods_mb_max <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble2_mb]][[2]], conv_eq_brick[[sub_ensemble2_mb]])
conv_stats_methods_mb_multi <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble2_mb]][[3]], conv_eq_brick[[sub_ensemble2_mb]])

conv_stats_methods_vp_average <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble2_vp]][[1]], conv_eq_brick[[sub_ensemble2_vp]])
conv_stats_methods_vp_max <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble2_vp]][[2]], conv_eq_brick[[sub_ensemble2_vp]])
conv_stats_methods_vp_multi <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble2_vp]][[3]], conv_eq_brick[[sub_ensemble2_vp]])

xlab_names_methods <- c("average", "max", "multi")
names(conv_stats_methods_mb_average$overlap_r1) <- xlab_names_methods
names(conv_stats_methods_mb_average$jaccard) <- xlab_names_methods
names(conv_stats_methods_mb_max$overlap_r1) <- xlab_names_methods
names(conv_stats_methods_mb_max$jaccard) <- xlab_names_methods
names(conv_stats_methods_mb_multi$overlap_r1) <- xlab_names_methods
names(conv_stats_methods_mb_multi$jaccard) <- xlab_names_methods

names(conv_stats_methods_vp_average$overlap_r1) <- xlab_names_methods
names(conv_stats_methods_vp_average$jaccard) <- xlab_names_methods
names(conv_stats_methods_vp_max$overlap_r1) <- xlab_names_methods
names(conv_stats_methods_vp_max$jaccard) <- xlab_names_methods
names(conv_stats_methods_vp_multi$overlap_r1) <- xlab_names_methods
names(conv_stats_methods_vp_multi$jaccard) <- xlab_names_methods

# overlap and jaccard plots
pdf(file = fp(p_plots,"ensemble2_methods_vp_overlap_jaccard.pdf"), width = 7, height = 5)
par(mfrow=c(2,3), mar=c(1,4,5,1), oma=c(4, 1, 1, 1), cex.main=1) # setting the plot parameters. 

barplot(conv_stats_methods_vp_average$overlap_r1[-1], main = "Percent Overlap: Average")
barplot(conv_stats_methods_vp_max$overlap_r1[-2], main = "Percent Overlap: Max")
barplot(conv_stats_methods_vp_multi$overlap_r1[-3], main = "Percent Overlap: Multi")

barplot(conv_stats_methods_vp_average$jaccard[-1], main = "Jaccard Similarity: Average")
barplot(conv_stats_methods_vp_max$jaccard[-2], main = "Jaccard Similarity: Max")
barplot(conv_stats_methods_vp_multi$jaccard[-3], main = "Jaccard Similarity: Multi")
dev.off()

pdf(file = fp(p_plots,"ensemble2_methods_mb_overlap_jaccard.pdf"), width = 7, height = 5)
par(mfrow=c(2,3), mar=c(1,4,5,1), oma=c(4, 1, 1, 1), cex.main=1) # setting the plot parameters. 

barplot(conv_stats_methods_mb_average$overlap_r1[-1], main = "Percent Overlap: Average")
barplot(conv_stats_methods_mb_max$overlap_r1[-2], main = "Percent Overlap: Max")
barplot(conv_stats_methods_mb_multi$overlap_r1[-3], main = "Percent Overlap: Multi")

barplot(conv_stats_methods_mb_average$jaccard[-1], main = "Jaccard Similarity: Average")
barplot(conv_stats_methods_mb_max$jaccard[-2], main = "Jaccard Similarity: Max")
barplot(conv_stats_methods_mb_multi$jaccard[-3], main = "Jaccard Similarity: Multi")
dev.off()


# summary statistics -------- i.e. area converted
results_eq[c(sub_ensemble2_mb, sub_ensemble2_vp, 28), ]
results_eq[sub_ensemble2,]
names(results_eq[c(sub_ensemble2_mb, sub_ensemble2_vp, 28), ])
sub_ensemble2_mb
sub_ensemble2_vp

xlab_names_methods_results = c("Ave mb", "Max mb", "Multi mb", "Ave vp", "Max vp", "Multi vp", "ref_yct")


pdf(file = fp(p_plots,"ensemble2_methods_total_area+bd_converted.pdf"), width = 7, height = 6)
par(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

# total area converted
barplot(results_eq[c(sub_ensemble2, 28), ]$area_conv, 
        main = "Area converted (km2)", 
        names.arg = xlab_names_methods_results,
        las = 2,
        ylab = "area converted (km2)")

barplot(results_eq[sub_ensemble2, ]$bd_conv/
          results_eq[sub_ensemble2, ]$unprotected_bd, 
        names.arg = xlab_names_methods_results[-7],
        las = 2,
        main = "% of Total Biodiversity Score Converted")

# -----
barplot(as.numeric(results_eq["reference_yct", c("m12_average_mb_bd_loss", "m13_max_mb_bd_loss", "m14_multi_mb_bd_loss", "m12_average_vp_bd_loss", "m13_max_vp_bd_loss", "m14_multi_vp_bd_loss")]), 
        col = "red",
        main = "Biodiversity Score Converted", 
        names.arg = xlab_names_methods_results[-7],
        las = 2,
        ylab = "Biodiversity Score converted")

barplot(results_eq[sub_ensemble2, ]$bd_conv, add = T, axes = F)


barplot(results_eq[sub_ensemble2, ]$bd100_conv, add = T, axes = F,
        col = "green")

#legend("topright", legend = c("Equal Weights (25%)" ,"Best Case (100%)", "Worst Case (0%)"), fill = c("gray", "green", "red"))


# -----
barplot(results_eq[sub_ensemble2, ]$bd_conv/results_eq[sub_ensemble2, ]$area_conv,
        main = "Biodiversity Score Converted \n as a Percent of Total Area Converted",
        names.arg = xlab_names_methods_results[-7],
        las = 2,
        ylab = "Percent of Total")

dev.off()


```

```{r en3_resolution}
sub_ensemble3 <- c(sub_ensemble3_all_species, sub_ensemble3_threat_species, sub_ensemble3_small_species, sub_ensemble3_small_threat_species)

names(conv_eq_brick[[sub_ensemble3_all_species]])
sub_ensemble3_all_species <- c(5, 20, 24)
ensemble3_all_species_conv
ensemble3_all_species_bd_input 

names(conv_eq_brick[[sub_ensemble3_threat_species]])
sub_ensemble3_threat_species <- c(6, 21, 25)
ensemble3_threat_species_conv
ensemble3_threat_species_bd_input

names(conv_eq_brick[[sub_ensemble3_small_species]])
sub_ensemble3_small_species <- c(8, 22, 26)
ensemble3_small_species_conv
ensemble3_small_species_bd_input

names(conv_eq_brick[[sub_ensemble3_small_threat_species]])
sub_ensemble3_small_threat_species <- c(9, 23, 27)
ensemble3_small_threat_species_conv
ensemble3_small_threat_species_bd_input 


# plots of bd inputs and conversion rasters --------------------
pdf(file = fp(p_plots,"ensemble3_reso_all_plots.pdf"), width = 7, height = 4)
par(mfrow=c(2,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(bd_inputs_brick[[sub_ensemble3_all_species]][[1]], box = F, axes = F, main = runs[sub_ensemble3_all_species][1]); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick[[sub_ensemble3_all_species]][[2]], box = F, axes = F, main = runs[sub_ensemble3_all_species][2]); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick[[sub_ensemble3_all_species]][[3]], box = F, axes = F, main = runs[sub_ensemble3_all_species][3]); plot(msk_shp, add=TRUE)

plot(conv_eq_brick[[sub_ensemble3_all_species]][[1]], box = F, axes = F, main = runs[sub_ensemble3_all_species][1]); plot(msk_shp, add=TRUE)
plot(conv_eq_brick[[sub_ensemble3_all_species]][[2]], box = F, axes = F, main = runs[sub_ensemble3_all_species][2]); plot(msk_shp, add=TRUE)
plot(conv_eq_brick[[sub_ensemble3_all_species]][[3]], box = F, axes = F, main = runs[sub_ensemble3_all_species][3]); plot(msk_shp, add=TRUE)
dev.off()

# ---
pdf(file = fp(p_plots,"ensemble3_reso_threat_plots.pdf"), width = 7, height = 4)
par(mfrow=c(2,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(bd_inputs_brick[[sub_ensemble3_threat_species]][[1]], box = F, axes = F, main = runs[sub_ensemble3_threat_species][1]); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick[[sub_ensemble3_threat_species]][[2]], box = F, axes = F, main = runs[sub_ensemble3_threat_species][2]); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick[[sub_ensemble3_threat_species]][[3]], box = F, axes = F, main = runs[sub_ensemble3_threat_species][3]); plot(msk_shp, add=TRUE)

plot(conv_eq_brick[[sub_ensemble3_threat_species]][[1]], box = F, axes = F, main = runs[sub_ensemble3_threat_species][1]); plot(msk_shp, add=TRUE)
plot(conv_eq_brick[[sub_ensemble3_threat_species]][[2]], box = F, axes = F, main = runs[sub_ensemble3_threat_species][2]); plot(msk_shp, add=TRUE)
plot(conv_eq_brick[[sub_ensemble3_threat_species]][[3]], box = F, axes = F, main = runs[sub_ensemble3_threat_species][3]); plot(msk_shp, add=TRUE)
dev.off()

# ---
pdf(file = fp(p_plots,"ensemble3_reso_small_plots.pdf"), width = 7, height = 4)
par(mfrow=c(2,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(bd_inputs_brick[[sub_ensemble3_small_species]][[1]], box = F, axes = F, main = runs[sub_ensemble3_small_species][1]); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick[[sub_ensemble3_small_species]][[2]], box = F, axes = F, main = runs[sub_ensemble3_small_species][2]); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick[[sub_ensemble3_small_species]][[3]], box = F, axes = F, main = runs[sub_ensemble3_small_species][3]); plot(msk_shp, add=TRUE)

plot(conv_eq_brick[[sub_ensemble3_small_species]][[1]], box = F, axes = F, main = runs[sub_ensemble3_small_species][1]); plot(msk_shp, add=TRUE)
plot(conv_eq_brick[[sub_ensemble3_small_species]][[2]], box = F, axes = F, main = runs[sub_ensemble3_small_species][2]); plot(msk_shp, add=TRUE)
plot(conv_eq_brick[[sub_ensemble3_small_species]][[3]], box = F, axes = F, main = runs[sub_ensemble3_small_species][3]); plot(msk_shp, add=TRUE)
dev.off()

# ---
pdf(file = fp(p_plots,"ensemble3_reso_small_threat_plots.pdf"), width = 7, height = 4)
par(mfrow=c(2,3), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

plot(bd_inputs_brick[[sub_ensemble3_small_threat_species]][[1]], box = F, axes = F, main = runs[sub_ensemble3_small_threat_species][1]); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick[[sub_ensemble3_small_threat_species]][[2]], box = F, axes = F, main = runs[sub_ensemble3_small_threat_species][2]); plot(msk_shp, add=TRUE)
plot(bd_inputs_brick[[sub_ensemble3_small_threat_species]][[3]], box = F, axes = F, main = runs[sub_ensemble3_small_threat_species][3]); plot(msk_shp, add=TRUE)

plot(conv_eq_brick[[sub_ensemble3_small_threat_species]][[1]], box = F, axes = F, main = runs[sub_ensemble3_small_threat_species][1]); plot(msk_shp, add=TRUE)
plot(conv_eq_brick[[sub_ensemble3_small_threat_species]][[2]], box = F, axes = F, main = runs[sub_ensemble3_small_threat_species][2]); plot(msk_shp, add=TRUE)
plot(conv_eq_brick[[sub_ensemble3_small_threat_species]][[3]], box = F, axes = F, main = runs[sub_ensemble3_small_threat_species][3]); plot(msk_shp, add=TRUE)
dev.off()

# --------------------
# bd input and conversion plots -------------------------------------------------
# ----
pdf(file = fp(p_plots,"ensemble3_reso_all_bd_input_conv_plots.pdf"), width = 9, height = 4)
par(mfrow=c(1, 2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(ensemble3_all_species_bd_input, box = F, axes = F, main = "Average Bd Input \n all species across resolutions"); plot(msk_shp, add=TRUE)
plot(ensemble3_all_species_conv, box = F, axes = F, main = "Average Conversion Areas \n all species across resolutions"); plot(msk_shp, add=TRUE)
dev.off()

# ----
pdf(file = fp(p_plots,"ensemble3_reso_threat_bd_input_conv_plots.pdf"), width = 9, height = 4)
par(mfrow=c(1, 2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(ensemble3_threat_species_bd_input, box = F, axes = F, main = "Average Bd Input \n threatened species across resolutions"); plot(msk_shp, add=TRUE)
plot(ensemble3_threat_species_conv, box = F, axes = F, main = "Average Conversion Areas \n threatened species across resolutions"); plot(msk_shp, add=TRUE)
dev.off()

# ----
pdf(file = fp(p_plots,"ensemble3_reso_small_bd_input_conv_plots.pdf"), width = 9, height = 4)
par(mfrow=c(1, 2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(ensemble3_small_species_bd_input, box = F, axes = F, main = "Average Bd Input \n small-ranged species across resolutions"); plot(msk_shp, add=TRUE)
plot(ensemble3_small_species_conv, box = F, axes = F, main = "Average Conversion Areas \n small-ranged species across resolutions"); plot(msk_shp, add=TRUE)
dev.off()

# ----
pdf(file = fp(p_plots,"ensemble3_reso_small_threat_bd_input_conv_plots.pdf"), width = 9, height = 4)
par(mfrow=c(1, 2), mar=c(1,2,2,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 
plot(ensemble3_small_threat_species_bd_input, box = F, axes = F, main = "Average Bd Input \n small -ranged or threatened species across resolutions"); plot(msk_shp, add=TRUE)
plot(ensemble3_small_threat_species_conv, box = F, axes = F, main = "Average Conversion Areas \n small -ranged or threatened species across resolutions"); plot(msk_shp, add=TRUE)
dev.off()


# raster stats -------------
runs[sub_ensemble3]
runs[sub_ensemble3_all_species]
runs[sub_ensemble3_threat_species]
runs[sub_ensemble3_small_species]
runs[sub_ensemble3_small_threat_species]

names(conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_all <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[1]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_all_10 <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[2]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_all_110 <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[3]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_threat <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[4]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_threat_10 <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[5]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_threat_110 <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[6]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_small <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[7]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_small_10 <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[8]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_small_110 <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[9]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_small_threat <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[10]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_small_threat_10 <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[11]], conv_eq_brick[[sub_ensemble3]])
conv_stats_resolution_small_threat_110 <- cc_raster_stats_lite(conv_eq_brick[[sub_ensemble3]][[12]], conv_eq_brick[[sub_ensemble3]])



xlab_names_resolution <- c("a", "a_10", "a_110", "t", "t_10", "t_110", "s", "s_10", "s_110", "s_t", "s_t_10", "s_t_110")
names(conv_stats_resolution_all$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_all_10$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_all_110$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_threat$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_threat_10$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_threat_110$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_small$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_small_10$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_small_110$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_small_threat$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_small_threat_10$overlap_r1) <- xlab_names_resolution
names(conv_stats_resolution_small_threat_110$overlap_r1) <- xlab_names_resolution

names(conv_stats_resolution_all$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_all_10$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_all_110$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_threat$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_threat_10$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_threat_110$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_small$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_small_10$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_small_110$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_small_threat$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_small_threat_10$jaccard) <- xlab_names_resolution
names(conv_stats_resolution_small_threat_110$jaccard) <- xlab_names_resolution

# overlap and jaccard plots
pdf(file = fp(p_plots,"ensemble3_reso_overlap_jaccard_a+t.pdf"), width = 9, height = 5)
par(mfrow=c(2,3), mar=c(1,4,5,1), oma=c(4, 1, 1, 1), cex.main=1) # setting the plot parameters. 

barplot(conv_stats_resolution_all$overlap_r1[-1], main = "Percent Overlap: All")
barplot(conv_stats_resolution_all_10$overlap_r1[-2], main = "Percent Overlap: All 10km")
barplot(conv_stats_resolution_all_110$overlap_r1[-3], main = "Percent Overlap: All 110km")

barplot(conv_stats_resolution_threat$overlap_r1[-4], main = "Percent Overlap: threat")
barplot(conv_stats_resolution_threat_10$overlap_r1[-5], main = "Percent Overlap: threat 10km")
barplot(conv_stats_resolution_threat_110$overlap_r1[-6], main = "Percent Overlap: threat 110km")
dev.off()

pdf(file = fp(p_plots,"ensemble3_reso_overlap_jaccard_s+s_t.pdf"), width = 9, height = 5)
par(mfrow=c(2,3), mar=c(1,4,5,1), oma=c(4, 1, 1, 1), cex.main=1) # setting the plot parameters. 

barplot(conv_stats_resolution_small$overlap_r1[-7], main = "Percent Overlap: small")
barplot(conv_stats_resolution_small_10$overlap_r1[-8], main = "Percent Overlap: small 10km")
barplot(conv_stats_resolution_small_110$overlap_r1[-9], main = "Percent Overlap: small 110km")

barplot(conv_stats_resolution_small_threat$overlap_r1[-10], main = "Percent Overlap: small_threat")
barplot(conv_stats_resolution_small_threat_10$overlap_r1[-11], main = "Percent Overlap: small_threat 10km")
barplot(conv_stats_resolution_small_threat_110$overlap_r1[-12], main = "Percent Overlap: small_threat 110km")
dev.off()


# summary statistics -------- i.e. area converted
results_eq[sub_ensemble3,]
names(results_eq[sub_ensemble3,])
xlab_names_resolution

pdf(file = fp(p_plots,"ensemble3_reso_total_area+bd_converted.pdf"), width = 12, height = 9)
par(mfrow=c(2,2), mar=c(4,4,4,1), oma=c(1, 1, 1, 1), cex.main=1) # setting the plot parameters. 

# total area converted
barplot(results_eq[c(sub_ensemble3, 28), ]$area_conv, 
        main = "Area converted (km2)", 
        names.arg = c(xlab_names_resolution,"ref_yct"),
        las = 2,
        ylab = "area converted (km2)")

barplot(results_eq[sub_ensemble3, ]$bd_conv/
          results_eq[sub_ensemble3, ]$unprotected_bd, 
        names.arg = xlab_names_resolution,
        las = 2,
        main = "% of Total Biodiversity Score Converted")

# -----
barplot(as.numeric(results_eq["reference_yct", c("m4_vert_all_bd_loss", "m15.1_vert_all_10_bd_loss", "m16.1_vert_all_110_bd_loss", "m5_vert_threat_bd_loss", "m15.2_vert_threat_10_bd_loss", "m16.2_vert_threat_110_bd_loss", "m6_vert_small_bd_loss", "m15.3_vert_small_10_bd_loss", "m16.4_vert_small_threat_110_bd_loss", "m7_vert_small_threat_bd_loss", "m15.4_vert_small_threat_10_bd_loss", "m16.3_vert_small_110_bd_loss")]), 
        col = "red",
        main = "Biodiversity Score Converted", 
        names.arg = xlab_names_resolution,
        las = 2,
        ylab = "Biodiversity Score converted")

barplot(results_eq[sub_ensemble3, ]$bd_conv, add = T, axes = F)

barplot(results_eq[sub_ensemble3, ]$bd100_conv, add = T, axes = F,
        col = "green")

legend("topright", legend = c("Equal Weights (25%)" ,"Best Case (100%)", "Worst Case (0%)"), fill = c("gray", "green", "red"))


# -----
barplot(results_eq[sub_ensemble3, ]$bd_conv/results_eq[sub_ensemble3, ]$area_conv,
        main = "Biodiversity Score Converted \n as a Percent of Total Area Converted",
        names.arg = xlab_names_resolution,
        las = 2,
        ylab = "Percent of Total")

dev.off()
```

```{r ind-rasters}

pdf(file = fp(p_plots,"m1_estes_plots.pdf"), width = 7, height = 3.2)
par(mfrow = c(1,2), mar=c(0, 2, 2, 1) + 0.1, oma = c(1, 1, 1, 1))
plot(bd_inputs_brick$m1_estes, 
     box = F, axes = F,
     main = "m1_estes \n Biodiversity Input")
plot(msk_shp, add = T)

plot(conv_eq_brick$m1_estes, 
     box = F, axes = F,
     main = "m1_estes \n Conversion Areas")
plot(msk_shp, add = T)
dev.off()

pdf(file = fp(p_plots,"m1_estes_bd_hist.pdf"), width = 4, height = 4)
hist(bd_inputs_brick$m1_estes, main = "Distribution of Biodiversity Values")
dev.off()
```


```{r en1-plot-results_eq}
results_ensemble1 <- results_eq[c(sub_ensemble1, 28:29), c(1:6, 8:10, 12:17)]


# total area converted
barplot(results_ensemble1$area_conv, 
        main = "Area converted (km2)", names.arg = c(1:13),
        xlab = "model run", ylab = "area converted (km2)")

#points(12, results_ensemble1$area_conv[12], col = "red") # reference_yct
#points(13, results_ensemble1$area_conv[13], col = "blue") # reference_y
hist(results_ensemble1$area_conv, breaks = 10)

results_ensemble1$unprotected_bd

barplot(results_ensemble1$bd_conv/
          results_ensemble1$unprotected_bd, 
        names.arg = c(1:13),
        main = "% of Total Biodiversity Score Converted")

# -----
barplot(results_ensemble1$bd_conv, 
       main = "Biodiversity Score Converted", 
       names.arg = c(1:13),
       xlab = "model run", ylab = "Biodiversity Score converted")
barplot(results_ensemble1$bd100_conv, add = T, col = "green",
       main = "Biodiversity Score Converted \n relative to best case scenario")
legend("topleft", legend = c("Equal Weights" ,"Best Case Scenario"), fill = c("gray", "green"))


# -----
barplot(results_ensemble1$bd_conv/results_ensemble1$area_conv,
        main = "Biodiversity Score Converted \n as a Percent of Total Area Converted",
        xlab = "model run", ylab = "Percent of Total")



rownames(results_ensemble1)
rownames(results_eq)
colnames(results_eq)
```

```{r en1-jaccard}
# ensemble1 jaccard and % overlap
m2_laurance_raster_stats$jaccard[sub_ensemble1]

barplot(m2_laurance_raster_stats$jaccard[sub_ensemble1], main = "Jaccard Similarity Index relative to Laurance", xlab = "Model Run", ylab = "Jaccard Index")
barplot(m2_laurance_raster_stats$overlap_r1[sub_ensemble1], main = "Percent Overlap with Laurance", 
     xlab = "Model Run", ylab = "% Overlap")

plot(results_ensemble1)
```

Outline
A1. Methods
a. Pure bd inputs, no yield variation
b. 100% Weight on bd
c. Equal Weights

A2. Resolution
a. Pure bd inputs, no yield variation
b. 100% Weight on bd
c. Equal Weights

A3. Biodiversity Facets.
a. Pure bd inputs, no yield variation
b. 100% Weight on bd
c. Equal Weights



A4. Consensus Conversion Areas
Where do the different biodiversity metrics agree to convert? Average the rasters, then run this through the toff model with 100% of the weight on biodiversity to get the consensus conversion areas. From this, you can calculate the impacts. 






```{r plot_resolution}
bd_inputs_brick
# all species
plot(conv_eq_brick$m4_vert_all)
plot(conv_eq_brick$m15.1_vert_all_10)
plot(conv_eq_brick$m16.1_vert_all_110)
plot(bd_inputs_brick$m4_vert_all)
plot(bd_inputs_brick$m15.1_vert_all_10)
plot(bd_inputs_brick$m16.1_vert_all_110)

# threatened species
plot(conv_eq_brick$m5_vert_threat)
plot(conv_eq_brick$m15.2_vert_threat_10)
plot(conv_eq_brick$m16.2_vert_threat_110)
plot(bd_inputs_brick$m5_vert_threat)
plot(bd_inputs_brick$m15.2_vert_threat_10)
plot(bd_inputs_brick$m16.2_vert_threat_110)

# small-ranged species
plot(conv_eq_brick$m6_vert_small)
plot(conv_eq_brick$m15.3_vert_small_10)
plot(conv_eq_brick$m16.3_vert_small_110)
plot(bd_inputs_brick$m6_vert_small)
plot(bd_inputs_brick$m15.3_vert_small_10)
plot(bd_inputs_brick$m16.3_vert_small_110)

# small or threatened species
par(mfrow = c(3, 2), mar=c(1,1,2,1), omi=c(0.1,0.1,0.1,0.1), cex.main=1)
plot(bd_inputs_brick$m7_vert_small_threat, 
     box = FALSE, axes = FALSE,
     main = "Small-ranged or Threatened Species Richness")
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, add = T)

plot(conv_eq_brick$m7_vert_small_threat, 
     box = FALSE, axes = FALSE,
     main = "Converted areas")
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, add = T)

plot(bd_inputs_brick$m15.4_vert_small_threat_10,
     box = FALSE, axes = FALSE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, add = T)

plot(conv_eq_brick$m15.4_vert_small_threat_10,
     box = FALSE, axes = FALSE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, add = T)

plot(bd_inputs_brick$m16.4_vert_small_threat_110,
     box = FALSE, axes = FALSE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, add = T)

plot(conv_eq_brick$m16.4_vert_small_threat_110,
     box = FALSE, axes = FALSE)
plot(msk_shp, add = T)
plot(pas, col = col_pas_all, add = T)
legend("bottomright", legend=levels(pas$type), fill = col_pas)

dev.off()


plot(msk_shp)
plot(conv_eq_brick$m16.4_vert_small_threat_110, add = T)

plot(msk_shp, add = T)
plot(pas, col = col_pas_all, add = T)
legend("bottomright", legend=levels(pas$type), fill = col_pas)


plot(pas[pas@data$type == "gma", ], add = TRUE, col = pacols[2],
       border = FALSE)
plot(pas[pas@data$type == "npark", ], add = TRUE, col = pacols[3],
       border = FALSE)
plot(roads, add = TRUE, lwd = 0.1, col = "grey")

plot(e_toff_r_soy, col="#41ab5d", add = TRUE, legend=FALSE)
mtext("(a) Estes et al. 2016, equal weights \n areas converted to maize \n displayed by conversion order", side = 3, adj = 0.05, line = -1.3, cex = cap_size) 
mtext("Maize", side = 4, adj = 0.5, line = -3.5, cex = cap_size) 
legend("bottomright", inset = 0.05, legend = c("GMAs", "NatParks","Soy"),
           pch = 15, col = c(pacols[2:3],"#41ab5d"), bty = "n",
           pt.cex = 1, cex = legend_size)
```




## 1. Where do Estes and Laurance overlap in conversion areas?
To make interpreting these results even easier, it is useful to compare the full tradeoff model outcomes for with the new @Laurance2014a data and the original @Estes2016a approach on the same plot. Figure 4 highlights areas of overlap, for both maize and soy.

```{r plot-laurance-estes-full-overlap, echo=FALSE, fig.cap="An expanded display of the full overlap between areas prioritized for conversion to maize and soy using biodiversity data from the original Estes et al. (2016) tradeoff analysis and newly incorporated data from Laurance et al. (2014). \\label{laurance-estes-overlap-plot}", fig.height=7, fig.width=7}
# Adding Laurance and Estes together, but multiplying the laurance raster by 3, to show areas of overlap
l_e_overlap <- overlay(e_toff_r_ms,l_toff_r_ms, fun = function(x,y){
        (1*x + 3*y)})

#pdf(file = fp(p_plots,"Laurance-Estes_Overlap.pdf"),
#    width = 7, height = 7)

par(mar=c(0, 2, 2, 0) + 0.1, cex.main=1.2, family="Times New Roman") # setting the plot parameters
# mar=c(1.5,4,7.5,2)
plot(l_e_overlap, col=col_overlap,
     axes = FALSE, box=FALSE, legend=FALSE)
plot(pas[pas@data$type == "gma", ], add = TRUE, col = pacols[2],
       border = FALSE)
plot(pas[pas@data$type == "npark", ], add = TRUE, col = pacols[3],
       border = FALSE)
plot(roads, add = TRUE, lwd = 0.08, col = "grey")
plot(msk_shp, add=TRUE)

legend("topleft", #inset = c(0.01,-0.08), # inset changes where the legend is placed. cex changes the text size.
       legend = c("GMAs", "NatParks",
         "No conversion",
         "Estes maize only",
         "Estes soy only",
         "Laurance maize only",
         "Both maize",
         "Laurance maize, Estes soy",
         "Laurance soy only",
         "Laurance soy, Estes maize",
         "Both soy"), pch = 15, col = c(pacols[2:3],col_overlap), 
       bty = "n", pt.cex = 1, cex = 0.9, ncol=1)
#dev.off()

# none, maize, soy
# 0, 1, 2 - estes 
# 0, 3, 6 - laurance

# 0 - no conversion - overlap
# 1 - e convert to maize, only
# 2 - e convert to soy, only
# 3 - l convert to maize, only 
# 4 - both convert to maize - overlap
# 5 - l convert to maize, e convert to soy
# 6 - l convert to soy, only
# 7 - l convert to soy, e convert to maize
# 8 - both convert to soy - overlap
```

```{r compare-laurance-estes-bd-plots, echo=FALSE, fig.cap="Comparing the Laurance (a) and Estes (b) composite biodiversity rasters. \\label{laurance-estes-bd-rasters-plot}", fig.width=7, fig.height=3.5}
#pdf(file = fp(p_plots,"Compare-BD-rasters-L_vs_E.pdf"),
#    width = 7, height = 3.5)
par(mfrow=c(1,2),mar=c(2,0,0,0)+0.1, omi=c(0.25,0.25,0.25,0.25), family="Times New Roman") # setting the plot parameters
cap_size <- 0.7
line_adjustment <- -0.1
leg_axis_adj <- 0.6

plot(laurance,
     col=col_main, axes = FALSE, box=FALSE, legend=FALSE)
plot(msk_shp, add=TRUE)
mtext("(a) Laurance: equally weighted \n within and between sublayers", side = 3, adj = 0.05, line = -1.3, cex = cap_size) 
mtext("low biodiversity      high biodiversity", side = 1, adj = 0.5, line = line_adjustment, cex = 0.6)
addRasterLegend(s1, location = "bottom", direction = "horizontal", side=3,
                nTicks = 0, cex.axis = leg_axis_adj, labelDist = 0.5, ramp=col_main)

plot(cp_raster,
     col=col_main, axes = FALSE, box=FALSE, legend=FALSE)
plot(msk_shp, add=TRUE)
mtext("(b) Estes: original composite \n biodiversity raster", side = 3, adj = 0.05, line = -1.3, cex = cap_size) 
mtext("low biodiversity      high biodiversity", side = 1, adj = 0.5, line = line_adjustment, cex = 0.6)
addRasterLegend(s1, location = "bottom", direction = "horizontal", side=3,
                nTicks = 0, cex.axis = leg_axis_adj, labelDist = 0.5, ramp=col_main)

#dev.off()
```


## Compare data.tables from each model run
```{r cellStats}
test <- m1_estes_toff$conv
test$m1 <- test$maize + test$soy
sum(test$m1)

cellStats(m1_estes_toff_outputs$conv_r_all, stat = "sum")

reference_yct
```



## Ensemble conservation priorities rasters
```{r}
# estes
plot(e_toff_r_all)
plot(e_toff_r$maize)
plot(e_toff_r$soy)

# laurance
plot(l_toff_r_all) # <- calc(l_toff_r, sum) # adds the maize and soy layers, to show all areas converted to maize and soy, regardless
plot(l_toff_r$maize)
plot(l_toff_r$soy)


# plot overlap
plot(l_e_overlap)


# average the rasters
l_e_average <- overlay(e_toff_r_all, l_toff_r_all, fun = function(x, y){(x+y)/2})
l_e_average2 <- (e_toff_r_all + l_toff_r_all)/2

plot(l_e_average)
plot(l_e_average1)
plot(l_e_average2)
x <- 2
y <- 3
mean(c(x,y))
```

Options:
simple average
Cross tabulation of all the model results, which is basically an average of where models show conversion
histogram of these things
```{r average-bd-inputs}
m1_estes
m2_laurance
m2.5_laurance_not_norm
m3_habitats
m4_vert_all
m5_vert_threat
m5.5_vert_threat_sum_norm
m6_vert_small
m7_vert_small_threat
m8_plants
m9_mam_threat
m10_bird_threat
m11_bird_sp_hab

ensemble_bd_input <- overlay(
  m1_estes, 
  m2_laurance, 
  m2.5_laurance_not_norm, 
  m3_habitats, 
  m4_vert_all, 
  m5_vert_threat, 
  m6_vert_small, 
  m7_vert_small_threat, 
  m8_plants, 
  m9_mam_threat, 
  m10_bird_threat, 
  m11_bird_sp_hab,
  fun = function(a, b, c, d, e, f, g, h, i, j, k, l){
    (a + b + c + d + e + f + g + h + i + j + k + l)/12
    }
  )

plot(m2_laurance)
plot(m2_laurance_toff_outputs$conv_r_all)
plot(m3_habitats_toff_outputs$conv_r_all)


ensemble_conv_r_all <- overlay(
  m1_estes_toff_outputs$conv_r_all, 
  m2_laurance_toff_outputs$conv_r_all, 
  m2.5_laurance_not_norm_toff_outputs$conv_r_all, 
  m3_habitats_toff_outputs$conv_r_all, 
  m4_vert_all_toff_outputs$conv_r_all, 
  m5_vert_threat_toff_outputs$conv_r_all, 
  m6_vert_small_toff_outputs$conv_r_all, 
  m7_vert_small_threat_toff_outputs$conv_r_all, 
  m8_plants_toff_outputs$conv_r_all, 
  m9_mam_threat_toff_outputs$conv_r_all, 
  m10_bird_threat_toff_outputs$conv_r_all, 
  m11_bird_sp_hab_toff_outputs$conv_r_all,
  fun = function(a, b, c, d, e, f, g, h, i, j, k, l){
    (a + b + c + d + e + f + g + h + i + j + k + l)/12
    }
  )

plot(ensemble_bd_input)
plot(ensemble_conv_r_all)

plot(vert_threat_richness_brick$norm_sum)
m1_estes_toff$conv


# area converted
plot(hotspots_zambia_r)


```
# Notes:
clustering within one area: hotspot analysis
around a surrounding area, are they the same, hotter, or colder. Within your neighborhood, 


Pearson statistics for comparing continuous rasters (composite biodviersity rasters)
Cohens Kappa or the Jaccard Index for comparing discrete categorical rasters (model outputs) - this requires me to define a reference raster (the ground truth) - maybe the average.

Congruence - Lyndon used 
% overlap
average distance to neighbor.
adjacency - average distance between each pixel on one map and its nearest neighbour in another (for pairwise comparisons)

## Tim's ideas:
Compare the outcome to the worst case scenario
Convert only the worst. Or, putting all the weight on yield.
How far from max is each model?

Compare to the reference within each ensemble
For the first ensemble, just use the average as the reference

Add up the area, and then add up the biodiversity in the cells that get converted.
Two things that could mask the significance of the biodiversity:
- completely different cells, but very similar cells
- yield dominates

- biodiversity max by putting all the weight on biodiversity. 
percent of the maximum...
nearest neighbor.
Measure of distance to nearest neighbor.

Worst case scenario is factoring in everything but biodiversity. 
Best case is I only care about giraffes

Comparing relative achievement. 

Ok...I need to compare:
Model spec conversion: total up the biodiversity score across all of the biodiversity input layers.
So, run the model with one input.
Calculate biodiversity impact by summing the biodiversity scores in each of the cells that gets converted.
You can then do that for each of the biodiveristy input layers. 




## Statistics
```{r stats}
r1 <- conv_eq_brick[[1]]
r2 <- conv_eq_brick[[2]]

raster1 <- r1
raster2 <- r2
plot(r1)
plot(r2)

test_stats <- cc_raster_stats(r1, r2)
conv_brick_stats <- cc_raster_stats(conv_eq_brick[[1]], conv_eq_brick)
object_size(conv_brick_stats)
names(conv_brick_stats$combination) <- mod_conv_eq_names
names(conv_brick_stats$intersection) <- mod_conv_eq_names
names(conv_brick_stats$union) <- mod_conv_eq_names
names(conv_brick_stats$overlap_r1) <- mod_conv_eq_names
names(conv_brick_stats$overlap_r2) <- mod_conv_eq_names
names(conv_brick_stats$jaccard) <- mod_conv_eq_names
  

plot(test_brick_stats$combination$layer.4)
did_it_work <- cc_raster_stats(r1, conv_eq_brick[[27]])


# Calculate the intersection of the two rasters, this is given by adding
  # the binary rasters together -> 2 indicates intersection
# try it with a brick:
raster2 <- conv_eq_brick
  combination <- raster1 + raster2
  plot(combination)
  intersection <- combination == 2
  plot(intersection)

  # Union is all the area covered by the both rasters
  union <- combination >= 1
  plot(union)

  overlap_r1 <- 
    (cellStats(intersection, stat = "sum") / 
       cellStats(raster1, stat = "sum"))
  overlap_r2 <- 
    (cellStats(intersection, stat = "sum") / 
       cellStats(raster2, stat = "sum"))

  jaccard <- 
    (cellStats(intersection, stat = "sum") / 
       cellStats(union, stat = "sum"))

  list(
    combination = combination,
    intersection = intersection,
    union = union,
    overlap_r1 = overlap_r1,
    overlap_r2 = overlap_r2,
    jaccard = jaccard
  )
```


How should I represent the differences or similarities between different raster results?

Option 1. `spatialEco::rasterCorrelation()` - this uses a moving window approach to calculate either the pearson, spearman, or covariance correlation between two rasters.
spatialEco also has a function for `raster.Zscore()` ("Calculates the modified z-score for all cells in a raster.") and `raster.change()` ("Compares two categorical rasters with a variety of statistical options.") which both might be useful. I don't quite know if these two will be useful. 
raster.downscale - Downscale raster to a higher resolution raster using robust regression
raster.entropy - Calculates entropy on integer raster (i.e., 8 bit 0-255)  
raster.gaussian.smooth - Applies a Gaussian smoothing kernel to smooth raster.

```{r z-score}

# test rasters:
plot(dt_r)
dt_r$mam



# Performs a simple moving window correlation between two rasters
tic()
test_cor <- rasterCorrelation(x = dt_r$mam, y = dt_r$bird, type = "pearson")
toc() # 56 seconds
plot(test_cor)

#
install.packages("CENFA")
tic()
test_cor_2[1] <- CENFA::parCov(dt_r$mam, dt_r$bird, progress = TRUE)
test_cor_2[2] <- CENFA::parCov(dt_r$mam, dt_r$amp, progress = TRUE)
test_cor_2[3] <- CENFA::parCov(dt_r$mam, dt_r$rep, progress = TRUE)
test_cor_2[4] <- CENFA::parCov(dt_r$bird, dt_r$amp, progress = TRUE)
test_cor_2[5] <- CENFA::parCov(dt_r$bird, dt_r$rep, progress = TRUE)
test_cor_2[6] <- CENFA::parCov(dt_r$amp, dt_r$rep, progress = TRUE)
print(test_cor_2)

toc()

plot(dt_r)

dt[, sum(mam > 0 & bird > 0)] # counts the rows where mam > 0 AND bird > 0 (intersection)
dt[, sum(mam > 0 | bird > 0)] # counts the rows where mam > 0 OR bird > 0 (union)


# overlap
dt[, sum(mam > 0 & bird > 0)] / # counts the rows where mam > 0 AND bird > 0 (intersection)
  dt[, sum(mam > 0)] # counts the rows where mam > 0 (just the set in mam)
# 0.2660749


# Jaccard, weighted
dt[, .(mam, bird) # select the two columns you're interested in... (this works with column names in quotes, or as column indices)
   ][, sum(pmin(.SD[,1], .SD[,2]))/sum(pmax(.SD[,1], .SD[,2]))] # then calculate the weighted Jaccard
# 0.1306791

# Jaccard, unweighted
dt[, sum(mam > 0 & bird > 0)] / # counts the rows where mam > 0 AND bird > 0 (intersection)
  dt[, sum(mam > 0 | bird > 0)] # counts the rows where mam > 0 OR bird > 0 (union)
# 0.1581873








plot(m1_estes)
z_score <- raster.Zscore(m1_estes)
plot(z_score)

hist(m1_estes, maxpixels = 1400000)
hist(z_score, maxpixels = 1400000)

summary(m1_estes)
cellStats()
quantile(m1_estes, 0.10)




```



- Cohen's Kappa statistic... (can use this through raster.change( stat = "kappa"))
```{r cohens-kappa}
plot(r1)
plot(r2)

dev.off()
plot(conv_r$bd100, 1:4)

# Compares two categorical rasters with a variety of statistical options
test_kappa <- raster.change(conv_r$bd100$vert_all,
                            conv_r$bd100$vert_endemism,
                            d = c(3,3), # window for comparing rasters
                            stat = "kappa" # only works for categorical rasters, i.e. conversion rasters
                            )


# note these don't work because they are not categorical. 
test_stats <- data.frame(
  stat_type = c(1, 1),
  value = c(1, 1)
)
tic()
test_stats[1,1] <- "pearson correlation"
test_stats_1 <- raster.change(dt_r$mam, dt_r$bird, d = c(3,3), stat = "kappa")
toc()
cellStats(test_stats_1, "sum")


tic()
test_stats[2,1] <- "Cohen's kappa"
test_stats[2,2] <- raster.change(x = dt_r$mam, y = dt_r$bird,
                          stat = "kappa" # only works for categorical rasters, i.e. conversion rasters
)
toc()




plot(test_kappa)
cellStats(test_kappa, mean)

plot(msk_shp)

test_ttest <- raster.change(r1,
                            r2,
                            d = c(3,3), # window for comparing rasters
                            stat = "t.test")


```


- `zonator::jaccard()` The Jaccard coefficient measures similarity between sample sets, and is defined as the size of the intersection divided by the size of the union of the sample sets

- Bivariate Moran index

- zonal statistics
- diffeR

Community ecology metrics for comparing community dissimilarity.

```{r statistics}
l_og <- raster("/Users/christophercrawford/Google Drive/_Projects/Zambia/agroEcoTradeoff/external/data_new/laurance_og.tif")
l <- laurance
plot(l_og + l)

plot(l_og)
plot(l)
spatialEco::rasterCorrelation()

library(spatialEco)
output_corr <- rasterCorrelation(l, l_og, s = 3, type = "pearson")
plot(output_corr)

output <- raster.change(l, l_og, d = c(3,3), stat = "cor")
output_kappa <- raster.change(l, l_og, d = c(3,3), stat = "kappa")
plot(output)

install.packages("zonator")
library(zonator)
zonator::jaccard(l, l_og)
```

# back pocket
## stats using just rasters
```{r total area converted}
# total area converted
names(conv_eq_brick)
area_converted <- cellStats(conv_eq_brick, stat = "sum") # this shows the total area being converted
hist(area_converted, 
     breaks = 20, xlim = c(min(area_converted), max(area_converted)))
plot(area_converted, main = "area converted", xlab = "model run", ylab = "area converted (km2)")

plot(conv_eq_brick$m1_estes)


# create data frame of areas to plot
area_converted_df <- data.frame(area_converted) %>%
  mutate(model_run = row_number(),
         model_name = brick_mod_names) %>%
  select(model_run, area_converted, model_name)

plot(area_converted_df[, 1:2])
points(x = 1, y = 44358, col = "red")

#### -----------------------------

area_converted_df
plot(area_converted_df[area_converted_df$model_name == "m1_estes", -3], add = TRUE, col = "red")

plot(x = c(1:29), y = data.frame(area_converted)$area_converted)
plot(x = c(1:29), y = area_converted)

plot(area_converted["m1_estes"], add = TRUE, col = "red")

summary(area_converted)

hist(area_converted["m1_estes"],
     breaks = 20, xlim = c(min(area_converted), max(area_converted)))

area_converted["m1_estes"]

area_converted[1]
area_converted[[1]]


```

```{r biodiversity_impacts}
# by multipling the conv_eq_brick by the bd_inputs_brick, I get a brick of the biodiversity scores in just the areas that get converted.
bd_impacts_brick <- conv_eq_brick[[1:27]] * bd_inputs_brick
names(bd_impacts_brick) <- runs

# by taking the sum of each biodiversity_impacts raster, I get the total biodiversity impact of conversion specific to each model run.
bd_impacts_scores <- cellStats(bd_impacts_brick, stat = "sum")
hist(bd_impacts_scores, breaks = 8)


# to get the biodiversity impacts of each model run's conversion recommendations, for the bd_input layer that was used int he model itself, but also across all of the other bd_input options, I can multiply a single conversion raster by the bd_inputs_brick, and then sum those to get scores.

```

```{r old_results_eq}
### --------------------------------------------
# or
# results_eq$propor_unprot_bd_conv <- results_eq$bd_conv / results_eq$unprotected_bd
results_eq$mod_run
# rownames(results_eq) <- mod_conv_eq_names


view(results_eq)
rownames(results_eq) <- runs_w_ref
colnames(results_eq) <- colnames_df# as.character(c(1:30))
colnames_df <- colnames(results_eq)


# ------------------------------------------
# divide columns by the total unprotected biodiversity:
results_eq$m1_estes_bd_loss / results_eq["m1_estes_conv", "unprotected_bd"]
filter(results_eq, mod_run == "m1_estes_conv")$unprotected_bd
results_eq["m1_estes_conv", "unprotected_bd"]

view(results_eq)
# test - cool, it worked!!
barplot(results_eq[sub_richness, ]$bd_conv/
          results_eq[sub_richness, ]$unprotected_bd,
        names.arg = c("all", "threat", "small", "s or t"),
        main = "% of Total Biodiversity Score Converted")

barplot(results_eq[sub_richness, ]$bd_conv_norm,
        names.arg = c("all", "threat", "small", "s or t"),
        main = "% of Unprotected Biodiversity Converted")

results_eq[sub_richness, ]$bd_conv_norm
results_eq[sub_richness, 1:5]
results_eq["m4_vert_all_conv", ]$bd_conv_norm # gives the total unprotected biodiversity score that was converted in the m4_vert_all_conv conversion scenario.
```


```{r old_bd-impacts-per-bd-input-for-each-model-run}
# replaced conv_dt with conv_eq_dt
# replaced bd_loss_dt_list with bd_loss_conv_eq_dt_list
# replaced bd_loss_list with bd_loss_conv_eq_list

# bd_loss_conv_eq_dt_list <- vector("list", length = length(runs)) # must create an empty list first. Can also do this with simply list()
# names(bd_loss_conv_eq_dt_list) <- runs

# % unprotected 
bd_loss_conv_eq_list <- vector("list", length = length(runs)) # must create an empty list first. Can also do this with simply list()
names(bd_loss_conv_eq_list) <- runs

tic()
for (i in 1:length(runs)) {
  # bd_loss_conv_eq_dt_list[[i]] <- bd_dt[[i + 2]] * conv_eq_dt[,-c(1:2)]
  # bd_loss_conv_eq_list[[i]] <- colSums(bd_loss_conv_eq_dt_list[[i]])
  bd_loss_conv_eq_list[[i]] <- bd_dt[[i + 2]] * conv_eq_dt[,-c(1:2)]
  bd_loss_conv_eq_list[[i]] <- colSums(bd_loss_conv_eq_list[[i]])
}
toc() # 49.562 seconds when overwriting itself, 51.245 seconds not overwriting.

# bd_loss_conv_eq_list is all I'm really interested in - I can probably get rid of bd_loss_conv_eq_dt_list.
# or alternatively, just have it overwrite itself within the for loop. This works.


# ----------------------------------------------------------------------------------------

m1_estes_bd_loss
bd_loss_conv_eq_list$m14_estes
test_r <- dt_to_raster(cbind(conv_eq_dt[, .(x, y)], bd_loss_conv_eq_dt_list$m14_estes), CRSobj)
plot(test_r$m2_vert_threat_conv)
plot(conv_eq_brick$m2_vert_threat)

# test this:
m1_estes_bd_loss_dt <- bd_dt$m1_estes * conv_eq_dt[,-c(1:2)]
m1_estes_bd_loss <- colSums(m1_estes_bd_loss_dt) # to get total biodiversity score lost according to the m1_estes bd layer, across all models.

# --------------------------------------------------
# --------------------------------------------------
# no longer necessary
# --------------------------------------------------
# --------------------------------------------------




bd_dt[[3]]
bd_dt$m1_vert_all_bd
bd_dt$m1_vert_all_bd 

length(m1_estes_bd_loss)

# no longer necessary
# --------------------------------------------------

# take one column in bd_dt (a bd input raster), and multiply it by all of the columns in conv_eq_dt, to get the biodiversity scores lost in each model run, according to the particular bd_input
m1_estes_bd_loss_dt <- bd_dt$m1_estes * conv_eq_dt[,-c(1:2)]
m1_estes_bd_loss <- colSums(m1_estes_bd_loss_dt) # to get total biodiversity score lost according to the m1_estes bd layer, across all models.

m2_laurance_bd_loss_dt <- bd_dt$m2_laurance * conv_eq_dt[,-c(1:2)]
m2_laurance_bd_loss <- colSums(m2_laurance_bd_loss_dt)

m2.5_laurance_not_norm_bd_loss_dt <- bd_dt$m2.5_laurance_not_norm * conv_eq_dt[,-c(1:2)]
m2.5_laurance_not_norm_bd_loss <- colSums(m2.5_laurance_not_norm_bd_loss_dt)

m3_habitats_bd_loss_dt <- bd_dt$m3_habitats * conv_eq_dt[,-c(1:2)]
m3_habitats_bd_loss <- colSums(m3_habitats_bd_loss_dt)

m4_vert_all_bd_loss_dt <- bd_dt$m4_vert_all * conv_eq_dt[,-c(1:2)]
m4_vert_all_bd_loss <- colSums(m4_vert_all_bd_loss_dt)

m5_vert_threat_bd_loss_dt <- bd_dt$m5_vert_threat * conv_eq_dt[,-c(1:2)]
m5_vert_threat_bd_loss <- colSums(m5_vert_threat_bd_loss_dt)

m5.5_vert_threat_sum_norm_bd_loss_dt <- bd_dt$m5.5_vert_threat_sum_norm * conv_eq_dt[,-c(1:2)]
m5.5_vert_threat_sum_norm_bd_loss <- colSums(m5.5_vert_threat_sum_norm_bd_loss_dt)

m6_vert_small_bd_loss_dt <- bd_dt$m6_vert_small * conv_eq_dt[,-c(1:2)]
m6_vert_small_bd_loss <- colSums(m6_vert_small_bd_loss_dt)

m7_vert_small_threat_bd_loss_dt <- bd_dt$m7_vert_small_threat * conv_eq_dt[,-c(1:2)]
m7_vert_small_threat_bd_loss <- colSums(m7_vert_small_threat_bd_loss_dt)

m8_plants_bd_loss_dt <- bd_dt$m8_plants * conv_eq_dt[,-c(1:2)]
m8_plants_bd_loss <- colSums(m8_plants_bd_loss_dt)

m9_mam_threat_bd_loss_dt <- bd_dt$m9_mam_threat * conv_eq_dt[,-c(1:2)]
m9_mam_threat_bd_loss <- colSums(m9_mam_threat_bd_loss_dt)

m10_bird_threat_bd_loss_dt <- bd_dt$m10_bird_threat * conv_eq_dt[,-c(1:2)]
m10_bird_threat_bd_loss <- colSums(m10_bird_threat_bd_loss_dt)

m11_bird_sp_hab_bd_loss_dt <- bd_dt$m11_bird_sp_hab * conv_eq_dt[,-c(1:2)]
m11_bird_sp_hab_bd_loss <- colSums(m11_bird_sp_hab_bd_loss_dt)

m12_average_mb_bd_loss_dt <- bd_dt$m12_average_mb * conv_eq_dt[,-c(1:2)]
m12_average_mb_bd_loss <- colSums(m12_average_mb_bd_loss_dt)

m12_average_vp_bd_loss_dt <- bd_dt$m12_average_vp * conv_eq_dt[,-c(1:2)]
m12_average_vp_bd_loss <- colSums(m12_average_vp_bd_loss_dt)

m13_max_mb_bd_loss_dt <- bd_dt$m13_max_mb * conv_eq_dt[,-c(1:2)]
m13_max_mb_bd_loss <- colSums(m13_max_mb_bd_loss_dt)

m13_max_vp_bd_loss_dt <- bd_dt$m13_max_vp * conv_eq_dt[,-c(1:2)]
m13_max_vp_bd_loss <- colSums(m13_max_vp_bd_loss_dt)

m14_multi_mb_bd_loss_dt <- bd_dt$m14_multi_mb * conv_eq_dt[,-c(1:2)]
m14_multi_mb_bd_loss <- colSums(m14_multi_mb_bd_loss_dt)

m14_multi_vp_bd_loss_dt <- bd_dt$m14_multi_vp * conv_eq_dt[,-c(1:2)]
m14_multi_vp_bd_loss <- colSums(m14_multi_vp_bd_loss_dt)

m15.1_vert_all_10_bd_loss_dt <- bd_dt$m15.1_vert_all_10 * conv_eq_dt[,-c(1:2)]
m15.1_vert_all_10_bd_loss <- colSums(m15.1_vert_all_10_bd_loss_dt)

m15.2_vert_threat_10_bd_loss_dt <- bd_dt$m15.2_vert_threat_10 * conv_eq_dt[,-c(1:2)]
m15.2_vert_threat_10_bd_loss <- colSums(m15.2_vert_threat_10_bd_loss_dt)

m15.3_vert_small_10_bd_loss_dt <- bd_dt$m15.3_vert_small_10 * conv_eq_dt[,-c(1:2)]
m15.3_vert_small_10_bd_loss <- colSums(m15.3_vert_small_10_bd_loss_dt)

m15.4_vert_small_threat_10_bd_loss_dt <- bd_dt$m15.4_vert_small_threat_10 * conv_eq_dt[,-c(1:2)]
m15.4_vert_small_threat_10_bd_loss <- colSums(m15.4_vert_small_threat_10_bd_loss_dt)

m16.1_vert_all_110_bd_loss_dt <- bd_dt$m16.1_vert_all_110 * conv_eq_dt[,-c(1:2)]
m16.1_vert_all_110_bd_loss <- colSums(m16.1_vert_all_110_bd_loss_dt)

m16.2_vert_threat_110_bd_loss_dt <- bd_dt$m16.2_vert_threat_110 * conv_eq_dt[,-c(1:2)]
m16.2_vert_threat_110_bd_loss <- colSums(m16.2_vert_threat_110_bd_loss_dt)

m16.3_vert_small_110_bd_loss_dt <- bd_dt$m16.3_vert_small_110 * conv_eq_dt[,-c(1:2)]
m16.3_vert_small_110_bd_loss <- colSums(m16.3_vert_small_110_bd_loss_dt)

m16.4_vert_small_threat_110_bd_loss_dt <- bd_dt$m16.4_vert_small_threat_110 * conv_eq_dt[,-c(1:2)]
m16.4_vert_small_threat_110_bd_loss <- colSums(m16.4_vert_small_threat_110_bd_loss_dt)

rm(
  m1_estes_bd_loss_dt,
  m2_laurance_bd_loss_dt,
  m2.5_laurance_not_norm_bd_loss_dt,
  m3_habitats_bd_loss_dt,
  m4_vert_all_bd_loss_dt,
  m5_vert_threat_bd_loss_dt,
  m5.5_vert_threat_sum_norm_bd_loss_dt,
  m6_vert_small_bd_loss_dt,
  m7_vert_small_threat_bd_loss_dt,
  m8_plants_bd_loss_dt,
  m9_mam_threat_bd_loss_dt,
  m10_bird_threat_bd_loss_dt,
  m11_bird_sp_hab_bd_loss_dt,
  m12_average_mb_bd_loss_dt,
  m12_average_vp_bd_loss_dt,
  m13_max_mb_bd_loss_dt,
  m13_max_vp_bd_loss_dt,
  m14_multi_mb_bd_loss_dt,
  m14_multi_vp_bd_loss_dt,
  m15.1_vert_all_10_bd_loss_dt,
  m15.2_vert_threat_10_bd_loss_dt,
  m15.3_vert_small_10_bd_loss_dt,
  m15.4_vert_small_threat_10_bd_loss_dt,
  m16.1_vert_all_110_bd_loss_dt,
  m16.2_vert_threat_110_bd_loss_dt,
  m16.3_vert_small_110_bd_loss_dt,
  m16.4_vert_small_threat_110_bd_loss_dt)
```
```{r unused-bd-loss-per-model-run}
# Not Used...

# ------------------------------------------
# to create a loop: 
# ------------------------------------------
bd_loss_per_conv_eq_list <- vector("list", length = length(runs)) # must create an empty list first. Can also do this with simply list()
names(bd_loss_per_conv_eq_dt_list) <- mod_conv_eq_names

bd_loss_per_conv_list <- vector("list", length = length(runs))
names(bd_loss_conv_eq_list) <- mod_conv_eq_names

for (i in 1:length(runs)) {
  bd_loss_per_conv_eq_list[[i]] <- conv_eq_dt[[i + 2]] * bd_dt[,-c(1:2)] # just switching conv_eq_dt and bd_dt orders. 
  bd_loss_per_conv_eq_list[[i]] <- colSums(bd_loss_conv_eq_dt_list[[i]])
}


# now I need to take one column in conv_eq_dt, and multiply it by all of the columns in bd_dt
m1_estes_conv_eq_bd_impacts <- conv_eq_dt$m1_estes_conv * bd_dt[,-c(1:2)]
m1_estes_conv_eq_bd_impacts_sum <- colSums(m1_estes_conv_eq_bd_impacts) # to get total biodiversity score lost in converted areas selected by m1_estes model


# now I need to take one column in conv_eq_dt, and multiply it by all of the columns in bd_dt
m1_estes_conv_eq_bd_impacts <- conv_eq_dt$m1_estes_conv * bd_dt[,-c(1:2)]
m1_estes_conv_eq_bd_impacts_sum <- colSums(m1_estes_conv_eq_bd_impacts) # to get total biodiversity score lost in converted areas selected by m1_estes model
m1_estes_unpro_bd
barplot(m1_estes_conv_eq_bd_impacts_sum)

m2_laurance_conv_eq_bd_impacts <- conv_eq_dt$m2_laurance_conv * bd_dt[,-c(1:2)]
m2_laurance_conv_eq_bd_impacts_sum <- colSums(m2_laurance_conv_eq_bd_impacts)

m2.5_laurance_not_norm_conv_eq_bd_impacts <- conv_eq_dt$m2.5_laurance_not_norm_conv * bd_dt[,-c(1:2)]
m2.5_laurance_not_norm_conv_eq_bd_impacts_sum <- colSums(m2.5_laurance_not_norm_conv_eq_bd_impacts)

m3_habitats_conv_eq_bd_impacts <- conv_eq_dt$m3_habitats_conv * bd_dt[,-c(1:2)]
m3_habitats_conv_eq_bd_impacts_sum <- colSums(m3_habitats_conv_eq_bd_impacts)

m4_vert_all_conv_eq_bd_impacts <- conv_eq_dt$m4_vert_all_conv * bd_dt[,-c(1:2)]
m4_vert_all_conv_eq_bd_impacts_sum <- colSums(m4_vert_all_conv_eq_bd_impacts)

m5_vert_threat_conv_eq_bd_impacts <- conv_eq_dt$m5_vert_threat_conv * bd_dt[,-c(1:2)]
m5_vert_threat_conv_eq_bd_impacts_sum <- colSums(m5_vert_threat_conv_eq_bd_impacts)

m5.5_vert_threat_sum_norm_conv_eq_bd_impacts <- conv_eq_dt$m5.5_vert_threat_sum_norm_conv * bd_dt[,-c(1:2)]
m5.5_vert_threat_sum_norm_conv_eq_bd_impacts_sum <- colSums(m5.5_vert_threat_sum_norm_conv_eq_bd_impacts)

m6_vert_small_conv_eq_bd_impacts <- conv_eq_dt$m6_vert_small_conv * bd_dt[,-c(1:2)]
m6_vert_small_conv_eq_bd_impacts_sum <- colSums(m6_vert_small_conv_eq_bd_impacts)

m7_vert_small_threat_conv_eq_bd_impacts <- conv_eq_dt$m7_vert_small_threat_conv * bd_dt[,-c(1:2)]
m7_vert_small_threat_conv_eq_bd_impacts_sum <- colSums(m7_vert_small_threat_conv_eq_bd_impacts)

m8_plants_conv_eq_bd_impacts <- conv_eq_dt$m8_plants_conv * bd_dt[,-c(1:2)]
m8_plants_conv_eq_bd_impacts_sum <- colSums(m8_plants_conv_eq_bd_impacts)

m9_mam_threat_conv_eq_bd_impacts <- conv_eq_dt$m9_mam_threat_conv * bd_dt[,-c(1:2)]
m9_mam_threat_conv_eq_bd_impacts_sum <- colSums(m9_mam_threat_conv_eq_bd_impacts)

m10_bird_threat_conv_eq_bd_impacts <- conv_eq_dt$m10_bird_threat_conv * bd_dt[,-c(1:2)]
m10_bird_threat_conv_eq_bd_impacts_sum <- colSums(m10_bird_threat_conv_eq_bd_impacts)

m10_bird_threat_conv_eq_bd_impacts <- conv_eq_dt$m10_bird_threat_conv * bd_dt[,-c(1:2)]
m10_bird_threat_conv_eq_bd_impacts_sum <- colSums(m10_bird_threat_conv_eq_bd_impacts)

m12_average_mb_conv_eq_bd_impacts <- conv_eq_dt$m12_average_mb_conv * bd_dt[,-c(1:2)]
m12_average_mb_conv_eq_bd_impacts_sum <- colSums(m12_average_mb_conv_eq_bd_impacts)

m12_average_vp_conv_eq_bd_impacts <- conv_eq_dt$m12_average_vp_conv * bd_dt[,-c(1:2)]
m12_average_vp_conv_eq_bd_impacts_sum <- colSums(m12_average_vp_conv_eq_bd_impacts)

m13_max_mb_conv_eq_bd_impacts <- conv_eq_dt$m13_max_mb_conv * bd_dt[,-c(1:2)]
m13_max_mb_conv_eq_bd_impacts_sum <- colSums(m13_max_mb_conv_eq_bd_impacts)

m13_max_vp_conv_eq_bd_impacts <- conv_eq_dt$m13_max_vp_conv * bd_dt[,-c(1:2)]
m13_max_vp_conv_eq_bd_impacts_sum <- colSums(m13_max_vp_conv_eq_bd_impacts)

m14_multi_mb_conv_eq_bd_impacts <- conv_eq_dt$m14_multi_mb_conv * bd_dt[,-c(1:2)]
m14_multi_mb_conv_eq_bd_impacts_sum <- colSums(m14_multi_mb_conv_eq_bd_impacts)

m14_multi_vp_conv_eq_bd_impacts <- conv_eq_dt$m14_multi_vp_conv * bd_dt[,-c(1:2)]
m14_multi_vp_conv_eq_bd_impacts_sum <- colSums(m14_multi_vp_conv_eq_bd_impacts)

m15.1_vert_all_10_conv_eq_bd_impacts <- conv_eq_dt$m15.1_vert_all_10_conv * bd_dt[,-c(1:2)]
m15.1_vert_all_10_conv_eq_bd_impacts_sum <- colSums(m15.1_vert_all_10_conv_eq_bd_impacts)

m15.2_vert_threat_10_conv_eq_bd_impacts <- conv_eq_dt$m15.2_vert_threat_10_conv * bd_dt[,-c(1:2)]
m15.2_vert_threat_10_conv_eq_bd_impacts_sum <- colSums(m15.2_vert_threat_10_conv_eq_bd_impacts)

m15.3_vert_small_10_conv_eq_bd_impacts <- conv_eq_dt$m15.3_vert_small_10_conv * bd_dt[,-c(1:2)]
m15.3_vert_small_10_conv_eq_bd_impacts_sum <- colSums(m15.3_vert_small_10_conv_eq_bd_impacts)

m15.4_vert_small_threat_10_conv_eq_bd_impacts <- conv_eq_dt$m15.4_vert_small_threat_10_conv * bd_dt[,-c(1:2)]
m15.4_vert_small_threat_10_conv_eq_bd_impacts_sum <- colSums(m15.4_vert_small_threat_10_conv_eq_bd_impacts)

m16.1_vert_all_110_conv_eq_bd_impacts <- conv_eq_dt$m16.1_vert_all_110_conv * bd_dt[,-c(1:2)]
m16.1_vert_all_110_conv_eq_bd_impacts_sum <- colSums(m16.1_vert_all_110_conv_eq_bd_impacts)

m16.2_vert_threat_110_conv_eq_bd_impacts <- conv_eq_dt$m16.2_vert_threat_110_conv * bd_dt[,-c(1:2)]
m16.2_vert_threat_110_conv_eq_bd_impacts_sum <- colSums(m16.2_vert_threat_110_conv_eq_bd_impacts)

m16.3_vert_small_110_conv_eq_bd_impacts <- conv_eq_dt$m16.3_vert_small_110_conv * bd_dt[,-c(1:2)]
m16.3_vert_small_110_conv_eq_bd_impacts_sum <- colSums(m16.3_vert_small_110_conv_eq_bd_impacts)

m16.4_vert_small_threat_110_conv_eq_bd_impacts <- conv_eq_dt$m16.4_vert_small_threat_110_conv * bd_dt[,-c(1:2)]
m16.4_vert_small_threat_110_conv_eq_bd_impacts_sum <- colSums(m16.4_vert_small_threat_110_conv_eq_bd_impacts)

reference_yct_conv_eq_bd_impacts <- conv_eq_dt$reference_yct * bd_dt[,-c(1:2)]
reference_yct_conv_eq_bd_impacts_sum <- colSums(reference_yct_conv_eq_bd_impacts)

reference_y_conv_eq_bd_impacts <- conv_eq_dt$reference_y * bd_dt[,-c(1:2)]
reference_y_conv_eq_bd_impacts_sum <- colSums(reference_y_conv_eq_bd_impacts)

runs_w_ref
```










Types of richness
Taxa -  threat
Methods - mammals and birds
Resolution threatened verts
Recipes

